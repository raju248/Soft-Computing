{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "4UMKTgRoeqfW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from os import path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RManlEUee0_s"
   },
   "outputs": [],
   "source": [
    "url = 'Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HC1Mh0lIGogh"
   },
   "outputs": [],
   "source": [
    "dataset_A = url + 'Dataset A.zip'\n",
    "with ZipFile(dataset_A, 'r') as zip:\n",
    "  zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "xy-Cey0sf9Fz",
    "outputId": "f9c9fdb1-de0d-4cd5-fea2-36834ce2cf65",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24298, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c00000.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c00001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c00002.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c00003.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c00004.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  digit\n",
       "0  c00000.png      6\n",
       "1  c00001.png      1\n",
       "2  c00002.png      3\n",
       "3  c00003.png      2\n",
       "4  c00004.png      7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'Dataset/'\n",
    "data_labels = pd.read_csv(PATH + 'training-c.csv', usecols = ['filename', 'digit'])\n",
    "print(data_labels.shape)\n",
    "data_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22806</th>\n",
       "      <td>c22806.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7032</th>\n",
       "      <td>c07032.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7031</th>\n",
       "      <td>c07031.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>c02051.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>c02052.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12764</th>\n",
       "      <td>c12764.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12780</th>\n",
       "      <td>c12780.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22181</th>\n",
       "      <td>c22181.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12721</th>\n",
       "      <td>c12721.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12148</th>\n",
       "      <td>c12148.png</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24298 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         filename  digit\n",
       "22806  c22806.png      0\n",
       "7032   c07032.png      0\n",
       "7031   c07031.png      0\n",
       "2051   c02051.png      0\n",
       "2052   c02052.png      0\n",
       "...           ...    ...\n",
       "12764  c12764.png      9\n",
       "12780  c12780.png      9\n",
       "22181  c22181.png      9\n",
       "12721  c12721.png      9\n",
       "12148  c12148.png      9\n",
       "\n",
       "[24298 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_labels.sort_values('digit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hTJ2ocEEHVGA"
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'Dataset/Train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9cc105c502d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mTRAIN_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Train'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAIN_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprocessImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[0msrc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfolder_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'Dataset/Train'"
     ]
    }
   ],
   "source": [
    "# TRAIN_PATH = url + 'Train'\n",
    "# os.mkdir(TRAIN_PATH)\n",
    "\n",
    "# def processImages(folder_name):\n",
    "#   src = PATH + folder_name + '/'\n",
    "#   dir_folders = os.listdir(src)\n",
    "#   for dir_name in dir_folders:\n",
    "#     file_name = os.path.join(src, dir_name)\n",
    "#     if os.path.isfile(file_name):\n",
    "#       shutil.copy(file_name, TRAIN_PATH) \n",
    "\n",
    "# processImages('training-a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = url + 'training-c'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zmE05jA4kTDU"
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df, root, transform=None):\n",
    "        self.data = df\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        \n",
    "        path = self.root + \"/\" + item[0]\n",
    "        image = Image.open(path).convert('L')\n",
    "        label = item[1]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adaZ60Uik-eb",
    "outputId": "8e66fb67-e670-485f-ac11-b60d2a5a3ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Samples:  24298\n"
     ]
    }
   ],
   "source": [
    "mean = [0.5,]\n",
    "std = [0.5, ]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data  = Dataset(data_labels, TRAIN_PATH, train_transform)\n",
    "test_data = Dataset(data_labels, TRAIN_PATH, test_transform)\n",
    "\n",
    "print(\"Trainig Samples: \", len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8htM9w2LmUVl"
   },
   "source": [
    "# **Base Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGG3l4vrmkI3",
    "outputId": "6a36b17c-57fd-45a9-f19d-4f4416f51407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246\n"
     ]
    }
   ],
   "source": [
    "batch_size = 300\n",
    "num_iters = 20000\n",
    "input_dim = 28*28\n",
    "num_hidden = 250\n",
    "output_dim = 10\n",
    "\n",
    "learning_rate = 0.025\n",
    "\n",
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsSesapsltZF",
    "outputId": "72b5fe74-6eaa-4c18-b642-a52ddb0f99d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:65\n",
      "Test dataloader:17\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "6jCcU8giniGS"
   },
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "#         self.softmax_1 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_2 = nn.Softmax(dim=0)\n",
    "#         self.softmax_2 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_3 = nn.ReLU()\n",
    "#         self.softmax_3 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_4 = nn.Softmax(dim=0)\n",
    "#         self.softmax_4 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_5= nn.ReLU()\n",
    "#         self.softmax_5 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_6 = nn.ReLU()\n",
    "        \n",
    "#         self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
    "#         self.relu_7 = nn.ReLU()\n",
    "        \n",
    "#         self.linear_8 = nn.Linear(num_hidden, num_hidden)\n",
    "#         self.relu_8 = nn.ReLU()\n",
    "        \n",
    "#         self.linear_9 = nn.Linear(num_hidden, num_hidden)\n",
    "#         self.relu_9 = nn.ReLU()\n",
    "\n",
    "#         self.linear_10 = nn.Linear(num_hidden, num_hidden)\n",
    "#         self.relu_10 = nn.ReLU()\n",
    "\n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out  = self.linear_1(x)\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        out  = self.linear_2(out)\n",
    "        out = self.relu_2(out)\n",
    " \n",
    "        out  = self.linear_3(out)\n",
    "        out = self.relu_3(out)\n",
    " \n",
    "        out  = self.linear_4(out)\n",
    "        out = self.relu_4(out)\n",
    " \n",
    "        out  = self.linear_5(out)\n",
    "        out = self.relu_5(out)\n",
    " \n",
    "        out  = self.linear_6(out)\n",
    "        out = self.relu_6(out)\n",
    "        \n",
    "#         out  = self.linear_7(out)\n",
    "#         out = self.relu_7(out)\n",
    "        \n",
    "#         out  = self.linear_8(out)\n",
    "#         out = self.relu_8(out)\n",
    "        \n",
    "#         out  = self.linear_9(out)\n",
    "#         out = self.relu_9(out)\n",
    "        \n",
    "#         out  = self.linear_10(out)\n",
    "#         out = self.relu_10(out)\n",
    "        \n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q23HotHio42L",
    "outputId": "1171c191-3742-47e9-fe29-daf9130927c8",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=250, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_2): Softmax(dim=0)\n",
       "  (linear_3): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_4): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_4): Softmax(dim=0)\n",
       "  (linear_5): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_5): ReLU()\n",
       "  (linear_6): Linear(in_features=250, out_features=250, bias=True)\n",
       "  (relu_6): ReLU()\n",
       "  (linear_out): Linear(in_features=250, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "V1YagXSipEth"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VJ_sYCMp2l9",
    "outputId": "1566b22e-45ca-4019-fcdc-424e3c20f11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Iteration: 10. Loss: 2.30826473236084. Accuracy: 10.310763531590862\n",
      "Iteration: 20. Loss: 2.244840621948242. Accuracy: 16.443712698086024\n",
      "Iteration: 30. Loss: 2.2106845378875732. Accuracy: 18.41942786581601\n",
      "Iteration: 40. Loss: 2.1182785034179688. Accuracy: 17.657954311586746\n",
      "Iteration: 50. Loss: 2.1779582500457764. Accuracy: 21.485902449063595\n",
      "Iteration: 60. Loss: 2.0394411087036133. Accuracy: 22.720724428894833\n",
      "Epoch:  2\n",
      "Iteration: 70. Loss: 2.061147451400757. Accuracy: 21.506482815394115\n",
      "Iteration: 80. Loss: 1.9856890439987183. Accuracy: 24.140769705700762\n",
      "Iteration: 90. Loss: 1.9853800535202026. Accuracy: 24.94340399259107\n",
      "Iteration: 100. Loss: 1.9546911716461182. Accuracy: 26.589833299032723\n",
      "Iteration: 110. Loss: 1.9448705911636353. Accuracy: 26.589833299032723\n",
      "Iteration: 120. Loss: 1.9281504154205322. Accuracy: 25.890100843795018\n",
      "Iteration: 130. Loss: 2.032702684402466. Accuracy: 27.41304795225355\n",
      "Epoch:  3\n",
      "Iteration: 140. Loss: 1.9785231351852417. Accuracy: 27.968717843177608\n",
      "Iteration: 150. Loss: 1.8996500968933105. Accuracy: 29.738629347602387\n",
      "Iteration: 160. Loss: 1.8577756881713867. Accuracy: 30.314879604856966\n",
      "Iteration: 170. Loss: 1.8643629550933838. Accuracy: 29.347602387322496\n",
      "Iteration: 180. Loss: 1.8930143117904663. Accuracy: 31.89956781230706\n",
      "Iteration: 190. Loss: 1.8227823972702026. Accuracy: 32.064210742951225\n",
      "Epoch:  4\n",
      "Iteration: 200. Loss: 1.8541501760482788. Accuracy: 33.6283185840708\n",
      "Iteration: 210. Loss: 1.847791314125061. Accuracy: 33.401934554435066\n",
      "Iteration: 220. Loss: 1.8305926322937012. Accuracy: 35.29532825684297\n",
      "Iteration: 230. Loss: 1.7110679149627686. Accuracy: 35.15126569252933\n",
      "Iteration: 240. Loss: 1.7835036516189575. Accuracy: 36.324346573369006\n",
      "Iteration: 250. Loss: 1.7534712553024292. Accuracy: 36.324346573369006\n",
      "Iteration: 260. Loss: 1.7605235576629639. Accuracy: 34.780819098579954\n",
      "Epoch:  5\n",
      "Iteration: 270. Loss: 1.617494821548462. Accuracy: 37.43568635521712\n",
      "Iteration: 280. Loss: 1.7249888181686401. Accuracy: 38.30006174109899\n",
      "Iteration: 290. Loss: 1.6946712732315063. Accuracy: 38.27948137476847\n",
      "Iteration: 300. Loss: 1.6409339904785156. Accuracy: 39.864169582218565\n",
      "Iteration: 310. Loss: 1.6678329706192017. Accuracy: 39.39082115661659\n",
      "Iteration: 320. Loss: 1.6054716110229492. Accuracy: 38.320642107429514\n",
      "Epoch:  6\n",
      "Iteration: 330. Loss: 1.5507047176361084. Accuracy: 38.0119366124717\n",
      "Iteration: 340. Loss: 1.6048823595046997. Accuracy: 39.246758592302946\n",
      "Iteration: 350. Loss: 1.6869710683822632. Accuracy: 39.28791932496399\n",
      "Iteration: 360. Loss: 1.659033179283142. Accuracy: 40.64622350277835\n",
      "Iteration: 370. Loss: 1.6227654218673706. Accuracy: 37.64149001852233\n",
      "Iteration: 380. Loss: 1.6314024925231934. Accuracy: 41.30479522535501\n",
      "Iteration: 390. Loss: 1.592170238494873. Accuracy: 39.34966042395555\n",
      "Epoch:  7\n",
      "Iteration: 400. Loss: 1.600203037261963. Accuracy: 42.39555464087261\n",
      "Iteration: 410. Loss: 1.5946201086044312. Accuracy: 40.522741304795225\n",
      "Iteration: 420. Loss: 1.5365562438964844. Accuracy: 43.34225149207656\n",
      "Iteration: 430. Loss: 1.4578229188919067. Accuracy: 43.75385881868697\n",
      "Iteration: 440. Loss: 1.548697829246521. Accuracy: 43.939082115661655\n",
      "Iteration: 450. Loss: 1.5657004117965698. Accuracy: 43.81559991767853\n",
      "Epoch:  8\n",
      "Iteration: 460. Loss: 1.5035144090652466. Accuracy: 43.79501955134801\n",
      "Iteration: 470. Loss: 1.4513589143753052. Accuracy: 43.280510393084995\n",
      "Iteration: 480. Loss: 1.4867085218429565. Accuracy: 44.45359127392467\n",
      "Iteration: 490. Loss: 1.4180490970611572. Accuracy: 44.22720724428895\n",
      "Iteration: 500. Loss: 1.4888343811035156. Accuracy: 44.49475200658572\n",
      "Iteration: 510. Loss: 1.4504406452178955. Accuracy: 44.782877135213006\n",
      "Iteration: 520. Loss: 1.5834050178527832. Accuracy: 40.522741304795225\n",
      "Epoch:  9\n",
      "Iteration: 530. Loss: 1.4438226222991943. Accuracy: 45.359127392467585\n",
      "Iteration: 540. Loss: 1.4120153188705444. Accuracy: 45.338547026137064\n",
      "Iteration: 550. Loss: 1.453950047492981. Accuracy: 44.96810043218769\n",
      "Iteration: 560. Loss: 1.4471429586410522. Accuracy: 46.07944021403581\n",
      "Iteration: 570. Loss: 1.3591251373291016. Accuracy: 45.15332372916238\n",
      "Iteration: 580. Loss: 1.3329665660858154. Accuracy: 46.73801193661247\n",
      "Epoch:  10\n",
      "Iteration: 590. Loss: 1.41694974899292. Accuracy: 47.12903889689237\n",
      "Iteration: 600. Loss: 1.4091788530349731. Accuracy: 47.14961926322289\n",
      "Iteration: 610. Loss: 1.3942402601242065. Accuracy: 47.95225355011319\n",
      "Iteration: 620. Loss: 1.3981386423110962. Accuracy: 47.37600329285861\n",
      "Iteration: 630. Loss: 1.302819848060608. Accuracy: 46.67627083762091\n",
      "Iteration: 640. Loss: 1.364323377609253. Accuracy: 46.75859230294299\n",
      "Iteration: 650. Loss: 1.8479114770889282. Accuracy: 41.819304383618025\n",
      "Epoch:  11\n",
      "Iteration: 660. Loss: 1.4351903200149536. Accuracy: 47.561226589833296\n",
      "Iteration: 670. Loss: 1.334328055381775. Accuracy: 47.74644988680799\n",
      "Iteration: 680. Loss: 1.320676326751709. Accuracy: 47.520065857172256\n",
      "Iteration: 690. Loss: 1.2567670345306396. Accuracy: 48.919530767647665\n",
      "Iteration: 700. Loss: 1.3223400115966797. Accuracy: 48.77546820333402\n",
      "Iteration: 710. Loss: 1.4471561908721924. Accuracy: 49.10475406462235\n",
      "Epoch:  12\n",
      "Iteration: 720. Loss: 1.3212316036224365. Accuracy: 48.67256637168141\n",
      "Iteration: 730. Loss: 1.253682017326355. Accuracy: 48.981271866639226\n",
      "Iteration: 740. Loss: 1.3004257678985596. Accuracy: 49.43403992591068\n",
      "Iteration: 750. Loss: 1.4818787574768066. Accuracy: 48.878370034986624\n",
      "Iteration: 760. Loss: 1.2755768299102783. Accuracy: 49.10475406462235\n",
      "Iteration: 770. Loss: 1.3445606231689453. Accuracy: 48.8577896686561\n",
      "Iteration: 780. Loss: 1.5352407693862915. Accuracy: 43.77443918501749\n",
      "Epoch:  13\n",
      "Iteration: 790. Loss: 1.3363040685653687. Accuracy: 48.38444124305413\n",
      "Iteration: 800. Loss: 1.3395788669586182. Accuracy: 49.90738835151266\n",
      "Iteration: 810. Loss: 1.2919028997421265. Accuracy: 48.05515538176579\n",
      "Iteration: 820. Loss: 1.4096373319625854. Accuracy: 49.536941757563284\n",
      "Iteration: 830. Loss: 1.2175629138946533. Accuracy: 50.52479934142828\n",
      "Iteration: 840. Loss: 1.3805993795394897. Accuracy: 50.01029018316526\n",
      "Epoch:  14\n",
      "Iteration: 850. Loss: 1.171722173690796. Accuracy: 49.96912945050422\n",
      "Iteration: 860. Loss: 1.1944347620010376. Accuracy: 50.463058242436716\n",
      "Iteration: 870. Loss: 1.2114475965499878. Accuracy: 50.95698703436921\n",
      "Iteration: 880. Loss: 1.306489109992981. Accuracy: 51.101049598682856\n",
      "Iteration: 890. Loss: 1.1515719890594482. Accuracy: 50.998147767030254\n",
      "Iteration: 900. Loss: 1.3498563766479492. Accuracy: 51.30685326198806\n",
      "Iteration: 910. Loss: 1.442987322807312. Accuracy: 46.2646635110105\n",
      "Epoch:  15\n",
      "Iteration: 920. Loss: 1.2254239320755005. Accuracy: 51.059888866021815\n",
      "Iteration: 930. Loss: 1.2517141103744507. Accuracy: 50.68944227207244\n",
      "Iteration: 940. Loss: 1.3069785833358765. Accuracy: 51.20395143033546\n",
      "Iteration: 950. Loss: 1.2456834316253662. Accuracy: 50.93640666803869\n",
      "Iteration: 960. Loss: 1.2110319137573242. Accuracy: 50.6482815394114\n",
      "Iteration: 970. Loss: 1.2224481105804443. Accuracy: 51.656719489606914\n",
      "Epoch:  16\n",
      "Iteration: 980. Loss: 1.2687517404556274. Accuracy: 50.09261164848734\n",
      "Iteration: 990. Loss: 1.1542441844940186. Accuracy: 52.438773410166704\n",
      "Iteration: 1000. Loss: 1.2551349401474. Accuracy: 51.26569252932702\n",
      "Iteration: 1010. Loss: 1.3075602054595947. Accuracy: 51.8419427865816\n",
      "Iteration: 1020. Loss: 1.1360341310501099. Accuracy: 51.45091582630171\n",
      "Iteration: 1030. Loss: 1.2853012084960938. Accuracy: 52.438773410166704\n",
      "Iteration: 1040. Loss: 1.5079365968704224. Accuracy: 50.17493311380942\n",
      "Epoch:  17\n",
      "Iteration: 1050. Loss: 1.0953600406646729. Accuracy: 52.17122864786993\n",
      "Iteration: 1060. Loss: 1.2450555562973022. Accuracy: 52.39761267750566\n",
      "Iteration: 1070. Loss: 1.109218955039978. Accuracy: 52.97386293476024\n",
      "Iteration: 1080. Loss: 1.1476775407791138. Accuracy: 52.04774644988681\n",
      "Iteration: 1090. Loss: 1.2050285339355469. Accuracy: 52.294710845853054\n",
      "Iteration: 1100. Loss: 1.164401888847351. Accuracy: 52.99444330109076\n",
      "Epoch:  18\n",
      "Iteration: 1110. Loss: 1.1439639329910278. Accuracy: 52.87096110310763\n",
      "Iteration: 1120. Loss: 1.1983399391174316. Accuracy: 53.59127392467586\n",
      "Iteration: 1130. Loss: 1.147849440574646. Accuracy: 52.68573780613295\n",
      "Iteration: 1140. Loss: 1.0637539625167847. Accuracy: 53.34430952870961\n",
      "Iteration: 1150. Loss: 1.131693959236145. Accuracy: 53.55011319201482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1160. Loss: 1.0498371124267578. Accuracy: 53.097345132743364\n",
      "Iteration: 1170. Loss: 1.3407237529754639. Accuracy: 51.101049598682856\n",
      "Epoch:  19\n",
      "Iteration: 1180. Loss: 1.105887532234192. Accuracy: 53.57069355834534\n",
      "Iteration: 1190. Loss: 1.2448062896728516. Accuracy: 52.80922000411607\n",
      "Iteration: 1200. Loss: 1.0287193059921265. Accuracy: 53.01502366742128\n",
      "Iteration: 1210. Loss: 1.0909217596054077. Accuracy: 52.76805927145503\n",
      "Iteration: 1220. Loss: 1.0963412523269653. Accuracy: 54.023461617616796\n",
      "Iteration: 1230. Loss: 1.2172634601593018. Accuracy: 52.80922000411607\n",
      "Epoch:  20\n",
      "Iteration: 1240. Loss: 1.202816367149353. Accuracy: 53.71475612265898\n",
      "Iteration: 1250. Loss: 1.0580251216888428. Accuracy: 53.797077587981065\n",
      "Iteration: 1260. Loss: 0.9970459938049316. Accuracy: 53.89997941963367\n",
      "Iteration: 1270. Loss: 1.138404369354248. Accuracy: 54.023461617616796\n",
      "Iteration: 1280. Loss: 1.1031495332717896. Accuracy: 54.558551142210334\n",
      "Iteration: 1290. Loss: 1.0713876485824585. Accuracy: 55.05247993414283\n",
      "Iteration: 1300. Loss: 1.5794926881790161. Accuracy: 49.18707552994443\n",
      "Epoch:  21\n",
      "Iteration: 1310. Loss: 1.0870767831802368. Accuracy: 53.61185429100638\n",
      "Iteration: 1320. Loss: 1.0727084875106812. Accuracy: 54.29100637991356\n",
      "Iteration: 1330. Loss: 1.0825644731521606. Accuracy: 54.08520271660836\n",
      "Iteration: 1340. Loss: 1.20853590965271. Accuracy: 54.88783700349866\n",
      "Iteration: 1350. Loss: 1.118651270866394. Accuracy: 55.50524799341428\n",
      "Iteration: 1360. Loss: 1.1224812269210815. Accuracy: 54.08520271660836\n",
      "Epoch:  22\n",
      "Iteration: 1370. Loss: 1.0585174560546875. Accuracy: 54.435068944227204\n",
      "Iteration: 1380. Loss: 1.0151156187057495. Accuracy: 54.24984564725252\n",
      "Iteration: 1390. Loss: 1.021077036857605. Accuracy: 55.5258283597448\n",
      "Iteration: 1400. Loss: 1.1022369861602783. Accuracy: 54.53797077587981\n",
      "Iteration: 1410. Loss: 1.1296337842941284. Accuracy: 55.278863963778555\n",
      "Iteration: 1420. Loss: 1.0839754343032837. Accuracy: 54.06462235027784\n",
      "Iteration: 1430. Loss: 1.361175775527954. Accuracy: 51.28627289565754\n",
      "Epoch:  23\n",
      "Iteration: 1440. Loss: 1.0756539106369019. Accuracy: 53.94114015229471\n",
      "Iteration: 1450. Loss: 1.055325984954834. Accuracy: 54.455649310557725\n",
      "Iteration: 1460. Loss: 0.9852889180183411. Accuracy: 55.11422103313439\n",
      "Iteration: 1470. Loss: 1.0967012643814087. Accuracy: 55.5258283597448\n",
      "Iteration: 1480. Loss: 1.1141505241394043. Accuracy: 55.07306030047335\n",
      "Iteration: 1490. Loss: 1.1329559087753296. Accuracy: 55.03189956781231\n",
      "Epoch:  24\n",
      "Iteration: 1500. Loss: 1.1019690036773682. Accuracy: 56.47252521094875\n",
      "Iteration: 1510. Loss: 1.0809662342071533. Accuracy: 54.78493517184606\n",
      "Iteration: 1520. Loss: 1.074598789215088. Accuracy: 56.060917884338345\n",
      "Iteration: 1530. Loss: 1.0350273847579956. Accuracy: 55.60814982506689\n",
      "Iteration: 1540. Loss: 1.0471060276031494. Accuracy: 55.44350689442272\n",
      "Iteration: 1550. Loss: 1.1549980640411377. Accuracy: 56.081498250668865\n",
      "Iteration: 1560. Loss: 1.4048112630844116. Accuracy: 51.82136242025108\n",
      "Epoch:  25\n",
      "Iteration: 1570. Loss: 1.037185549736023. Accuracy: 55.60814982506689\n",
      "Iteration: 1580. Loss: 1.1387293338775635. Accuracy: 55.17596213212595\n",
      "Iteration: 1590. Loss: 0.9323279857635498. Accuracy: 56.45194484461823\n",
      "Iteration: 1600. Loss: 1.0329415798187256. Accuracy: 56.801811072237086\n",
      "Iteration: 1610. Loss: 1.096483826637268. Accuracy: 56.122658983329906\n",
      "Iteration: 1620. Loss: 0.9694865942001343. Accuracy: 55.17596213212595\n",
      "Epoch:  26\n",
      "Iteration: 1630. Loss: 0.9516595602035522. Accuracy: 55.79337312204157\n",
      "Iteration: 1640. Loss: 1.1111876964569092. Accuracy: 56.20498044865199\n",
      "Iteration: 1650. Loss: 1.0080583095550537. Accuracy: 56.575427042601355\n",
      "Iteration: 1660. Loss: 1.00123929977417. Accuracy: 56.65774850792344\n",
      "Iteration: 1670. Loss: 0.9269136786460876. Accuracy: 57.19283803251698\n",
      "Iteration: 1680. Loss: 1.1027848720550537. Accuracy: 56.28730191397407\n",
      "Iteration: 1690. Loss: 1.241808533668518. Accuracy: 54.31158674624408\n",
      "Epoch:  27\n",
      "Iteration: 1700. Loss: 1.0505343675613403. Accuracy: 56.16381971599095\n",
      "Iteration: 1710. Loss: 1.036581039428711. Accuracy: 57.23399876517802\n",
      "Iteration: 1720. Loss: 1.0061626434326172. Accuracy: 56.90471290388969\n",
      "Iteration: 1730. Loss: 1.0363550186157227. Accuracy: 57.27515949783906\n",
      "Iteration: 1740. Loss: 0.9980205297470093. Accuracy: 57.68676682444948\n",
      "Iteration: 1750. Loss: 1.0898935794830322. Accuracy: 57.398641695822185\n",
      "Epoch:  28\n",
      "Iteration: 1760. Loss: 1.0077461004257202. Accuracy: 56.740069973245525\n",
      "Iteration: 1770. Loss: 0.9395063519477844. Accuracy: 57.336900596830624\n",
      "Iteration: 1780. Loss: 1.003443956375122. Accuracy: 56.740069973245525\n",
      "Iteration: 1790. Loss: 0.877712607383728. Accuracy: 57.13109693352542\n",
      "Iteration: 1800. Loss: 0.9925432205200195. Accuracy: 56.94587363655073\n",
      "Iteration: 1810. Loss: 1.0757167339324951. Accuracy: 57.54270426013583\n",
      "Iteration: 1820. Loss: 1.2265275716781616. Accuracy: 54.88783700349866\n",
      "Epoch:  29\n",
      "Iteration: 1830. Loss: 1.0099552869796753. Accuracy: 57.398641695822185\n",
      "Iteration: 1840. Loss: 1.0132817029953003. Accuracy: 57.68676682444948\n",
      "Iteration: 1850. Loss: 0.8335976600646973. Accuracy: 57.60444535912739\n",
      "Iteration: 1860. Loss: 0.9852792620658875. Accuracy: 57.87199012142416\n",
      "Iteration: 1870. Loss: 0.9054067730903625. Accuracy: 57.66618645811896\n",
      "Iteration: 1880. Loss: 0.9542518258094788. Accuracy: 57.78966865610208\n",
      "Epoch:  30\n",
      "Iteration: 1890. Loss: 0.9654409885406494. Accuracy: 58.36591891335666\n",
      "Iteration: 1900. Loss: 1.0182286500930786. Accuracy: 58.48940111133978\n",
      "Iteration: 1910. Loss: 0.938700258731842. Accuracy: 58.96274953694176\n",
      "Iteration: 1920. Loss: 1.0286692380905151. Accuracy: 58.53056184400082\n",
      "Iteration: 1930. Loss: 1.0604970455169678. Accuracy: 58.016052685737804\n",
      "Iteration: 1940. Loss: 1.0133509635925293. Accuracy: 58.5099814776703\n",
      "Iteration: 1950. Loss: 1.3426166772842407. Accuracy: 55.66989092405845\n",
      "Epoch:  31\n",
      "Iteration: 1960. Loss: 0.85176682472229. Accuracy: 57.83082938876312\n",
      "Iteration: 1970. Loss: 0.8985701203346252. Accuracy: 59.1068121012554\n",
      "Iteration: 1980. Loss: 0.986565351486206. Accuracy: 60.156410784111955\n",
      "Iteration: 1990. Loss: 1.0250259637832642. Accuracy: 58.11895451739041\n",
      "Iteration: 2000. Loss: 1.0373411178588867. Accuracy: 58.55114221033134\n",
      "Iteration: 2010. Loss: 1.0077409744262695. Accuracy: 58.53056184400082\n",
      "Epoch:  32\n",
      "Iteration: 2020. Loss: 0.9853792190551758. Accuracy: 58.53056184400082\n",
      "Iteration: 2030. Loss: 0.9309890866279602. Accuracy: 58.71578514097551\n",
      "Iteration: 2040. Loss: 0.8983504176139832. Accuracy: 59.209713932908\n",
      "Iteration: 2050. Loss: 0.918121874332428. Accuracy: 59.31261576456061\n",
      "Iteration: 2060. Loss: 0.9418414235115051. Accuracy: 58.34533854702614\n",
      "Iteration: 2070. Loss: 0.8623408079147339. Accuracy: 58.057213418398845\n",
      "Iteration: 2080. Loss: 1.5230666399002075. Accuracy: 56.28730191397407\n",
      "Epoch:  33\n",
      "Iteration: 2090. Loss: 1.009492039680481. Accuracy: 57.76908828977156\n",
      "Iteration: 2100. Loss: 0.9911389350891113. Accuracy: 59.58016052685738\n",
      "Iteration: 2110. Loss: 0.9281284809112549. Accuracy: 58.92158880428072\n",
      "Iteration: 2120. Loss: 0.8859211206436157. Accuracy: 59.90944638814571\n",
      "Iteration: 2130. Loss: 0.91744464635849. Accuracy: 59.02449063593332\n",
      "Iteration: 2140. Loss: 0.8643192648887634. Accuracy: 59.209713932908\n",
      "Epoch:  34\n",
      "Iteration: 2150. Loss: 0.9145343899726868. Accuracy: 60.01234821979831\n",
      "Iteration: 2160. Loss: 0.9039139747619629. Accuracy: 59.76538382383207\n",
      "Iteration: 2170. Loss: 0.9291892647743225. Accuracy: 60.05350895245935\n",
      "Iteration: 2180. Loss: 0.9196172952651978. Accuracy: 58.818686972628115\n",
      "Iteration: 2190. Loss: 0.998028039932251. Accuracy: 60.197571516772996\n",
      "Iteration: 2200. Loss: 0.8791599273681641. Accuracy: 59.62132125951842\n",
      "Iteration: 2210. Loss: 1.3387449979782104. Accuracy: 59.1068121012554\n",
      "Epoch:  35\n",
      "Iteration: 2220. Loss: 0.9071696996688843. Accuracy: 59.477258695204775\n",
      "Iteration: 2230. Loss: 1.0568888187408447. Accuracy: 60.362214447417166\n",
      "Iteration: 2240. Loss: 0.8953230977058411. Accuracy: 60.44453591273925\n",
      "Iteration: 2250. Loss: 0.8151562213897705. Accuracy: 60.50627701173081\n",
      "Iteration: 2260. Loss: 0.9817558526992798. Accuracy: 60.897303972010704\n",
      "Iteration: 2270. Loss: 0.8485199809074402. Accuracy: 60.71208067503601\n",
      "Epoch:  36\n",
      "Iteration: 2280. Loss: 0.8239955306053162. Accuracy: 60.300473348425605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2290. Loss: 0.8574457764625549. Accuracy: 59.93002675447623\n",
      "Iteration: 2300. Loss: 0.9512265920639038. Accuracy: 60.7944021403581\n",
      "Iteration: 2310. Loss: 0.9305089116096497. Accuracy: 60.773821774027574\n",
      "Iteration: 2320. Loss: 0.8203861713409424. Accuracy: 61.000205803663306\n",
      "Iteration: 2330. Loss: 0.9781204462051392. Accuracy: 60.46511627906977\n",
      "Iteration: 2340. Loss: 1.242319107055664. Accuracy: 59.80654455649311\n",
      "Epoch:  37\n",
      "Iteration: 2350. Loss: 0.8498420715332031. Accuracy: 61.51471496192632\n",
      "Iteration: 2360. Loss: 0.8395586609840393. Accuracy: 60.71208067503601\n",
      "Iteration: 2370. Loss: 0.9109242558479309. Accuracy: 61.28833093229059\n",
      "Iteration: 2380. Loss: 0.7822128534317017. Accuracy: 60.60917884338341\n",
      "Iteration: 2390. Loss: 0.9297908544540405. Accuracy: 61.20600946696851\n",
      "Iteration: 2400. Loss: 0.8617746829986572. Accuracy: 60.753241407697054\n",
      "Epoch:  38\n",
      "Iteration: 2410. Loss: 0.8219089508056641. Accuracy: 61.72051862523153\n",
      "Iteration: 2420. Loss: 0.8363009691238403. Accuracy: 61.679357892570486\n",
      "Iteration: 2430. Loss: 0.799071729183197. Accuracy: 60.50627701173081\n",
      "Iteration: 2440. Loss: 0.9961012601852417. Accuracy: 61.35007203128216\n",
      "Iteration: 2450. Loss: 0.9675419330596924. Accuracy: 61.020786169993826\n",
      "Iteration: 2460. Loss: 0.8401726484298706. Accuracy: 61.10310763531591\n",
      "Iteration: 2470. Loss: 1.3060253858566284. Accuracy: 58.57172257666186\n",
      "Epoch:  39\n",
      "Iteration: 2480. Loss: 0.8006771206855774. Accuracy: 60.176991150442475\n",
      "Iteration: 2490. Loss: 0.8295220732688904. Accuracy: 61.96748302119778\n",
      "Iteration: 2500. Loss: 0.804169774055481. Accuracy: 61.51471496192632\n",
      "Iteration: 2510. Loss: 0.7438410520553589. Accuracy: 61.96748302119778\n",
      "Iteration: 2520. Loss: 0.9003604054450989. Accuracy: 61.74109899156205\n",
      "Iteration: 2530. Loss: 0.833154022693634. Accuracy: 61.92632228853674\n",
      "Epoch:  40\n",
      "Iteration: 2540. Loss: 0.7630423903465271. Accuracy: 61.51471496192632\n",
      "Iteration: 2550. Loss: 0.8549234867095947. Accuracy: 62.193867050833504\n",
      "Iteration: 2560. Loss: 0.8122487664222717. Accuracy: 60.62975920971393\n",
      "Iteration: 2570. Loss: 0.8592308759689331. Accuracy: 61.535295328256844\n",
      "Iteration: 2580. Loss: 0.8451175689697266. Accuracy: 61.96748302119778\n",
      "Iteration: 2590. Loss: 0.8204991221427917. Accuracy: 61.9880633875283\n",
      "Iteration: 2600. Loss: 1.1360294818878174. Accuracy: 60.23873224943404\n",
      "Epoch:  41\n",
      "Iteration: 2610. Loss: 0.8062447905540466. Accuracy: 60.938464704671745\n",
      "Iteration: 2620. Loss: 0.8593599200248718. Accuracy: 62.276188516155585\n",
      "Iteration: 2630. Loss: 0.881136953830719. Accuracy: 61.82342045688413\n",
      "Iteration: 2640. Loss: 0.8861075043678284. Accuracy: 62.317349248816626\n",
      "Iteration: 2650. Loss: 0.8048059940338135. Accuracy: 62.214447417164024\n",
      "Iteration: 2660. Loss: 0.7192348837852478. Accuracy: 61.26775056596007\n",
      "Epoch:  42\n",
      "Iteration: 2670. Loss: 0.8387994766235352. Accuracy: 61.51471496192632\n",
      "Iteration: 2680. Loss: 0.936760663986206. Accuracy: 61.43239349660424\n",
      "Iteration: 2690. Loss: 0.9719982743263245. Accuracy: 60.979625437332786\n",
      "Iteration: 2700. Loss: 0.7664383053779602. Accuracy: 63.037662070384854\n",
      "Iteration: 2710. Loss: 0.9290513396263123. Accuracy: 62.193867050833504\n",
      "Iteration: 2720. Loss: 0.826463520526886. Accuracy: 62.50257254579132\n",
      "Iteration: 2730. Loss: 1.2978209257125854. Accuracy: 60.23873224943404\n",
      "Epoch:  43\n",
      "Iteration: 2740. Loss: 0.7483645677566528. Accuracy: 62.0909652191809\n",
      "Iteration: 2750. Loss: 0.9055283665657043. Accuracy: 62.193867050833504\n",
      "Iteration: 2760. Loss: 0.9407468438148499. Accuracy: 62.35850998147767\n",
      "Iteration: 2770. Loss: 0.8439188003540039. Accuracy: 63.59333196130891\n",
      "Iteration: 2780. Loss: 0.9111893773078918. Accuracy: 62.52315291212184\n",
      "Iteration: 2790. Loss: 0.8028316497802734. Accuracy: 62.50257254579132\n",
      "Epoch:  44\n",
      "Iteration: 2800. Loss: 0.8604560494422913. Accuracy: 62.56431364478288\n",
      "Iteration: 2810. Loss: 0.7859736084938049. Accuracy: 62.72895657542704\n",
      "Iteration: 2820. Loss: 0.720148503780365. Accuracy: 62.461411813130276\n",
      "Iteration: 2830. Loss: 0.8281732797622681. Accuracy: 63.119983535706936\n",
      "Iteration: 2840. Loss: 0.7760812640190125. Accuracy: 62.72895657542704\n",
      "Iteration: 2850. Loss: 0.7955425381660461. Accuracy: 63.017081704054334\n",
      "Iteration: 2860. Loss: 1.3939744234085083. Accuracy: 56.719489606915005\n",
      "Epoch:  45\n",
      "Iteration: 2870. Loss: 0.7645967602729797. Accuracy: 62.996501337723814\n",
      "Iteration: 2880. Loss: 0.7945759892463684. Accuracy: 62.97592097139329\n",
      "Iteration: 2890. Loss: 0.8295077681541443. Accuracy: 63.22288536735954\n",
      "Iteration: 2900. Loss: 0.86468505859375. Accuracy: 62.379090347808194\n",
      "Iteration: 2910. Loss: 0.8059883713722229. Accuracy: 63.92261782259724\n",
      "Iteration: 2920. Loss: 0.8417657613754272. Accuracy: 62.996501337723814\n",
      "Epoch:  46\n",
      "Iteration: 2930. Loss: 0.7561762928962708. Accuracy: 62.62605474377444\n",
      "Iteration: 2940. Loss: 0.831372857093811. Accuracy: 63.099403169376416\n",
      "Iteration: 2950. Loss: 0.758120596408844. Accuracy: 63.53159086231735\n",
      "Iteration: 2960. Loss: 0.8065205812454224. Accuracy: 62.56431364478288\n",
      "Iteration: 2970. Loss: 0.817988395690918. Accuracy: 63.53159086231735\n",
      "Iteration: 2980. Loss: 0.8582065105438232. Accuracy: 62.62605474377444\n",
      "Iteration: 2990. Loss: 1.3207056522369385. Accuracy: 61.51471496192632\n",
      "Epoch:  47\n",
      "Iteration: 3000. Loss: 0.782841145992279. Accuracy: 63.46984976332579\n",
      "Iteration: 3010. Loss: 0.7860615253448486. Accuracy: 63.737394525622555\n",
      "Iteration: 3020. Loss: 0.7297084927558899. Accuracy: 62.81127804074912\n",
      "Iteration: 3030. Loss: 0.8240069150924683. Accuracy: 63.98435892158881\n",
      "Iteration: 3040. Loss: 0.7114059925079346. Accuracy: 63.42868903066475\n",
      "Iteration: 3050. Loss: 0.7425559163093567. Accuracy: 63.16114426836798\n",
      "Epoch:  48\n",
      "Iteration: 3060. Loss: 0.8442504405975342. Accuracy: 63.655073060300474\n",
      "Iteration: 3070. Loss: 0.7262232899665833. Accuracy: 62.15270631817246\n",
      "Iteration: 3080. Loss: 0.8544576168060303. Accuracy: 63.757974891953076\n",
      "Iteration: 3090. Loss: 0.878940761089325. Accuracy: 64.10784111957193\n",
      "Iteration: 3100. Loss: 0.6852952837944031. Accuracy: 63.757974891953076\n",
      "Iteration: 3110. Loss: 0.6907336115837097. Accuracy: 63.655073060300474\n",
      "Iteration: 3120. Loss: 0.9096152782440186. Accuracy: 62.70837620909652\n",
      "Epoch:  49\n",
      "Iteration: 3130. Loss: 0.7325822710990906. Accuracy: 62.996501337723814\n",
      "Iteration: 3140. Loss: 0.7576620578765869. Accuracy: 63.59333196130891\n",
      "Iteration: 3150. Loss: 0.713989794254303. Accuracy: 64.2724840502161\n",
      "Iteration: 3160. Loss: 0.7451684474945068. Accuracy: 64.35480551553817\n",
      "Iteration: 3170. Loss: 0.7816212177276611. Accuracy: 63.81971599094464\n",
      "Iteration: 3180. Loss: 0.7790254950523376. Accuracy: 63.86087672360568\n",
      "Epoch:  50\n",
      "Iteration: 3190. Loss: 0.8633514642715454. Accuracy: 63.90203745626672\n",
      "Iteration: 3200. Loss: 0.7737483978271484. Accuracy: 64.14900185223297\n",
      "Iteration: 3210. Loss: 0.7538260817527771. Accuracy: 63.63449269396995\n",
      "Iteration: 3220. Loss: 0.6549986004829407. Accuracy: 64.08726075324141\n",
      "Iteration: 3230. Loss: 0.743628203868866. Accuracy: 64.66351101049598\n",
      "Iteration: 3240. Loss: 0.7409878969192505. Accuracy: 64.00493928791933\n",
      "Iteration: 3250. Loss: 1.1728086471557617. Accuracy: 62.74953694175756\n",
      "Epoch:  51\n",
      "Iteration: 3260. Loss: 0.6929733753204346. Accuracy: 64.31364478287713\n",
      "Iteration: 3270. Loss: 0.8033644556999207. Accuracy: 63.655073060300474\n",
      "Iteration: 3280. Loss: 0.723178505897522. Accuracy: 64.23132331755505\n",
      "Iteration: 3290. Loss: 0.7875256538391113. Accuracy: 63.46984976332579\n",
      "Iteration: 3300. Loss: 0.8381622433662415. Accuracy: 64.14900185223297\n",
      "Iteration: 3310. Loss: 0.8384714722633362. Accuracy: 63.94319818892776\n",
      "Epoch:  52\n",
      "Iteration: 3320. Loss: 0.6903190016746521. Accuracy: 63.79913562461412\n",
      "Iteration: 3330. Loss: 0.7530584931373596. Accuracy: 63.92261782259724\n",
      "Iteration: 3340. Loss: 0.684473991394043. Accuracy: 64.66351101049598\n",
      "Iteration: 3350. Loss: 0.7553808093070984. Accuracy: 64.21074295122453\n",
      "Iteration: 3360. Loss: 0.7372494339942932. Accuracy: 64.60176991150442\n",
      "Iteration: 3370. Loss: 0.8354418277740479. Accuracy: 63.63449269396995\n",
      "Iteration: 3380. Loss: 1.1502512693405151. Accuracy: 61.96748302119778\n",
      "Epoch:  53\n",
      "Iteration: 3390. Loss: 0.7236289381980896. Accuracy: 64.16958221856349\n",
      "Iteration: 3400. Loss: 0.7793466448783875. Accuracy: 64.82815394114016\n",
      "Iteration: 3410. Loss: 0.7192555069923401. Accuracy: 64.84873430747068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3420. Loss: 0.7757675647735596. Accuracy: 64.25190368388557\n",
      "Iteration: 3430. Loss: 0.7721464037895203. Accuracy: 64.08726075324141\n",
      "Iteration: 3440. Loss: 0.8113781213760376. Accuracy: 63.86087672360568\n",
      "Epoch:  54\n",
      "Iteration: 3450. Loss: 0.6986600160598755. Accuracy: 64.25190368388557\n",
      "Iteration: 3460. Loss: 0.7259736657142639. Accuracy: 65.0751183371064\n",
      "Iteration: 3470. Loss: 0.7041202187538147. Accuracy: 64.72525210948754\n",
      "Iteration: 3480. Loss: 0.6629340052604675. Accuracy: 64.62235027783494\n",
      "Iteration: 3490. Loss: 0.73895263671875. Accuracy: 64.45770734719078\n",
      "Iteration: 3500. Loss: 0.7179149985313416. Accuracy: 64.2724840502161\n",
      "Iteration: 3510. Loss: 1.0695699453353882. Accuracy: 63.14056390203746\n",
      "Epoch:  55\n",
      "Iteration: 3520. Loss: 0.6817556023597717. Accuracy: 64.99279687178432\n",
      "Iteration: 3530. Loss: 0.7962680459022522. Accuracy: 64.00493928791933\n",
      "Iteration: 3540. Loss: 0.7685311436653137. Accuracy: 65.05453797077588\n",
      "Iteration: 3550. Loss: 0.7100496292114258. Accuracy: 65.01337723811484\n",
      "Iteration: 3560. Loss: 0.7452709674835205. Accuracy: 64.04610002058037\n",
      "Iteration: 3570. Loss: 0.7750268578529358. Accuracy: 64.80757357480964\n",
      "Epoch:  56\n",
      "Iteration: 3580. Loss: 0.6841904520988464. Accuracy: 64.00493928791933\n",
      "Iteration: 3590. Loss: 0.7123616933822632. Accuracy: 64.21074295122453\n",
      "Iteration: 3600. Loss: 0.8378894925117493. Accuracy: 64.70467174315702\n",
      "Iteration: 3610. Loss: 0.7107530832290649. Accuracy: 64.12842148590245\n",
      "Iteration: 3620. Loss: 0.8203026652336121. Accuracy: 65.19860053508953\n",
      "Iteration: 3630. Loss: 0.7206096649169922. Accuracy: 64.64293064416546\n",
      "Iteration: 3640. Loss: 1.2180445194244385. Accuracy: 63.84029635727516\n",
      "Epoch:  57\n",
      "Iteration: 3650. Loss: 0.6893949508666992. Accuracy: 65.87775262399671\n",
      "Iteration: 3660. Loss: 0.7115433216094971. Accuracy: 64.00493928791933\n",
      "Iteration: 3670. Loss: 0.7207239866256714. Accuracy: 64.80757357480964\n",
      "Iteration: 3680. Loss: 0.7377708554267883. Accuracy: 65.44556493105577\n",
      "Iteration: 3690. Loss: 0.650047242641449. Accuracy: 64.49886807985182\n",
      "Iteration: 3700. Loss: 0.7488650679588318. Accuracy: 65.30150236674213\n",
      "Epoch:  58\n",
      "Iteration: 3710. Loss: 0.7910723090171814. Accuracy: 65.32208273307265\n",
      "Iteration: 3720. Loss: 0.7175453305244446. Accuracy: 64.84873430747068\n",
      "Iteration: 3730. Loss: 0.7699708938598633. Accuracy: 64.95163613912328\n",
      "Iteration: 3740. Loss: 0.8033198714256287. Accuracy: 65.42498456472525\n",
      "Iteration: 3750. Loss: 0.6965878009796143. Accuracy: 65.61020786169993\n",
      "Iteration: 3760. Loss: 0.6601583361625671. Accuracy: 64.49886807985182\n",
      "Iteration: 3770. Loss: 1.117641568183899. Accuracy: 64.10784111957193\n",
      "Epoch:  59\n",
      "Iteration: 3780. Loss: 0.7047280669212341. Accuracy: 65.03395760444536\n",
      "Iteration: 3790. Loss: 0.6649975776672363. Accuracy: 65.7748507923441\n",
      "Iteration: 3800. Loss: 0.8816192746162415. Accuracy: 64.7664128421486\n",
      "Iteration: 3810. Loss: 0.7194340229034424. Accuracy: 65.42498456472525\n",
      "Iteration: 3820. Loss: 0.6125379800796509. Accuracy: 65.81601152500515\n",
      "Iteration: 3830. Loss: 0.7038299441337585. Accuracy: 64.60176991150442\n",
      "Epoch:  60\n",
      "Iteration: 3840. Loss: 0.6748189926147461. Accuracy: 65.48672566371681\n",
      "Iteration: 3850. Loss: 0.8233760595321655. Accuracy: 64.93105577279276\n",
      "Iteration: 3860. Loss: 0.7072989344596863. Accuracy: 64.84873430747068\n",
      "Iteration: 3870. Loss: 0.722801923751831. Accuracy: 65.15743980242848\n",
      "Iteration: 3880. Loss: 0.8441201448440552. Accuracy: 65.11627906976744\n",
      "Iteration: 3890. Loss: 0.6817464232444763. Accuracy: 65.05453797077588\n",
      "Iteration: 3900. Loss: 1.3850177526474. Accuracy: 63.57275159497839\n",
      "Epoch:  61\n",
      "Iteration: 3910. Loss: 0.7806101441383362. Accuracy: 65.54846676270837\n",
      "Iteration: 3920. Loss: 0.7212536931037903. Accuracy: 64.41654661452974\n",
      "Iteration: 3930. Loss: 0.6375973224639893. Accuracy: 65.11627906976744\n",
      "Iteration: 3940. Loss: 0.700072705745697. Accuracy: 65.50730603004733\n",
      "Iteration: 3950. Loss: 0.8029979467391968. Accuracy: 64.6840913768265\n",
      "Iteration: 3960. Loss: 0.8079317212104797. Accuracy: 65.69252932702202\n",
      "Epoch:  62\n",
      "Iteration: 3970. Loss: 0.6670593023300171. Accuracy: 65.89833299032723\n",
      "Iteration: 3980. Loss: 0.7533140778541565. Accuracy: 65.2809220004116\n",
      "Iteration: 3990. Loss: 0.6396191120147705. Accuracy: 65.54846676270837\n",
      "Iteration: 4000. Loss: 0.6952595710754395. Accuracy: 66.08355628730192\n",
      "Iteration: 4010. Loss: 0.7522743344306946. Accuracy: 66.43342251492076\n",
      "Iteration: 4020. Loss: 0.7152183055877686. Accuracy: 64.95163613912328\n",
      "Iteration: 4030. Loss: 0.9489770531654358. Accuracy: 65.0751183371064\n",
      "Epoch:  63\n",
      "Iteration: 4040. Loss: 0.6878315806388855. Accuracy: 65.79543115867463\n",
      "Iteration: 4050. Loss: 0.6004036664962769. Accuracy: 65.44556493105577\n",
      "Iteration: 4060. Loss: 0.6426512002944946. Accuracy: 65.75427042601358\n",
      "Iteration: 4070. Loss: 0.6801884174346924. Accuracy: 65.79543115867463\n",
      "Iteration: 4080. Loss: 0.7660354375839233. Accuracy: 65.63078822803045\n",
      "Iteration: 4090. Loss: 0.7318848967552185. Accuracy: 65.34266309940317\n",
      "Epoch:  64\n",
      "Iteration: 4100. Loss: 0.6925169229507446. Accuracy: 67.03025313850587\n",
      "Iteration: 4110. Loss: 0.7716599106788635. Accuracy: 66.14529738629348\n",
      "Iteration: 4120. Loss: 0.5438598394393921. Accuracy: 65.91891335665775\n",
      "Iteration: 4130. Loss: 0.7103825211524963. Accuracy: 65.38382383206421\n",
      "Iteration: 4140. Loss: 0.890828549861908. Accuracy: 65.79543115867463\n",
      "Iteration: 4150. Loss: 0.7390390038490295. Accuracy: 66.18645811895452\n",
      "Iteration: 4160. Loss: 1.0203624963760376. Accuracy: 64.45770734719078\n",
      "Epoch:  65\n",
      "Iteration: 4170. Loss: 0.593330979347229. Accuracy: 65.98065445564932\n",
      "Iteration: 4180. Loss: 0.7389546036720276. Accuracy: 65.54846676270837\n",
      "Iteration: 4190. Loss: 0.6827441453933716. Accuracy: 66.33052068326816\n",
      "Iteration: 4200. Loss: 0.6577955484390259. Accuracy: 66.30994031693764\n",
      "Iteration: 4210. Loss: 0.7349896430969238. Accuracy: 66.04239555464088\n",
      "Iteration: 4220. Loss: 0.6466947197914124. Accuracy: 66.12471701996296\n",
      "Epoch:  66\n",
      "Iteration: 4230. Loss: 0.7588469386100769. Accuracy: 65.58962749536941\n",
      "Iteration: 4240. Loss: 0.6879411339759827. Accuracy: 65.71310969335254\n",
      "Iteration: 4250. Loss: 0.6889402866363525. Accuracy: 65.52788639637785\n",
      "Iteration: 4260. Loss: 0.679444432258606. Accuracy: 66.08355628730192\n",
      "Iteration: 4270. Loss: 0.5650088787078857. Accuracy: 66.88619057419223\n",
      "Iteration: 4280. Loss: 0.738468587398529. Accuracy: 65.81601152500515\n",
      "Iteration: 4290. Loss: 1.045193076133728. Accuracy: 63.96377855525829\n",
      "Epoch:  67\n",
      "Iteration: 4300. Loss: 0.6374831795692444. Accuracy: 66.49516361391233\n",
      "Iteration: 4310. Loss: 0.6363315582275391. Accuracy: 66.55690471290389\n",
      "Iteration: 4320. Loss: 0.5840540528297424. Accuracy: 65.75427042601358\n",
      "Iteration: 4330. Loss: 0.6541639566421509. Accuracy: 66.4745832475818\n",
      "Iteration: 4340. Loss: 0.6639286875724792. Accuracy: 66.02181518831036\n",
      "Iteration: 4350. Loss: 0.6827341914176941. Accuracy: 66.49516361391233\n",
      "Epoch:  68\n",
      "Iteration: 4360. Loss: 0.779303789138794. Accuracy: 65.91891335665775\n",
      "Iteration: 4370. Loss: 0.6362924575805664. Accuracy: 66.24819921794608\n",
      "Iteration: 4380. Loss: 0.6701171398162842. Accuracy: 66.68038691088701\n",
      "Iteration: 4390. Loss: 0.6632480025291443. Accuracy: 66.61864581189545\n",
      "Iteration: 4400. Loss: 0.6878886222839355. Accuracy: 66.30994031693764\n",
      "Iteration: 4410. Loss: 0.6571313142776489. Accuracy: 66.72154764354805\n",
      "Iteration: 4420. Loss: 1.0623579025268555. Accuracy: 64.95163613912328\n",
      "Epoch:  69\n",
      "Iteration: 4430. Loss: 0.6177231669425964. Accuracy: 66.08355628730192\n",
      "Iteration: 4440. Loss: 0.6136188507080078. Accuracy: 66.51574398024285\n",
      "Iteration: 4450. Loss: 0.6496350765228271. Accuracy: 66.18645811895452\n",
      "Iteration: 4460. Loss: 0.7252311110496521. Accuracy: 66.24819921794608\n",
      "Iteration: 4470. Loss: 0.7217197418212891. Accuracy: 66.165877752624\n",
      "Iteration: 4480. Loss: 0.679261326789856. Accuracy: 66.0629759209714\n",
      "Epoch:  70\n",
      "Iteration: 4490. Loss: 0.6017820239067078. Accuracy: 66.92735130685327\n",
      "Iteration: 4500. Loss: 0.7289174795150757. Accuracy: 66.45400288125128\n",
      "Iteration: 4510. Loss: 0.8077407479286194. Accuracy: 65.93949372298827\n",
      "Iteration: 4520. Loss: 0.6484190821647644. Accuracy: 67.13315497015847\n",
      "Iteration: 4530. Loss: 0.6619555950164795. Accuracy: 66.61864581189545\n",
      "Iteration: 4540. Loss: 0.6766390204429626. Accuracy: 66.8656102078617\n",
      "Iteration: 4550. Loss: 0.9612165093421936. Accuracy: 65.34266309940317\n",
      "Epoch:  71\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4560. Loss: 0.6123785972595215. Accuracy: 66.5774850792344\n",
      "Iteration: 4570. Loss: 0.7458011507987976. Accuracy: 66.30994031693764\n",
      "Iteration: 4580. Loss: 0.7089620232582092. Accuracy: 66.4745832475818\n",
      "Iteration: 4590. Loss: 0.7214362621307373. Accuracy: 66.24819921794608\n",
      "Iteration: 4600. Loss: 0.5956353545188904. Accuracy: 66.43342251492076\n",
      "Iteration: 4610. Loss: 0.708264946937561. Accuracy: 66.72154764354805\n",
      "Epoch:  72\n",
      "Iteration: 4620. Loss: 0.6533766388893127. Accuracy: 66.96851203951431\n",
      "Iteration: 4630. Loss: 0.644101619720459. Accuracy: 67.21547643548055\n",
      "Iteration: 4640. Loss: 0.6918818950653076. Accuracy: 67.29779790080264\n",
      "Iteration: 4650. Loss: 0.6818993091583252. Accuracy: 67.00967277217535\n",
      "Iteration: 4660. Loss: 0.5992242693901062. Accuracy: 67.05083350483639\n",
      "Iteration: 4670. Loss: 0.6209002733230591. Accuracy: 66.39226178225972\n",
      "Iteration: 4680. Loss: 0.860144853591919. Accuracy: 66.35110104959868\n",
      "Epoch:  73\n",
      "Iteration: 4690. Loss: 0.639574408531189. Accuracy: 67.58592302942992\n",
      "Iteration: 4700. Loss: 0.6492165327072144. Accuracy: 67.27721753447211\n",
      "Iteration: 4710. Loss: 0.6847774982452393. Accuracy: 66.49516361391233\n",
      "Iteration: 4720. Loss: 0.7669754028320312. Accuracy: 67.2566371681416\n",
      "Iteration: 4730. Loss: 0.6366977095603943. Accuracy: 66.2687795842766\n",
      "Iteration: 4740. Loss: 0.5946011543273926. Accuracy: 66.28935995060712\n",
      "Epoch:  74\n",
      "Iteration: 4750. Loss: 0.6139004230499268. Accuracy: 66.90677094052275\n",
      "Iteration: 4760. Loss: 0.6568872928619385. Accuracy: 66.49516361391233\n",
      "Iteration: 4770. Loss: 0.7049160003662109. Accuracy: 67.3595389997942\n",
      "Iteration: 4780. Loss: 0.6489177942276001. Accuracy: 67.07141387116691\n",
      "Iteration: 4790. Loss: 0.6182581186294556. Accuracy: 66.28935995060712\n",
      "Iteration: 4800. Loss: 0.6560283899307251. Accuracy: 66.49516361391233\n",
      "Iteration: 4810. Loss: 1.270547866821289. Accuracy: 65.73369005968306\n",
      "Epoch:  75\n",
      "Iteration: 4820. Loss: 0.6019149422645569. Accuracy: 67.27721753447211\n",
      "Iteration: 4830. Loss: 0.589637279510498. Accuracy: 66.90677094052275\n",
      "Iteration: 4840. Loss: 0.6628119945526123. Accuracy: 67.00967277217535\n",
      "Iteration: 4850. Loss: 0.6540067195892334. Accuracy: 66.88619057419223\n",
      "Iteration: 4860. Loss: 0.7083207964897156. Accuracy: 67.00967277217535\n",
      "Iteration: 4870. Loss: 0.5154195427894592. Accuracy: 67.64766412842148\n",
      "Epoch:  76\n",
      "Iteration: 4880. Loss: 0.6504992246627808. Accuracy: 67.40069973245524\n",
      "Iteration: 4890. Loss: 0.6806038618087769. Accuracy: 67.50360156410784\n",
      "Iteration: 4900. Loss: 0.5533608794212341. Accuracy: 67.79172669273512\n",
      "Iteration: 4910. Loss: 0.6726495027542114. Accuracy: 67.27721753447211\n",
      "Iteration: 4920. Loss: 0.6591938734054565. Accuracy: 67.668244494752\n",
      "Iteration: 4930. Loss: 0.6098034977912903. Accuracy: 67.11257460382795\n",
      "Iteration: 4940. Loss: 1.1150708198547363. Accuracy: 65.63078822803045\n",
      "Epoch:  77\n",
      "Iteration: 4950. Loss: 0.6202312111854553. Accuracy: 66.68038691088701\n",
      "Iteration: 4960. Loss: 0.7021298408508301. Accuracy: 67.5653426630994\n",
      "Iteration: 4970. Loss: 0.5855499505996704. Accuracy: 66.98909240584483\n",
      "Iteration: 4980. Loss: 0.7162806391716003. Accuracy: 67.38011936612472\n",
      "Iteration: 4990. Loss: 0.6937928199768066. Accuracy: 67.52418193043836\n",
      "Iteration: 5000. Loss: 0.6448417901992798. Accuracy: 67.48302119777732\n",
      "Epoch:  78\n",
      "Iteration: 5010. Loss: 0.7009105086326599. Accuracy: 66.82444947520065\n",
      "Iteration: 5020. Loss: 0.6400908827781677. Accuracy: 67.42128009878576\n",
      "Iteration: 5030. Loss: 0.5980451703071594. Accuracy: 66.63922617822597\n",
      "Iteration: 5040. Loss: 0.6624216437339783. Accuracy: 67.33895863346368\n",
      "Iteration: 5050. Loss: 0.5786249041557312. Accuracy: 66.90677094052275\n",
      "Iteration: 5060. Loss: 0.6229248046875. Accuracy: 67.21547643548055\n",
      "Iteration: 5070. Loss: 1.0313206911087036. Accuracy: 65.83659189133567\n",
      "Epoch:  79\n",
      "Iteration: 5080. Loss: 0.638241171836853. Accuracy: 67.668244494752\n",
      "Iteration: 5090. Loss: 0.6432971954345703. Accuracy: 67.2566371681416\n",
      "Iteration: 5100. Loss: 0.8456242680549622. Accuracy: 67.72998559374356\n",
      "Iteration: 5110. Loss: 0.705533504486084. Accuracy: 67.60650339576044\n",
      "Iteration: 5120. Loss: 0.6651067733764648. Accuracy: 67.27721753447211\n",
      "Iteration: 5130. Loss: 0.6318728923797607. Accuracy: 68.03869108870138\n",
      "Epoch:  80\n",
      "Iteration: 5140. Loss: 0.7005608081817627. Accuracy: 67.2566371681416\n",
      "Iteration: 5150. Loss: 0.6151015758514404. Accuracy: 66.84502984153119\n",
      "Iteration: 5160. Loss: 0.6152924299240112. Accuracy: 67.54476229676888\n",
      "Iteration: 5170. Loss: 0.6731157898902893. Accuracy: 67.62708376209096\n",
      "Iteration: 5180. Loss: 0.6165013909339905. Accuracy: 67.62708376209096\n",
      "Iteration: 5190. Loss: 0.5899902582168579. Accuracy: 66.70096727721753\n",
      "Iteration: 5200. Loss: 1.03294038772583. Accuracy: 66.59806544556493\n",
      "Epoch:  81\n",
      "Iteration: 5210. Loss: 0.7067480683326721. Accuracy: 66.84502984153119\n",
      "Iteration: 5220. Loss: 0.6431687474250793. Accuracy: 67.48302119777732\n",
      "Iteration: 5230. Loss: 0.7012313008308411. Accuracy: 67.42128009878576\n",
      "Iteration: 5240. Loss: 0.6165897846221924. Accuracy: 67.79172669273512\n",
      "Iteration: 5250. Loss: 0.6044337153434753. Accuracy: 67.05083350483639\n",
      "Iteration: 5260. Loss: 0.5572769045829773. Accuracy: 68.0592714550319\n",
      "Epoch:  82\n",
      "Iteration: 5270. Loss: 0.6382388472557068. Accuracy: 67.64766412842148\n",
      "Iteration: 5280. Loss: 0.7696022391319275. Accuracy: 67.11257460382795\n",
      "Iteration: 5290. Loss: 0.569715142250061. Accuracy: 67.62708376209096\n",
      "Iteration: 5300. Loss: 0.5495426058769226. Accuracy: 66.68038691088701\n",
      "Iteration: 5310. Loss: 0.5864623785018921. Accuracy: 67.3595389997942\n",
      "Iteration: 5320. Loss: 0.7298439741134644. Accuracy: 68.07985182136242\n",
      "Iteration: 5330. Loss: 1.1658731698989868. Accuracy: 66.10413665363244\n",
      "Epoch:  83\n",
      "Iteration: 5340. Loss: 0.671410858631134. Accuracy: 68.26507511833711\n",
      "Iteration: 5350. Loss: 0.5705817341804504. Accuracy: 67.38011936612472\n",
      "Iteration: 5360. Loss: 0.6857556104660034. Accuracy: 68.42971804898127\n",
      "Iteration: 5370. Loss: 0.6880903840065002. Accuracy: 67.8740481580572\n",
      "Iteration: 5380. Loss: 0.666716992855072. Accuracy: 68.28565548466763\n",
      "Iteration: 5390. Loss: 0.7029552459716797. Accuracy: 67.85346779172669\n",
      "Epoch:  84\n",
      "Iteration: 5400. Loss: 0.611426591873169. Accuracy: 67.97694998970982\n",
      "Iteration: 5410. Loss: 0.509097158908844. Accuracy: 67.19489606915003\n",
      "Iteration: 5420. Loss: 0.6624810695648193. Accuracy: 67.81230705906565\n",
      "Iteration: 5430. Loss: 0.7004268765449524. Accuracy: 67.85346779172669\n",
      "Iteration: 5440. Loss: 0.616641104221344. Accuracy: 66.74212800987857\n",
      "Iteration: 5450. Loss: 0.5264468193054199. Accuracy: 67.72998559374356\n",
      "Iteration: 5460. Loss: 0.7960473895072937. Accuracy: 66.53632434657337\n",
      "Epoch:  85\n",
      "Iteration: 5470. Loss: 0.621555507183075. Accuracy: 67.54476229676888\n",
      "Iteration: 5480. Loss: 0.6548234820365906. Accuracy: 67.29779790080264\n",
      "Iteration: 5490. Loss: 0.6464720368385315. Accuracy: 66.90677094052275\n",
      "Iteration: 5500. Loss: 0.6645793914794922. Accuracy: 67.5653426630994\n",
      "Iteration: 5510. Loss: 0.6686773300170898. Accuracy: 67.89462852438773\n",
      "Iteration: 5520. Loss: 0.7649259567260742. Accuracy: 68.1621732866845\n",
      "Epoch:  86\n",
      "Iteration: 5530. Loss: 0.4983499050140381. Accuracy: 67.54476229676888\n",
      "Iteration: 5540. Loss: 0.6505908370018005. Accuracy: 68.32681621732867\n",
      "Iteration: 5550. Loss: 0.6018334627151489. Accuracy: 68.69726281127804\n",
      "Iteration: 5560. Loss: 0.5793629884719849. Accuracy: 67.52418193043836\n",
      "Iteration: 5570. Loss: 0.5386489629745483. Accuracy: 68.49145914797283\n",
      "Iteration: 5580. Loss: 0.6457393169403076. Accuracy: 68.26507511833711\n",
      "Iteration: 5590. Loss: 1.1139962673187256. Accuracy: 66.63922617822597\n",
      "Epoch:  87\n",
      "Iteration: 5600. Loss: 0.7768360376358032. Accuracy: 68.656102078617\n",
      "Iteration: 5610. Loss: 0.677488386631012. Accuracy: 67.68882486108252\n",
      "Iteration: 5620. Loss: 0.6138125658035278. Accuracy: 68.26507511833711\n",
      "Iteration: 5630. Loss: 0.5531765222549438. Accuracy: 67.07141387116691\n",
      "Iteration: 5640. Loss: 0.6066939830780029. Accuracy: 68.34739658365919\n",
      "Iteration: 5650. Loss: 0.5581899285316467. Accuracy: 67.93578925704878\n",
      "Epoch:  88\n",
      "Iteration: 5660. Loss: 0.6205155253410339. Accuracy: 67.9563696233793\n",
      "Iteration: 5670. Loss: 0.5715271234512329. Accuracy: 67.72998559374356\n",
      "Iteration: 5680. Loss: 0.5616486668586731. Accuracy: 67.85346779172669\n",
      "Iteration: 5690. Loss: 0.5683940649032593. Accuracy: 67.89462852438773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5700. Loss: 0.6910758018493652. Accuracy: 67.62708376209096\n",
      "Iteration: 5710. Loss: 0.6731971502304077. Accuracy: 68.71784317760856\n",
      "Iteration: 5720. Loss: 0.8943735957145691. Accuracy: 66.78328874253961\n",
      "Epoch:  89\n",
      "Iteration: 5730. Loss: 0.5936828851699829. Accuracy: 68.42971804898127\n",
      "Iteration: 5740. Loss: 0.6465256214141846. Accuracy: 68.47087878164231\n",
      "Iteration: 5750. Loss: 0.5455852746963501. Accuracy: 67.38011936612472\n",
      "Iteration: 5760. Loss: 0.5933559536933899. Accuracy: 67.68882486108252\n",
      "Iteration: 5770. Loss: 0.644838809967041. Accuracy: 67.62708376209096\n",
      "Iteration: 5780. Loss: 0.649417519569397. Accuracy: 68.34739658365919\n",
      "Epoch:  90\n",
      "Iteration: 5790. Loss: 0.5570467114448547. Accuracy: 67.40069973245524\n",
      "Iteration: 5800. Loss: 0.6367841362953186. Accuracy: 68.26507511833711\n",
      "Iteration: 5810. Loss: 0.6074239611625671. Accuracy: 68.656102078617\n",
      "Iteration: 5820. Loss: 0.718816876411438. Accuracy: 68.03869108870138\n",
      "Iteration: 5830. Loss: 0.6364425420761108. Accuracy: 68.10043218769295\n",
      "Iteration: 5840. Loss: 0.5718268156051636. Accuracy: 68.14159292035399\n",
      "Iteration: 5850. Loss: 1.1530845165252686. Accuracy: 67.40069973245524\n",
      "Epoch:  91\n",
      "Iteration: 5860. Loss: 0.655897319316864. Accuracy: 68.12101255402347\n",
      "Iteration: 5870. Loss: 0.6486729383468628. Accuracy: 67.81230705906565\n",
      "Iteration: 5880. Loss: 0.6128795742988586. Accuracy: 68.22391438567607\n",
      "Iteration: 5890. Loss: 0.6171866059303284. Accuracy: 68.28565548466763\n",
      "Iteration: 5900. Loss: 0.6499870419502258. Accuracy: 67.93578925704878\n",
      "Iteration: 5910. Loss: 0.5734485387802124. Accuracy: 68.07985182136242\n",
      "Epoch:  92\n",
      "Iteration: 5920. Loss: 0.5450148582458496. Accuracy: 67.38011936612472\n",
      "Iteration: 5930. Loss: 0.5554214119911194. Accuracy: 69.02654867256638\n",
      "Iteration: 5940. Loss: 0.6449459791183472. Accuracy: 68.71784317760856\n",
      "Iteration: 5950. Loss: 0.6567209362983704. Accuracy: 68.20333401934555\n",
      "Iteration: 5960. Loss: 0.5596337914466858. Accuracy: 68.47087878164231\n",
      "Iteration: 5970. Loss: 0.6802096962928772. Accuracy: 67.85346779172669\n",
      "Iteration: 5980. Loss: 0.6918190717697144. Accuracy: 67.40069973245524\n",
      "Epoch:  93\n",
      "Iteration: 5990. Loss: 0.48156973719596863. Accuracy: 68.30623585099815\n",
      "Iteration: 6000. Loss: 0.6743522882461548. Accuracy: 68.01811072237086\n",
      "Iteration: 6010. Loss: 0.6328243017196655. Accuracy: 68.24449475200659\n",
      "Iteration: 6020. Loss: 0.5112063884735107. Accuracy: 68.28565548466763\n",
      "Iteration: 6030. Loss: 0.6204609870910645. Accuracy: 68.51203951430335\n",
      "Iteration: 6040. Loss: 0.5655148029327393. Accuracy: 68.14159292035399\n",
      "Epoch:  94\n",
      "Iteration: 6050. Loss: 0.6342950463294983. Accuracy: 68.0592714550319\n",
      "Iteration: 6060. Loss: 0.6229162812232971. Accuracy: 68.51203951430335\n",
      "Iteration: 6070. Loss: 0.5179388523101807. Accuracy: 68.38855731632023\n",
      "Iteration: 6080. Loss: 0.5746706128120422. Accuracy: 68.22391438567607\n",
      "Iteration: 6090. Loss: 0.668956458568573. Accuracy: 68.0592714550319\n",
      "Iteration: 6100. Loss: 0.6168000102043152. Accuracy: 68.32681621732867\n",
      "Iteration: 6110. Loss: 1.0266680717468262. Accuracy: 67.54476229676888\n",
      "Epoch:  95\n",
      "Iteration: 6120. Loss: 0.7100372910499573. Accuracy: 67.9563696233793\n",
      "Iteration: 6130. Loss: 0.5972635746002197. Accuracy: 69.17061123688002\n",
      "Iteration: 6140. Loss: 0.6011610627174377. Accuracy: 68.69726281127804\n",
      "Iteration: 6150. Loss: 0.6004359126091003. Accuracy: 69.02654867256638\n",
      "Iteration: 6160. Loss: 0.6756979823112488. Accuracy: 68.71784317760856\n",
      "Iteration: 6170. Loss: 0.4839223325252533. Accuracy: 68.42971804898127\n",
      "Epoch:  96\n",
      "Iteration: 6180. Loss: 0.5691332221031189. Accuracy: 69.00596830623586\n",
      "Iteration: 6190. Loss: 0.5671195387840271. Accuracy: 67.38011936612472\n",
      "Iteration: 6200. Loss: 0.657601535320282. Accuracy: 68.80016464293064\n",
      "Iteration: 6210. Loss: 0.5095998048782349. Accuracy: 68.07985182136242\n",
      "Iteration: 6220. Loss: 0.5926576852798462. Accuracy: 68.34739658365919\n",
      "Iteration: 6230. Loss: 0.5542044639587402. Accuracy: 69.23235233587158\n",
      "Iteration: 6240. Loss: 1.0596171617507935. Accuracy: 67.75056596007408\n",
      "Epoch:  97\n",
      "Iteration: 6250. Loss: 0.5404974818229675. Accuracy: 69.17061123688002\n",
      "Iteration: 6260. Loss: 0.5723634958267212. Accuracy: 69.2529327022021\n",
      "Iteration: 6270. Loss: 0.7668253779411316. Accuracy: 68.80016464293064\n",
      "Iteration: 6280. Loss: 0.6870957612991333. Accuracy: 69.0471290388969\n",
      "Iteration: 6290. Loss: 0.5647262334823608. Accuracy: 68.656102078617\n",
      "Iteration: 6300. Loss: 0.6078202128410339. Accuracy: 68.82074500926116\n",
      "Epoch:  98\n",
      "Iteration: 6310. Loss: 0.7582898139953613. Accuracy: 68.07985182136242\n",
      "Iteration: 6320. Loss: 0.6244578957557678. Accuracy: 69.12945050421898\n",
      "Iteration: 6330. Loss: 0.6253871917724609. Accuracy: 68.73842354393908\n",
      "Iteration: 6340. Loss: 0.6088429689407349. Accuracy: 68.5532002469644\n",
      "Iteration: 6350. Loss: 0.6148673892021179. Accuracy: 68.45029841531179\n",
      "Iteration: 6360. Loss: 0.6806493401527405. Accuracy: 68.82074500926116\n",
      "Iteration: 6370. Loss: 1.381864309310913. Accuracy: 67.91520889071826\n",
      "Epoch:  99\n",
      "Iteration: 6380. Loss: 0.5731050372123718. Accuracy: 68.59436097962543\n",
      "Iteration: 6390. Loss: 0.5325114727020264. Accuracy: 68.94422720724428\n",
      "Iteration: 6400. Loss: 0.5376856923103333. Accuracy: 69.10887013788846\n",
      "Iteration: 6410. Loss: 0.5368833541870117. Accuracy: 68.5532002469644\n",
      "Iteration: 6420. Loss: 0.7483079433441162. Accuracy: 68.84132537559168\n",
      "Iteration: 6430. Loss: 0.5955795645713806. Accuracy: 68.656102078617\n",
      "Epoch:  100\n",
      "Iteration: 6440. Loss: 0.5501694083213806. Accuracy: 68.47087878164231\n",
      "Iteration: 6450. Loss: 0.6074977517127991. Accuracy: 68.59436097962543\n",
      "Iteration: 6460. Loss: 0.6337665319442749. Accuracy: 69.21177196954106\n",
      "Iteration: 6470. Loss: 0.5492583513259888. Accuracy: 68.26507511833711\n",
      "Iteration: 6480. Loss: 0.684112012386322. Accuracy: 68.57378061329491\n",
      "Iteration: 6490. Loss: 0.568023145198822. Accuracy: 68.63552171228648\n",
      "Iteration: 6500. Loss: 0.8676576614379883. Accuracy: 67.8740481580572\n",
      "Epoch:  101\n",
      "Iteration: 6510. Loss: 0.6287826299667358. Accuracy: 68.10043218769295\n",
      "Iteration: 6520. Loss: 0.6230859160423279. Accuracy: 68.8619057419222\n",
      "Iteration: 6530. Loss: 0.5873902440071106. Accuracy: 69.37641490018522\n",
      "Iteration: 6540. Loss: 0.5275882482528687. Accuracy: 68.88248610825272\n",
      "Iteration: 6550. Loss: 0.6076620817184448. Accuracy: 69.41757563284627\n",
      "Iteration: 6560. Loss: 0.5749420523643494. Accuracy: 69.29409343486314\n",
      "Epoch:  102\n",
      "Iteration: 6570. Loss: 0.6033587455749512. Accuracy: 69.08828977155794\n",
      "Iteration: 6580. Loss: 0.5560178756713867. Accuracy: 69.33525416752418\n",
      "Iteration: 6590. Loss: 0.6071804761886597. Accuracy: 68.94422720724428\n",
      "Iteration: 6600. Loss: 0.5944039821624756. Accuracy: 68.98538793990534\n",
      "Iteration: 6610. Loss: 0.6322832107543945. Accuracy: 68.94422720724428\n",
      "Iteration: 6620. Loss: 0.6274197101593018. Accuracy: 69.2529327022021\n",
      "Iteration: 6630. Loss: 1.025871753692627. Accuracy: 67.9563696233793\n",
      "Epoch:  103\n",
      "Iteration: 6640. Loss: 0.5290986895561218. Accuracy: 68.36797694998971\n",
      "Iteration: 6650. Loss: 0.5973442792892456. Accuracy: 68.7590039102696\n",
      "Iteration: 6660. Loss: 0.47614431381225586. Accuracy: 70.01440625643137\n",
      "Iteration: 6670. Loss: 0.5375052094459534. Accuracy: 68.24449475200659\n",
      "Iteration: 6680. Loss: 0.585545003414154. Accuracy: 69.08828977155794\n",
      "Iteration: 6690. Loss: 0.5136956572532654. Accuracy: 68.73842354393908\n",
      "Epoch:  104\n",
      "Iteration: 6700. Loss: 0.6107907295227051. Accuracy: 69.08828977155794\n",
      "Iteration: 6710. Loss: 0.579059362411499. Accuracy: 69.2529327022021\n",
      "Iteration: 6720. Loss: 0.6634441018104553. Accuracy: 69.17061123688002\n",
      "Iteration: 6730. Loss: 0.6090899109840393. Accuracy: 69.10887013788846\n",
      "Iteration: 6740. Loss: 0.5417182445526123. Accuracy: 68.94422720724428\n",
      "Iteration: 6750. Loss: 0.5692220330238342. Accuracy: 69.60279892982095\n",
      "Iteration: 6760. Loss: 1.0676696300506592. Accuracy: 67.81230705906565\n",
      "Epoch:  105\n",
      "Iteration: 6770. Loss: 0.6690018773078918. Accuracy: 68.656102078617\n",
      "Iteration: 6780. Loss: 0.5708237886428833. Accuracy: 69.23235233587158\n",
      "Iteration: 6790. Loss: 0.5192699432373047. Accuracy: 69.12945050421898\n",
      "Iteration: 6800. Loss: 0.6109777092933655. Accuracy: 68.84132537559168\n",
      "Iteration: 6810. Loss: 0.5512815117835999. Accuracy: 68.8619057419222\n",
      "Iteration: 6820. Loss: 0.5892017483711243. Accuracy: 69.29409343486314\n",
      "Epoch:  106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6830. Loss: 0.5747465491294861. Accuracy: 69.33525416752418\n",
      "Iteration: 6840. Loss: 0.5981569290161133. Accuracy: 68.84132537559168\n",
      "Iteration: 6850. Loss: 0.5550256371498108. Accuracy: 69.4587363655073\n",
      "Iteration: 6860. Loss: 0.518992006778717. Accuracy: 69.41757563284627\n",
      "Iteration: 6870. Loss: 0.4920531213283539. Accuracy: 69.19119160321054\n",
      "Iteration: 6880. Loss: 0.5669877529144287. Accuracy: 69.19119160321054\n",
      "Iteration: 6890. Loss: 0.8043858408927917. Accuracy: 69.37641490018522\n",
      "Epoch:  107\n",
      "Iteration: 6900. Loss: 0.5085447430610657. Accuracy: 69.64395966248199\n",
      "Iteration: 6910. Loss: 0.48484498262405396. Accuracy: 69.82918295945667\n",
      "Iteration: 6920. Loss: 0.4931102395057678. Accuracy: 70.15846882074501\n",
      "Iteration: 6930. Loss: 0.6152799129486084. Accuracy: 69.39699526651575\n",
      "Iteration: 6940. Loss: 0.5890650749206543. Accuracy: 69.0471290388969\n",
      "Iteration: 6950. Loss: 0.693462610244751. Accuracy: 68.82074500926116\n",
      "Epoch:  108\n",
      "Iteration: 6960. Loss: 0.6164639592170715. Accuracy: 69.21177196954106\n",
      "Iteration: 6970. Loss: 0.7017744779586792. Accuracy: 69.0471290388969\n",
      "Iteration: 6980. Loss: 0.6104360222816467. Accuracy: 69.58221856349043\n",
      "Iteration: 6990. Loss: 0.5855711102485657. Accuracy: 69.17061123688002\n",
      "Iteration: 7000. Loss: 0.5264238119125366. Accuracy: 69.4587363655073\n",
      "Iteration: 7010. Loss: 0.5489027500152588. Accuracy: 69.33525416752418\n",
      "Iteration: 7020. Loss: 0.9040921926498413. Accuracy: 68.94422720724428\n",
      "Epoch:  109\n",
      "Iteration: 7030. Loss: 0.6581767797470093. Accuracy: 68.61494134595596\n",
      "Iteration: 7040. Loss: 0.568001925945282. Accuracy: 69.80860259312615\n",
      "Iteration: 7050. Loss: 0.5191332101821899. Accuracy: 69.43815599917679\n",
      "Iteration: 7060. Loss: 0.6127145290374756. Accuracy: 69.66454002881251\n",
      "Iteration: 7070. Loss: 0.5861457586288452. Accuracy: 69.70570076147355\n",
      "Iteration: 7080. Loss: 0.5763072967529297. Accuracy: 69.66454002881251\n",
      "Epoch:  110\n",
      "Iteration: 7090. Loss: 0.5680912137031555. Accuracy: 69.4587363655073\n",
      "Iteration: 7100. Loss: 0.5901010036468506. Accuracy: 68.90306647458324\n",
      "Iteration: 7110. Loss: 0.4777117371559143. Accuracy: 69.58221856349043\n",
      "Iteration: 7120. Loss: 0.465194433927536. Accuracy: 69.47931673183783\n",
      "Iteration: 7130. Loss: 0.5422183275222778. Accuracy: 69.91150442477876\n",
      "Iteration: 7140. Loss: 0.5525276064872742. Accuracy: 69.93208479110928\n",
      "Iteration: 7150. Loss: 0.9210568070411682. Accuracy: 69.08828977155794\n",
      "Epoch:  111\n",
      "Iteration: 7160. Loss: 0.559339165687561. Accuracy: 69.3558345338547\n",
      "Iteration: 7170. Loss: 0.6088014245033264. Accuracy: 69.49989709816835\n",
      "Iteration: 7180. Loss: 0.5906681418418884. Accuracy: 69.4587363655073\n",
      "Iteration: 7190. Loss: 0.5870838165283203. Accuracy: 69.21177196954106\n",
      "Iteration: 7200. Loss: 0.5426821112632751. Accuracy: 69.78802222679563\n",
      "Iteration: 7210. Loss: 0.5412847399711609. Accuracy: 69.89092405844823\n",
      "Epoch:  112\n",
      "Iteration: 7220. Loss: 0.5826778411865234. Accuracy: 69.29409343486314\n",
      "Iteration: 7230. Loss: 0.5285007953643799. Accuracy: 69.06770940522742\n",
      "Iteration: 7240. Loss: 0.5451551079750061. Accuracy: 69.8497633257872\n",
      "Iteration: 7250. Loss: 0.49078133702278137. Accuracy: 69.43815599917679\n",
      "Iteration: 7260. Loss: 0.5462998151779175. Accuracy: 69.66454002881251\n",
      "Iteration: 7270. Loss: 0.5577614903450012. Accuracy: 70.26137065239762\n",
      "Iteration: 7280. Loss: 0.8820732235908508. Accuracy: 69.3558345338547\n",
      "Epoch:  113\n",
      "Iteration: 7290. Loss: 0.5611413717269897. Accuracy: 69.2529327022021\n",
      "Iteration: 7300. Loss: 0.49097463488578796. Accuracy: 69.1500308705495\n",
      "Iteration: 7310. Loss: 0.5203081965446472. Accuracy: 69.54105783082939\n",
      "Iteration: 7320. Loss: 0.5705986618995667. Accuracy: 69.80860259312615\n",
      "Iteration: 7330. Loss: 0.5567730069160461. Accuracy: 69.72628112780407\n",
      "Iteration: 7340. Loss: 0.5592126250267029. Accuracy: 69.4587363655073\n",
      "Epoch:  114\n",
      "Iteration: 7350. Loss: 0.5672594308853149. Accuracy: 70.17904918707553\n",
      "Iteration: 7360. Loss: 0.5575747489929199. Accuracy: 69.33525416752418\n",
      "Iteration: 7370. Loss: 0.5648337006568909. Accuracy: 70.40543321671126\n",
      "Iteration: 7380. Loss: 0.5132514238357544. Accuracy: 69.76744186046511\n",
      "Iteration: 7390. Loss: 0.5410587787628174. Accuracy: 69.1500308705495\n",
      "Iteration: 7400. Loss: 0.47298336029052734. Accuracy: 69.49989709816835\n",
      "Iteration: 7410. Loss: 0.9957916736602783. Accuracy: 69.12945050421898\n",
      "Epoch:  115\n",
      "Iteration: 7420. Loss: 0.6417480111122131. Accuracy: 69.56163819715991\n",
      "Iteration: 7430. Loss: 0.42560189962387085. Accuracy: 69.8497633257872\n",
      "Iteration: 7440. Loss: 0.5152861475944519. Accuracy: 69.29409343486314\n",
      "Iteration: 7450. Loss: 0.6087814569473267. Accuracy: 70.11730808808397\n",
      "Iteration: 7460. Loss: 0.5657597184181213. Accuracy: 69.78802222679563\n",
      "Iteration: 7470. Loss: 0.6282579302787781. Accuracy: 69.62337929615147\n",
      "Epoch:  116\n",
      "Iteration: 7480. Loss: 0.4690167307853699. Accuracy: 69.23235233587158\n",
      "Iteration: 7490. Loss: 0.6058313250541687. Accuracy: 69.93208479110928\n",
      "Iteration: 7500. Loss: 0.5380613207817078. Accuracy: 70.46717431570282\n",
      "Iteration: 7510. Loss: 0.5698531866073608. Accuracy: 69.31467380119366\n",
      "Iteration: 7520. Loss: 0.5310968160629272. Accuracy: 69.99382589010084\n",
      "Iteration: 7530. Loss: 0.5420398116111755. Accuracy: 69.37641490018522\n",
      "Iteration: 7540. Loss: 1.101344108581543. Accuracy: 68.53261988063387\n",
      "Epoch:  117\n",
      "Iteration: 7550. Loss: 0.5409544110298157. Accuracy: 69.91150442477876\n",
      "Iteration: 7560. Loss: 0.5182744860649109. Accuracy: 70.42601358304178\n",
      "Iteration: 7570. Loss: 0.5829534530639648. Accuracy: 69.93208479110928\n",
      "Iteration: 7580. Loss: 0.5903736352920532. Accuracy: 70.03498662276189\n",
      "Iteration: 7590. Loss: 0.5470960736274719. Accuracy: 70.01440625643137\n",
      "Iteration: 7600. Loss: 0.517833948135376. Accuracy: 69.33525416752418\n",
      "Epoch:  118\n",
      "Iteration: 7610. Loss: 0.530702531337738. Accuracy: 69.78802222679563\n",
      "Iteration: 7620. Loss: 0.5383664965629578. Accuracy: 70.09672772175345\n",
      "Iteration: 7630. Loss: 0.515579104423523. Accuracy: 69.43815599917679\n",
      "Iteration: 7640. Loss: 0.58140629529953. Accuracy: 70.22020991973658\n",
      "Iteration: 7650. Loss: 0.5097545981407166. Accuracy: 69.82918295945667\n",
      "Iteration: 7660. Loss: 0.5020508766174316. Accuracy: 69.8497633257872\n",
      "Iteration: 7670. Loss: 1.0302250385284424. Accuracy: 69.47931673183783\n",
      "Epoch:  119\n",
      "Iteration: 7680. Loss: 0.4860709607601166. Accuracy: 70.28195101872814\n",
      "Iteration: 7690. Loss: 0.5339460372924805. Accuracy: 69.54105783082939\n",
      "Iteration: 7700. Loss: 0.6611784100532532. Accuracy: 70.11730808808397\n",
      "Iteration: 7710. Loss: 0.540693998336792. Accuracy: 70.09672772175345\n",
      "Iteration: 7720. Loss: 0.5059728026390076. Accuracy: 69.58221856349043\n",
      "Iteration: 7730. Loss: 0.5218983292579651. Accuracy: 70.61123688001646\n",
      "Epoch:  120\n",
      "Iteration: 7740. Loss: 0.5553712248802185. Accuracy: 70.28195101872814\n",
      "Iteration: 7750. Loss: 0.5433809161186218. Accuracy: 70.1378884544145\n",
      "Iteration: 7760. Loss: 0.4632825255393982. Accuracy: 70.42601358304178\n",
      "Iteration: 7770. Loss: 0.5729888677597046. Accuracy: 70.32311175138918\n",
      "Iteration: 7780. Loss: 0.5611644983291626. Accuracy: 70.15846882074501\n",
      "Iteration: 7790. Loss: 0.4421927332878113. Accuracy: 69.91150442477876\n",
      "Iteration: 7800. Loss: 0.830488383769989. Accuracy: 69.99382589010084\n",
      "Epoch:  121\n",
      "Iteration: 7810. Loss: 0.5257643461227417. Accuracy: 70.19962955340606\n",
      "Iteration: 7820. Loss: 0.5950504541397095. Accuracy: 70.09672772175345\n",
      "Iteration: 7830. Loss: 0.553108811378479. Accuracy: 69.9526651574398\n",
      "Iteration: 7840. Loss: 0.5285289287567139. Accuracy: 70.38485285038074\n",
      "Iteration: 7850. Loss: 0.4455249607563019. Accuracy: 70.4465939493723\n",
      "Iteration: 7860. Loss: 0.5834909081459045. Accuracy: 70.11730808808397\n",
      "Epoch:  122\n",
      "Iteration: 7870. Loss: 0.4639700949192047. Accuracy: 69.87034369211771\n",
      "Iteration: 7880. Loss: 0.5146238803863525. Accuracy: 69.49989709816835\n",
      "Iteration: 7890. Loss: 0.494601845741272. Accuracy: 70.22020991973658\n",
      "Iteration: 7900. Loss: 0.5066304802894592. Accuracy: 70.03498662276189\n",
      "Iteration: 7910. Loss: 0.5992468595504761. Accuracy: 70.1378884544145\n",
      "Iteration: 7920. Loss: 0.42256370186805725. Accuracy: 70.79646017699115\n",
      "Iteration: 7930. Loss: 1.4059584140777588. Accuracy: 69.0471290388969\n",
      "Epoch:  123\n",
      "Iteration: 7940. Loss: 0.5312213897705078. Accuracy: 70.01440625643137\n",
      "Iteration: 7950. Loss: 0.49968379735946655. Accuracy: 69.74686149413459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7960. Loss: 0.478706419467926. Accuracy: 70.57007614735542\n",
      "Iteration: 7970. Loss: 0.4767226576805115. Accuracy: 70.67297797900802\n",
      "Iteration: 7980. Loss: 0.4509316384792328. Accuracy: 70.4465939493723\n",
      "Iteration: 7990. Loss: 0.53708416223526. Accuracy: 70.69355834533854\n",
      "Epoch:  124\n",
      "Iteration: 8000. Loss: 0.4796229600906372. Accuracy: 70.01440625643137\n",
      "Iteration: 8010. Loss: 0.4738154709339142. Accuracy: 70.67297797900802\n",
      "Iteration: 8020. Loss: 0.5514525771141052. Accuracy: 70.07614735542293\n",
      "Iteration: 8030. Loss: 0.5478172898292542. Accuracy: 70.50833504836386\n",
      "Iteration: 8040. Loss: 0.5156094431877136. Accuracy: 70.46717431570282\n",
      "Iteration: 8050. Loss: 0.5353542566299438. Accuracy: 70.71413871166907\n",
      "Iteration: 8060. Loss: 1.0205767154693604. Accuracy: 69.10887013788846\n",
      "Epoch:  125\n",
      "Iteration: 8070. Loss: 0.5499420166015625. Accuracy: 70.4465939493723\n",
      "Iteration: 8080. Loss: 0.4589061439037323. Accuracy: 70.30253138505866\n",
      "Iteration: 8090. Loss: 0.5819308757781982. Accuracy: 70.63181724634698\n",
      "Iteration: 8100. Loss: 0.5283288359642029. Accuracy: 70.09672772175345\n",
      "Iteration: 8110. Loss: 0.565086305141449. Accuracy: 70.36427248405022\n",
      "Iteration: 8120. Loss: 0.5153779983520508. Accuracy: 70.81704054332167\n",
      "Epoch:  126\n",
      "Iteration: 8130. Loss: 0.5088618993759155. Accuracy: 69.8497633257872\n",
      "Iteration: 8140. Loss: 0.5379151701927185. Accuracy: 70.69355834533854\n",
      "Iteration: 8150. Loss: 0.5499546527862549. Accuracy: 69.8497633257872\n",
      "Iteration: 8160. Loss: 0.5177170038223267. Accuracy: 71.10516567194897\n",
      "Iteration: 8170. Loss: 0.6097968816757202. Accuracy: 70.30253138505866\n",
      "Iteration: 8180. Loss: 0.5824980139732361. Accuracy: 70.48775468203334\n",
      "Iteration: 8190. Loss: 1.1318334341049194. Accuracy: 69.80860259312615\n",
      "Epoch:  127\n",
      "Iteration: 8200. Loss: 0.47225087881088257. Accuracy: 70.63181724634698\n",
      "Iteration: 8210. Loss: 0.49449998140335083. Accuracy: 71.20806750360157\n",
      "Iteration: 8220. Loss: 0.525804340839386. Accuracy: 70.15846882074501\n",
      "Iteration: 8230. Loss: 0.5120342969894409. Accuracy: 70.4465939493723\n",
      "Iteration: 8240. Loss: 0.4686184227466583. Accuracy: 70.52891541469438\n",
      "Iteration: 8250. Loss: 0.5651114583015442. Accuracy: 70.59065651368594\n",
      "Epoch:  128\n",
      "Iteration: 8260. Loss: 0.581831693649292. Accuracy: 70.40543321671126\n",
      "Iteration: 8270. Loss: 0.4318687319755554. Accuracy: 70.07614735542293\n",
      "Iteration: 8280. Loss: 0.5871233344078064. Accuracy: 70.6523976126775\n",
      "Iteration: 8290. Loss: 0.5028050541877747. Accuracy: 70.46717431570282\n",
      "Iteration: 8300. Loss: 0.4837433993816376. Accuracy: 70.42601358304178\n",
      "Iteration: 8310. Loss: 0.5271456837654114. Accuracy: 70.48775468203334\n",
      "Iteration: 8320. Loss: 1.3922951221466064. Accuracy: 69.58221856349043\n",
      "Epoch:  129\n",
      "Iteration: 8330. Loss: 0.4798629879951477. Accuracy: 70.69355834533854\n",
      "Iteration: 8340. Loss: 0.5156728029251099. Accuracy: 70.42601358304178\n",
      "Iteration: 8350. Loss: 0.4290963113307953. Accuracy: 70.38485285038074\n",
      "Iteration: 8360. Loss: 0.42070484161376953. Accuracy: 70.48775468203334\n",
      "Iteration: 8370. Loss: 0.5170698761940002. Accuracy: 70.6523976126775\n",
      "Iteration: 8380. Loss: 0.5767855644226074. Accuracy: 70.59065651368594\n",
      "Epoch:  130\n",
      "Iteration: 8390. Loss: 0.4679882228374481. Accuracy: 70.1378884544145\n",
      "Iteration: 8400. Loss: 0.5346283912658691. Accuracy: 70.2407902860671\n",
      "Iteration: 8410. Loss: 0.45476898550987244. Accuracy: 70.89936200864375\n",
      "Iteration: 8420. Loss: 0.4422767758369446. Accuracy: 70.42601358304178\n",
      "Iteration: 8430. Loss: 0.5163620710372925. Accuracy: 70.87878164231323\n",
      "Iteration: 8440. Loss: 0.5285278558731079. Accuracy: 70.94052274130479\n",
      "Iteration: 8450. Loss: 0.822359025478363. Accuracy: 69.60279892982095\n",
      "Epoch:  131\n",
      "Iteration: 8460. Loss: 0.5494177341461182. Accuracy: 70.40543321671126\n",
      "Iteration: 8470. Loss: 0.46371087431907654. Accuracy: 70.36427248405022\n",
      "Iteration: 8480. Loss: 0.5690878033638. Accuracy: 70.83762090965219\n",
      "Iteration: 8490. Loss: 0.5298694372177124. Accuracy: 70.94052274130479\n",
      "Iteration: 8500. Loss: 0.485214501619339. Accuracy: 70.59065651368594\n",
      "Iteration: 8510. Loss: 0.5721592307090759. Accuracy: 71.20806750360157\n",
      "Epoch:  132\n",
      "Iteration: 8520. Loss: 0.42928609251976013. Accuracy: 71.45503189956781\n",
      "Iteration: 8530. Loss: 0.48774316906929016. Accuracy: 70.50833504836386\n",
      "Iteration: 8540. Loss: 0.44077250361442566. Accuracy: 70.69355834533854\n",
      "Iteration: 8550. Loss: 0.47653523087501526. Accuracy: 70.87878164231323\n",
      "Iteration: 8560. Loss: 0.5368236899375916. Accuracy: 70.96110310763531\n",
      "Iteration: 8570. Loss: 0.5439038276672363. Accuracy: 70.48775468203334\n",
      "Iteration: 8580. Loss: 0.6794242858886719. Accuracy: 70.50833504836386\n",
      "Epoch:  133\n",
      "Iteration: 8590. Loss: 0.5163130760192871. Accuracy: 70.38485285038074\n",
      "Iteration: 8600. Loss: 0.5244215726852417. Accuracy: 71.00226384029635\n",
      "Iteration: 8610. Loss: 0.5236849188804626. Accuracy: 71.00226384029635\n",
      "Iteration: 8620. Loss: 0.4001757800579071. Accuracy: 71.41387116690677\n",
      "Iteration: 8630. Loss: 0.5746057629585266. Accuracy: 71.06400493928793\n",
      "Iteration: 8640. Loss: 0.5394846200942993. Accuracy: 71.12574603827949\n",
      "Epoch:  134\n",
      "Iteration: 8650. Loss: 0.48494455218315125. Accuracy: 70.17904918707553\n",
      "Iteration: 8660. Loss: 0.4723564088344574. Accuracy: 70.59065651368594\n",
      "Iteration: 8670. Loss: 0.3912060558795929. Accuracy: 71.22864786993209\n",
      "Iteration: 8680. Loss: 0.5300897359848022. Accuracy: 71.61967483021198\n",
      "Iteration: 8690. Loss: 0.49783915281295776. Accuracy: 71.10516567194897\n",
      "Iteration: 8700. Loss: 0.49744561314582825. Accuracy: 70.52891541469438\n",
      "Iteration: 8710. Loss: 0.6928099393844604. Accuracy: 70.19962955340606\n",
      "Epoch:  135\n",
      "Iteration: 8720. Loss: 0.5380904674530029. Accuracy: 70.94052274130479\n",
      "Iteration: 8730. Loss: 0.665799081325531. Accuracy: 70.69355834533854\n",
      "Iteration: 8740. Loss: 0.5036227107048035. Accuracy: 70.83762090965219\n",
      "Iteration: 8750. Loss: 0.49596598744392395. Accuracy: 71.39329080057625\n",
      "Iteration: 8760. Loss: 0.4840133786201477. Accuracy: 71.47561226589833\n",
      "Iteration: 8770. Loss: 0.4665078818798065. Accuracy: 70.50833504836386\n",
      "Epoch:  136\n",
      "Iteration: 8780. Loss: 0.49394771456718445. Accuracy: 70.2407902860671\n",
      "Iteration: 8790. Loss: 0.4686722457408905. Accuracy: 71.20806750360157\n",
      "Iteration: 8800. Loss: 0.42323195934295654. Accuracy: 70.85820127598271\n",
      "Iteration: 8810. Loss: 0.4744148850440979. Accuracy: 70.73471907799959\n",
      "Iteration: 8820. Loss: 0.4948863685131073. Accuracy: 71.6402551965425\n",
      "Iteration: 8830. Loss: 0.47879526019096375. Accuracy: 72.134183988475\n",
      "Iteration: 8840. Loss: 0.6515557169914246. Accuracy: 71.12574603827949\n",
      "Epoch:  137\n",
      "Iteration: 8850. Loss: 0.5052204132080078. Accuracy: 70.61123688001646\n",
      "Iteration: 8860. Loss: 0.43892374634742737. Accuracy: 70.42601358304178\n",
      "Iteration: 8870. Loss: 0.5893895030021667. Accuracy: 70.48775468203334\n",
      "Iteration: 8880. Loss: 0.515397310256958. Accuracy: 71.06400493928793\n",
      "Iteration: 8890. Loss: 0.5021552443504333. Accuracy: 70.96110310763531\n",
      "Iteration: 8900. Loss: 0.49342650175094604. Accuracy: 71.24922823626261\n",
      "Epoch:  138\n",
      "Iteration: 8910. Loss: 0.38320717215538025. Accuracy: 70.71413871166907\n",
      "Iteration: 8920. Loss: 0.5853314995765686. Accuracy: 71.31096933525417\n",
      "Iteration: 8930. Loss: 0.488730788230896. Accuracy: 71.12574603827949\n",
      "Iteration: 8940. Loss: 0.5483587384223938. Accuracy: 70.46717431570282\n",
      "Iteration: 8950. Loss: 0.4950326681137085. Accuracy: 70.69355834533854\n",
      "Iteration: 8960. Loss: 0.5053573846817017. Accuracy: 71.45503189956781\n",
      "Iteration: 8970. Loss: 0.9710970520973206. Accuracy: 70.07614735542293\n",
      "Epoch:  139\n",
      "Iteration: 8980. Loss: 0.5581142902374268. Accuracy: 70.67297797900802\n",
      "Iteration: 8990. Loss: 0.46759042143821716. Accuracy: 71.24922823626261\n",
      "Iteration: 9000. Loss: 0.517754852771759. Accuracy: 71.00226384029635\n",
      "Iteration: 9010. Loss: 0.4161492884159088. Accuracy: 71.76373739452562\n",
      "Iteration: 9020. Loss: 0.46333789825439453. Accuracy: 71.7431570281951\n",
      "Iteration: 9030. Loss: 0.45712733268737793. Accuracy: 71.78431776085614\n",
      "Epoch:  140\n",
      "Iteration: 9040. Loss: 0.48195475339889526. Accuracy: 70.83762090965219\n",
      "Iteration: 9050. Loss: 0.4523693919181824. Accuracy: 71.14632640461001\n",
      "Iteration: 9060. Loss: 0.49491456151008606. Accuracy: 71.08458530561845\n",
      "Iteration: 9070. Loss: 0.5307167172431946. Accuracy: 70.96110310763531\n",
      "Iteration: 9080. Loss: 0.5244978070259094. Accuracy: 70.61123688001646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9090. Loss: 0.5159211754798889. Accuracy: 71.78431776085614\n",
      "Iteration: 9100. Loss: 0.9923399686813354. Accuracy: 69.93208479110928\n",
      "Epoch:  141\n",
      "Iteration: 9110. Loss: 0.555132269859314. Accuracy: 71.04342457295739\n",
      "Iteration: 9120. Loss: 0.4838738441467285. Accuracy: 71.39329080057625\n",
      "Iteration: 9130. Loss: 0.5324346423149109. Accuracy: 70.81704054332167\n",
      "Iteration: 9140. Loss: 0.4570293128490448. Accuracy: 72.03128215682239\n",
      "Iteration: 9150. Loss: 0.5364232659339905. Accuracy: 70.89936200864375\n",
      "Iteration: 9160. Loss: 0.4997212290763855. Accuracy: 71.22864786993209\n",
      "Epoch:  142\n",
      "Iteration: 9170. Loss: 0.5324070453643799. Accuracy: 70.89936200864375\n",
      "Iteration: 9180. Loss: 0.5972191691398621. Accuracy: 71.82547849351718\n",
      "Iteration: 9190. Loss: 0.48243647813796997. Accuracy: 71.16690677094053\n",
      "Iteration: 9200. Loss: 0.4916755259037018. Accuracy: 71.66083556287302\n",
      "Iteration: 9210. Loss: 0.42931878566741943. Accuracy: 71.57851409755094\n",
      "Iteration: 9220. Loss: 0.5208964943885803. Accuracy: 71.16690677094053\n",
      "Iteration: 9230. Loss: 0.7348617315292358. Accuracy: 70.11730808808397\n",
      "Epoch:  143\n",
      "Iteration: 9240. Loss: 0.44623473286628723. Accuracy: 71.00226384029635\n",
      "Iteration: 9250. Loss: 0.4477204382419586. Accuracy: 71.18748713727105\n",
      "Iteration: 9260. Loss: 0.4792414903640747. Accuracy: 71.33154970158469\n",
      "Iteration: 9270. Loss: 0.4610588550567627. Accuracy: 70.89936200864375\n",
      "Iteration: 9280. Loss: 0.5255782008171082. Accuracy: 70.98168347396583\n",
      "Iteration: 9290. Loss: 0.4546946585178375. Accuracy: 71.47561226589833\n",
      "Epoch:  144\n",
      "Iteration: 9300. Loss: 0.4593900442123413. Accuracy: 69.91150442477876\n",
      "Iteration: 9310. Loss: 0.4612479507923126. Accuracy: 71.18748713727105\n",
      "Iteration: 9320. Loss: 0.41440850496292114. Accuracy: 71.33154970158469\n",
      "Iteration: 9330. Loss: 0.43171489238739014. Accuracy: 71.06400493928793\n",
      "Iteration: 9340. Loss: 0.37582632899284363. Accuracy: 70.98168347396583\n",
      "Iteration: 9350. Loss: 0.4607311487197876. Accuracy: 71.24922823626261\n",
      "Iteration: 9360. Loss: 1.1692581176757812. Accuracy: 70.09672772175345\n",
      "Epoch:  145\n",
      "Iteration: 9370. Loss: 0.4159582257270813. Accuracy: 71.10516567194897\n",
      "Iteration: 9380. Loss: 0.42923298478126526. Accuracy: 70.79646017699115\n",
      "Iteration: 9390. Loss: 0.4465191662311554. Accuracy: 71.39329080057625\n",
      "Iteration: 9400. Loss: 0.5575454831123352. Accuracy: 71.22864786993209\n",
      "Iteration: 9410. Loss: 0.4423665404319763. Accuracy: 71.39329080057625\n",
      "Iteration: 9420. Loss: 0.466567724943161. Accuracy: 70.98168347396583\n",
      "Epoch:  146\n",
      "Iteration: 9430. Loss: 0.4677041172981262. Accuracy: 70.67297797900802\n",
      "Iteration: 9440. Loss: 0.5203552842140198. Accuracy: 70.79646017699115\n",
      "Iteration: 9450. Loss: 0.49616095423698425. Accuracy: 71.16690677094053\n",
      "Iteration: 9460. Loss: 0.45874324440956116. Accuracy: 71.4344515332373\n",
      "Iteration: 9470. Loss: 0.4766172170639038. Accuracy: 71.61967483021198\n",
      "Iteration: 9480. Loss: 0.5185803174972534. Accuracy: 70.73471907799959\n",
      "Iteration: 9490. Loss: 1.0521107912063599. Accuracy: 71.49619263222885\n",
      "Epoch:  147\n",
      "Iteration: 9500. Loss: 0.42476728558540344. Accuracy: 71.29038896892365\n",
      "Iteration: 9510. Loss: 0.45004263520240784. Accuracy: 71.37271043424573\n",
      "Iteration: 9520. Loss: 0.4589996933937073. Accuracy: 71.31096933525417\n",
      "Iteration: 9530. Loss: 0.45573821663856506. Accuracy: 71.68141592920354\n",
      "Iteration: 9540. Loss: 0.525501012802124. Accuracy: 70.91994237497427\n",
      "Iteration: 9550. Loss: 0.4432468116283417. Accuracy: 71.59909446388146\n",
      "Epoch:  148\n",
      "Iteration: 9560. Loss: 0.5610598921775818. Accuracy: 71.16690677094053\n",
      "Iteration: 9570. Loss: 0.4485205113887787. Accuracy: 71.10516567194897\n",
      "Iteration: 9580. Loss: 0.5972587466239929. Accuracy: 71.86663922617822\n",
      "Iteration: 9590. Loss: 0.4725700914859772. Accuracy: 71.55793373122042\n",
      "Iteration: 9600. Loss: 0.4694041907787323. Accuracy: 71.24922823626261\n",
      "Iteration: 9610. Loss: 0.5247434973716736. Accuracy: 71.47561226589833\n",
      "Iteration: 9620. Loss: 0.8658844232559204. Accuracy: 70.48775468203334\n",
      "Epoch:  149\n",
      "Iteration: 9630. Loss: 0.5091893672943115. Accuracy: 71.12574603827949\n",
      "Iteration: 9640. Loss: 0.497475266456604. Accuracy: 71.22864786993209\n",
      "Iteration: 9650. Loss: 0.45318838953971863. Accuracy: 71.47561226589833\n",
      "Iteration: 9660. Loss: 0.4012325406074524. Accuracy: 71.80489812718666\n",
      "Iteration: 9670. Loss: 0.45608633756637573. Accuracy: 71.76373739452562\n",
      "Iteration: 9680. Loss: 0.4714505076408386. Accuracy: 71.33154970158469\n",
      "Epoch:  150\n",
      "Iteration: 9690. Loss: 0.5144458413124084. Accuracy: 70.96110310763531\n",
      "Iteration: 9700. Loss: 0.4456530213356018. Accuracy: 71.24922823626261\n",
      "Iteration: 9710. Loss: 0.4531491994857788. Accuracy: 71.78431776085614\n",
      "Iteration: 9720. Loss: 0.4552028775215149. Accuracy: 71.35213006791521\n",
      "Iteration: 9730. Loss: 0.4527934193611145. Accuracy: 71.45503189956781\n",
      "Iteration: 9740. Loss: 0.4366743564605713. Accuracy: 71.78431776085614\n",
      "Iteration: 9750. Loss: 1.0085943937301636. Accuracy: 70.2407902860671\n",
      "Epoch:  151\n",
      "Iteration: 9760. Loss: 0.46593552827835083. Accuracy: 71.16690677094053\n",
      "Iteration: 9770. Loss: 0.45319893956184387. Accuracy: 71.57851409755094\n",
      "Iteration: 9780. Loss: 0.42417117953300476. Accuracy: 71.59909446388146\n",
      "Iteration: 9790. Loss: 0.45110082626342773. Accuracy: 71.76373739452562\n",
      "Iteration: 9800. Loss: 0.5104249119758606. Accuracy: 71.9489606915003\n",
      "Iteration: 9810. Loss: 0.48844385147094727. Accuracy: 71.80489812718666\n",
      "Epoch:  152\n",
      "Iteration: 9820. Loss: 0.557161808013916. Accuracy: 71.31096933525417\n",
      "Iteration: 9830. Loss: 0.5105173587799072. Accuracy: 71.82547849351718\n",
      "Iteration: 9840. Loss: 0.556525707244873. Accuracy: 71.88721959250874\n",
      "Iteration: 9850. Loss: 0.4947142004966736. Accuracy: 71.02284420662687\n",
      "Iteration: 9860. Loss: 0.4335014820098877. Accuracy: 71.61967483021198\n",
      "Iteration: 9870. Loss: 0.5594413876533508. Accuracy: 71.37271043424573\n",
      "Iteration: 9880. Loss: 1.3136630058288574. Accuracy: 70.83762090965219\n",
      "Epoch:  153\n",
      "Iteration: 9890. Loss: 0.5244871377944946. Accuracy: 72.2370858201276\n",
      "Iteration: 9900. Loss: 0.4592446982860565. Accuracy: 71.90779995883926\n",
      "Iteration: 9910. Loss: 0.37176892161369324. Accuracy: 72.29882691911916\n",
      "Iteration: 9920. Loss: 0.5180423855781555. Accuracy: 72.56637168141593\n",
      "Iteration: 9930. Loss: 0.5022456645965576. Accuracy: 71.80489812718666\n",
      "Iteration: 9940. Loss: 0.537372350692749. Accuracy: 71.59909446388146\n",
      "Epoch:  154\n",
      "Iteration: 9950. Loss: 0.40007272362709045. Accuracy: 71.00226384029635\n",
      "Iteration: 9960. Loss: 0.4438878893852234. Accuracy: 71.4344515332373\n",
      "Iteration: 9970. Loss: 0.44266846776008606. Accuracy: 71.8460588598477\n",
      "Iteration: 9980. Loss: 0.4755142331123352. Accuracy: 71.88721959250874\n",
      "Iteration: 9990. Loss: 0.4921663999557495. Accuracy: 72.01070179049186\n",
      "Iteration: 10000. Loss: 0.409962922334671. Accuracy: 71.90779995883926\n",
      "Iteration: 10010. Loss: 1.0803810358047485. Accuracy: 69.9526651574398\n",
      "Epoch:  155\n",
      "Iteration: 10020. Loss: 0.5913943648338318. Accuracy: 71.24922823626261\n",
      "Iteration: 10030. Loss: 0.5351381301879883. Accuracy: 71.39329080057625\n",
      "Iteration: 10040. Loss: 0.37411314249038696. Accuracy: 72.19592508746656\n",
      "Iteration: 10050. Loss: 0.4301643371582031. Accuracy: 71.78431776085614\n",
      "Iteration: 10060. Loss: 0.5046964883804321. Accuracy: 72.40172875077177\n",
      "Iteration: 10070. Loss: 0.510854184627533. Accuracy: 72.42230911710229\n",
      "Epoch:  156\n",
      "Iteration: 10080. Loss: 0.4332319498062134. Accuracy: 71.39329080057625\n",
      "Iteration: 10090. Loss: 0.5245051980018616. Accuracy: 72.46346984976333\n",
      "Iteration: 10100. Loss: 0.5078754425048828. Accuracy: 72.21650545379708\n",
      "Iteration: 10110. Loss: 0.4231656789779663. Accuracy: 71.76373739452562\n",
      "Iteration: 10120. Loss: 0.4582306444644928. Accuracy: 72.03128215682239\n",
      "Iteration: 10130. Loss: 0.4162119925022125. Accuracy: 71.7431570281951\n",
      "Iteration: 10140. Loss: 1.012398362159729. Accuracy: 70.67297797900802\n",
      "Epoch:  157\n",
      "Iteration: 10150. Loss: 0.4897882044315338. Accuracy: 71.78431776085614\n",
      "Iteration: 10160. Loss: 0.5723735094070435. Accuracy: 72.64869314673801\n",
      "Iteration: 10170. Loss: 0.4727405309677124. Accuracy: 72.60753241407697\n",
      "Iteration: 10180. Loss: 0.44417738914489746. Accuracy: 71.35213006791521\n",
      "Iteration: 10190. Loss: 0.44356897473335266. Accuracy: 71.31096933525417\n",
      "Iteration: 10200. Loss: 0.4574931263923645. Accuracy: 71.10516567194897\n",
      "Epoch:  158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10210. Loss: 0.5025579333305359. Accuracy: 71.72257666186458\n",
      "Iteration: 10220. Loss: 0.384628564119339. Accuracy: 71.57851409755094\n",
      "Iteration: 10230. Loss: 0.3970670700073242. Accuracy: 71.76373739452562\n",
      "Iteration: 10240. Loss: 0.5434617400169373. Accuracy: 71.90779995883926\n",
      "Iteration: 10250. Loss: 0.42187532782554626. Accuracy: 72.36056801811073\n",
      "Iteration: 10260. Loss: 0.4375308156013489. Accuracy: 72.01070179049186\n",
      "Iteration: 10270. Loss: 0.7822747230529785. Accuracy: 71.16690677094053\n",
      "Epoch:  159\n",
      "Iteration: 10280. Loss: 0.5959386229515076. Accuracy: 71.51677299855938\n",
      "Iteration: 10290. Loss: 0.41662344336509705. Accuracy: 71.99012142416134\n",
      "Iteration: 10300. Loss: 0.4532721936702728. Accuracy: 71.70199629553406\n",
      "Iteration: 10310. Loss: 0.48290202021598816. Accuracy: 71.66083556287302\n",
      "Iteration: 10320. Loss: 0.5148303508758545. Accuracy: 72.09302325581395\n",
      "Iteration: 10330. Loss: 0.5238762497901917. Accuracy: 71.80489812718666\n",
      "Epoch:  160\n",
      "Iteration: 10340. Loss: 0.5058877468109131. Accuracy: 71.90779995883926\n",
      "Iteration: 10350. Loss: 0.4251839816570282. Accuracy: 71.10516567194897\n",
      "Iteration: 10360. Loss: 0.42536985874176025. Accuracy: 71.86663922617822\n",
      "Iteration: 10370. Loss: 0.43365365266799927. Accuracy: 71.61967483021198\n",
      "Iteration: 10380. Loss: 0.5104319453239441. Accuracy: 71.9489606915003\n",
      "Iteration: 10390. Loss: 0.46725210547447205. Accuracy: 72.81333607738217\n",
      "Iteration: 10400. Loss: 0.906463086605072. Accuracy: 71.76373739452562\n",
      "Epoch:  161\n",
      "Iteration: 10410. Loss: 0.4519692361354828. Accuracy: 71.35213006791521\n",
      "Iteration: 10420. Loss: 0.4244448244571686. Accuracy: 72.21650545379708\n",
      "Iteration: 10430. Loss: 0.34873175621032715. Accuracy: 71.59909446388146\n",
      "Iteration: 10440. Loss: 0.42501822113990784. Accuracy: 71.68141592920354\n",
      "Iteration: 10450. Loss: 0.3638928532600403. Accuracy: 71.49619263222885\n",
      "Iteration: 10460. Loss: 0.4482830762863159. Accuracy: 72.54579131508541\n",
      "Epoch:  162\n",
      "Iteration: 10470. Loss: 0.4076109528541565. Accuracy: 71.90779995883926\n",
      "Iteration: 10480. Loss: 0.4250551462173462. Accuracy: 72.2370858201276\n",
      "Iteration: 10490. Loss: 0.42167869210243225. Accuracy: 72.01070179049186\n",
      "Iteration: 10500. Loss: 0.5343390107154846. Accuracy: 71.80489812718666\n",
      "Iteration: 10510. Loss: 0.4384821951389313. Accuracy: 72.03128215682239\n",
      "Iteration: 10520. Loss: 0.48634907603263855. Accuracy: 71.6402551965425\n",
      "Iteration: 10530. Loss: 0.9609645009040833. Accuracy: 71.41387116690677\n",
      "Epoch:  163\n",
      "Iteration: 10540. Loss: 0.4724509119987488. Accuracy: 71.45503189956781\n",
      "Iteration: 10550. Loss: 0.4064435362815857. Accuracy: 71.06400493928793\n",
      "Iteration: 10560. Loss: 0.4639352858066559. Accuracy: 71.5373533648899\n",
      "Iteration: 10570. Loss: 0.4358755052089691. Accuracy: 72.19592508746656\n",
      "Iteration: 10580. Loss: 0.46555012464523315. Accuracy: 72.3399876517802\n",
      "Iteration: 10590. Loss: 0.4369715452194214. Accuracy: 72.25766618645812\n",
      "Epoch:  164\n",
      "Iteration: 10600. Loss: 0.5086570382118225. Accuracy: 71.9489606915003\n",
      "Iteration: 10610. Loss: 0.4804302453994751. Accuracy: 71.41387116690677\n",
      "Iteration: 10620. Loss: 0.542461633682251. Accuracy: 72.17534472113604\n",
      "Iteration: 10630. Loss: 0.5175224542617798. Accuracy: 71.39329080057625\n",
      "Iteration: 10640. Loss: 0.4645123779773712. Accuracy: 71.6402551965425\n",
      "Iteration: 10650. Loss: 0.3721613883972168. Accuracy: 72.19592508746656\n",
      "Iteration: 10660. Loss: 0.754496157169342. Accuracy: 71.96954105783082\n",
      "Epoch:  165\n",
      "Iteration: 10670. Loss: 0.4359526038169861. Accuracy: 71.99012142416134\n",
      "Iteration: 10680. Loss: 0.5949446558952332. Accuracy: 71.92838032516978\n",
      "Iteration: 10690. Loss: 0.3804851472377777. Accuracy: 72.0518625231529\n",
      "Iteration: 10700. Loss: 0.3922213613986969. Accuracy: 72.03128215682239\n",
      "Iteration: 10710. Loss: 0.3687509000301361. Accuracy: 72.46346984976333\n",
      "Iteration: 10720. Loss: 0.44212016463279724. Accuracy: 72.62811278040749\n",
      "Epoch:  166\n",
      "Iteration: 10730. Loss: 0.42241349816322327. Accuracy: 72.40172875077177\n",
      "Iteration: 10740. Loss: 0.38434910774230957. Accuracy: 71.47561226589833\n",
      "Iteration: 10750. Loss: 0.4182932674884796. Accuracy: 72.19592508746656\n",
      "Iteration: 10760. Loss: 0.41028982400894165. Accuracy: 72.56637168141593\n",
      "Iteration: 10770. Loss: 0.3882543444633484. Accuracy: 71.70199629553406\n",
      "Iteration: 10780. Loss: 0.35480496287345886. Accuracy: 71.7431570281951\n",
      "Iteration: 10790. Loss: 0.9796300530433655. Accuracy: 71.90779995883926\n",
      "Epoch:  167\n",
      "Iteration: 10800. Loss: 0.359821617603302. Accuracy: 72.07244288948343\n",
      "Iteration: 10810. Loss: 0.41516396403312683. Accuracy: 71.26980860259313\n",
      "Iteration: 10820. Loss: 0.42318177223205566. Accuracy: 72.60753241407697\n",
      "Iteration: 10830. Loss: 0.4415792226791382. Accuracy: 71.39329080057625\n",
      "Iteration: 10840. Loss: 0.45974060893058777. Accuracy: 71.7431570281951\n",
      "Iteration: 10850. Loss: 0.4874526560306549. Accuracy: 71.90779995883926\n",
      "Epoch:  168\n",
      "Iteration: 10860. Loss: 0.4692433178424835. Accuracy: 72.2370858201276\n",
      "Iteration: 10870. Loss: 0.4351154565811157. Accuracy: 71.57851409755094\n",
      "Iteration: 10880. Loss: 0.43346303701400757. Accuracy: 71.37271043424573\n",
      "Iteration: 10890. Loss: 0.3704070448875427. Accuracy: 71.22864786993209\n",
      "Iteration: 10900. Loss: 0.4477640390396118. Accuracy: 72.01070179049186\n",
      "Iteration: 10910. Loss: 0.5049745440483093. Accuracy: 71.70199629553406\n",
      "Iteration: 10920. Loss: 1.113612174987793. Accuracy: 71.72257666186458\n",
      "Epoch:  169\n",
      "Iteration: 10930. Loss: 0.4453326463699341. Accuracy: 72.25766618645812\n",
      "Iteration: 10940. Loss: 0.3522791564464569. Accuracy: 72.07244288948343\n",
      "Iteration: 10950. Loss: 0.449443519115448. Accuracy: 72.27824655278864\n",
      "Iteration: 10960. Loss: 0.3994872272014618. Accuracy: 71.5373533648899\n",
      "Iteration: 10970. Loss: 0.46269333362579346. Accuracy: 71.90779995883926\n",
      "Iteration: 10980. Loss: 0.4712316393852234. Accuracy: 72.19592508746656\n",
      "Epoch:  170\n",
      "Iteration: 10990. Loss: 0.3407962918281555. Accuracy: 72.62811278040749\n",
      "Iteration: 11000. Loss: 0.42340704798698425. Accuracy: 71.47561226589833\n",
      "Iteration: 11010. Loss: 0.4800727963447571. Accuracy: 71.82547849351718\n",
      "Iteration: 11020. Loss: 0.40382760763168335. Accuracy: 72.75159497839061\n",
      "Iteration: 11030. Loss: 0.4063893258571625. Accuracy: 72.11360362214448\n",
      "Iteration: 11040. Loss: 0.4503284692764282. Accuracy: 72.54579131508541\n",
      "Iteration: 11050. Loss: 0.6992830634117126. Accuracy: 71.9489606915003\n",
      "Epoch:  171\n",
      "Iteration: 11060. Loss: 0.5582646727561951. Accuracy: 72.19592508746656\n",
      "Iteration: 11070. Loss: 0.4541351795196533. Accuracy: 72.52521094875489\n",
      "Iteration: 11080. Loss: 0.43438467383384705. Accuracy: 71.92838032516978\n",
      "Iteration: 11090. Loss: 0.3979909121990204. Accuracy: 71.99012142416134\n",
      "Iteration: 11100. Loss: 0.47871923446655273. Accuracy: 72.38114838444125\n",
      "Iteration: 11110. Loss: 0.5427834391593933. Accuracy: 71.90779995883926\n",
      "Epoch:  172\n",
      "Iteration: 11120. Loss: 0.38724786043167114. Accuracy: 72.89565754270426\n",
      "Iteration: 11130. Loss: 0.32784396409988403. Accuracy: 72.38114838444125\n",
      "Iteration: 11140. Loss: 0.4116993546485901. Accuracy: 72.56637168141593\n",
      "Iteration: 11150. Loss: 0.38894757628440857. Accuracy: 72.62811278040749\n",
      "Iteration: 11160. Loss: 0.4052748680114746. Accuracy: 72.8339164437127\n",
      "Iteration: 11170. Loss: 0.4950302243232727. Accuracy: 72.21650545379708\n",
      "Iteration: 11180. Loss: 0.9146669507026672. Accuracy: 71.59909446388146\n",
      "Epoch:  173\n",
      "Iteration: 11190. Loss: 0.40641891956329346. Accuracy: 72.09302325581395\n",
      "Iteration: 11200. Loss: 0.3888225257396698. Accuracy: 71.47561226589833\n",
      "Iteration: 11210. Loss: 0.45516616106033325. Accuracy: 72.44288948343281\n",
      "Iteration: 11220. Loss: 0.3422172963619232. Accuracy: 72.46346984976333\n",
      "Iteration: 11230. Loss: 0.4405500888824463. Accuracy: 72.01070179049186\n",
      "Iteration: 11240. Loss: 0.5104933381080627. Accuracy: 72.85449681004322\n",
      "Epoch:  174\n",
      "Iteration: 11250. Loss: 0.3918716609477997. Accuracy: 71.59909446388146\n",
      "Iteration: 11260. Loss: 0.4125506281852722. Accuracy: 72.07244288948343\n",
      "Iteration: 11270. Loss: 0.48140624165534973. Accuracy: 72.89565754270426\n",
      "Iteration: 11280. Loss: 0.41601860523223877. Accuracy: 72.40172875077177\n",
      "Iteration: 11290. Loss: 0.3616930842399597. Accuracy: 72.19592508746656\n",
      "Iteration: 11300. Loss: 0.4330306053161621. Accuracy: 71.96954105783082\n",
      "Iteration: 11310. Loss: 0.8697180151939392. Accuracy: 71.5373533648899\n",
      "Epoch:  175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11320. Loss: 0.44479817152023315. Accuracy: 72.42230911710229\n",
      "Iteration: 11330. Loss: 0.5182201862335205. Accuracy: 72.68985387939905\n",
      "Iteration: 11340. Loss: 0.45263585448265076. Accuracy: 72.62811278040749\n",
      "Iteration: 11350. Loss: 0.36853134632110596. Accuracy: 72.64869314673801\n",
      "Iteration: 11360. Loss: 0.44679179787635803. Accuracy: 72.40172875077177\n",
      "Iteration: 11370. Loss: 0.5004991292953491. Accuracy: 72.48405021609385\n",
      "Epoch:  176\n",
      "Iteration: 11380. Loss: 0.43644779920578003. Accuracy: 72.0518625231529\n",
      "Iteration: 11390. Loss: 0.4227449595928192. Accuracy: 72.54579131508541\n",
      "Iteration: 11400. Loss: 0.4943675696849823. Accuracy: 73.45132743362832\n",
      "Iteration: 11410. Loss: 0.3710049092769623. Accuracy: 72.27824655278864\n",
      "Iteration: 11420. Loss: 0.4816264808177948. Accuracy: 72.2370858201276\n",
      "Iteration: 11430. Loss: 0.4324457347393036. Accuracy: 72.60753241407697\n",
      "Iteration: 11440. Loss: 0.7590497732162476. Accuracy: 72.0518625231529\n",
      "Epoch:  177\n",
      "Iteration: 11450. Loss: 0.4523244798183441. Accuracy: 72.15476435480552\n",
      "Iteration: 11460. Loss: 0.40196236968040466. Accuracy: 72.60753241407697\n",
      "Iteration: 11470. Loss: 0.5529388785362244. Accuracy: 72.71043424572957\n",
      "Iteration: 11480. Loss: 0.4940284788608551. Accuracy: 72.46346984976333\n",
      "Iteration: 11490. Loss: 0.340582937002182. Accuracy: 72.03128215682239\n",
      "Iteration: 11500. Loss: 0.49969086050987244. Accuracy: 71.99012142416134\n",
      "Epoch:  178\n",
      "Iteration: 11510. Loss: 0.435388445854187. Accuracy: 72.0518625231529\n",
      "Iteration: 11520. Loss: 0.402304470539093. Accuracy: 72.21650545379708\n",
      "Iteration: 11530. Loss: 0.4313993752002716. Accuracy: 72.25766618645812\n",
      "Iteration: 11540. Loss: 0.33189868927001953. Accuracy: 71.92838032516978\n",
      "Iteration: 11550. Loss: 0.5457558631896973. Accuracy: 72.40172875077177\n",
      "Iteration: 11560. Loss: 0.3750208914279938. Accuracy: 71.7431570281951\n",
      "Iteration: 11570. Loss: 0.7779595851898193. Accuracy: 72.89565754270426\n",
      "Epoch:  179\n",
      "Iteration: 11580. Loss: 0.5212210416793823. Accuracy: 73.01913974068738\n",
      "Iteration: 11590. Loss: 0.41817858815193176. Accuracy: 72.17534472113604\n",
      "Iteration: 11600. Loss: 0.4352227747440338. Accuracy: 71.80489812718666\n",
      "Iteration: 11610. Loss: 0.3715296685695648. Accuracy: 72.62811278040749\n",
      "Iteration: 11620. Loss: 0.48161208629608154. Accuracy: 72.81333607738217\n",
      "Iteration: 11630. Loss: 0.48155802488327026. Accuracy: 72.81333607738217\n",
      "Epoch:  180\n",
      "Iteration: 11640. Loss: 0.4775932729244232. Accuracy: 71.82547849351718\n",
      "Iteration: 11650. Loss: 0.3972204923629761. Accuracy: 72.25766618645812\n",
      "Iteration: 11660. Loss: 0.3905062675476074. Accuracy: 72.81333607738217\n",
      "Iteration: 11670. Loss: 0.35997387766838074. Accuracy: 72.50463058242437\n",
      "Iteration: 11680. Loss: 0.3564746081829071. Accuracy: 72.91623790903478\n",
      "Iteration: 11690. Loss: 0.40507376194000244. Accuracy: 72.2370858201276\n",
      "Iteration: 11700. Loss: 0.7345286011695862. Accuracy: 72.25766618645812\n",
      "Epoch:  181\n",
      "Iteration: 11710. Loss: 0.367324560880661. Accuracy: 72.58695204774645\n",
      "Iteration: 11720. Loss: 0.41745108366012573. Accuracy: 72.95739864169582\n",
      "Iteration: 11730. Loss: 0.42287904024124146. Accuracy: 72.7310146120601\n",
      "Iteration: 11740. Loss: 0.37956610321998596. Accuracy: 73.08088083967894\n",
      "Iteration: 11750. Loss: 0.5540465116500854. Accuracy: 72.0518625231529\n",
      "Iteration: 11760. Loss: 0.4108109474182129. Accuracy: 72.48405021609385\n",
      "Epoch:  182\n",
      "Iteration: 11770. Loss: 0.4365251660346985. Accuracy: 72.38114838444125\n",
      "Iteration: 11780. Loss: 0.38540711998939514. Accuracy: 72.3399876517802\n",
      "Iteration: 11790. Loss: 0.3692657947540283. Accuracy: 72.17534472113604\n",
      "Iteration: 11800. Loss: 0.504962682723999. Accuracy: 72.52521094875489\n",
      "Iteration: 11810. Loss: 0.34970083832740784. Accuracy: 71.92838032516978\n",
      "Iteration: 11820. Loss: 0.4284219443798065. Accuracy: 72.40172875077177\n",
      "Iteration: 11830. Loss: 0.6346005201339722. Accuracy: 72.97797900802634\n",
      "Epoch:  183\n",
      "Iteration: 11840. Loss: 0.35013529658317566. Accuracy: 72.64869314673801\n",
      "Iteration: 11850. Loss: 0.43669676780700684. Accuracy: 72.71043424572957\n",
      "Iteration: 11860. Loss: 0.4181821048259735. Accuracy: 72.8339164437127\n",
      "Iteration: 11870. Loss: 0.3909945785999298. Accuracy: 72.25766618645812\n",
      "Iteration: 11880. Loss: 0.34567174315452576. Accuracy: 72.17534472113604\n",
      "Iteration: 11890. Loss: 0.43927693367004395. Accuracy: 72.8339164437127\n",
      "Epoch:  184\n",
      "Iteration: 11900. Loss: 0.4066612124443054. Accuracy: 72.68985387939905\n",
      "Iteration: 11910. Loss: 0.33907589316368103. Accuracy: 72.62811278040749\n",
      "Iteration: 11920. Loss: 0.3252529799938202. Accuracy: 73.34842560197572\n",
      "Iteration: 11930. Loss: 0.39065349102020264. Accuracy: 72.48405021609385\n",
      "Iteration: 11940. Loss: 0.373031884431839. Accuracy: 72.25766618645812\n",
      "Iteration: 11950. Loss: 0.4092573821544647. Accuracy: 71.88721959250874\n",
      "Iteration: 11960. Loss: 0.7465972900390625. Accuracy: 72.0518625231529\n",
      "Epoch:  185\n",
      "Iteration: 11970. Loss: 0.3741917312145233. Accuracy: 72.11360362214448\n",
      "Iteration: 11980. Loss: 0.36691829562187195. Accuracy: 72.50463058242437\n",
      "Iteration: 11990. Loss: 0.42645809054374695. Accuracy: 72.71043424572957\n",
      "Iteration: 12000. Loss: 0.5050855278968811. Accuracy: 72.8339164437127\n",
      "Iteration: 12010. Loss: 0.3826969265937805. Accuracy: 72.54579131508541\n",
      "Iteration: 12020. Loss: 0.4246126413345337. Accuracy: 72.48405021609385\n",
      "Epoch:  186\n",
      "Iteration: 12030. Loss: 0.39435598254203796. Accuracy: 72.21650545379708\n",
      "Iteration: 12040. Loss: 0.39737364649772644. Accuracy: 72.48405021609385\n",
      "Iteration: 12050. Loss: 0.47474971413612366. Accuracy: 72.62811278040749\n",
      "Iteration: 12060. Loss: 0.46102070808410645. Accuracy: 72.19592508746656\n",
      "Iteration: 12070. Loss: 0.3962053954601288. Accuracy: 73.94525622556081\n",
      "Iteration: 12080. Loss: 0.43845394253730774. Accuracy: 72.56637168141593\n",
      "Iteration: 12090. Loss: 0.7626501321792603. Accuracy: 71.88721959250874\n",
      "Epoch:  187\n",
      "Iteration: 12100. Loss: 0.4909953773021698. Accuracy: 72.17534472113604\n",
      "Iteration: 12110. Loss: 0.46778956055641174. Accuracy: 72.42230911710229\n",
      "Iteration: 12120. Loss: 0.3717886209487915. Accuracy: 72.77217534472113\n",
      "Iteration: 12130. Loss: 0.40932533144950867. Accuracy: 72.50463058242437\n",
      "Iteration: 12140. Loss: 0.41594284772872925. Accuracy: 73.08088083967894\n",
      "Iteration: 12150. Loss: 0.3728865683078766. Accuracy: 72.15476435480552\n",
      "Epoch:  188\n",
      "Iteration: 12160. Loss: 0.4478206932544708. Accuracy: 72.85449681004322\n",
      "Iteration: 12170. Loss: 0.4404769241809845. Accuracy: 73.12204157233998\n",
      "Iteration: 12180. Loss: 0.38730597496032715. Accuracy: 72.95739864169582\n",
      "Iteration: 12190. Loss: 0.3693481981754303. Accuracy: 72.56637168141593\n",
      "Iteration: 12200. Loss: 0.4067349135875702. Accuracy: 72.03128215682239\n",
      "Iteration: 12210. Loss: 0.42562004923820496. Accuracy: 72.7310146120601\n",
      "Iteration: 12220. Loss: 0.8651324510574341. Accuracy: 72.11360362214448\n",
      "Epoch:  189\n",
      "Iteration: 12230. Loss: 0.44004136323928833. Accuracy: 72.64869314673801\n",
      "Iteration: 12240. Loss: 0.3270510733127594. Accuracy: 72.38114838444125\n",
      "Iteration: 12250. Loss: 0.42377740144729614. Accuracy: 73.5336488989504\n",
      "Iteration: 12260. Loss: 0.40793895721435547. Accuracy: 73.16320230500104\n",
      "Iteration: 12270. Loss: 0.41879385709762573. Accuracy: 73.41016670096728\n",
      "Iteration: 12280. Loss: 0.3106576204299927. Accuracy: 72.81333607738217\n",
      "Epoch:  190\n",
      "Iteration: 12290. Loss: 0.38740968704223633. Accuracy: 73.06030047334842\n",
      "Iteration: 12300. Loss: 0.4333614110946655. Accuracy: 72.77217534472113\n",
      "Iteration: 12310. Loss: 0.3866580128669739. Accuracy: 72.79275571105165\n",
      "Iteration: 12320. Loss: 0.4025750458240509. Accuracy: 72.44288948343281\n",
      "Iteration: 12330. Loss: 0.5001540184020996. Accuracy: 72.89565754270426\n",
      "Iteration: 12340. Loss: 0.33970922231674194. Accuracy: 73.36900596830624\n",
      "Iteration: 12350. Loss: 1.0190227031707764. Accuracy: 72.0518625231529\n",
      "Epoch:  191\n",
      "Iteration: 12360. Loss: 0.36843186616897583. Accuracy: 72.38114838444125\n",
      "Iteration: 12370. Loss: 0.4211432635784149. Accuracy: 72.52521094875489\n",
      "Iteration: 12380. Loss: 0.38492530584335327. Accuracy: 72.60753241407697\n",
      "Iteration: 12390. Loss: 0.3840881288051605. Accuracy: 73.06030047334842\n",
      "Iteration: 12400. Loss: 0.5189396739006042. Accuracy: 72.44288948343281\n",
      "Iteration: 12410. Loss: 0.4453287720680237. Accuracy: 72.01070179049186\n",
      "Epoch:  192\n",
      "Iteration: 12420. Loss: 0.4471435546875. Accuracy: 72.52521094875489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12430. Loss: 0.42179548740386963. Accuracy: 73.51306853261988\n",
      "Iteration: 12440. Loss: 0.5150839686393738. Accuracy: 72.54579131508541\n",
      "Iteration: 12450. Loss: 0.40187549591064453. Accuracy: 72.54579131508541\n",
      "Iteration: 12460. Loss: 0.4140813648700714. Accuracy: 72.89565754270426\n",
      "Iteration: 12470. Loss: 0.37864676117897034. Accuracy: 72.89565754270426\n",
      "Iteration: 12480. Loss: 0.5914340019226074. Accuracy: 72.85449681004322\n",
      "Epoch:  193\n",
      "Iteration: 12490. Loss: 0.4291226267814636. Accuracy: 73.18378267133156\n",
      "Iteration: 12500. Loss: 0.3946315348148346. Accuracy: 72.85449681004322\n",
      "Iteration: 12510. Loss: 0.41444966197013855. Accuracy: 73.49248816628936\n",
      "Iteration: 12520. Loss: 0.3789386749267578. Accuracy: 73.1426219386705\n",
      "Iteration: 12530. Loss: 0.39806827902793884. Accuracy: 72.71043424572957\n",
      "Iteration: 12540. Loss: 0.30868250131607056. Accuracy: 72.56637168141593\n",
      "Epoch:  194\n",
      "Iteration: 12550. Loss: 0.39676597714424133. Accuracy: 72.3399876517802\n",
      "Iteration: 12560. Loss: 0.3837079405784607. Accuracy: 73.47190779995884\n",
      "Iteration: 12570. Loss: 0.4112376868724823. Accuracy: 73.26610413665364\n",
      "Iteration: 12580. Loss: 0.41997766494750977. Accuracy: 73.1426219386705\n",
      "Iteration: 12590. Loss: 0.3769674301147461. Accuracy: 72.99855937435686\n",
      "Iteration: 12600. Loss: 0.367693692445755. Accuracy: 73.08088083967894\n",
      "Iteration: 12610. Loss: 0.673173189163208. Accuracy: 72.15476435480552\n",
      "Epoch:  195\n",
      "Iteration: 12620. Loss: 0.37000101804733276. Accuracy: 73.06030047334842\n",
      "Iteration: 12630. Loss: 0.3284894824028015. Accuracy: 72.50463058242437\n",
      "Iteration: 12640. Loss: 0.5220662951469421. Accuracy: 72.8339164437127\n",
      "Iteration: 12650. Loss: 0.3630571961402893. Accuracy: 73.30726486931468\n",
      "Iteration: 12660. Loss: 0.41309043765068054. Accuracy: 73.08088083967894\n",
      "Iteration: 12670. Loss: 0.3743792772293091. Accuracy: 73.06030047334842\n",
      "Epoch:  196\n",
      "Iteration: 12680. Loss: 0.3735909163951874. Accuracy: 73.28668450298416\n",
      "Iteration: 12690. Loss: 0.3143015503883362. Accuracy: 72.38114838444125\n",
      "Iteration: 12700. Loss: 0.3926180899143219. Accuracy: 72.134183988475\n",
      "Iteration: 12710. Loss: 0.42620906233787537. Accuracy: 72.71043424572957\n",
      "Iteration: 12720. Loss: 0.3433932363986969. Accuracy: 73.30726486931468\n",
      "Iteration: 12730. Loss: 0.41062137484550476. Accuracy: 73.51306853261988\n",
      "Iteration: 12740. Loss: 0.9246166944503784. Accuracy: 71.90779995883926\n",
      "Epoch:  197\n",
      "Iteration: 12750. Loss: 0.39149972796440125. Accuracy: 72.44288948343281\n",
      "Iteration: 12760. Loss: 0.4366651475429535. Accuracy: 73.16320230500104\n",
      "Iteration: 12770. Loss: 0.4125615060329437. Accuracy: 72.9368182753653\n",
      "Iteration: 12780. Loss: 0.4035278260707855. Accuracy: 73.67771146326405\n",
      "Iteration: 12790. Loss: 0.2992493212223053. Accuracy: 72.97797900802634\n",
      "Iteration: 12800. Loss: 0.4538630545139313. Accuracy: 73.5336488989504\n",
      "Epoch:  198\n",
      "Iteration: 12810. Loss: 0.4502326548099518. Accuracy: 72.36056801811073\n",
      "Iteration: 12820. Loss: 0.415688693523407. Accuracy: 73.98641695822185\n",
      "Iteration: 12830. Loss: 0.3202458322048187. Accuracy: 73.34842560197572\n",
      "Iteration: 12840. Loss: 0.3995484709739685. Accuracy: 72.29882691911916\n",
      "Iteration: 12850. Loss: 0.46116212010383606. Accuracy: 72.9368182753653\n",
      "Iteration: 12860. Loss: 0.4172036945819855. Accuracy: 72.03128215682239\n",
      "Iteration: 12870. Loss: 0.7642717361450195. Accuracy: 72.29882691911916\n",
      "Epoch:  199\n",
      "Iteration: 12880. Loss: 0.43749070167541504. Accuracy: 71.72257666186458\n",
      "Iteration: 12890. Loss: 0.4233556389808655. Accuracy: 73.38958633463676\n",
      "Iteration: 12900. Loss: 0.4589834213256836. Accuracy: 73.2249434039926\n",
      "Iteration: 12910. Loss: 0.35889875888824463. Accuracy: 72.68985387939905\n",
      "Iteration: 12920. Loss: 0.4260074496269226. Accuracy: 72.99855937435686\n",
      "Iteration: 12930. Loss: 0.4452385902404785. Accuracy: 72.68985387939905\n",
      "Epoch:  200\n",
      "Iteration: 12940. Loss: 0.4609556496143341. Accuracy: 73.4307470672978\n",
      "Iteration: 12950. Loss: 0.4218870997428894. Accuracy: 72.68985387939905\n",
      "Iteration: 12960. Loss: 0.3499763607978821. Accuracy: 73.636550730603\n",
      "Iteration: 12970. Loss: 0.31344491243362427. Accuracy: 73.20436303766208\n",
      "Iteration: 12980. Loss: 0.35456427931785583. Accuracy: 73.0397201070179\n",
      "Iteration: 12990. Loss: 0.35079336166381836. Accuracy: 73.30726486931468\n",
      "Iteration: 13000. Loss: 1.1283037662506104. Accuracy: 72.71043424572957\n",
      "Epoch:  201\n",
      "Iteration: 13010. Loss: 0.4072306752204895. Accuracy: 72.89565754270426\n",
      "Iteration: 13020. Loss: 0.40743178129196167. Accuracy: 73.84235439390821\n",
      "Iteration: 13030. Loss: 0.3965204954147339. Accuracy: 72.75159497839061\n",
      "Iteration: 13040. Loss: 0.3373996615409851. Accuracy: 72.62811278040749\n",
      "Iteration: 13050. Loss: 0.40275877714157104. Accuracy: 72.64869314673801\n",
      "Iteration: 13060. Loss: 0.3318203091621399. Accuracy: 72.95739864169582\n",
      "Epoch:  202\n",
      "Iteration: 13070. Loss: 0.39720991253852844. Accuracy: 73.28668450298416\n",
      "Iteration: 13080. Loss: 0.42504364252090454. Accuracy: 73.41016670096728\n",
      "Iteration: 13090. Loss: 0.4291202425956726. Accuracy: 73.45132743362832\n",
      "Iteration: 13100. Loss: 0.302557110786438. Accuracy: 73.34842560197572\n",
      "Iteration: 13110. Loss: 0.38012203574180603. Accuracy: 73.26610413665364\n",
      "Iteration: 13120. Loss: 0.3334575891494751. Accuracy: 73.41016670096728\n",
      "Iteration: 13130. Loss: 0.8997373580932617. Accuracy: 72.64869314673801\n",
      "Epoch:  203\n",
      "Iteration: 13140. Loss: 0.36670348048210144. Accuracy: 72.25766618645812\n",
      "Iteration: 13150. Loss: 0.3534673750400543. Accuracy: 72.91623790903478\n",
      "Iteration: 13160. Loss: 0.4473361074924469. Accuracy: 73.24552377032312\n",
      "Iteration: 13170. Loss: 0.3736633360385895. Accuracy: 73.1426219386705\n",
      "Iteration: 13180. Loss: 0.3550831079483032. Accuracy: 72.48405021609385\n",
      "Iteration: 13190. Loss: 0.5570150017738342. Accuracy: 72.81333607738217\n",
      "Epoch:  204\n",
      "Iteration: 13200. Loss: 0.42976027727127075. Accuracy: 73.10146120600946\n",
      "Iteration: 13210. Loss: 0.38795793056488037. Accuracy: 73.08088083967894\n",
      "Iteration: 13220. Loss: 0.6022468209266663. Accuracy: 73.82177402757769\n",
      "Iteration: 13230. Loss: 0.4087124764919281. Accuracy: 73.3278452356452\n",
      "Iteration: 13240. Loss: 0.3399152159690857. Accuracy: 73.38958633463676\n",
      "Iteration: 13250. Loss: 0.37325814366340637. Accuracy: 73.28668450298416\n",
      "Iteration: 13260. Loss: 0.7924895286560059. Accuracy: 72.17534472113604\n",
      "Epoch:  205\n",
      "Iteration: 13270. Loss: 0.3508360981941223. Accuracy: 72.68985387939905\n",
      "Iteration: 13280. Loss: 0.40654700994491577. Accuracy: 73.71887219592509\n",
      "Iteration: 13290. Loss: 0.38521793484687805. Accuracy: 73.67771146326405\n",
      "Iteration: 13300. Loss: 0.41356754302978516. Accuracy: 73.20436303766208\n",
      "Iteration: 13310. Loss: 0.3404662013053894. Accuracy: 73.65713109693353\n",
      "Iteration: 13320. Loss: 0.40723392367362976. Accuracy: 72.75159497839061\n",
      "Epoch:  206\n",
      "Iteration: 13330. Loss: 0.3823947310447693. Accuracy: 73.34842560197572\n",
      "Iteration: 13340. Loss: 0.33628755807876587. Accuracy: 73.80119366124717\n",
      "Iteration: 13350. Loss: 0.35950350761413574. Accuracy: 73.10146120600946\n",
      "Iteration: 13360. Loss: 0.2938951253890991. Accuracy: 72.99855937435686\n",
      "Iteration: 13370. Loss: 0.3703017234802246. Accuracy: 73.24552377032312\n",
      "Iteration: 13380. Loss: 0.3669893741607666. Accuracy: 73.30726486931468\n",
      "Iteration: 13390. Loss: 0.9632341861724854. Accuracy: 73.2249434039926\n",
      "Epoch:  207\n",
      "Iteration: 13400. Loss: 0.3075374662876129. Accuracy: 73.18378267133156\n",
      "Iteration: 13410. Loss: 0.34158384799957275. Accuracy: 73.71887219592509\n",
      "Iteration: 13420. Loss: 0.4005594551563263. Accuracy: 73.38958633463676\n",
      "Iteration: 13430. Loss: 0.4097701907157898. Accuracy: 72.99855937435686\n",
      "Iteration: 13440. Loss: 0.39287006855010986. Accuracy: 73.90409549289977\n",
      "Iteration: 13450. Loss: 0.46399444341659546. Accuracy: 73.59538999794196\n",
      "Epoch:  208\n",
      "Iteration: 13460. Loss: 0.5132321715354919. Accuracy: 73.0397201070179\n",
      "Iteration: 13470. Loss: 0.3524862825870514. Accuracy: 73.86293476023873\n",
      "Iteration: 13480. Loss: 0.40974557399749756. Accuracy: 73.34842560197572\n",
      "Iteration: 13490. Loss: 0.31338196992874146. Accuracy: 73.30726486931468\n",
      "Iteration: 13500. Loss: 0.37730246782302856. Accuracy: 72.81333607738217\n",
      "Iteration: 13510. Loss: 0.35065001249313354. Accuracy: 73.20436303766208\n",
      "Iteration: 13520. Loss: 0.8147359490394592. Accuracy: 71.99012142416134\n",
      "Epoch:  209\n",
      "Iteration: 13530. Loss: 0.37573742866516113. Accuracy: 73.18378267133156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13540. Loss: 0.32898738980293274. Accuracy: 73.80119366124717\n",
      "Iteration: 13550. Loss: 0.433902382850647. Accuracy: 73.61597036427248\n",
      "Iteration: 13560. Loss: 0.3754153549671173. Accuracy: 72.9368182753653\n",
      "Iteration: 13570. Loss: 0.33947640657424927. Accuracy: 72.79275571105165\n",
      "Iteration: 13580. Loss: 0.3908756375312805. Accuracy: 73.82177402757769\n",
      "Epoch:  210\n",
      "Iteration: 13590. Loss: 0.3543057143688202. Accuracy: 72.9368182753653\n",
      "Iteration: 13600. Loss: 0.35022416710853577. Accuracy: 73.73945256225561\n",
      "Iteration: 13610. Loss: 0.31854158639907837. Accuracy: 74.10989915620497\n",
      "Iteration: 13620. Loss: 0.41529157757759094. Accuracy: 73.80119366124717\n",
      "Iteration: 13630. Loss: 0.4268251657485962. Accuracy: 74.06873842354393\n",
      "Iteration: 13640. Loss: 0.3251335918903351. Accuracy: 72.87507717637374\n",
      "Iteration: 13650. Loss: 0.9486440420150757. Accuracy: 72.60753241407697\n",
      "Epoch:  211\n",
      "Iteration: 13660. Loss: 0.44951844215393066. Accuracy: 73.41016670096728\n",
      "Iteration: 13670. Loss: 0.4651901125907898. Accuracy: 73.06030047334842\n",
      "Iteration: 13680. Loss: 0.32481712102890015. Accuracy: 73.78061329491665\n",
      "Iteration: 13690. Loss: 0.30968332290649414. Accuracy: 72.8339164437127\n",
      "Iteration: 13700. Loss: 0.3275853097438812. Accuracy: 73.24552377032312\n",
      "Iteration: 13710. Loss: 0.4161081314086914. Accuracy: 73.5336488989504\n",
      "Epoch:  212\n",
      "Iteration: 13720. Loss: 0.4065956175327301. Accuracy: 73.67771146326405\n",
      "Iteration: 13730. Loss: 0.3674086630344391. Accuracy: 73.88351512656925\n",
      "Iteration: 13740. Loss: 0.402242511510849. Accuracy: 73.73945256225561\n",
      "Iteration: 13750. Loss: 0.43228963017463684. Accuracy: 73.41016670096728\n",
      "Iteration: 13760. Loss: 0.3515353500843048. Accuracy: 73.16320230500104\n",
      "Iteration: 13770. Loss: 0.42876720428466797. Accuracy: 73.18378267133156\n",
      "Iteration: 13780. Loss: 1.0672378540039062. Accuracy: 72.42230911710229\n",
      "Epoch:  213\n",
      "Iteration: 13790. Loss: 0.36477357149124146. Accuracy: 73.59538999794196\n",
      "Iteration: 13800. Loss: 0.42390912771224976. Accuracy: 72.87507717637374\n",
      "Iteration: 13810. Loss: 0.3791365921497345. Accuracy: 73.67771146326405\n",
      "Iteration: 13820. Loss: 0.41710424423217773. Accuracy: 73.49248816628936\n",
      "Iteration: 13830. Loss: 0.43833160400390625. Accuracy: 73.12204157233998\n",
      "Iteration: 13840. Loss: 0.32142767310142517. Accuracy: 73.5336488989504\n",
      "Epoch:  214\n",
      "Iteration: 13850. Loss: 0.3416787087917328. Accuracy: 73.16320230500104\n",
      "Iteration: 13860. Loss: 0.4300406277179718. Accuracy: 73.28668450298416\n",
      "Iteration: 13870. Loss: 0.3085334599018097. Accuracy: 73.65713109693353\n",
      "Iteration: 13880. Loss: 0.3594995141029358. Accuracy: 73.16320230500104\n",
      "Iteration: 13890. Loss: 0.43557292222976685. Accuracy: 73.20436303766208\n",
      "Iteration: 13900. Loss: 0.30356720089912415. Accuracy: 73.30726486931468\n",
      "Iteration: 13910. Loss: 0.6219274401664734. Accuracy: 73.2249434039926\n",
      "Epoch:  215\n",
      "Iteration: 13920. Loss: 0.31603261828422546. Accuracy: 73.5336488989504\n",
      "Iteration: 13930. Loss: 0.3654116094112396. Accuracy: 73.18378267133156\n",
      "Iteration: 13940. Loss: 0.3730241060256958. Accuracy: 73.38958633463676\n",
      "Iteration: 13950. Loss: 0.36288580298423767. Accuracy: 73.49248816628936\n",
      "Iteration: 13960. Loss: 0.39153289794921875. Accuracy: 73.34842560197572\n",
      "Iteration: 13970. Loss: 0.4122265875339508. Accuracy: 73.3278452356452\n",
      "Epoch:  216\n",
      "Iteration: 13980. Loss: 0.3186773359775543. Accuracy: 73.92467585923029\n",
      "Iteration: 13990. Loss: 0.38685303926467896. Accuracy: 73.636550730603\n",
      "Iteration: 14000. Loss: 0.36350467801094055. Accuracy: 73.55422926528092\n",
      "Iteration: 14010. Loss: 0.3915517032146454. Accuracy: 73.5336488989504\n",
      "Iteration: 14020. Loss: 0.3799781799316406. Accuracy: 73.69829182959457\n",
      "Iteration: 14030. Loss: 0.36370107531547546. Accuracy: 73.65713109693353\n",
      "Iteration: 14040. Loss: 0.6144687533378601. Accuracy: 72.75159497839061\n",
      "Epoch:  217\n",
      "Iteration: 14050. Loss: 0.3339233100414276. Accuracy: 73.08088083967894\n",
      "Iteration: 14060. Loss: 0.3016660809516907. Accuracy: 73.96583659189133\n",
      "Iteration: 14070. Loss: 0.38189396262168884. Accuracy: 72.85449681004322\n",
      "Iteration: 14080. Loss: 0.362558513879776. Accuracy: 73.26610413665364\n",
      "Iteration: 14090. Loss: 0.34805750846862793. Accuracy: 73.67771146326405\n",
      "Iteration: 14100. Loss: 0.3201039433479309. Accuracy: 73.88351512656925\n",
      "Epoch:  218\n",
      "Iteration: 14110. Loss: 0.3777218461036682. Accuracy: 73.08088083967894\n",
      "Iteration: 14120. Loss: 0.4044802486896515. Accuracy: 73.38958633463676\n",
      "Iteration: 14130. Loss: 0.4811897873878479. Accuracy: 73.84235439390821\n",
      "Iteration: 14140. Loss: 0.31839853525161743. Accuracy: 73.59538999794196\n",
      "Iteration: 14150. Loss: 0.3391510248184204. Accuracy: 72.87507717637374\n",
      "Iteration: 14160. Loss: 0.3831135630607605. Accuracy: 74.19222062152706\n",
      "Iteration: 14170. Loss: 0.7288316488265991. Accuracy: 73.65713109693353\n",
      "Epoch:  219\n",
      "Iteration: 14180. Loss: 0.34358882904052734. Accuracy: 73.59538999794196\n",
      "Iteration: 14190. Loss: 0.34725362062454224. Accuracy: 73.71887219592509\n",
      "Iteration: 14200. Loss: 0.2780424654483795. Accuracy: 73.18378267133156\n",
      "Iteration: 14210. Loss: 0.33340856432914734. Accuracy: 73.24552377032312\n",
      "Iteration: 14220. Loss: 0.34182053804397583. Accuracy: 73.49248816628936\n",
      "Iteration: 14230. Loss: 0.33809852600097656. Accuracy: 73.41016670096728\n",
      "Epoch:  220\n",
      "Iteration: 14240. Loss: 0.4318161904811859. Accuracy: 73.16320230500104\n",
      "Iteration: 14250. Loss: 0.35261964797973633. Accuracy: 73.78061329491665\n",
      "Iteration: 14260. Loss: 0.4290976822376251. Accuracy: 73.76003292858613\n",
      "Iteration: 14270. Loss: 0.40462562441825867. Accuracy: 73.69829182959457\n",
      "Iteration: 14280. Loss: 0.3210643529891968. Accuracy: 73.82177402757769\n",
      "Iteration: 14290. Loss: 0.4049304723739624. Accuracy: 73.61597036427248\n",
      "Iteration: 14300. Loss: 0.7423437833786011. Accuracy: 73.45132743362832\n",
      "Epoch:  221\n",
      "Iteration: 14310. Loss: 0.38956549763679504. Accuracy: 73.06030047334842\n",
      "Iteration: 14320. Loss: 0.3777914047241211. Accuracy: 74.10989915620497\n",
      "Iteration: 14330. Loss: 0.41510871052742004. Accuracy: 73.45132743362832\n",
      "Iteration: 14340. Loss: 0.27476221323013306. Accuracy: 73.84235439390821\n",
      "Iteration: 14350. Loss: 0.3973826467990875. Accuracy: 74.33628318584071\n",
      "Iteration: 14360. Loss: 0.3733392357826233. Accuracy: 73.59538999794196\n",
      "Epoch:  222\n",
      "Iteration: 14370. Loss: 0.43478769063949585. Accuracy: 73.61597036427248\n",
      "Iteration: 14380. Loss: 0.3063993453979492. Accuracy: 73.76003292858613\n",
      "Iteration: 14390. Loss: 0.29988574981689453. Accuracy: 73.69829182959457\n",
      "Iteration: 14400. Loss: 0.34406402707099915. Accuracy: 73.26610413665364\n",
      "Iteration: 14410. Loss: 0.3986204266548157. Accuracy: 74.3157028195102\n",
      "Iteration: 14420. Loss: 0.3566327691078186. Accuracy: 73.61597036427248\n",
      "Iteration: 14430. Loss: 0.7276657819747925. Accuracy: 73.5336488989504\n",
      "Epoch:  223\n",
      "Iteration: 14440. Loss: 0.3078613877296448. Accuracy: 73.49248816628936\n",
      "Iteration: 14450. Loss: 0.3130772113800049. Accuracy: 73.08088083967894\n",
      "Iteration: 14460. Loss: 0.3356088697910309. Accuracy: 73.82177402757769\n",
      "Iteration: 14470. Loss: 0.42859476804733276. Accuracy: 73.2249434039926\n",
      "Iteration: 14480. Loss: 0.36513200402259827. Accuracy: 73.78061329491665\n",
      "Iteration: 14490. Loss: 0.34515631198883057. Accuracy: 73.65713109693353\n",
      "Epoch:  224\n",
      "Iteration: 14500. Loss: 0.34983646869659424. Accuracy: 73.96583659189133\n",
      "Iteration: 14510. Loss: 0.38627755641937256. Accuracy: 74.06873842354393\n",
      "Iteration: 14520. Loss: 0.29526787996292114. Accuracy: 73.59538999794196\n",
      "Iteration: 14530. Loss: 0.3985731899738312. Accuracy: 73.57480963161144\n",
      "Iteration: 14540. Loss: 0.3978532552719116. Accuracy: 74.4186046511628\n",
      "Iteration: 14550. Loss: 0.33649060130119324. Accuracy: 73.45132743362832\n",
      "Iteration: 14560. Loss: 0.7634502649307251. Accuracy: 72.58695204774645\n",
      "Epoch:  225\n",
      "Iteration: 14570. Loss: 0.36379754543304443. Accuracy: 73.51306853261988\n",
      "Iteration: 14580. Loss: 0.34081050753593445. Accuracy: 74.04815805721341\n",
      "Iteration: 14590. Loss: 0.32984745502471924. Accuracy: 72.97797900802634\n",
      "Iteration: 14600. Loss: 0.3374471068382263. Accuracy: 73.98641695822185\n",
      "Iteration: 14610. Loss: 0.3541737496852875. Accuracy: 73.88351512656925\n",
      "Iteration: 14620. Loss: 0.4636771082878113. Accuracy: 74.00699732455237\n",
      "Epoch:  226\n",
      "Iteration: 14630. Loss: 0.3378661274909973. Accuracy: 74.19222062152706\n",
      "Iteration: 14640. Loss: 0.36030420660972595. Accuracy: 74.04815805721341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14650. Loss: 0.3691694140434265. Accuracy: 74.08931878987445\n",
      "Iteration: 14660. Loss: 0.3816615045070648. Accuracy: 73.92467585923029\n",
      "Iteration: 14670. Loss: 0.37192225456237793. Accuracy: 74.37744391850175\n",
      "Iteration: 14680. Loss: 0.2954082787036896. Accuracy: 73.57480963161144\n",
      "Iteration: 14690. Loss: 0.8642794489860535. Accuracy: 72.40172875077177\n",
      "Epoch:  227\n",
      "Iteration: 14700. Loss: 0.3949468433856964. Accuracy: 74.58324758180696\n",
      "Iteration: 14710. Loss: 0.38313648104667664. Accuracy: 73.73945256225561\n",
      "Iteration: 14720. Loss: 0.4442829489707947. Accuracy: 73.55422926528092\n",
      "Iteration: 14730. Loss: 0.4301674962043762. Accuracy: 73.86293476023873\n",
      "Iteration: 14740. Loss: 0.4265049397945404. Accuracy: 74.23338135418811\n",
      "Iteration: 14750. Loss: 0.31731316447257996. Accuracy: 74.17164025519654\n",
      "Epoch:  228\n",
      "Iteration: 14760. Loss: 0.37503865361213684. Accuracy: 73.65713109693353\n",
      "Iteration: 14770. Loss: 0.26077401638031006. Accuracy: 73.636550730603\n",
      "Iteration: 14780. Loss: 0.29532989859580994. Accuracy: 73.55422926528092\n",
      "Iteration: 14790. Loss: 0.3439794182777405. Accuracy: 73.86293476023873\n",
      "Iteration: 14800. Loss: 0.3365456461906433. Accuracy: 74.15105988886602\n",
      "Iteration: 14810. Loss: 0.32318881154060364. Accuracy: 73.84235439390821\n",
      "Iteration: 14820. Loss: 1.2431366443634033. Accuracy: 73.90409549289977\n",
      "Epoch:  229\n",
      "Iteration: 14830. Loss: 0.33675193786621094. Accuracy: 73.71887219592509\n",
      "Iteration: 14840. Loss: 0.37298643589019775. Accuracy: 73.86293476023873\n",
      "Iteration: 14850. Loss: 0.37356892228126526. Accuracy: 73.51306853261988\n",
      "Iteration: 14860. Loss: 0.38251614570617676. Accuracy: 74.06873842354393\n",
      "Iteration: 14870. Loss: 0.32222431898117065. Accuracy: 73.88351512656925\n",
      "Iteration: 14880. Loss: 0.4453830420970917. Accuracy: 73.47190779995884\n",
      "Epoch:  230\n",
      "Iteration: 14890. Loss: 0.24038872122764587. Accuracy: 74.29512245317967\n",
      "Iteration: 14900. Loss: 0.3223775625228882. Accuracy: 73.78061329491665\n",
      "Iteration: 14910. Loss: 0.35007867217063904. Accuracy: 74.17164025519654\n",
      "Iteration: 14920. Loss: 0.329881489276886. Accuracy: 73.2249434039926\n",
      "Iteration: 14930. Loss: 0.4053508937358856. Accuracy: 73.82177402757769\n",
      "Iteration: 14940. Loss: 0.40666717290878296. Accuracy: 73.0397201070179\n",
      "Iteration: 14950. Loss: 0.914932906627655. Accuracy: 74.624408314468\n",
      "Epoch:  231\n",
      "Iteration: 14960. Loss: 0.3495103716850281. Accuracy: 73.90409549289977\n",
      "Iteration: 14970. Loss: 0.31483832001686096. Accuracy: 73.59538999794196\n",
      "Iteration: 14980. Loss: 0.35423651337623596. Accuracy: 74.58324758180696\n",
      "Iteration: 14990. Loss: 0.39779898524284363. Accuracy: 73.65713109693353\n",
      "Iteration: 15000. Loss: 0.428831547498703. Accuracy: 73.92467585923029\n",
      "Iteration: 15010. Loss: 0.386127233505249. Accuracy: 73.51306853261988\n",
      "Epoch:  232\n",
      "Iteration: 15020. Loss: 0.32695820927619934. Accuracy: 74.21280098785759\n",
      "Iteration: 15030. Loss: 0.41324207186698914. Accuracy: 74.54208684914592\n",
      "Iteration: 15040. Loss: 0.32165849208831787. Accuracy: 73.26610413665364\n",
      "Iteration: 15050. Loss: 0.3185524642467499. Accuracy: 73.5336488989504\n",
      "Iteration: 15060. Loss: 0.3313882052898407. Accuracy: 73.78061329491665\n",
      "Iteration: 15070. Loss: 0.31462574005126953. Accuracy: 74.89195307676476\n",
      "Iteration: 15080. Loss: 0.9426894783973694. Accuracy: 74.21280098785759\n",
      "Epoch:  233\n",
      "Iteration: 15090. Loss: 0.40314745903015137. Accuracy: 74.39802428483227\n",
      "Iteration: 15100. Loss: 0.30367982387542725. Accuracy: 73.41016670096728\n",
      "Iteration: 15110. Loss: 0.2892533540725708. Accuracy: 74.15105988886602\n",
      "Iteration: 15120. Loss: 0.32893916964530945. Accuracy: 74.35686355217123\n",
      "Iteration: 15130. Loss: 0.384992778301239. Accuracy: 73.96583659189133\n",
      "Iteration: 15140. Loss: 0.4292103052139282. Accuracy: 74.68614941345956\n",
      "Epoch:  234\n",
      "Iteration: 15150. Loss: 0.3734656870365143. Accuracy: 73.82177402757769\n",
      "Iteration: 15160. Loss: 0.3356339633464813. Accuracy: 74.35686355217123\n",
      "Iteration: 15170. Loss: 0.2962166965007782. Accuracy: 74.0275776908829\n",
      "Iteration: 15180. Loss: 0.3221922218799591. Accuracy: 74.39802428483227\n",
      "Iteration: 15190. Loss: 0.39864203333854675. Accuracy: 74.54208684914592\n",
      "Iteration: 15200. Loss: 0.3806361258029938. Accuracy: 73.67771146326405\n",
      "Iteration: 15210. Loss: 1.1517915725708008. Accuracy: 73.73945256225561\n",
      "Epoch:  235\n",
      "Iteration: 15220. Loss: 0.3275989294052124. Accuracy: 74.39802428483227\n",
      "Iteration: 15230. Loss: 0.36784952878952026. Accuracy: 74.50092611648488\n",
      "Iteration: 15240. Loss: 0.2827293574810028. Accuracy: 74.39802428483227\n",
      "Iteration: 15250. Loss: 0.2766936123371124. Accuracy: 75.01543527474789\n",
      "Iteration: 15260. Loss: 0.43495580554008484. Accuracy: 74.76847087878164\n",
      "Iteration: 15270. Loss: 0.3106946051120758. Accuracy: 74.0275776908829\n",
      "Epoch:  236\n",
      "Iteration: 15280. Loss: 0.3229486346244812. Accuracy: 74.1304795225355\n",
      "Iteration: 15290. Loss: 0.30758973956108093. Accuracy: 74.39802428483227\n",
      "Iteration: 15300. Loss: 0.307778000831604. Accuracy: 73.08088083967894\n",
      "Iteration: 15310. Loss: 0.29326409101486206. Accuracy: 74.33628318584071\n",
      "Iteration: 15320. Loss: 0.3418807089328766. Accuracy: 74.25396172051863\n",
      "Iteration: 15330. Loss: 0.29718223214149475. Accuracy: 73.4307470672978\n",
      "Iteration: 15340. Loss: 0.9995563626289368. Accuracy: 73.47190779995884\n",
      "Epoch:  237\n",
      "Iteration: 15350. Loss: 0.3591352701187134. Accuracy: 74.35686355217123\n",
      "Iteration: 15360. Loss: 0.3394055962562561. Accuracy: 74.25396172051863\n",
      "Iteration: 15370. Loss: 0.33178719878196716. Accuracy: 74.33628318584071\n",
      "Iteration: 15380. Loss: 0.3602046072483063. Accuracy: 74.0275776908829\n",
      "Iteration: 15390. Loss: 0.2754914462566376. Accuracy: 74.15105988886602\n",
      "Iteration: 15400. Loss: 0.3403213620185852. Accuracy: 74.0275776908829\n",
      "Epoch:  238\n",
      "Iteration: 15410. Loss: 0.29741179943084717. Accuracy: 74.45976538382384\n",
      "Iteration: 15420. Loss: 0.38071247935295105. Accuracy: 74.45976538382384\n",
      "Iteration: 15430. Loss: 0.34591370820999146. Accuracy: 74.45976538382384\n",
      "Iteration: 15440. Loss: 0.3505324125289917. Accuracy: 74.76847087878164\n",
      "Iteration: 15450. Loss: 0.3113456070423126. Accuracy: 74.624408314468\n",
      "Iteration: 15460. Loss: 0.3936796188354492. Accuracy: 74.04815805721341\n",
      "Iteration: 15470. Loss: 0.4945129156112671. Accuracy: 74.25396172051863\n",
      "Epoch:  239\n",
      "Iteration: 15480. Loss: 0.34020912647247314. Accuracy: 74.66556904712904\n",
      "Iteration: 15490. Loss: 0.36235836148262024. Accuracy: 74.56266721547644\n",
      "Iteration: 15500. Loss: 0.30059579014778137. Accuracy: 74.33628318584071\n",
      "Iteration: 15510. Loss: 0.4560471177101135. Accuracy: 74.3157028195102\n",
      "Iteration: 15520. Loss: 0.4432164132595062. Accuracy: 74.06873842354393\n",
      "Iteration: 15530. Loss: 0.3395730257034302. Accuracy: 74.0275776908829\n",
      "Epoch:  240\n",
      "Iteration: 15540. Loss: 0.36229684948921204. Accuracy: 74.06873842354393\n",
      "Iteration: 15550. Loss: 0.4697060286998749. Accuracy: 74.35686355217123\n",
      "Iteration: 15560. Loss: 0.4164115786552429. Accuracy: 74.4186046511628\n",
      "Iteration: 15570. Loss: 0.41350582242012024. Accuracy: 74.37744391850175\n",
      "Iteration: 15580. Loss: 0.32025909423828125. Accuracy: 74.39802428483227\n",
      "Iteration: 15590. Loss: 0.3737185001373291. Accuracy: 73.88351512656925\n",
      "Iteration: 15600. Loss: 0.8205760717391968. Accuracy: 73.69829182959457\n",
      "Epoch:  241\n",
      "Iteration: 15610. Loss: 0.344673216342926. Accuracy: 74.33628318584071\n",
      "Iteration: 15620. Loss: 0.34838443994522095. Accuracy: 74.68614941345956\n",
      "Iteration: 15630. Loss: 0.24067316949367523. Accuracy: 74.19222062152706\n",
      "Iteration: 15640. Loss: 0.3287948668003082. Accuracy: 73.49248816628936\n",
      "Iteration: 15650. Loss: 0.31592416763305664. Accuracy: 74.80963161144268\n",
      "Iteration: 15660. Loss: 0.3396032154560089. Accuracy: 73.94525622556081\n",
      "Epoch:  242\n",
      "Iteration: 15670. Loss: 0.3521497845649719. Accuracy: 73.41016670096728\n",
      "Iteration: 15680. Loss: 0.44672515988349915. Accuracy: 73.84235439390821\n",
      "Iteration: 15690. Loss: 0.38757145404815674. Accuracy: 74.00699732455237\n",
      "Iteration: 15700. Loss: 0.2667597830295563. Accuracy: 74.43918501749332\n",
      "Iteration: 15710. Loss: 0.36919930577278137. Accuracy: 74.70672977979008\n",
      "Iteration: 15720. Loss: 0.3445032835006714. Accuracy: 73.65713109693353\n",
      "Iteration: 15730. Loss: 0.7219807505607605. Accuracy: 73.80119366124717\n",
      "Epoch:  243\n",
      "Iteration: 15740. Loss: 0.33582741022109985. Accuracy: 74.37744391850175\n",
      "Iteration: 15750. Loss: 0.3797000050544739. Accuracy: 73.82177402757769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15760. Loss: 0.2609989643096924. Accuracy: 74.48034575015436\n",
      "Iteration: 15770. Loss: 0.30931392312049866. Accuracy: 74.25396172051863\n",
      "Iteration: 15780. Loss: 0.4258018434047699. Accuracy: 74.74789051245112\n",
      "Iteration: 15790. Loss: 0.31875696778297424. Accuracy: 74.21280098785759\n",
      "Epoch:  244\n",
      "Iteration: 15800. Loss: 0.38734930753707886. Accuracy: 74.3157028195102\n",
      "Iteration: 15810. Loss: 0.29074832797050476. Accuracy: 74.68614941345956\n",
      "Iteration: 15820. Loss: 0.3640962541103363. Accuracy: 74.68614941345956\n",
      "Iteration: 15830. Loss: 0.3683358132839203. Accuracy: 74.10989915620497\n",
      "Iteration: 15840. Loss: 0.31043750047683716. Accuracy: 74.78905124511216\n",
      "Iteration: 15850. Loss: 0.31732597947120667. Accuracy: 73.92467585923029\n",
      "Iteration: 15860. Loss: 0.6149374842643738. Accuracy: 74.48034575015436\n",
      "Epoch:  245\n",
      "Iteration: 15870. Loss: 0.3066796064376831. Accuracy: 74.54208684914592\n",
      "Iteration: 15880. Loss: 0.3006224036216736. Accuracy: 74.45976538382384\n",
      "Iteration: 15890. Loss: 0.32512250542640686. Accuracy: 73.4307470672978\n",
      "Iteration: 15900. Loss: 0.377775102853775. Accuracy: 74.21280098785759\n",
      "Iteration: 15910. Loss: 0.32237157225608826. Accuracy: 74.15105988886602\n",
      "Iteration: 15920. Loss: 0.41106146574020386. Accuracy: 74.70672977979008\n",
      "Epoch:  246\n",
      "Iteration: 15930. Loss: 0.344896137714386. Accuracy: 73.67771146326405\n",
      "Iteration: 15940. Loss: 0.3158913254737854. Accuracy: 74.21280098785759\n",
      "Iteration: 15950. Loss: 0.4112430810928345. Accuracy: 73.94525622556081\n",
      "Iteration: 15960. Loss: 0.34818264842033386. Accuracy: 73.69829182959457\n",
      "Iteration: 15970. Loss: 0.2880036234855652. Accuracy: 73.71887219592509\n",
      "Iteration: 15980. Loss: 0.4122917652130127. Accuracy: 73.57480963161144\n",
      "Iteration: 15990. Loss: 0.6249231100082397. Accuracy: 74.33628318584071\n"
     ]
    }
   ],
   "source": [
    "iteration_loss = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: ', epoch + 1)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images) \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 10 == 0:        \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            iteration_loss.append(loss.item())\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "IwU44FpRqO9t"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_base_copy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "1AIS0RVwq8ul",
    "outputId": "91f24f38-911c-4bca-bde1-107f33dc4107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.30826473236084, 2.244840621948242, 2.2106845378875732, 2.1182785034179688, 2.1779582500457764, 2.0394411087036133, 2.061147451400757, 1.9856890439987183, 1.9853800535202026, 1.9546911716461182, 1.9448705911636353, 1.9281504154205322, 2.032702684402466, 1.9785231351852417, 1.8996500968933105, 1.8577756881713867, 1.8643629550933838, 1.8930143117904663, 1.8227823972702026, 1.8541501760482788, 1.847791314125061, 1.8305926322937012, 1.7110679149627686, 1.7835036516189575, 1.7534712553024292, 1.7605235576629639, 1.617494821548462, 1.7249888181686401, 1.6946712732315063, 1.6409339904785156, 1.6678329706192017, 1.6054716110229492, 1.5507047176361084, 1.6048823595046997, 1.6869710683822632, 1.659033179283142, 1.6227654218673706, 1.6314024925231934, 1.592170238494873, 1.600203037261963, 1.5946201086044312, 1.5365562438964844, 1.4578229188919067, 1.548697829246521, 1.5657004117965698, 1.5035144090652466, 1.4513589143753052, 1.4867085218429565, 1.4180490970611572, 1.4888343811035156, 1.4504406452178955, 1.5834050178527832, 1.4438226222991943, 1.4120153188705444, 1.453950047492981, 1.4471429586410522, 1.3591251373291016, 1.3329665660858154, 1.41694974899292, 1.4091788530349731, 1.3942402601242065, 1.3981386423110962, 1.302819848060608, 1.364323377609253, 1.8479114770889282, 1.4351903200149536, 1.334328055381775, 1.320676326751709, 1.2567670345306396, 1.3223400115966797, 1.4471561908721924, 1.3212316036224365, 1.253682017326355, 1.3004257678985596, 1.4818787574768066, 1.2755768299102783, 1.3445606231689453, 1.5352407693862915, 1.3363040685653687, 1.3395788669586182, 1.2919028997421265, 1.4096373319625854, 1.2175629138946533, 1.3805993795394897, 1.171722173690796, 1.1944347620010376, 1.2114475965499878, 1.306489109992981, 1.1515719890594482, 1.3498563766479492, 1.442987322807312, 1.2254239320755005, 1.2517141103744507, 1.3069785833358765, 1.2456834316253662, 1.2110319137573242, 1.2224481105804443, 1.2687517404556274, 1.1542441844940186, 1.2551349401474, 1.3075602054595947, 1.1360341310501099, 1.2853012084960938, 1.5079365968704224, 1.0953600406646729, 1.2450555562973022, 1.109218955039978, 1.1476775407791138, 1.2050285339355469, 1.164401888847351, 1.1439639329910278, 1.1983399391174316, 1.147849440574646, 1.0637539625167847, 1.131693959236145, 1.0498371124267578, 1.3407237529754639, 1.105887532234192, 1.2448062896728516, 1.0287193059921265, 1.0909217596054077, 1.0963412523269653, 1.2172634601593018, 1.202816367149353, 1.0580251216888428, 0.9970459938049316, 1.138404369354248, 1.1031495332717896, 1.0713876485824585, 1.5794926881790161, 1.0870767831802368, 1.0727084875106812, 1.0825644731521606, 1.20853590965271, 1.118651270866394, 1.1224812269210815, 1.0585174560546875, 1.0151156187057495, 1.021077036857605, 1.1022369861602783, 1.1296337842941284, 1.0839754343032837, 1.361175775527954, 1.0756539106369019, 1.055325984954834, 0.9852889180183411, 1.0967012643814087, 1.1141505241394043, 1.1329559087753296, 1.1019690036773682, 1.0809662342071533, 1.074598789215088, 1.0350273847579956, 1.0471060276031494, 1.1549980640411377, 1.4048112630844116, 1.037185549736023, 1.1387293338775635, 0.9323279857635498, 1.0329415798187256, 1.096483826637268, 0.9694865942001343, 0.9516595602035522, 1.1111876964569092, 1.0080583095550537, 1.00123929977417, 0.9269136786460876, 1.1027848720550537, 1.241808533668518, 1.0505343675613403, 1.036581039428711, 1.0061626434326172, 1.0363550186157227, 0.9980205297470093, 1.0898935794830322, 1.0077461004257202, 0.9395063519477844, 1.003443956375122, 0.877712607383728, 0.9925432205200195, 1.0757167339324951, 1.2265275716781616, 1.0099552869796753, 1.0132817029953003, 0.8335976600646973, 0.9852792620658875, 0.9054067730903625, 0.9542518258094788, 0.9654409885406494, 1.0182286500930786, 0.938700258731842, 1.0286692380905151, 1.0604970455169678, 1.0133509635925293, 1.3426166772842407, 0.85176682472229, 0.8985701203346252, 0.986565351486206, 1.0250259637832642, 1.0373411178588867, 1.0077409744262695, 0.9853792190551758, 0.9309890866279602, 0.8983504176139832, 0.918121874332428, 0.9418414235115051, 0.8623408079147339, 1.5230666399002075, 1.009492039680481, 0.9911389350891113, 0.9281284809112549, 0.8859211206436157, 0.91744464635849, 0.8643192648887634, 0.9145343899726868, 0.9039139747619629, 0.9291892647743225, 0.9196172952651978, 0.998028039932251, 0.8791599273681641, 1.3387449979782104, 0.9071696996688843, 1.0568888187408447, 0.8953230977058411, 0.8151562213897705, 0.9817558526992798, 0.8485199809074402, 0.8239955306053162, 0.8574457764625549, 0.9512265920639038, 0.9305089116096497, 0.8203861713409424, 0.9781204462051392, 1.242319107055664, 0.8498420715332031, 0.8395586609840393, 0.9109242558479309, 0.7822128534317017, 0.9297908544540405, 0.8617746829986572, 0.8219089508056641, 0.8363009691238403, 0.799071729183197, 0.9961012601852417, 0.9675419330596924, 0.8401726484298706, 1.3060253858566284, 0.8006771206855774, 0.8295220732688904, 0.804169774055481, 0.7438410520553589, 0.9003604054450989, 0.833154022693634, 0.7630423903465271, 0.8549234867095947, 0.8122487664222717, 0.8592308759689331, 0.8451175689697266, 0.8204991221427917, 1.1360294818878174, 0.8062447905540466, 0.8593599200248718, 0.881136953830719, 0.8861075043678284, 0.8048059940338135, 0.7192348837852478, 0.8387994766235352, 0.936760663986206, 0.9719982743263245, 0.7664383053779602, 0.9290513396263123, 0.826463520526886, 1.2978209257125854, 0.7483645677566528, 0.9055283665657043, 0.9407468438148499, 0.8439188003540039, 0.9111893773078918, 0.8028316497802734, 0.8604560494422913, 0.7859736084938049, 0.720148503780365, 0.8281732797622681, 0.7760812640190125, 0.7955425381660461, 1.3939744234085083, 0.7645967602729797, 0.7945759892463684, 0.8295077681541443, 0.86468505859375, 0.8059883713722229, 0.8417657613754272, 0.7561762928962708, 0.831372857093811, 0.758120596408844, 0.8065205812454224, 0.817988395690918, 0.8582065105438232, 1.3207056522369385, 0.782841145992279, 0.7860615253448486, 0.7297084927558899, 0.8240069150924683, 0.7114059925079346, 0.7425559163093567, 0.8442504405975342, 0.7262232899665833, 0.8544576168060303, 0.878940761089325, 0.6852952837944031, 0.6907336115837097, 0.9096152782440186, 0.7325822710990906, 0.7576620578765869, 0.713989794254303, 0.7451684474945068, 0.7816212177276611, 0.7790254950523376, 0.8633514642715454, 0.7737483978271484, 0.7538260817527771, 0.6549986004829407, 0.743628203868866, 0.7409878969192505, 1.1728086471557617, 0.6929733753204346, 0.8033644556999207, 0.723178505897522, 0.7875256538391113, 0.8381622433662415, 0.8384714722633362, 0.6903190016746521, 0.7530584931373596, 0.684473991394043, 0.7553808093070984, 0.7372494339942932, 0.8354418277740479, 1.1502512693405151, 0.7236289381980896, 0.7793466448783875, 0.7192555069923401, 0.7757675647735596, 0.7721464037895203, 0.8113781213760376, 0.6986600160598755, 0.7259736657142639, 0.7041202187538147, 0.6629340052604675, 0.73895263671875, 0.7179149985313416, 1.0695699453353882, 0.6817556023597717, 0.7962680459022522, 0.7685311436653137, 0.7100496292114258, 0.7452709674835205, 0.7750268578529358, 0.6841904520988464, 0.7123616933822632, 0.8378894925117493, 0.7107530832290649, 0.8203026652336121, 0.7206096649169922, 1.2180445194244385, 0.6893949508666992, 0.7115433216094971, 0.7207239866256714, 0.7377708554267883, 0.650047242641449, 0.7488650679588318, 0.7910723090171814, 0.7175453305244446, 0.7699708938598633, 0.8033198714256287, 0.6965878009796143, 0.6601583361625671, 1.117641568183899, 0.7047280669212341, 0.6649975776672363, 0.8816192746162415, 0.7194340229034424, 0.6125379800796509, 0.7038299441337585, 0.6748189926147461, 0.8233760595321655, 0.7072989344596863, 0.722801923751831, 0.8441201448440552, 0.6817464232444763, 1.3850177526474, 0.7806101441383362, 0.7212536931037903, 0.6375973224639893, 0.700072705745697, 0.8029979467391968, 0.8079317212104797, 0.6670593023300171, 0.7533140778541565, 0.6396191120147705, 0.6952595710754395, 0.7522743344306946, 0.7152183055877686, 0.9489770531654358, 0.6878315806388855, 0.6004036664962769, 0.6426512002944946, 0.6801884174346924, 0.7660354375839233, 0.7318848967552185, 0.6925169229507446, 0.7716599106788635, 0.5438598394393921, 0.7103825211524963, 0.890828549861908, 0.7390390038490295, 1.0203624963760376, 0.593330979347229, 0.7389546036720276, 0.6827441453933716, 0.6577955484390259, 0.7349896430969238, 0.6466947197914124, 0.7588469386100769, 0.6879411339759827, 0.6889402866363525, 0.679444432258606, 0.5650088787078857, 0.738468587398529, 1.045193076133728, 0.6374831795692444, 0.6363315582275391, 0.5840540528297424, 0.6541639566421509, 0.6639286875724792, 0.6827341914176941, 0.779303789138794, 0.6362924575805664, 0.6701171398162842, 0.6632480025291443, 0.6878886222839355, 0.6571313142776489, 1.0623579025268555, 0.6177231669425964, 0.6136188507080078, 0.6496350765228271, 0.7252311110496521, 0.7217197418212891, 0.679261326789856, 0.6017820239067078, 0.7289174795150757, 0.8077407479286194, 0.6484190821647644, 0.6619555950164795, 0.6766390204429626, 0.9612165093421936, 0.6123785972595215, 0.7458011507987976, 0.7089620232582092, 0.7214362621307373, 0.5956353545188904, 0.708264946937561, 0.6533766388893127, 0.644101619720459, 0.6918818950653076, 0.6818993091583252, 0.5992242693901062, 0.6209002733230591, 0.860144853591919, 0.639574408531189, 0.6492165327072144, 0.6847774982452393, 0.7669754028320312, 0.6366977095603943, 0.5946011543273926, 0.6139004230499268, 0.6568872928619385, 0.7049160003662109, 0.6489177942276001, 0.6182581186294556, 0.6560283899307251, 1.270547866821289, 0.6019149422645569, 0.589637279510498, 0.6628119945526123, 0.6540067195892334, 0.7083207964897156, 0.5154195427894592, 0.6504992246627808, 0.6806038618087769, 0.5533608794212341, 0.6726495027542114, 0.6591938734054565, 0.6098034977912903, 1.1150708198547363, 0.6202312111854553, 0.7021298408508301, 0.5855499505996704, 0.7162806391716003, 0.6937928199768066, 0.6448417901992798, 0.7009105086326599, 0.6400908827781677, 0.5980451703071594, 0.6624216437339783, 0.5786249041557312, 0.6229248046875, 1.0313206911087036, 0.638241171836853, 0.6432971954345703, 0.8456242680549622, 0.705533504486084, 0.6651067733764648, 0.6318728923797607, 0.7005608081817627, 0.6151015758514404, 0.6152924299240112, 0.6731157898902893, 0.6165013909339905, 0.5899902582168579, 1.03294038772583, 0.7067480683326721, 0.6431687474250793, 0.7012313008308411, 0.6165897846221924, 0.6044337153434753, 0.5572769045829773, 0.6382388472557068, 0.7696022391319275, 0.569715142250061, 0.5495426058769226, 0.5864623785018921, 0.7298439741134644, 1.1658731698989868, 0.671410858631134, 0.5705817341804504, 0.6857556104660034, 0.6880903840065002, 0.666716992855072, 0.7029552459716797, 0.611426591873169, 0.509097158908844, 0.6624810695648193, 0.7004268765449524, 0.616641104221344, 0.5264468193054199, 0.7960473895072937, 0.621555507183075, 0.6548234820365906, 0.6464720368385315, 0.6645793914794922, 0.6686773300170898, 0.7649259567260742, 0.4983499050140381, 0.6505908370018005, 0.6018334627151489, 0.5793629884719849, 0.5386489629745483, 0.6457393169403076, 1.1139962673187256, 0.7768360376358032, 0.677488386631012, 0.6138125658035278, 0.5531765222549438, 0.6066939830780029, 0.5581899285316467, 0.6205155253410339, 0.5715271234512329, 0.5616486668586731, 0.5683940649032593, 0.6910758018493652, 0.6731971502304077, 0.8943735957145691, 0.5936828851699829, 0.6465256214141846, 0.5455852746963501, 0.5933559536933899, 0.644838809967041, 0.649417519569397, 0.5570467114448547, 0.6367841362953186, 0.6074239611625671, 0.718816876411438, 0.6364425420761108, 0.5718268156051636, 1.1530845165252686, 0.655897319316864, 0.6486729383468628, 0.6128795742988586, 0.6171866059303284, 0.6499870419502258, 0.5734485387802124, 0.5450148582458496, 0.5554214119911194, 0.6449459791183472, 0.6567209362983704, 0.5596337914466858, 0.6802096962928772, 0.6918190717697144, 0.48156973719596863, 0.6743522882461548, 0.6328243017196655, 0.5112063884735107, 0.6204609870910645, 0.5655148029327393, 0.6342950463294983, 0.6229162812232971, 0.5179388523101807, 0.5746706128120422, 0.668956458568573, 0.6168000102043152, 1.0266680717468262, 0.7100372910499573, 0.5972635746002197, 0.6011610627174377, 0.6004359126091003, 0.6756979823112488, 0.4839223325252533, 0.5691332221031189, 0.5671195387840271, 0.657601535320282, 0.5095998048782349, 0.5926576852798462, 0.5542044639587402, 1.0596171617507935, 0.5404974818229675, 0.5723634958267212, 0.7668253779411316, 0.6870957612991333, 0.5647262334823608, 0.6078202128410339, 0.7582898139953613, 0.6244578957557678, 0.6253871917724609, 0.6088429689407349, 0.6148673892021179, 0.6806493401527405, 1.381864309310913, 0.5731050372123718, 0.5325114727020264, 0.5376856923103333, 0.5368833541870117, 0.7483079433441162, 0.5955795645713806, 0.5501694083213806, 0.6074977517127991, 0.6337665319442749, 0.5492583513259888, 0.684112012386322, 0.568023145198822, 0.8676576614379883, 0.6287826299667358, 0.6230859160423279, 0.5873902440071106, 0.5275882482528687, 0.6076620817184448, 0.5749420523643494, 0.6033587455749512, 0.5560178756713867, 0.6071804761886597, 0.5944039821624756, 0.6322832107543945, 0.6274197101593018, 1.025871753692627, 0.5290986895561218, 0.5973442792892456, 0.47614431381225586, 0.5375052094459534, 0.585545003414154, 0.5136956572532654, 0.6107907295227051, 0.579059362411499, 0.6634441018104553, 0.6090899109840393, 0.5417182445526123, 0.5692220330238342, 1.0676696300506592, 0.6690018773078918, 0.5708237886428833, 0.5192699432373047, 0.6109777092933655, 0.5512815117835999, 0.5892017483711243, 0.5747465491294861, 0.5981569290161133, 0.5550256371498108, 0.518992006778717, 0.4920531213283539, 0.5669877529144287, 0.8043858408927917, 0.5085447430610657, 0.48484498262405396, 0.4931102395057678, 0.6152799129486084, 0.5890650749206543, 0.693462610244751, 0.6164639592170715, 0.7017744779586792, 0.6104360222816467, 0.5855711102485657, 0.5264238119125366, 0.5489027500152588, 0.9040921926498413, 0.6581767797470093, 0.568001925945282, 0.5191332101821899, 0.6127145290374756, 0.5861457586288452, 0.5763072967529297, 0.5680912137031555, 0.5901010036468506, 0.4777117371559143, 0.465194433927536, 0.5422183275222778, 0.5525276064872742, 0.9210568070411682, 0.559339165687561, 0.6088014245033264, 0.5906681418418884, 0.5870838165283203, 0.5426821112632751, 0.5412847399711609, 0.5826778411865234, 0.5285007953643799, 0.5451551079750061, 0.49078133702278137, 0.5462998151779175, 0.5577614903450012, 0.8820732235908508, 0.5611413717269897, 0.49097463488578796, 0.5203081965446472, 0.5705986618995667, 0.5567730069160461, 0.5592126250267029, 0.5672594308853149, 0.5575747489929199, 0.5648337006568909, 0.5132514238357544, 0.5410587787628174, 0.47298336029052734, 0.9957916736602783, 0.6417480111122131, 0.42560189962387085, 0.5152861475944519, 0.6087814569473267, 0.5657597184181213, 0.6282579302787781, 0.4690167307853699, 0.6058313250541687, 0.5380613207817078, 0.5698531866073608, 0.5310968160629272, 0.5420398116111755, 1.101344108581543, 0.5409544110298157, 0.5182744860649109, 0.5829534530639648, 0.5903736352920532, 0.5470960736274719, 0.517833948135376, 0.530702531337738, 0.5383664965629578, 0.515579104423523, 0.58140629529953, 0.5097545981407166, 0.5020508766174316, 1.0302250385284424, 0.4860709607601166, 0.5339460372924805, 0.6611784100532532, 0.540693998336792, 0.5059728026390076, 0.5218983292579651, 0.5553712248802185, 0.5433809161186218, 0.4632825255393982, 0.5729888677597046, 0.5611644983291626, 0.4421927332878113, 0.830488383769989, 0.5257643461227417, 0.5950504541397095, 0.553108811378479, 0.5285289287567139, 0.4455249607563019, 0.5834909081459045, 0.4639700949192047, 0.5146238803863525, 0.494601845741272, 0.5066304802894592, 0.5992468595504761, 0.42256370186805725, 1.4059584140777588, 0.5312213897705078, 0.49968379735946655, 0.478706419467926, 0.4767226576805115, 0.4509316384792328, 0.53708416223526, 0.4796229600906372, 0.4738154709339142, 0.5514525771141052, 0.5478172898292542, 0.5156094431877136, 0.5353542566299438, 1.0205767154693604, 0.5499420166015625, 0.4589061439037323, 0.5819308757781982, 0.5283288359642029, 0.565086305141449, 0.5153779983520508, 0.5088618993759155, 0.5379151701927185, 0.5499546527862549, 0.5177170038223267, 0.6097968816757202, 0.5824980139732361, 1.1318334341049194, 0.47225087881088257, 0.49449998140335083, 0.525804340839386, 0.5120342969894409, 0.4686184227466583, 0.5651114583015442, 0.581831693649292, 0.4318687319755554, 0.5871233344078064, 0.5028050541877747, 0.4837433993816376, 0.5271456837654114, 1.3922951221466064, 0.4798629879951477, 0.5156728029251099, 0.4290963113307953, 0.42070484161376953, 0.5170698761940002, 0.5767855644226074, 0.4679882228374481, 0.5346283912658691, 0.45476898550987244, 0.4422767758369446, 0.5163620710372925, 0.5285278558731079, 0.822359025478363, 0.5494177341461182, 0.46371087431907654, 0.5690878033638, 0.5298694372177124, 0.485214501619339, 0.5721592307090759, 0.42928609251976013, 0.48774316906929016, 0.44077250361442566, 0.47653523087501526, 0.5368236899375916, 0.5439038276672363, 0.6794242858886719, 0.5163130760192871, 0.5244215726852417, 0.5236849188804626, 0.4001757800579071, 0.5746057629585266, 0.5394846200942993, 0.48494455218315125, 0.4723564088344574, 0.3912060558795929, 0.5300897359848022, 0.49783915281295776, 0.49744561314582825, 0.6928099393844604, 0.5380904674530029, 0.665799081325531, 0.5036227107048035, 0.49596598744392395, 0.4840133786201477, 0.4665078818798065, 0.49394771456718445, 0.4686722457408905, 0.42323195934295654, 0.4744148850440979, 0.4948863685131073, 0.47879526019096375, 0.6515557169914246, 0.5052204132080078, 0.43892374634742737, 0.5893895030021667, 0.515397310256958, 0.5021552443504333, 0.49342650175094604, 0.38320717215538025, 0.5853314995765686, 0.488730788230896, 0.5483587384223938, 0.4950326681137085, 0.5053573846817017, 0.9710970520973206, 0.5581142902374268, 0.46759042143821716, 0.517754852771759, 0.4161492884159088, 0.46333789825439453, 0.45712733268737793, 0.48195475339889526, 0.4523693919181824, 0.49491456151008606, 0.5307167172431946, 0.5244978070259094, 0.5159211754798889, 0.9923399686813354, 0.555132269859314, 0.4838738441467285, 0.5324346423149109, 0.4570293128490448, 0.5364232659339905, 0.4997212290763855, 0.5324070453643799, 0.5972191691398621, 0.48243647813796997, 0.4916755259037018, 0.42931878566741943, 0.5208964943885803, 0.7348617315292358, 0.44623473286628723, 0.4477204382419586, 0.4792414903640747, 0.4610588550567627, 0.5255782008171082, 0.4546946585178375, 0.4593900442123413, 0.4612479507923126, 0.41440850496292114, 0.43171489238739014, 0.37582632899284363, 0.4607311487197876, 1.1692581176757812, 0.4159582257270813, 0.42923298478126526, 0.4465191662311554, 0.5575454831123352, 0.4423665404319763, 0.466567724943161, 0.4677041172981262, 0.5203552842140198, 0.49616095423698425, 0.45874324440956116, 0.4766172170639038, 0.5185803174972534, 1.0521107912063599, 0.42476728558540344, 0.45004263520240784, 0.4589996933937073, 0.45573821663856506, 0.525501012802124, 0.4432468116283417, 0.5610598921775818, 0.4485205113887787, 0.5972587466239929, 0.4725700914859772, 0.4694041907787323, 0.5247434973716736, 0.8658844232559204, 0.5091893672943115, 0.497475266456604, 0.45318838953971863, 0.4012325406074524, 0.45608633756637573, 0.4714505076408386, 0.5144458413124084, 0.4456530213356018, 0.4531491994857788, 0.4552028775215149, 0.4527934193611145, 0.4366743564605713, 1.0085943937301636, 0.46593552827835083, 0.45319893956184387, 0.42417117953300476, 0.45110082626342773, 0.5104249119758606, 0.48844385147094727, 0.557161808013916, 0.5105173587799072, 0.556525707244873, 0.4947142004966736, 0.4335014820098877, 0.5594413876533508, 1.3136630058288574, 0.5244871377944946, 0.4592446982860565, 0.37176892161369324, 0.5180423855781555, 0.5022456645965576, 0.537372350692749, 0.40007272362709045, 0.4438878893852234, 0.44266846776008606, 0.4755142331123352, 0.4921663999557495, 0.409962922334671, 1.0803810358047485, 0.5913943648338318, 0.5351381301879883, 0.37411314249038696, 0.4301643371582031, 0.5046964883804321, 0.510854184627533, 0.4332319498062134, 0.5245051980018616, 0.5078754425048828, 0.4231656789779663, 0.4582306444644928, 0.4162119925022125, 1.012398362159729, 0.4897882044315338, 0.5723735094070435, 0.4727405309677124, 0.44417738914489746, 0.44356897473335266, 0.4574931263923645, 0.5025579333305359, 0.384628564119339, 0.3970670700073242, 0.5434617400169373, 0.42187532782554626, 0.4375308156013489, 0.7822747230529785, 0.5959386229515076, 0.41662344336509705, 0.4532721936702728, 0.48290202021598816, 0.5148303508758545, 0.5238762497901917, 0.5058877468109131, 0.4251839816570282, 0.42536985874176025, 0.43365365266799927, 0.5104319453239441, 0.46725210547447205, 0.906463086605072, 0.4519692361354828, 0.4244448244571686, 0.34873175621032715, 0.42501822113990784, 0.3638928532600403, 0.4482830762863159, 0.4076109528541565, 0.4250551462173462, 0.42167869210243225, 0.5343390107154846, 0.4384821951389313, 0.48634907603263855, 0.9609645009040833, 0.4724509119987488, 0.4064435362815857, 0.4639352858066559, 0.4358755052089691, 0.46555012464523315, 0.4369715452194214, 0.5086570382118225, 0.4804302453994751, 0.542461633682251, 0.5175224542617798, 0.4645123779773712, 0.3721613883972168, 0.754496157169342, 0.4359526038169861, 0.5949446558952332, 0.3804851472377777, 0.3922213613986969, 0.3687509000301361, 0.44212016463279724, 0.42241349816322327, 0.38434910774230957, 0.4182932674884796, 0.41028982400894165, 0.3882543444633484, 0.35480496287345886, 0.9796300530433655, 0.359821617603302, 0.41516396403312683, 0.42318177223205566, 0.4415792226791382, 0.45974060893058777, 0.4874526560306549, 0.4692433178424835, 0.4351154565811157, 0.43346303701400757, 0.3704070448875427, 0.4477640390396118, 0.5049745440483093, 1.113612174987793, 0.4453326463699341, 0.3522791564464569, 0.449443519115448, 0.3994872272014618, 0.46269333362579346, 0.4712316393852234, 0.3407962918281555, 0.42340704798698425, 0.4800727963447571, 0.40382760763168335, 0.4063893258571625, 0.4503284692764282, 0.6992830634117126, 0.5582646727561951, 0.4541351795196533, 0.43438467383384705, 0.3979909121990204, 0.47871923446655273, 0.5427834391593933, 0.38724786043167114, 0.32784396409988403, 0.4116993546485901, 0.38894757628440857, 0.4052748680114746, 0.4950302243232727, 0.9146669507026672, 0.40641891956329346, 0.3888225257396698, 0.45516616106033325, 0.3422172963619232, 0.4405500888824463, 0.5104933381080627, 0.3918716609477997, 0.4125506281852722, 0.48140624165534973, 0.41601860523223877, 0.3616930842399597, 0.4330306053161621, 0.8697180151939392, 0.44479817152023315, 0.5182201862335205, 0.45263585448265076, 0.36853134632110596, 0.44679179787635803, 0.5004991292953491, 0.43644779920578003, 0.4227449595928192, 0.4943675696849823, 0.3710049092769623, 0.4816264808177948, 0.4324457347393036, 0.7590497732162476, 0.4523244798183441, 0.40196236968040466, 0.5529388785362244, 0.4940284788608551, 0.340582937002182, 0.49969086050987244, 0.435388445854187, 0.402304470539093, 0.4313993752002716, 0.33189868927001953, 0.5457558631896973, 0.3750208914279938, 0.7779595851898193, 0.5212210416793823, 0.41817858815193176, 0.4352227747440338, 0.3715296685695648, 0.48161208629608154, 0.48155802488327026, 0.4775932729244232, 0.3972204923629761, 0.3905062675476074, 0.35997387766838074, 0.3564746081829071, 0.40507376194000244, 0.7345286011695862, 0.367324560880661, 0.41745108366012573, 0.42287904024124146, 0.37956610321998596, 0.5540465116500854, 0.4108109474182129, 0.4365251660346985, 0.38540711998939514, 0.3692657947540283, 0.504962682723999, 0.34970083832740784, 0.4284219443798065, 0.6346005201339722, 0.35013529658317566, 0.43669676780700684, 0.4181821048259735, 0.3909945785999298, 0.34567174315452576, 0.43927693367004395, 0.4066612124443054, 0.33907589316368103, 0.3252529799938202, 0.39065349102020264, 0.373031884431839, 0.4092573821544647, 0.7465972900390625, 0.3741917312145233, 0.36691829562187195, 0.42645809054374695, 0.5050855278968811, 0.3826969265937805, 0.4246126413345337, 0.39435598254203796, 0.39737364649772644, 0.47474971413612366, 0.46102070808410645, 0.3962053954601288, 0.43845394253730774, 0.7626501321792603, 0.4909953773021698, 0.46778956055641174, 0.3717886209487915, 0.40932533144950867, 0.41594284772872925, 0.3728865683078766, 0.4478206932544708, 0.4404769241809845, 0.38730597496032715, 0.3693481981754303, 0.4067349135875702, 0.42562004923820496, 0.8651324510574341, 0.44004136323928833, 0.3270510733127594, 0.42377740144729614, 0.40793895721435547, 0.41879385709762573, 0.3106576204299927, 0.38740968704223633, 0.4333614110946655, 0.3866580128669739, 0.4025750458240509, 0.5001540184020996, 0.33970922231674194, 1.0190227031707764, 0.36843186616897583, 0.4211432635784149, 0.38492530584335327, 0.3840881288051605, 0.5189396739006042, 0.4453287720680237, 0.4471435546875, 0.42179548740386963, 0.5150839686393738, 0.40187549591064453, 0.4140813648700714, 0.37864676117897034, 0.5914340019226074, 0.4291226267814636, 0.3946315348148346, 0.41444966197013855, 0.3789386749267578, 0.39806827902793884, 0.30868250131607056, 0.39676597714424133, 0.3837079405784607, 0.4112376868724823, 0.41997766494750977, 0.3769674301147461, 0.367693692445755, 0.673173189163208, 0.37000101804733276, 0.3284894824028015, 0.5220662951469421, 0.3630571961402893, 0.41309043765068054, 0.3743792772293091, 0.3735909163951874, 0.3143015503883362, 0.3926180899143219, 0.42620906233787537, 0.3433932363986969, 0.41062137484550476, 0.9246166944503784, 0.39149972796440125, 0.4366651475429535, 0.4125615060329437, 0.4035278260707855, 0.2992493212223053, 0.4538630545139313, 0.4502326548099518, 0.415688693523407, 0.3202458322048187, 0.3995484709739685, 0.46116212010383606, 0.4172036945819855, 0.7642717361450195, 0.43749070167541504, 0.4233556389808655, 0.4589834213256836, 0.35889875888824463, 0.4260074496269226, 0.4452385902404785, 0.4609556496143341, 0.4218870997428894, 0.3499763607978821, 0.31344491243362427, 0.35456427931785583, 0.35079336166381836, 1.1283037662506104, 0.4072306752204895, 0.40743178129196167, 0.3965204954147339, 0.3373996615409851, 0.40275877714157104, 0.3318203091621399, 0.39720991253852844, 0.42504364252090454, 0.4291202425956726, 0.302557110786438, 0.38012203574180603, 0.3334575891494751, 0.8997373580932617, 0.36670348048210144, 0.3534673750400543, 0.4473361074924469, 0.3736633360385895, 0.3550831079483032, 0.5570150017738342, 0.42976027727127075, 0.38795793056488037, 0.6022468209266663, 0.4087124764919281, 0.3399152159690857, 0.37325814366340637, 0.7924895286560059, 0.3508360981941223, 0.40654700994491577, 0.38521793484687805, 0.41356754302978516, 0.3404662013053894, 0.40723392367362976, 0.3823947310447693, 0.33628755807876587, 0.35950350761413574, 0.2938951253890991, 0.3703017234802246, 0.3669893741607666, 0.9632341861724854, 0.3075374662876129, 0.34158384799957275, 0.4005594551563263, 0.4097701907157898, 0.39287006855010986, 0.46399444341659546, 0.5132321715354919, 0.3524862825870514, 0.40974557399749756, 0.31338196992874146, 0.37730246782302856, 0.35065001249313354, 0.8147359490394592, 0.37573742866516113, 0.32898738980293274, 0.433902382850647, 0.3754153549671173, 0.33947640657424927, 0.3908756375312805, 0.3543057143688202, 0.35022416710853577, 0.31854158639907837, 0.41529157757759094, 0.4268251657485962, 0.3251335918903351, 0.9486440420150757, 0.44951844215393066, 0.4651901125907898, 0.32481712102890015, 0.30968332290649414, 0.3275853097438812, 0.4161081314086914, 0.4065956175327301, 0.3674086630344391, 0.402242511510849, 0.43228963017463684, 0.3515353500843048, 0.42876720428466797, 1.0672378540039062, 0.36477357149124146, 0.42390912771224976, 0.3791365921497345, 0.41710424423217773, 0.43833160400390625, 0.32142767310142517, 0.3416787087917328, 0.4300406277179718, 0.3085334599018097, 0.3594995141029358, 0.43557292222976685, 0.30356720089912415, 0.6219274401664734, 0.31603261828422546, 0.3654116094112396, 0.3730241060256958, 0.36288580298423767, 0.39153289794921875, 0.4122265875339508, 0.3186773359775543, 0.38685303926467896, 0.36350467801094055, 0.3915517032146454, 0.3799781799316406, 0.36370107531547546, 0.6144687533378601, 0.3339233100414276, 0.3016660809516907, 0.38189396262168884, 0.362558513879776, 0.34805750846862793, 0.3201039433479309, 0.3777218461036682, 0.4044802486896515, 0.4811897873878479, 0.31839853525161743, 0.3391510248184204, 0.3831135630607605, 0.7288316488265991, 0.34358882904052734, 0.34725362062454224, 0.2780424654483795, 0.33340856432914734, 0.34182053804397583, 0.33809852600097656, 0.4318161904811859, 0.35261964797973633, 0.4290976822376251, 0.40462562441825867, 0.3210643529891968, 0.4049304723739624, 0.7423437833786011, 0.38956549763679504, 0.3777914047241211, 0.41510871052742004, 0.27476221323013306, 0.3973826467990875, 0.3733392357826233, 0.43478769063949585, 0.3063993453979492, 0.29988574981689453, 0.34406402707099915, 0.3986204266548157, 0.3566327691078186, 0.7276657819747925, 0.3078613877296448, 0.3130772113800049, 0.3356088697910309, 0.42859476804733276, 0.36513200402259827, 0.34515631198883057, 0.34983646869659424, 0.38627755641937256, 0.29526787996292114, 0.3985731899738312, 0.3978532552719116, 0.33649060130119324, 0.7634502649307251, 0.36379754543304443, 0.34081050753593445, 0.32984745502471924, 0.3374471068382263, 0.3541737496852875, 0.4636771082878113, 0.3378661274909973, 0.36030420660972595, 0.3691694140434265, 0.3816615045070648, 0.37192225456237793, 0.2954082787036896, 0.8642794489860535, 0.3949468433856964, 0.38313648104667664, 0.4442829489707947, 0.4301674962043762, 0.4265049397945404, 0.31731316447257996, 0.37503865361213684, 0.26077401638031006, 0.29532989859580994, 0.3439794182777405, 0.3365456461906433, 0.32318881154060364, 1.2431366443634033, 0.33675193786621094, 0.37298643589019775, 0.37356892228126526, 0.38251614570617676, 0.32222431898117065, 0.4453830420970917, 0.24038872122764587, 0.3223775625228882, 0.35007867217063904, 0.329881489276886, 0.4053508937358856, 0.40666717290878296, 0.914932906627655, 0.3495103716850281, 0.31483832001686096, 0.35423651337623596, 0.39779898524284363, 0.428831547498703, 0.386127233505249, 0.32695820927619934, 0.41324207186698914, 0.32165849208831787, 0.3185524642467499, 0.3313882052898407, 0.31462574005126953, 0.9426894783973694, 0.40314745903015137, 0.30367982387542725, 0.2892533540725708, 0.32893916964530945, 0.384992778301239, 0.4292103052139282, 0.3734656870365143, 0.3356339633464813, 0.2962166965007782, 0.3221922218799591, 0.39864203333854675, 0.3806361258029938, 1.1517915725708008, 0.3275989294052124, 0.36784952878952026, 0.2827293574810028, 0.2766936123371124, 0.43495580554008484, 0.3106946051120758, 0.3229486346244812, 0.30758973956108093, 0.307778000831604, 0.29326409101486206, 0.3418807089328766, 0.29718223214149475, 0.9995563626289368, 0.3591352701187134, 0.3394055962562561, 0.33178719878196716, 0.3602046072483063, 0.2754914462566376, 0.3403213620185852, 0.29741179943084717, 0.38071247935295105, 0.34591370820999146, 0.3505324125289917, 0.3113456070423126, 0.3936796188354492, 0.4945129156112671, 0.34020912647247314, 0.36235836148262024, 0.30059579014778137, 0.4560471177101135, 0.4432164132595062, 0.3395730257034302, 0.36229684948921204, 0.4697060286998749, 0.4164115786552429, 0.41350582242012024, 0.32025909423828125, 0.3737185001373291, 0.8205760717391968, 0.344673216342926, 0.34838443994522095, 0.24067316949367523, 0.3287948668003082, 0.31592416763305664, 0.3396032154560089, 0.3521497845649719, 0.44672515988349915, 0.38757145404815674, 0.2667597830295563, 0.36919930577278137, 0.3445032835006714, 0.7219807505607605, 0.33582741022109985, 0.3797000050544739, 0.2609989643096924, 0.30931392312049866, 0.4258018434047699, 0.31875696778297424, 0.38734930753707886, 0.29074832797050476, 0.3640962541103363, 0.3683358132839203, 0.31043750047683716, 0.31732597947120667, 0.6149374842643738, 0.3066796064376831, 0.3006224036216736, 0.32512250542640686, 0.377775102853775, 0.32237157225608826, 0.41106146574020386, 0.344896137714386, 0.3158913254737854, 0.4112430810928345, 0.34818264842033386, 0.2880036234855652, 0.4122917652130127, 0.6249231100082397]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (iteration_loss)\n",
    "plt.plot(iteration_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "num_iters = 20000\n",
    "input_dim = 28*28\n",
    "num_hidden = 330\n",
    "output_dim = 10\n",
    "\n",
    "learning_rate = 0.025\n",
    "\n",
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        self.relu_1 = nn.ReLU()\n",
    " \n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_2 = nn.ReLU()\n",
    " \n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_3 = nn.ReLU()\n",
    " \n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_4 = nn.Softmax(dim=0)\n",
    " \n",
    "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_5= nn.ReLU()\n",
    " \n",
    "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_6 = nn.ReLU()\n",
    " \n",
    "        self.linear_out = nn.Linear(num_hidden, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out  = self.linear_1(x)\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        out  = self.linear_2(out)\n",
    "        out = self.relu_2(out)\n",
    " \n",
    "        out  = self.linear_3(out)\n",
    "        out = self.relu_3(out)\n",
    " \n",
    "        out  = self.linear_4(out)\n",
    "        out = self.relu_4(out)\n",
    " \n",
    "        out  = self.linear_5(out)\n",
    "        out = self.relu_5(out)\n",
    " \n",
    "        out  = self.linear_6(out)\n",
    "        out = self.relu_6(out)\n",
    "        \n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:78\n",
      "Test dataloader:20\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=340, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=340, out_features=340, bias=True)\n",
       "  (relu_2): ReLU()\n",
       "  (linear_3): Linear(in_features=340, out_features=340, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_4): Linear(in_features=340, out_features=340, bias=True)\n",
       "  (relu_4): Softmax(dim=0)\n",
       "  (linear_5): Linear(in_features=340, out_features=340, bias=True)\n",
       "  (relu_5): ReLU()\n",
       "  (linear_6): Linear(in_features=340, out_features=340, bias=True)\n",
       "  (relu_6): ReLU()\n",
       "  (linear_out): Linear(in_features=340, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Iteration: 10. Loss: 2.300997734069824. Accuracy: 10.22844206626878\n",
      "Iteration: 20. Loss: 2.3055310249328613. Accuracy: 9.672772175344722\n",
      "Iteration: 30. Loss: 2.3004531860351562. Accuracy: 9.672772175344722\n",
      "Iteration: 40. Loss: 2.293670654296875. Accuracy: 14.591479728339165\n",
      "Iteration: 50. Loss: 2.2598161697387695. Accuracy: 14.982506688619058\n",
      "Iteration: 60. Loss: 2.2019400596618652. Accuracy: 15.044247787610619\n",
      "Iteration: 70. Loss: 2.137847900390625. Accuracy: 16.60835562873019\n",
      "Epoch:  2\n",
      "Iteration: 80. Loss: 2.1626009941101074. Accuracy: 21.012554023461618\n",
      "Iteration: 90. Loss: 2.273488759994507. Accuracy: 18.66639226178226\n",
      "Iteration: 100. Loss: 2.2151618003845215. Accuracy: 20.353982300884955\n",
      "Iteration: 110. Loss: 2.132821559906006. Accuracy: 19.921794607944022\n",
      "Iteration: 120. Loss: 2.1348633766174316. Accuracy: 21.38300061741099\n",
      "Iteration: 130. Loss: 2.103851556777954. Accuracy: 22.103313438979214\n",
      "Iteration: 140. Loss: 2.0649843215942383. Accuracy: 21.876929409343486\n",
      "Iteration: 150. Loss: 2.1035704612731934. Accuracy: 23.029429923852646\n",
      "Epoch:  3\n",
      "Iteration: 160. Loss: 2.0434072017669678. Accuracy: 22.741304795225354\n",
      "Iteration: 170. Loss: 2.108135938644409. Accuracy: 22.412018933937023\n",
      "Iteration: 180. Loss: 2.0894734859466553. Accuracy: 23.358715785140976\n",
      "Iteration: 190. Loss: 2.0101513862609863. Accuracy: 23.688001646429306\n",
      "Iteration: 200. Loss: 2.056121349334717. Accuracy: 23.4821979831241\n",
      "Iteration: 210. Loss: 1.9963839054107666. Accuracy: 23.832064210742953\n",
      "Iteration: 220. Loss: 1.985136866569519. Accuracy: 25.04630582424367\n",
      "Iteration: 230. Loss: 1.96055006980896. Accuracy: 24.71701996295534\n",
      "Epoch:  4\n",
      "Iteration: 240. Loss: 2.0018982887268066. Accuracy: 25.437332784523566\n",
      "Iteration: 250. Loss: 2.0207643508911133. Accuracy: 25.02572545791315\n",
      "Iteration: 260. Loss: 1.9696134328842163. Accuracy: 24.531796665980654\n",
      "Iteration: 270. Loss: 2.0263688564300537. Accuracy: 26.054743774439185\n",
      "Iteration: 280. Loss: 1.983209490776062. Accuracy: 26.4663511010496\n",
      "Iteration: 290. Loss: 2.0111641883850098. Accuracy: 25.807779378472937\n",
      "Iteration: 300. Loss: 1.9228787422180176. Accuracy: 27.001440625643138\n",
      "Iteration: 310. Loss: 1.9401109218597412. Accuracy: 27.35130685326199\n",
      "Epoch:  5\n",
      "Iteration: 320. Loss: 1.934268593788147. Accuracy: 27.1660835562873\n",
      "Iteration: 330. Loss: 1.8035476207733154. Accuracy: 28.277423338135417\n",
      "Iteration: 340. Loss: 1.9089335203170776. Accuracy: 29.018316526034162\n",
      "Iteration: 350. Loss: 1.9297959804534912. Accuracy: 29.615147149619265\n",
      "Iteration: 360. Loss: 1.8941313028335571. Accuracy: 28.462646635110104\n",
      "Iteration: 370. Loss: 1.8629851341247559. Accuracy: 31.117513891747272\n",
      "Iteration: 380. Loss: 1.9325755834579468. Accuracy: 29.30644165466145\n",
      "Iteration: 390. Loss: 2.079625129699707. Accuracy: 29.80037044659395\n",
      "Epoch:  6\n",
      "Iteration: 400. Loss: 1.8088762760162354. Accuracy: 30.541263634492694\n",
      "Iteration: 410. Loss: 1.8703217506408691. Accuracy: 29.82095081292447\n",
      "Iteration: 420. Loss: 1.9359214305877686. Accuracy: 31.26157645606092\n",
      "Iteration: 430. Loss: 1.756811261177063. Accuracy: 31.446799753035602\n",
      "Iteration: 440. Loss: 1.8632378578186035. Accuracy: 31.529121218357687\n",
      "Iteration: 450. Loss: 1.8790465593338013. Accuracy: 32.20827330726487\n",
      "Iteration: 460. Loss: 1.7561073303222656. Accuracy: 32.5375591685532\n",
      "Epoch:  7\n",
      "Iteration: 470. Loss: 1.828674077987671. Accuracy: 31.467380119366126\n",
      "Iteration: 480. Loss: 1.721001386642456. Accuracy: 32.94916649516362\n",
      "Iteration: 490. Loss: 1.9301656484603882. Accuracy: 32.57871990121424\n",
      "Iteration: 500. Loss: 1.8426222801208496. Accuracy: 30.479522535501133\n",
      "Iteration: 510. Loss: 1.8568161725997925. Accuracy: 32.80510393084997\n",
      "Iteration: 520. Loss: 1.8270330429077148. Accuracy: 32.908005762502576\n",
      "Iteration: 530. Loss: 1.7374153137207031. Accuracy: 32.908005762502576\n",
      "Iteration: 540. Loss: 1.8082523345947266. Accuracy: 34.51327433628319\n",
      "Epoch:  8\n",
      "Iteration: 550. Loss: 1.8689409494400024. Accuracy: 32.88742539617205\n",
      "Iteration: 560. Loss: 1.8381657600402832. Accuracy: 33.566577485079236\n",
      "Iteration: 570. Loss: 1.78706693649292. Accuracy: 34.842560197571515\n",
      "Iteration: 580. Loss: 1.805719017982483. Accuracy: 34.780819098579954\n",
      "Iteration: 590. Loss: 1.761533498764038. Accuracy: 35.645194484461825\n",
      "Iteration: 600. Loss: 1.798932671546936. Accuracy: 34.45153323729162\n",
      "Iteration: 610. Loss: 1.7629766464233398. Accuracy: 36.83885573163202\n",
      "Iteration: 620. Loss: 1.7697336673736572. Accuracy: 38.320642107429514\n",
      "Epoch:  9\n",
      "Iteration: 630. Loss: 1.6788215637207031. Accuracy: 37.04465939493723\n",
      "Iteration: 640. Loss: 1.6753156185150146. Accuracy: 37.518007820539204\n",
      "Iteration: 650. Loss: 1.709541916847229. Accuracy: 37.27104342457296\n",
      "Iteration: 660. Loss: 1.6196496486663818. Accuracy: 39.020374562667214\n",
      "Iteration: 670. Loss: 1.7444316148757935. Accuracy: 38.93805309734513\n",
      "Iteration: 680. Loss: 1.6658656597137451. Accuracy: 39.226178225972426\n",
      "Iteration: 690. Loss: 1.7001081705093384. Accuracy: 38.91747273101461\n",
      "Iteration: 700. Loss: 1.6781268119812012. Accuracy: 37.559168553200244\n",
      "Epoch:  10\n",
      "Iteration: 710. Loss: 1.6132622957229614. Accuracy: 39.76126775056596\n",
      "Iteration: 720. Loss: 1.6089423894882202. Accuracy: 39.94649104754065\n",
      "Iteration: 730. Loss: 1.7105060815811157. Accuracy: 40.04939287919325\n",
      "Iteration: 740. Loss: 1.855621576309204. Accuracy: 37.49742745420868\n",
      "Iteration: 750. Loss: 1.5221376419067383. Accuracy: 39.61720518625231\n",
      "Iteration: 760. Loss: 1.728410005569458. Accuracy: 41.03725046305824\n",
      "Iteration: 770. Loss: 1.5775409936904907. Accuracy: 40.502160938464705\n",
      "Iteration: 780. Loss: 1.6795077323913574. Accuracy: 39.843589215888045\n",
      "Epoch:  11\n",
      "Iteration: 790. Loss: 1.6094805002212524. Accuracy: 41.26363449269397\n",
      "Iteration: 800. Loss: 1.6992459297180176. Accuracy: 40.62564313644783\n",
      "Iteration: 810. Loss: 1.670319676399231. Accuracy: 41.07841119571928\n",
      "Iteration: 820. Loss: 1.4391928911209106. Accuracy: 42.27207244288948\n",
      "Iteration: 830. Loss: 1.6371476650238037. Accuracy: 42.35439390821156\n",
      "Iteration: 840. Loss: 1.6546787023544312. Accuracy: 41.922206215270634\n",
      "Iteration: 850. Loss: 1.6504254341125488. Accuracy: 41.42827742333814\n",
      "Epoch:  12\n",
      "Iteration: 860. Loss: 1.5878283977508545. Accuracy: 41.26363449269397\n",
      "Iteration: 870. Loss: 1.4454371929168701. Accuracy: 43.11586746244083\n",
      "Iteration: 880. Loss: 1.587782859802246. Accuracy: 41.88104548260959\n",
      "Iteration: 890. Loss: 1.6188937425613403. Accuracy: 40.481580572134185\n",
      "Iteration: 900. Loss: 1.6070551872253418. Accuracy: 43.218769294093434\n",
      "Iteration: 910. Loss: 1.7112787961959839. Accuracy: 44.782877135213006\n",
      "Iteration: 920. Loss: 1.6031540632247925. Accuracy: 43.280510393084995\n",
      "Iteration: 930. Loss: 1.6762253046035767. Accuracy: 44.53591273924676\n",
      "Epoch:  13\n",
      "Iteration: 940. Loss: 1.5483421087265015. Accuracy: 44.30952870961103\n",
      "Iteration: 950. Loss: 1.4257838726043701. Accuracy: 44.30952870961103\n",
      "Iteration: 960. Loss: 1.565645694732666. Accuracy: 45.09158263017082\n",
      "Iteration: 970. Loss: 1.420289158821106. Accuracy: 45.85305618440008\n",
      "Iteration: 980. Loss: 1.3716835975646973. Accuracy: 44.762296768882486\n",
      "Iteration: 990. Loss: 1.451507329940796. Accuracy: 45.441448857789666\n",
      "Iteration: 1000. Loss: 1.5595142841339111. Accuracy: 46.223502778349456\n",
      "Iteration: 1010. Loss: 1.4294403791427612. Accuracy: 44.18604651162791\n",
      "Epoch:  14\n",
      "Iteration: 1020. Loss: 1.4962263107299805. Accuracy: 46.61452973862935\n",
      "Iteration: 1030. Loss: 1.4326722621917725. Accuracy: 45.52377032311175\n",
      "Iteration: 1040. Loss: 1.362143874168396. Accuracy: 46.141181313027374\n",
      "Iteration: 1050. Loss: 1.577041745185852. Accuracy: 46.32640461000206\n",
      "Iteration: 1060. Loss: 1.3966305255889893. Accuracy: 47.520065857172256\n",
      "Iteration: 1070. Loss: 1.4046730995178223. Accuracy: 48.219798312409964\n",
      "Iteration: 1080. Loss: 1.3745282888412476. Accuracy: 47.19077999588393\n",
      "Iteration: 1090. Loss: 1.3647575378417969. Accuracy: 47.0672977979008\n",
      "Epoch:  15\n",
      "Iteration: 1100. Loss: 1.4260327816009521. Accuracy: 47.29368182753653\n",
      "Iteration: 1110. Loss: 1.4063526391983032. Accuracy: 47.37600329285861\n",
      "Iteration: 1120. Loss: 1.374187707901001. Accuracy: 48.50792344103725\n",
      "Iteration: 1130. Loss: 1.4825146198272705. Accuracy: 48.36386087672361\n",
      "Iteration: 1140. Loss: 1.4961047172546387. Accuracy: 48.46676270837621\n",
      "Iteration: 1150. Loss: 1.4391286373138428. Accuracy: 47.27310146120601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1160. Loss: 1.3698928356170654. Accuracy: 48.898950401317144\n",
      "Iteration: 1170. Loss: 1.413051724433899. Accuracy: 47.74644988680799\n",
      "Epoch:  16\n",
      "Iteration: 1180. Loss: 1.3922902345657349. Accuracy: 49.06359333196131\n",
      "Iteration: 1190. Loss: 1.3961365222930908. Accuracy: 48.40502160938465\n",
      "Iteration: 1200. Loss: 1.4424190521240234. Accuracy: 48.7548878370035\n",
      "Iteration: 1210. Loss: 1.462703824043274. Accuracy: 48.50792344103725\n",
      "Iteration: 1220. Loss: 1.3652669191360474. Accuracy: 48.59024490635933\n",
      "Iteration: 1230. Loss: 1.5731021165847778. Accuracy: 48.40502160938465\n",
      "Iteration: 1240. Loss: 1.3780897855758667. Accuracy: 49.04301296563079\n",
      "Epoch:  17\n",
      "Iteration: 1250. Loss: 1.3726791143417358. Accuracy: 48.63140563902037\n",
      "Iteration: 1260. Loss: 1.3246283531188965. Accuracy: 49.639843589215886\n",
      "Iteration: 1270. Loss: 1.3487186431884766. Accuracy: 48.878370034986624\n",
      "Iteration: 1280. Loss: 1.3764369487762451. Accuracy: 48.281539411401525\n",
      "Iteration: 1290. Loss: 1.3335509300231934. Accuracy: 49.10475406462235\n",
      "Iteration: 1300. Loss: 1.298822045326233. Accuracy: 50.29841531179255\n",
      "Iteration: 1310. Loss: 1.288769245147705. Accuracy: 48.81662893599506\n",
      "Iteration: 1320. Loss: 1.2812548875808716. Accuracy: 49.742745420868495\n",
      "Epoch:  18\n",
      "Iteration: 1330. Loss: 1.2996000051498413. Accuracy: 50.07203128215682\n",
      "Iteration: 1340. Loss: 1.3781577348709106. Accuracy: 49.98970981683474\n",
      "Iteration: 1350. Loss: 1.208460807800293. Accuracy: 50.0514509158263\n",
      "Iteration: 1360. Loss: 1.3626031875610352. Accuracy: 50.60712080675036\n",
      "Iteration: 1370. Loss: 1.3522528409957886. Accuracy: 49.742745420868495\n",
      "Iteration: 1380. Loss: 1.4279615879058838. Accuracy: 50.71002263840296\n",
      "Iteration: 1390. Loss: 1.1279675960540771. Accuracy: 50.236674212800985\n",
      "Iteration: 1400. Loss: 1.3761776685714722. Accuracy: 51.883103519242646\n",
      "Epoch:  19\n",
      "Iteration: 1410. Loss: 1.2460235357284546. Accuracy: 51.2451121629965\n",
      "Iteration: 1420. Loss: 1.3513563871383667. Accuracy: 51.38917472731015\n",
      "Iteration: 1430. Loss: 1.3874638080596924. Accuracy: 50.401317143445155\n",
      "Iteration: 1440. Loss: 1.2429465055465698. Accuracy: 51.96542498456473\n",
      "Iteration: 1450. Loss: 1.230306625366211. Accuracy: 52.64457707347191\n",
      "Iteration: 1460. Loss: 1.4194070100784302. Accuracy: 48.77546820333402\n",
      "Iteration: 1470. Loss: 1.3246359825134277. Accuracy: 50.0514509158263\n",
      "Iteration: 1480. Loss: 1.163732886314392. Accuracy: 52.17122864786993\n",
      "Epoch:  20\n",
      "Iteration: 1490. Loss: 1.1720316410064697. Accuracy: 51.20395143033546\n",
      "Iteration: 1500. Loss: 1.1833887100219727. Accuracy: 52.21238938053097\n",
      "Iteration: 1510. Loss: 1.2674944400787354. Accuracy: 52.62399670714139\n",
      "Iteration: 1520. Loss: 1.1748414039611816. Accuracy: 51.94484461823421\n",
      "Iteration: 1530. Loss: 1.3147666454315186. Accuracy: 50.89524593537765\n",
      "Iteration: 1540. Loss: 1.4069870710372925. Accuracy: 52.82980037044659\n",
      "Iteration: 1550. Loss: 1.29219388961792. Accuracy: 53.220827330726486\n",
      "Iteration: 1560. Loss: 1.4816995859146118. Accuracy: 52.25355011319201\n",
      "Epoch:  21\n",
      "Iteration: 1570. Loss: 1.1655751466751099. Accuracy: 52.60341634081087\n",
      "Iteration: 1580. Loss: 1.3569436073303223. Accuracy: 52.97386293476024\n",
      "Iteration: 1590. Loss: 1.169708490371704. Accuracy: 52.60341634081087\n",
      "Iteration: 1600. Loss: 1.1992065906524658. Accuracy: 54.04404198394732\n",
      "Iteration: 1610. Loss: 1.1536121368408203. Accuracy: 52.99444330109076\n",
      "Iteration: 1620. Loss: 1.196447491645813. Accuracy: 53.38547026137065\n",
      "Iteration: 1630. Loss: 1.1668471097946167. Accuracy: 52.97386293476024\n",
      "Epoch:  22\n",
      "Iteration: 1640. Loss: 1.226557970046997. Accuracy: 54.70261370652398\n",
      "Iteration: 1650. Loss: 1.2358213663101196. Accuracy: 53.92055978596419\n",
      "Iteration: 1660. Loss: 1.2842053174972534. Accuracy: 53.7353364889895\n",
      "Iteration: 1670. Loss: 1.0691176652908325. Accuracy: 53.34430952870961\n",
      "Iteration: 1680. Loss: 1.2331500053405762. Accuracy: 53.55011319201482\n",
      "Iteration: 1690. Loss: 1.2146544456481934. Accuracy: 54.10578308293888\n",
      "Iteration: 1700. Loss: 1.3045694828033447. Accuracy: 54.04404198394732\n",
      "Iteration: 1710. Loss: 1.1919798851013184. Accuracy: 53.982300884955755\n",
      "Epoch:  23\n",
      "Iteration: 1720. Loss: 1.165889024734497. Accuracy: 53.838238320642105\n",
      "Iteration: 1730. Loss: 1.106135606765747. Accuracy: 53.50895245935378\n",
      "Iteration: 1740. Loss: 1.2645821571350098. Accuracy: 52.99444330109076\n",
      "Iteration: 1750. Loss: 1.266566276550293. Accuracy: 53.755916855320024\n",
      "Iteration: 1760. Loss: 1.0728617906570435. Accuracy: 53.61185429100638\n",
      "Iteration: 1770. Loss: 1.1835289001464844. Accuracy: 54.16752418193044\n",
      "Iteration: 1780. Loss: 1.0703003406524658. Accuracy: 54.599711874871375\n",
      "Iteration: 1790. Loss: 1.2766352891921997. Accuracy: 54.682033340193456\n",
      "Epoch:  24\n",
      "Iteration: 1800. Loss: 1.0692015886306763. Accuracy: 54.78493517184606\n",
      "Iteration: 1810. Loss: 1.1911667585372925. Accuracy: 53.179666598065445\n",
      "Iteration: 1820. Loss: 1.0602178573608398. Accuracy: 53.776497221650544\n",
      "Iteration: 1830. Loss: 1.0789605379104614. Accuracy: 55.73163202305001\n",
      "Iteration: 1840. Loss: 1.1916593313217163. Accuracy: 55.03189956781231\n",
      "Iteration: 1850. Loss: 1.1668078899383545. Accuracy: 53.817657954311585\n",
      "Iteration: 1860. Loss: 1.122877597808838. Accuracy: 54.53797077587981\n",
      "Iteration: 1870. Loss: 1.2219438552856445. Accuracy: 54.31158674624408\n",
      "Epoch:  25\n",
      "Iteration: 1880. Loss: 1.0853159427642822. Accuracy: 55.40234616176168\n",
      "Iteration: 1890. Loss: 1.0867077112197876. Accuracy: 55.19654249845647\n",
      "Iteration: 1900. Loss: 1.2148411273956299. Accuracy: 54.99073883515126\n",
      "Iteration: 1910. Loss: 1.075975775718689. Accuracy: 55.44350689442272\n",
      "Iteration: 1920. Loss: 1.2920819520950317. Accuracy: 55.17596213212595\n",
      "Iteration: 1930. Loss: 1.1547904014587402. Accuracy: 56.0197571516773\n",
      "Iteration: 1940. Loss: 1.1251962184906006. Accuracy: 53.65301502366742\n",
      "Iteration: 1950. Loss: 1.308761715888977. Accuracy: 56.122658983329906\n",
      "Epoch:  26\n",
      "Iteration: 1960. Loss: 1.000038504600525. Accuracy: 54.80551553817658\n",
      "Iteration: 1970. Loss: 1.1828700304031372. Accuracy: 55.64931055772793\n",
      "Iteration: 1980. Loss: 1.0833150148391724. Accuracy: 56.04033751800782\n",
      "Iteration: 1990. Loss: 1.185899019241333. Accuracy: 55.916855320024695\n",
      "Iteration: 2000. Loss: 1.2438080310821533. Accuracy: 55.40234616176168\n",
      "Iteration: 2010. Loss: 1.2817871570587158. Accuracy: 55.71105165671949\n",
      "Iteration: 2020. Loss: 1.0858577489852905. Accuracy: 56.82239143856761\n",
      "Epoch:  27\n",
      "Iteration: 2030. Loss: 1.1617023944854736. Accuracy: 56.43136447828771\n",
      "Iteration: 2040. Loss: 1.004878044128418. Accuracy: 56.081498250668865\n",
      "Iteration: 2050. Loss: 1.071077585220337. Accuracy: 56.513685943609794\n",
      "Iteration: 2060. Loss: 1.1526598930358887. Accuracy: 56.24614118131303\n",
      "Iteration: 2070. Loss: 1.1532492637634277. Accuracy: 55.896274953694174\n",
      "Iteration: 2080. Loss: 1.1101328134536743. Accuracy: 55.75221238938053\n",
      "Iteration: 2090. Loss: 1.2143046855926514. Accuracy: 55.48466762708376\n",
      "Iteration: 2100. Loss: 1.1002521514892578. Accuracy: 57.23399876517802\n",
      "Epoch:  28\n",
      "Iteration: 2110. Loss: 1.1989121437072754. Accuracy: 56.801811072237086\n",
      "Iteration: 2120. Loss: 1.1717844009399414. Accuracy: 56.781230705906566\n",
      "Iteration: 2130. Loss: 1.1957645416259766. Accuracy: 56.143239349660426\n",
      "Iteration: 2140. Loss: 1.112884521484375. Accuracy: 56.41078411195719\n",
      "Iteration: 2150. Loss: 1.1160567998886108. Accuracy: 56.26672154764355\n",
      "Iteration: 2160. Loss: 1.0361872911453247. Accuracy: 56.678328874253964\n",
      "Iteration: 2170. Loss: 1.115575909614563. Accuracy: 56.34904301296563\n",
      "Iteration: 2180. Loss: 1.158514142036438. Accuracy: 56.534266309940314\n",
      "Epoch:  29\n",
      "Iteration: 2190. Loss: 1.1443825960159302. Accuracy: 56.26672154764355\n",
      "Iteration: 2200. Loss: 1.1294424533843994. Accuracy: 57.13109693352542\n",
      "Iteration: 2210. Loss: 1.1208064556121826. Accuracy: 55.978596419016256\n",
      "Iteration: 2220. Loss: 1.0238604545593262. Accuracy: 57.460382794813746\n",
      "Iteration: 2230. Loss: 1.1316444873809814. Accuracy: 56.59600740893188\n",
      "Iteration: 2240. Loss: 1.318385124206543. Accuracy: 55.11422103313439\n",
      "Iteration: 2250. Loss: 1.0179318189620972. Accuracy: 56.49310557727927\n",
      "Iteration: 2260. Loss: 1.1415458917617798. Accuracy: 57.68676682444948\n",
      "Epoch:  30\n",
      "Iteration: 2270. Loss: 1.0069618225097656. Accuracy: 55.54640872607533\n",
      "Iteration: 2280. Loss: 1.0542038679122925. Accuracy: 56.82239143856761\n",
      "Iteration: 2290. Loss: 1.0986210107803345. Accuracy: 57.72792755711052\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2300. Loss: 1.0498608350753784. Accuracy: 57.04877546820333\n",
      "Iteration: 2310. Loss: 0.9278580546379089. Accuracy: 56.32846264663511\n",
      "Iteration: 2320. Loss: 1.1637247800827026. Accuracy: 56.122658983329906\n",
      "Iteration: 2330. Loss: 1.0332518815994263. Accuracy: 56.92529327022021\n",
      "Iteration: 2340. Loss: 1.1745789051055908. Accuracy: 57.76908828977156\n",
      "Epoch:  31\n",
      "Iteration: 2350. Loss: 1.0896942615509033. Accuracy: 56.88413253755917\n",
      "Iteration: 2360. Loss: 0.968345582485199. Accuracy: 57.336900596830624\n",
      "Iteration: 2370. Loss: 1.15581214427948. Accuracy: 56.88413253755917\n",
      "Iteration: 2380. Loss: 1.053167462348938. Accuracy: 57.62502572545791\n",
      "Iteration: 2390. Loss: 0.9710516333580017. Accuracy: 58.11895451739041\n",
      "Iteration: 2400. Loss: 1.144068717956543. Accuracy: 57.17225766618646\n",
      "Iteration: 2410. Loss: 0.9665423631668091. Accuracy: 57.995472319407284\n",
      "Epoch:  32\n",
      "Iteration: 2420. Loss: 1.046118974685669. Accuracy: 56.36962337929615\n",
      "Iteration: 2430. Loss: 1.0915446281433105. Accuracy: 56.060917884338345\n",
      "Iteration: 2440. Loss: 1.0693856477737427. Accuracy: 55.40234616176168\n",
      "Iteration: 2450. Loss: 1.0511728525161743. Accuracy: 56.41078411195719\n",
      "Iteration: 2460. Loss: 1.0680352449417114. Accuracy: 57.62502572545791\n",
      "Iteration: 2470. Loss: 1.0136750936508179. Accuracy: 58.201275982712495\n",
      "Iteration: 2480. Loss: 1.0719125270843506. Accuracy: 58.36591891335666\n",
      "Iteration: 2490. Loss: 1.1708446741104126. Accuracy: 57.06935583453385\n",
      "Epoch:  33\n",
      "Iteration: 2500. Loss: 1.0443187952041626. Accuracy: 57.8102490224326\n",
      "Iteration: 2510. Loss: 1.074453353881836. Accuracy: 58.96274953694176\n",
      "Iteration: 2520. Loss: 1.052638053894043. Accuracy: 59.08623173492488\n",
      "Iteration: 2530. Loss: 1.0642213821411133. Accuracy: 59.16855320024696\n",
      "Iteration: 2540. Loss: 0.9637759923934937. Accuracy: 57.68676682444948\n",
      "Iteration: 2550. Loss: 1.0604205131530762. Accuracy: 58.160115250051454\n",
      "Iteration: 2560. Loss: 0.9936754703521729. Accuracy: 58.55114221033134\n",
      "Iteration: 2570. Loss: 1.0103117227554321. Accuracy: 59.0039102696028\n",
      "Epoch:  34\n",
      "Iteration: 2580. Loss: 1.0165678262710571. Accuracy: 59.1068121012554\n",
      "Iteration: 2590. Loss: 1.0581345558166504. Accuracy: 59.477258695204775\n",
      "Iteration: 2600. Loss: 0.9636737108230591. Accuracy: 59.12739246758592\n",
      "Iteration: 2610. Loss: 1.0344092845916748. Accuracy: 59.12739246758592\n",
      "Iteration: 2620. Loss: 1.005422830581665. Accuracy: 59.1068121012554\n",
      "Iteration: 2630. Loss: 1.0914902687072754. Accuracy: 58.180695616381975\n",
      "Iteration: 2640. Loss: 1.089648962020874. Accuracy: 57.974891953076764\n",
      "Iteration: 2650. Loss: 1.0976953506469727. Accuracy: 59.477258695204775\n",
      "Epoch:  35\n",
      "Iteration: 2660. Loss: 1.071256160736084. Accuracy: 59.39493722988269\n",
      "Iteration: 2670. Loss: 0.9844638705253601. Accuracy: 59.06565136859436\n",
      "Iteration: 2680. Loss: 0.9360723495483398. Accuracy: 59.41551759621321\n",
      "Iteration: 2690. Loss: 0.9779852628707886. Accuracy: 59.14797283391644\n",
      "Iteration: 2700. Loss: 1.0663189888000488. Accuracy: 58.859847705289155\n",
      "Iteration: 2710. Loss: 0.9439917206764221. Accuracy: 58.654044041983944\n",
      "Iteration: 2720. Loss: 0.9285353422164917. Accuracy: 59.16855320024696\n",
      "Iteration: 2730. Loss: 1.0190914869308472. Accuracy: 59.18913356657748\n",
      "Epoch:  36\n",
      "Iteration: 2740. Loss: 0.9128422141075134. Accuracy: 59.209713932908\n",
      "Iteration: 2750. Loss: 0.949984073638916. Accuracy: 59.559580160526856\n",
      "Iteration: 2760. Loss: 0.9845280051231384. Accuracy: 59.76538382383207\n",
      "Iteration: 2770. Loss: 0.9906142354011536. Accuracy: 60.54743774439185\n",
      "Iteration: 2780. Loss: 1.0107066631317139. Accuracy: 59.86828565548467\n",
      "Iteration: 2790. Loss: 0.9321497678756714. Accuracy: 59.477258695204775\n",
      "Iteration: 2800. Loss: 1.0465370416641235. Accuracy: 60.44453591273925\n",
      "Epoch:  37\n",
      "Iteration: 2810. Loss: 0.927864670753479. Accuracy: 59.99176785346779\n",
      "Iteration: 2820. Loss: 0.9391903281211853. Accuracy: 59.456678328874254\n",
      "Iteration: 2830. Loss: 0.9151967167854309. Accuracy: 60.65033957604445\n",
      "Iteration: 2840. Loss: 0.9603943824768066. Accuracy: 60.48569664540029\n",
      "Iteration: 2850. Loss: 0.9518795609474182. Accuracy: 61.08252726898539\n",
      "Iteration: 2860. Loss: 0.950566291809082. Accuracy: 61.679357892570486\n",
      "Iteration: 2870. Loss: 0.9929893612861633. Accuracy: 59.7036427248405\n",
      "Iteration: 2880. Loss: 0.8898465633392334. Accuracy: 61.28833093229059\n",
      "Epoch:  38\n",
      "Iteration: 2890. Loss: 0.9309537410736084. Accuracy: 61.22658983329903\n",
      "Iteration: 2900. Loss: 0.878166139125824. Accuracy: 61.37065239761268\n",
      "Iteration: 2910. Loss: 0.9182566404342651. Accuracy: 60.46511627906977\n",
      "Iteration: 2920. Loss: 0.9539937376976013. Accuracy: 61.535295328256844\n",
      "Iteration: 2930. Loss: 1.015242338180542. Accuracy: 60.156410784111955\n",
      "Iteration: 2940. Loss: 0.9592012763023376. Accuracy: 61.41181313027372\n",
      "Iteration: 2950. Loss: 1.0433787107467651. Accuracy: 60.959045071002265\n",
      "Iteration: 2960. Loss: 0.9193559885025024. Accuracy: 61.16484873430747\n",
      "Epoch:  39\n",
      "Iteration: 2970. Loss: 0.9149921536445618. Accuracy: 61.555875694587364\n",
      "Iteration: 2980. Loss: 0.947540283203125. Accuracy: 59.95060712080675\n",
      "Iteration: 2990. Loss: 0.946998655796051. Accuracy: 61.24717019962955\n",
      "Iteration: 3000. Loss: 0.8774527311325073. Accuracy: 61.37065239761268\n",
      "Iteration: 3010. Loss: 0.9691530466079712. Accuracy: 61.26775056596007\n",
      "Iteration: 3020. Loss: 0.9547931551933289. Accuracy: 62.00864375385882\n",
      "Iteration: 3030. Loss: 0.925918459892273. Accuracy: 61.86458118954518\n",
      "Iteration: 3040. Loss: 0.9319002628326416. Accuracy: 61.000205803663306\n",
      "Epoch:  40\n",
      "Iteration: 3050. Loss: 0.8522214293479919. Accuracy: 61.90574192220622\n",
      "Iteration: 3060. Loss: 0.8367712497711182. Accuracy: 61.10310763531591\n",
      "Iteration: 3070. Loss: 0.8079549074172974. Accuracy: 62.13212595184194\n",
      "Iteration: 3080. Loss: 0.8769344687461853. Accuracy: 61.535295328256844\n",
      "Iteration: 3090. Loss: 0.9844203591346741. Accuracy: 62.77011730808808\n",
      "Iteration: 3100. Loss: 0.951726496219635. Accuracy: 61.78225972422309\n",
      "Iteration: 3110. Loss: 0.7564242482185364. Accuracy: 62.7906976744186\n",
      "Iteration: 3120. Loss: 0.8831215500831604. Accuracy: 63.40810866433422\n",
      "Epoch:  41\n",
      "Iteration: 3130. Loss: 0.8864309191703796. Accuracy: 63.98435892158881\n",
      "Iteration: 3140. Loss: 1.130949854850769. Accuracy: 63.757974891953076\n",
      "Iteration: 3150. Loss: 0.7430040836334229. Accuracy: 62.873019139740684\n",
      "Iteration: 3160. Loss: 0.7767952084541321. Accuracy: 62.95534060506277\n",
      "Iteration: 3170. Loss: 0.8853223323822021. Accuracy: 62.07038485285038\n",
      "Iteration: 3180. Loss: 0.9354493618011475. Accuracy: 63.1817246346985\n",
      "Iteration: 3190. Loss: 0.7870762944221497. Accuracy: 63.51101049598683\n",
      "Epoch:  42\n",
      "Iteration: 3200. Loss: 0.6975840926170349. Accuracy: 63.017081704054334\n",
      "Iteration: 3210. Loss: 0.9543725252151489. Accuracy: 63.119983535706936\n",
      "Iteration: 3220. Loss: 0.7980124950408936. Accuracy: 63.36694793167318\n",
      "Iteration: 3230. Loss: 0.7978066205978394. Accuracy: 63.655073060300474\n",
      "Iteration: 3240. Loss: 0.8578510880470276. Accuracy: 63.98435892158881\n",
      "Iteration: 3250. Loss: 0.7873410582542419. Accuracy: 63.3875282980037\n",
      "Iteration: 3260. Loss: 0.729471743106842. Accuracy: 64.43712698086026\n",
      "Iteration: 3270. Loss: 0.814362108707428. Accuracy: 64.95163613912328\n",
      "Epoch:  43\n",
      "Iteration: 3280. Loss: 0.7974957227706909. Accuracy: 63.49043012965631\n",
      "Iteration: 3290. Loss: 0.7173880934715271. Accuracy: 63.757974891953076\n",
      "Iteration: 3300. Loss: 0.8032882809638977. Accuracy: 64.2724840502161\n",
      "Iteration: 3310. Loss: 0.8794218301773071. Accuracy: 63.55217122864787\n",
      "Iteration: 3320. Loss: 0.912352979183197. Accuracy: 64.84873430747068\n",
      "Iteration: 3330. Loss: 0.7472768425941467. Accuracy: 64.00493928791933\n",
      "Iteration: 3340. Loss: 0.7520912885665894. Accuracy: 63.1817246346985\n",
      "Iteration: 3350. Loss: 0.8113601207733154. Accuracy: 64.56060917884338\n",
      "Epoch:  44\n",
      "Iteration: 3360. Loss: 0.8899667859077454. Accuracy: 63.79913562461412\n",
      "Iteration: 3370. Loss: 0.8490071296691895. Accuracy: 64.5811895451739\n",
      "Iteration: 3380. Loss: 0.8851497173309326. Accuracy: 64.5811895451739\n",
      "Iteration: 3390. Loss: 0.7356998324394226. Accuracy: 64.8693146738012\n",
      "Iteration: 3400. Loss: 0.7795733213424683. Accuracy: 64.64293064416546\n",
      "Iteration: 3410. Loss: 0.9217978715896606. Accuracy: 64.35480551553817\n",
      "Iteration: 3420. Loss: 0.9528483152389526. Accuracy: 64.62235027783494\n",
      "Iteration: 3430. Loss: 0.7513043284416199. Accuracy: 65.11627906976744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  45\n",
      "Iteration: 3440. Loss: 0.9113947153091431. Accuracy: 65.48672566371681\n",
      "Iteration: 3450. Loss: 0.8254045844078064. Accuracy: 64.93105577279276\n",
      "Iteration: 3460. Loss: 0.7266813516616821. Accuracy: 64.60176991150442\n",
      "Iteration: 3470. Loss: 0.8164031505584717. Accuracy: 64.29306441654661\n",
      "Iteration: 3480. Loss: 0.9176157712936401. Accuracy: 64.66351101049598\n",
      "Iteration: 3490. Loss: 0.8529603481292725. Accuracy: 65.0751183371064\n",
      "Iteration: 3500. Loss: 0.8821334838867188. Accuracy: 65.0751183371064\n",
      "Iteration: 3510. Loss: 1.0280146598815918. Accuracy: 64.3753858818687\n",
      "Epoch:  46\n",
      "Iteration: 3520. Loss: 0.9542189240455627. Accuracy: 65.40440419839473\n",
      "Iteration: 3530. Loss: 0.7185377478599548. Accuracy: 65.87775262399671\n",
      "Iteration: 3540. Loss: 0.8347190022468567. Accuracy: 65.15743980242848\n",
      "Iteration: 3550. Loss: 0.7012073397636414. Accuracy: 65.85717225766619\n",
      "Iteration: 3560. Loss: 0.8438834547996521. Accuracy: 64.62235027783494\n",
      "Iteration: 3570. Loss: 0.9531105756759644. Accuracy: 66.24819921794608\n",
      "Iteration: 3580. Loss: 0.7701168656349182. Accuracy: 65.48672566371681\n",
      "Epoch:  47\n",
      "Iteration: 3590. Loss: 0.8343712091445923. Accuracy: 65.32208273307265\n",
      "Iteration: 3600. Loss: 0.9486244916915894. Accuracy: 66.24819921794608\n",
      "Iteration: 3610. Loss: 0.8439552187919617. Accuracy: 65.40440419839473\n",
      "Iteration: 3620. Loss: 0.8373240828514099. Accuracy: 66.12471701996296\n",
      "Iteration: 3630. Loss: 0.7442750334739685. Accuracy: 66.5774850792344\n",
      "Iteration: 3640. Loss: 0.8236022591590881. Accuracy: 66.84502984153119\n",
      "Iteration: 3650. Loss: 0.7052605152130127. Accuracy: 66.88619057419223\n",
      "Iteration: 3660. Loss: 0.7502588033676147. Accuracy: 65.93949372298827\n",
      "Epoch:  48\n",
      "Iteration: 3670. Loss: 0.9308075904846191. Accuracy: 64.93105577279276\n",
      "Iteration: 3680. Loss: 0.8224083185195923. Accuracy: 65.69252932702202\n",
      "Iteration: 3690. Loss: 0.7355954647064209. Accuracy: 66.12471701996296\n",
      "Iteration: 3700. Loss: 0.7580318450927734. Accuracy: 65.89833299032723\n",
      "Iteration: 3710. Loss: 0.7120506763458252. Accuracy: 67.3595389997942\n",
      "Iteration: 3720. Loss: 0.8546572923660278. Accuracy: 65.91891335665775\n",
      "Iteration: 3730. Loss: 0.7677344083786011. Accuracy: 66.74212800987857\n",
      "Iteration: 3740. Loss: 0.818892776966095. Accuracy: 67.33895863346368\n",
      "Epoch:  49\n",
      "Iteration: 3750. Loss: 0.7308007478713989. Accuracy: 65.30150236674213\n",
      "Iteration: 3760. Loss: 0.7473370432853699. Accuracy: 66.39226178225972\n",
      "Iteration: 3770. Loss: 0.7893672585487366. Accuracy: 66.80386910887013\n",
      "Iteration: 3780. Loss: 0.864655077457428. Accuracy: 66.22761885161556\n",
      "Iteration: 3790. Loss: 0.7996344566345215. Accuracy: 65.63078822803045\n",
      "Iteration: 3800. Loss: 0.7001815438270569. Accuracy: 65.26034163408109\n",
      "Iteration: 3810. Loss: 0.7362277507781982. Accuracy: 66.20703848528504\n",
      "Iteration: 3820. Loss: 0.8518832325935364. Accuracy: 66.68038691088701\n",
      "Epoch:  50\n",
      "Iteration: 3830. Loss: 0.6806528568267822. Accuracy: 65.38382383206421\n",
      "Iteration: 3840. Loss: 0.7919384837150574. Accuracy: 66.00123482197984\n",
      "Iteration: 3850. Loss: 0.6551642417907715. Accuracy: 66.59806544556493\n",
      "Iteration: 3860. Loss: 0.7676212787628174. Accuracy: 67.40069973245524\n",
      "Iteration: 3870. Loss: 0.8156959414482117. Accuracy: 66.76270837620909\n",
      "Iteration: 3880. Loss: 0.8105956315994263. Accuracy: 66.00123482197984\n",
      "Iteration: 3890. Loss: 0.7759267687797546. Accuracy: 67.19489606915003\n",
      "Iteration: 3900. Loss: 0.9820322394371033. Accuracy: 66.4745832475818\n",
      "Epoch:  51\n",
      "Iteration: 3910. Loss: 0.9542052149772644. Accuracy: 66.35110104959868\n",
      "Iteration: 3920. Loss: 0.7584662437438965. Accuracy: 66.70096727721753\n",
      "Iteration: 3930. Loss: 0.830567479133606. Accuracy: 66.65980654455649\n",
      "Iteration: 3940. Loss: 0.7322199940681458. Accuracy: 67.29779790080264\n",
      "Iteration: 3950. Loss: 0.7156566977500916. Accuracy: 66.92735130685327\n",
      "Iteration: 3960. Loss: 0.8171098828315735. Accuracy: 67.29779790080264\n",
      "Iteration: 3970. Loss: 0.7074763774871826. Accuracy: 66.94793167318379\n",
      "Epoch:  52\n",
      "Iteration: 3980. Loss: 0.6594236493110657. Accuracy: 67.15373533648899\n",
      "Iteration: 3990. Loss: 0.6973798274993896. Accuracy: 66.96851203951431\n",
      "Iteration: 4000. Loss: 0.8401687145233154. Accuracy: 67.5653426630994\n",
      "Iteration: 4010. Loss: 0.8043984770774841. Accuracy: 67.93578925704878\n",
      "Iteration: 4020. Loss: 0.6096691489219666. Accuracy: 67.50360156410784\n",
      "Iteration: 4030. Loss: 0.6375237107276917. Accuracy: 68.22391438567607\n",
      "Iteration: 4040. Loss: 0.7052519917488098. Accuracy: 66.96851203951431\n",
      "Iteration: 4050. Loss: 0.7569554448127747. Accuracy: 66.90677094052275\n",
      "Epoch:  53\n",
      "Iteration: 4060. Loss: 0.7100122570991516. Accuracy: 67.07141387116691\n",
      "Iteration: 4070. Loss: 0.6719605326652527. Accuracy: 67.64766412842148\n",
      "Iteration: 4080. Loss: 0.7469471096992493. Accuracy: 67.8740481580572\n",
      "Iteration: 4090. Loss: 0.7615293264389038. Accuracy: 67.62708376209096\n",
      "Iteration: 4100. Loss: 0.7181124091148376. Accuracy: 67.23605680181107\n",
      "Iteration: 4110. Loss: 0.7425163388252258. Accuracy: 67.64766412842148\n",
      "Iteration: 4120. Loss: 0.7253302335739136. Accuracy: 67.38011936612472\n",
      "Iteration: 4130. Loss: 0.6793464422225952. Accuracy: 67.668244494752\n",
      "Epoch:  54\n",
      "Iteration: 4140. Loss: 0.744339108467102. Accuracy: 67.38011936612472\n",
      "Iteration: 4150. Loss: 0.7403641939163208. Accuracy: 68.07985182136242\n",
      "Iteration: 4160. Loss: 0.7081335783004761. Accuracy: 68.03869108870138\n",
      "Iteration: 4170. Loss: 0.5853406190872192. Accuracy: 67.91520889071826\n",
      "Iteration: 4180. Loss: 0.5463569164276123. Accuracy: 67.5653426630994\n",
      "Iteration: 4190. Loss: 0.7735967040061951. Accuracy: 67.03025313850587\n",
      "Iteration: 4200. Loss: 0.6808052659034729. Accuracy: 69.08828977155794\n",
      "Iteration: 4210. Loss: 0.6328222751617432. Accuracy: 67.52418193043836\n",
      "Epoch:  55\n",
      "Iteration: 4220. Loss: 0.6445690393447876. Accuracy: 68.5532002469644\n",
      "Iteration: 4230. Loss: 0.7033840417861938. Accuracy: 68.71784317760856\n",
      "Iteration: 4240. Loss: 0.7039105296134949. Accuracy: 68.40913768265075\n",
      "Iteration: 4250. Loss: 0.5886037945747375. Accuracy: 68.53261988063387\n",
      "Iteration: 4260. Loss: 0.5945792198181152. Accuracy: 68.0592714550319\n",
      "Iteration: 4270. Loss: 0.67583167552948. Accuracy: 68.42971804898127\n",
      "Iteration: 4280. Loss: 0.6292870044708252. Accuracy: 68.12101255402347\n",
      "Iteration: 4290. Loss: 0.996093213558197. Accuracy: 68.38855731632023\n",
      "Epoch:  56\n",
      "Iteration: 4300. Loss: 0.8564294576644897. Accuracy: 67.4624408314468\n",
      "Iteration: 4310. Loss: 0.6484714150428772. Accuracy: 68.30623585099815\n",
      "Iteration: 4320. Loss: 0.6833884119987488. Accuracy: 68.51203951430335\n",
      "Iteration: 4330. Loss: 0.6424970030784607. Accuracy: 68.656102078617\n",
      "Iteration: 4340. Loss: 0.607223629951477. Accuracy: 69.19119160321054\n",
      "Iteration: 4350. Loss: 0.6264688372612. Accuracy: 68.80016464293064\n",
      "Iteration: 4360. Loss: 0.662352979183197. Accuracy: 68.20333401934555\n",
      "Epoch:  57\n",
      "Iteration: 4370. Loss: 0.5537537932395935. Accuracy: 68.69726281127804\n",
      "Iteration: 4380. Loss: 0.6652752161026001. Accuracy: 68.98538793990534\n",
      "Iteration: 4390. Loss: 0.6757374405860901. Accuracy: 69.64395966248199\n",
      "Iteration: 4400. Loss: 0.700215756893158. Accuracy: 68.51203951430335\n",
      "Iteration: 4410. Loss: 0.656991720199585. Accuracy: 68.82074500926116\n",
      "Iteration: 4420. Loss: 0.6993100643157959. Accuracy: 68.94422720724428\n",
      "Iteration: 4430. Loss: 0.6147624850273132. Accuracy: 69.0471290388969\n",
      "Iteration: 4440. Loss: 0.6482439637184143. Accuracy: 68.20333401934555\n",
      "Epoch:  58\n",
      "Iteration: 4450. Loss: 0.7099024653434753. Accuracy: 68.80016464293064\n",
      "Iteration: 4460. Loss: 0.5710747838020325. Accuracy: 70.30253138505866\n",
      "Iteration: 4470. Loss: 0.6365783214569092. Accuracy: 69.21177196954106\n",
      "Iteration: 4480. Loss: 0.654449462890625. Accuracy: 67.85346779172669\n",
      "Iteration: 4490. Loss: 0.6430726647377014. Accuracy: 67.75056596007408\n",
      "Iteration: 4500. Loss: 0.6548357605934143. Accuracy: 69.31467380119366\n",
      "Iteration: 4510. Loss: 0.6065467596054077. Accuracy: 69.08828977155794\n",
      "Iteration: 4520. Loss: 0.6234865784645081. Accuracy: 69.10887013788846\n",
      "Epoch:  59\n",
      "Iteration: 4530. Loss: 0.7133356928825378. Accuracy: 68.45029841531179\n",
      "Iteration: 4540. Loss: 0.7022888660430908. Accuracy: 68.40913768265075\n",
      "Iteration: 4550. Loss: 0.6076604723930359. Accuracy: 69.1500308705495\n",
      "Iteration: 4560. Loss: 0.7564523220062256. Accuracy: 69.00596830623586\n",
      "Iteration: 4570. Loss: 0.5823429226875305. Accuracy: 68.71784317760856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4580. Loss: 0.6417157053947449. Accuracy: 68.656102078617\n",
      "Iteration: 4590. Loss: 0.6542680263519287. Accuracy: 69.66454002881251\n",
      "Iteration: 4600. Loss: 0.7830401659011841. Accuracy: 69.23235233587158\n",
      "Epoch:  60\n",
      "Iteration: 4610. Loss: 0.5671398639678955. Accuracy: 69.23235233587158\n",
      "Iteration: 4620. Loss: 0.7284606099128723. Accuracy: 69.80860259312615\n",
      "Iteration: 4630. Loss: 0.5655337572097778. Accuracy: 68.88248610825272\n",
      "Iteration: 4640. Loss: 0.79538893699646. Accuracy: 70.03498662276189\n",
      "Iteration: 4650. Loss: 0.5634211897850037. Accuracy: 69.54105783082939\n",
      "Iteration: 4660. Loss: 0.5811803936958313. Accuracy: 70.38485285038074\n",
      "Iteration: 4670. Loss: 0.5637202262878418. Accuracy: 69.66454002881251\n",
      "Iteration: 4680. Loss: 0.769558310508728. Accuracy: 70.09672772175345\n",
      "Epoch:  61\n",
      "Iteration: 4690. Loss: 0.6775792837142944. Accuracy: 70.03498662276189\n",
      "Iteration: 4700. Loss: 0.7010868787765503. Accuracy: 69.49989709816835\n",
      "Iteration: 4710. Loss: 0.5987759232521057. Accuracy: 69.2529327022021\n",
      "Iteration: 4720. Loss: 0.5965215563774109. Accuracy: 68.77958427660012\n",
      "Iteration: 4730. Loss: 0.8277323842048645. Accuracy: 69.58221856349043\n",
      "Iteration: 4740. Loss: 0.6379169821739197. Accuracy: 70.01440625643137\n",
      "Iteration: 4750. Loss: 0.649314284324646. Accuracy: 69.52047746449887\n",
      "Epoch:  62\n",
      "Iteration: 4760. Loss: 0.533976674079895. Accuracy: 69.80860259312615\n",
      "Iteration: 4770. Loss: 0.568584144115448. Accuracy: 70.26137065239762\n",
      "Iteration: 4780. Loss: 0.552358090877533. Accuracy: 70.28195101872814\n",
      "Iteration: 4790. Loss: 0.7222222685813904. Accuracy: 70.05556698909241\n",
      "Iteration: 4800. Loss: 0.7358425259590149. Accuracy: 69.3558345338547\n",
      "Iteration: 4810. Loss: 0.6546105742454529. Accuracy: 70.07614735542293\n",
      "Iteration: 4820. Loss: 0.5813993811607361. Accuracy: 70.32311175138918\n",
      "Iteration: 4830. Loss: 0.6101997494697571. Accuracy: 69.89092405844823\n",
      "Epoch:  63\n",
      "Iteration: 4840. Loss: 0.6874557137489319. Accuracy: 69.82918295945667\n",
      "Iteration: 4850. Loss: 0.6348468661308289. Accuracy: 70.3436921177197\n",
      "Iteration: 4860. Loss: 0.7000423669815063. Accuracy: 70.05556698909241\n",
      "Iteration: 4870. Loss: 0.6131653785705566. Accuracy: 69.76744186046511\n",
      "Iteration: 4880. Loss: 0.5758908987045288. Accuracy: 69.23235233587158\n",
      "Iteration: 4890. Loss: 0.626789391040802. Accuracy: 70.28195101872814\n",
      "Iteration: 4900. Loss: 0.6049656867980957. Accuracy: 70.26137065239762\n",
      "Iteration: 4910. Loss: 0.5772792100906372. Accuracy: 69.58221856349043\n",
      "Epoch:  64\n",
      "Iteration: 4920. Loss: 0.6518569588661194. Accuracy: 70.05556698909241\n",
      "Iteration: 4930. Loss: 0.6574767231941223. Accuracy: 69.49989709816835\n",
      "Iteration: 4940. Loss: 0.7048653364181519. Accuracy: 70.59065651368594\n",
      "Iteration: 4950. Loss: 0.6137676239013672. Accuracy: 69.91150442477876\n",
      "Iteration: 4960. Loss: 0.6761193871498108. Accuracy: 70.83762090965219\n",
      "Iteration: 4970. Loss: 0.7147954702377319. Accuracy: 70.17904918707553\n",
      "Iteration: 4980. Loss: 0.5477502942085266. Accuracy: 70.59065651368594\n",
      "Iteration: 4990. Loss: 0.5995663404464722. Accuracy: 70.50833504836386\n",
      "Epoch:  65\n",
      "Iteration: 5000. Loss: 0.6776159405708313. Accuracy: 71.37271043424573\n",
      "Iteration: 5010. Loss: 0.5920949578285217. Accuracy: 70.50833504836386\n",
      "Iteration: 5020. Loss: 0.5957043170928955. Accuracy: 70.96110310763531\n",
      "Iteration: 5030. Loss: 0.5320671200752258. Accuracy: 70.36427248405022\n",
      "Iteration: 5040. Loss: 0.5134820938110352. Accuracy: 70.7552994443301\n",
      "Iteration: 5050. Loss: 0.5675098299980164. Accuracy: 69.97324552377032\n",
      "Iteration: 5060. Loss: 0.584693431854248. Accuracy: 70.91994237497427\n",
      "Iteration: 5070. Loss: 0.7641626000404358. Accuracy: 70.50833504836386\n",
      "Epoch:  66\n",
      "Iteration: 5080. Loss: 0.6347910761833191. Accuracy: 70.91994237497427\n",
      "Iteration: 5090. Loss: 0.5424707531929016. Accuracy: 71.04342457295739\n",
      "Iteration: 5100. Loss: 0.6086218357086182. Accuracy: 70.89936200864375\n",
      "Iteration: 5110. Loss: 0.5336378812789917. Accuracy: 70.5494957810249\n",
      "Iteration: 5120. Loss: 0.6277608275413513. Accuracy: 71.26980860259313\n",
      "Iteration: 5130. Loss: 0.5733047723770142. Accuracy: 70.61123688001646\n",
      "Iteration: 5140. Loss: 0.5599516034126282. Accuracy: 71.31096933525417\n",
      "Epoch:  67\n",
      "Iteration: 5150. Loss: 0.5183717608451843. Accuracy: 70.59065651368594\n",
      "Iteration: 5160. Loss: 0.6217797994613647. Accuracy: 71.08458530561845\n",
      "Iteration: 5170. Loss: 0.595634937286377. Accuracy: 71.49619263222885\n",
      "Iteration: 5180. Loss: 0.5206645131111145. Accuracy: 70.05556698909241\n",
      "Iteration: 5190. Loss: 0.7073981165885925. Accuracy: 71.29038896892365\n",
      "Iteration: 5200. Loss: 0.49533531069755554. Accuracy: 70.89936200864375\n",
      "Iteration: 5210. Loss: 0.5061635375022888. Accuracy: 71.37271043424573\n",
      "Iteration: 5220. Loss: 0.5307698845863342. Accuracy: 71.18748713727105\n",
      "Epoch:  68\n",
      "Iteration: 5230. Loss: 0.565879225730896. Accuracy: 70.77587981066063\n",
      "Iteration: 5240. Loss: 0.5483837127685547. Accuracy: 71.55793373122042\n",
      "Iteration: 5250. Loss: 0.572885274887085. Accuracy: 71.49619263222885\n",
      "Iteration: 5260. Loss: 0.5423036813735962. Accuracy: 70.61123688001646\n",
      "Iteration: 5270. Loss: 0.6176901459693909. Accuracy: 71.68141592920354\n",
      "Iteration: 5280. Loss: 0.4714054465293884. Accuracy: 71.82547849351718\n",
      "Iteration: 5290. Loss: 0.6240844130516052. Accuracy: 70.91994237497427\n",
      "Iteration: 5300. Loss: 0.5407482385635376. Accuracy: 71.76373739452562\n",
      "Epoch:  69\n",
      "Iteration: 5310. Loss: 0.5545706748962402. Accuracy: 71.35213006791521\n",
      "Iteration: 5320. Loss: 0.5699598789215088. Accuracy: 71.02284420662687\n",
      "Iteration: 5330. Loss: 0.5942457318305969. Accuracy: 70.7552994443301\n",
      "Iteration: 5340. Loss: 0.6206429600715637. Accuracy: 71.35213006791521\n",
      "Iteration: 5350. Loss: 0.6437857747077942. Accuracy: 70.98168347396583\n",
      "Iteration: 5360. Loss: 0.593441903591156. Accuracy: 71.49619263222885\n",
      "Iteration: 5370. Loss: 0.577808678150177. Accuracy: 70.87878164231323\n",
      "Iteration: 5380. Loss: 0.5607275366783142. Accuracy: 71.02284420662687\n",
      "Epoch:  70\n",
      "Iteration: 5390. Loss: 0.6456878185272217. Accuracy: 70.81704054332167\n",
      "Iteration: 5400. Loss: 0.4778795540332794. Accuracy: 71.88721959250874\n",
      "Iteration: 5410. Loss: 0.5910380482673645. Accuracy: 71.78431776085614\n",
      "Iteration: 5420. Loss: 0.5649638175964355. Accuracy: 71.76373739452562\n",
      "Iteration: 5430. Loss: 0.5744850635528564. Accuracy: 71.5373533648899\n",
      "Iteration: 5440. Loss: 0.620948851108551. Accuracy: 71.78431776085614\n",
      "Iteration: 5450. Loss: 0.5064558982849121. Accuracy: 71.00226384029635\n",
      "Iteration: 5460. Loss: 0.5050951838493347. Accuracy: 71.49619263222885\n",
      "Epoch:  71\n",
      "Iteration: 5470. Loss: 0.5162131786346436. Accuracy: 71.51677299855938\n",
      "Iteration: 5480. Loss: 0.6387128233909607. Accuracy: 72.15476435480552\n",
      "Iteration: 5490. Loss: 0.5754672884941101. Accuracy: 71.12574603827949\n",
      "Iteration: 5500. Loss: 0.5843915939331055. Accuracy: 71.49619263222885\n",
      "Iteration: 5510. Loss: 0.5384929776191711. Accuracy: 71.9489606915003\n",
      "Iteration: 5520. Loss: 0.5415477156639099. Accuracy: 72.07244288948343\n",
      "Iteration: 5530. Loss: 0.5598657727241516. Accuracy: 71.68141592920354\n",
      "Epoch:  72\n",
      "Iteration: 5540. Loss: 0.5434644818305969. Accuracy: 71.20806750360157\n",
      "Iteration: 5550. Loss: 0.5139898061752319. Accuracy: 71.06400493928793\n",
      "Iteration: 5560. Loss: 0.5962844491004944. Accuracy: 71.99012142416134\n",
      "Iteration: 5570. Loss: 0.5916511416435242. Accuracy: 71.90779995883926\n",
      "Iteration: 5580. Loss: 0.546882152557373. Accuracy: 72.07244288948343\n",
      "Iteration: 5590. Loss: 0.5012884736061096. Accuracy: 72.03128215682239\n",
      "Iteration: 5600. Loss: 0.4800202548503876. Accuracy: 72.07244288948343\n",
      "Iteration: 5610. Loss: 0.47152602672576904. Accuracy: 71.76373739452562\n",
      "Epoch:  73\n",
      "Iteration: 5620. Loss: 0.5511951446533203. Accuracy: 71.06400493928793\n",
      "Iteration: 5630. Loss: 0.5534992218017578. Accuracy: 72.48405021609385\n",
      "Iteration: 5640. Loss: 0.48644840717315674. Accuracy: 71.78431776085614\n",
      "Iteration: 5650. Loss: 0.5699387788772583. Accuracy: 72.48405021609385\n",
      "Iteration: 5660. Loss: 0.641447126865387. Accuracy: 72.46346984976333\n",
      "Iteration: 5670. Loss: 0.4477449059486389. Accuracy: 72.46346984976333\n",
      "Iteration: 5680. Loss: 0.49301743507385254. Accuracy: 72.60753241407697\n",
      "Iteration: 5690. Loss: 0.5282570719718933. Accuracy: 72.29882691911916\n",
      "Epoch:  74\n",
      "Iteration: 5700. Loss: 0.4534124732017517. Accuracy: 71.45503189956781\n",
      "Iteration: 5710. Loss: 0.4856704771518707. Accuracy: 72.87507717637374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5720. Loss: 0.6978082656860352. Accuracy: 71.96954105783082\n",
      "Iteration: 5730. Loss: 0.46556925773620605. Accuracy: 72.11360362214448\n",
      "Iteration: 5740. Loss: 0.5855373740196228. Accuracy: 72.07244288948343\n",
      "Iteration: 5750. Loss: 0.5127472877502441. Accuracy: 71.29038896892365\n",
      "Iteration: 5760. Loss: 0.5097877979278564. Accuracy: 72.50463058242437\n",
      "Iteration: 5770. Loss: 0.4993308484554291. Accuracy: 71.59909446388146\n",
      "Epoch:  75\n",
      "Iteration: 5780. Loss: 0.6156001687049866. Accuracy: 71.59909446388146\n",
      "Iteration: 5790. Loss: 0.5323359966278076. Accuracy: 73.30726486931468\n",
      "Iteration: 5800. Loss: 0.5048936009407043. Accuracy: 72.60753241407697\n",
      "Iteration: 5810. Loss: 0.5094736218452454. Accuracy: 72.81333607738217\n",
      "Iteration: 5820. Loss: 0.550277590751648. Accuracy: 72.58695204774645\n",
      "Iteration: 5830. Loss: 0.4278395473957062. Accuracy: 72.21650545379708\n",
      "Iteration: 5840. Loss: 0.44168367981910706. Accuracy: 72.0518625231529\n",
      "Iteration: 5850. Loss: 0.7367560267448425. Accuracy: 72.66927351306853\n",
      "Epoch:  76\n",
      "Iteration: 5860. Loss: 0.48557764291763306. Accuracy: 72.29882691911916\n",
      "Iteration: 5870. Loss: 0.47048667073249817. Accuracy: 72.29882691911916\n",
      "Iteration: 5880. Loss: 0.5051752328872681. Accuracy: 72.58695204774645\n",
      "Iteration: 5890. Loss: 0.5119873881340027. Accuracy: 72.3399876517802\n",
      "Iteration: 5900. Loss: 0.48467686772346497. Accuracy: 73.5336488989504\n",
      "Iteration: 5910. Loss: 0.5461680293083191. Accuracy: 72.8339164437127\n",
      "Iteration: 5920. Loss: 0.5481665730476379. Accuracy: 72.7310146120601\n",
      "Epoch:  77\n",
      "Iteration: 5930. Loss: 0.43347662687301636. Accuracy: 73.78061329491665\n",
      "Iteration: 5940. Loss: 0.49505168199539185. Accuracy: 72.8339164437127\n",
      "Iteration: 5950. Loss: 0.501865029335022. Accuracy: 72.15476435480552\n",
      "Iteration: 5960. Loss: 0.4137081801891327. Accuracy: 73.0397201070179\n",
      "Iteration: 5970. Loss: 0.3864048421382904. Accuracy: 72.31940728544969\n",
      "Iteration: 5980. Loss: 0.48769423365592957. Accuracy: 72.9368182753653\n",
      "Iteration: 5990. Loss: 0.39595988392829895. Accuracy: 72.68985387939905\n",
      "Iteration: 6000. Loss: 0.4398552477359772. Accuracy: 72.19592508746656\n",
      "Epoch:  78\n",
      "Iteration: 6010. Loss: 0.49520987272262573. Accuracy: 72.01070179049186\n",
      "Iteration: 6020. Loss: 0.532518208026886. Accuracy: 72.44288948343281\n",
      "Iteration: 6030. Loss: 0.41986221075057983. Accuracy: 72.8339164437127\n",
      "Iteration: 6040. Loss: 0.6144998073577881. Accuracy: 72.66927351306853\n",
      "Iteration: 6050. Loss: 0.5052051544189453. Accuracy: 73.12204157233998\n",
      "Iteration: 6060. Loss: 0.5965994000434875. Accuracy: 73.01913974068738\n",
      "Iteration: 6070. Loss: 0.5914484858512878. Accuracy: 73.28668450298416\n",
      "Iteration: 6080. Loss: 0.5676400065422058. Accuracy: 72.46346984976333\n",
      "Epoch:  79\n",
      "Iteration: 6090. Loss: 0.49547550082206726. Accuracy: 72.11360362214448\n",
      "Iteration: 6100. Loss: 0.501508355140686. Accuracy: 71.90779995883926\n",
      "Iteration: 6110. Loss: 0.4211186468601227. Accuracy: 72.29882691911916\n",
      "Iteration: 6120. Loss: 0.49129408597946167. Accuracy: 72.58695204774645\n",
      "Iteration: 6130. Loss: 0.503532350063324. Accuracy: 73.49248816628936\n",
      "Iteration: 6140. Loss: 0.5354390144348145. Accuracy: 72.89565754270426\n",
      "Iteration: 6150. Loss: 0.4859451949596405. Accuracy: 73.41016670096728\n",
      "Iteration: 6160. Loss: 0.543326199054718. Accuracy: 72.42230911710229\n",
      "Epoch:  80\n",
      "Iteration: 6170. Loss: 0.5304203033447266. Accuracy: 73.01913974068738\n",
      "Iteration: 6180. Loss: 0.42868712544441223. Accuracy: 72.81333607738217\n",
      "Iteration: 6190. Loss: 0.4417884349822998. Accuracy: 72.8339164437127\n",
      "Iteration: 6200. Loss: 0.3989068269729614. Accuracy: 73.38958633463676\n",
      "Iteration: 6210. Loss: 0.45547205209732056. Accuracy: 72.52521094875489\n",
      "Iteration: 6220. Loss: 0.42420580983161926. Accuracy: 72.95739864169582\n",
      "Iteration: 6230. Loss: 0.6194882988929749. Accuracy: 72.79275571105165\n",
      "Iteration: 6240. Loss: 0.5816403031349182. Accuracy: 73.36900596830624\n",
      "Epoch:  81\n",
      "Iteration: 6250. Loss: 0.42936936020851135. Accuracy: 73.71887219592509\n",
      "Iteration: 6260. Loss: 0.45120707154273987. Accuracy: 72.75159497839061\n",
      "Iteration: 6270. Loss: 0.47224217653274536. Accuracy: 73.10146120600946\n",
      "Iteration: 6280. Loss: 0.551438570022583. Accuracy: 72.54579131508541\n",
      "Iteration: 6290. Loss: 0.3933601677417755. Accuracy: 73.06030047334842\n",
      "Iteration: 6300. Loss: 0.3623906970024109. Accuracy: 72.8339164437127\n",
      "Iteration: 6310. Loss: 0.5443757176399231. Accuracy: 73.80119366124717\n",
      "Epoch:  82\n",
      "Iteration: 6320. Loss: 0.386077344417572. Accuracy: 72.9368182753653\n",
      "Iteration: 6330. Loss: 0.5377974510192871. Accuracy: 72.95739864169582\n",
      "Iteration: 6340. Loss: 0.5073678493499756. Accuracy: 72.87507717637374\n",
      "Iteration: 6350. Loss: 0.4527136981487274. Accuracy: 73.4307470672978\n",
      "Iteration: 6360. Loss: 0.4429478645324707. Accuracy: 72.58695204774645\n",
      "Iteration: 6370. Loss: 0.4109778106212616. Accuracy: 73.88351512656925\n",
      "Iteration: 6380. Loss: 0.46628767251968384. Accuracy: 73.51306853261988\n",
      "Iteration: 6390. Loss: 0.5047054290771484. Accuracy: 73.94525622556081\n",
      "Epoch:  83\n",
      "Iteration: 6400. Loss: 0.39842745661735535. Accuracy: 74.29512245317967\n",
      "Iteration: 6410. Loss: 0.476676881313324. Accuracy: 73.65713109693353\n",
      "Iteration: 6420. Loss: 0.5655587911605835. Accuracy: 74.17164025519654\n",
      "Iteration: 6430. Loss: 0.49439531564712524. Accuracy: 73.5336488989504\n",
      "Iteration: 6440. Loss: 0.4692750871181488. Accuracy: 73.61597036427248\n",
      "Iteration: 6450. Loss: 0.4430420994758606. Accuracy: 74.06873842354393\n",
      "Iteration: 6460. Loss: 0.5403755307197571. Accuracy: 74.0275776908829\n",
      "Iteration: 6470. Loss: 0.5049329996109009. Accuracy: 73.49248816628936\n",
      "Epoch:  84\n",
      "Iteration: 6480. Loss: 0.45174330472946167. Accuracy: 73.67771146326405\n",
      "Iteration: 6490. Loss: 0.45272353291511536. Accuracy: 73.2249434039926\n",
      "Iteration: 6500. Loss: 0.42161375284194946. Accuracy: 73.67771146326405\n",
      "Iteration: 6510. Loss: 0.5187890529632568. Accuracy: 73.38958633463676\n",
      "Iteration: 6520. Loss: 0.425814151763916. Accuracy: 74.54208684914592\n",
      "Iteration: 6530. Loss: 0.4082530438899994. Accuracy: 74.15105988886602\n",
      "Iteration: 6540. Loss: 0.4896222651004791. Accuracy: 74.15105988886602\n",
      "Iteration: 6550. Loss: 0.49280455708503723. Accuracy: 72.9368182753653\n",
      "Epoch:  85\n",
      "Iteration: 6560. Loss: 0.5454762578010559. Accuracy: 72.99855937435686\n",
      "Iteration: 6570. Loss: 0.47900840640068054. Accuracy: 73.55422926528092\n",
      "Iteration: 6580. Loss: 0.41463369131088257. Accuracy: 74.10989915620497\n",
      "Iteration: 6590. Loss: 0.4106747806072235. Accuracy: 73.34842560197572\n",
      "Iteration: 6600. Loss: 0.44751089811325073. Accuracy: 74.27454208684915\n",
      "Iteration: 6610. Loss: 0.4745528995990753. Accuracy: 73.16320230500104\n",
      "Iteration: 6620. Loss: 0.5133635997772217. Accuracy: 74.17164025519654\n",
      "Iteration: 6630. Loss: 0.5729228854179382. Accuracy: 73.36900596830624\n",
      "Epoch:  86\n",
      "Iteration: 6640. Loss: 0.3831932544708252. Accuracy: 73.16320230500104\n",
      "Iteration: 6650. Loss: 0.43892791867256165. Accuracy: 73.80119366124717\n",
      "Iteration: 6660. Loss: 0.4616882801055908. Accuracy: 73.94525622556081\n",
      "Iteration: 6670. Loss: 0.5321273803710938. Accuracy: 73.41016670096728\n",
      "Iteration: 6680. Loss: 0.4926692247390747. Accuracy: 73.45132743362832\n",
      "Iteration: 6690. Loss: 0.42313462495803833. Accuracy: 73.84235439390821\n",
      "Iteration: 6700. Loss: 0.4498436450958252. Accuracy: 73.80119366124717\n",
      "Epoch:  87\n",
      "Iteration: 6710. Loss: 0.3052530288696289. Accuracy: 73.10146120600946\n",
      "Iteration: 6720. Loss: 0.4157617688179016. Accuracy: 73.1426219386705\n",
      "Iteration: 6730. Loss: 0.48536747694015503. Accuracy: 73.01913974068738\n",
      "Iteration: 6740. Loss: 0.5304453372955322. Accuracy: 74.3157028195102\n",
      "Iteration: 6750. Loss: 0.4562303423881531. Accuracy: 74.00699732455237\n",
      "Iteration: 6760. Loss: 0.3793700933456421. Accuracy: 74.37744391850175\n",
      "Iteration: 6770. Loss: 0.34611910581588745. Accuracy: 73.69829182959457\n",
      "Iteration: 6780. Loss: 0.4298337697982788. Accuracy: 74.15105988886602\n",
      "Epoch:  88\n",
      "Iteration: 6790. Loss: 0.39906126260757446. Accuracy: 73.86293476023873\n",
      "Iteration: 6800. Loss: 0.4350745677947998. Accuracy: 73.69829182959457\n",
      "Iteration: 6810. Loss: 0.4885045886039734. Accuracy: 73.96583659189133\n",
      "Iteration: 6820. Loss: 0.5037922263145447. Accuracy: 72.95739864169582\n",
      "Iteration: 6830. Loss: 0.43300724029541016. Accuracy: 74.15105988886602\n",
      "Iteration: 6840. Loss: 0.508481502532959. Accuracy: 73.71887219592509\n",
      "Iteration: 6850. Loss: 0.4235014319419861. Accuracy: 74.06873842354393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6860. Loss: 0.39097875356674194. Accuracy: 73.636550730603\n",
      "Epoch:  89\n",
      "Iteration: 6870. Loss: 0.46029990911483765. Accuracy: 74.06873842354393\n",
      "Iteration: 6880. Loss: 0.4056778848171234. Accuracy: 74.9331138094258\n",
      "Iteration: 6890. Loss: 0.48813825845718384. Accuracy: 74.48034575015436\n",
      "Iteration: 6900. Loss: 0.4510781764984131. Accuracy: 74.15105988886602\n",
      "Iteration: 6910. Loss: 0.44853490591049194. Accuracy: 74.29512245317967\n",
      "Iteration: 6920. Loss: 0.4017734229564667. Accuracy: 74.29512245317967\n",
      "Iteration: 6930. Loss: 0.3936830461025238. Accuracy: 73.636550730603\n",
      "Iteration: 6940. Loss: 0.47149917483329773. Accuracy: 73.65713109693353\n",
      "Epoch:  90\n",
      "Iteration: 6950. Loss: 0.36934855580329895. Accuracy: 74.29512245317967\n",
      "Iteration: 6960. Loss: 0.4813442826271057. Accuracy: 73.61597036427248\n",
      "Iteration: 6970. Loss: 0.4904840290546417. Accuracy: 74.5215064828154\n",
      "Iteration: 6980. Loss: 0.41343119740486145. Accuracy: 73.76003292858613\n",
      "Iteration: 6990. Loss: 0.33081865310668945. Accuracy: 74.21280098785759\n",
      "Iteration: 7000. Loss: 0.47908416390419006. Accuracy: 74.624408314468\n",
      "Iteration: 7010. Loss: 0.3694595992565155. Accuracy: 74.10989915620497\n",
      "Iteration: 7020. Loss: 0.48248955607414246. Accuracy: 74.1304795225355\n",
      "Epoch:  91\n",
      "Iteration: 7030. Loss: 0.33556392788887024. Accuracy: 74.27454208684915\n",
      "Iteration: 7040. Loss: 0.42360058426856995. Accuracy: 73.88351512656925\n",
      "Iteration: 7050. Loss: 0.43896740674972534. Accuracy: 74.33628318584071\n",
      "Iteration: 7060. Loss: 0.491738498210907. Accuracy: 74.64498868079852\n",
      "Iteration: 7070. Loss: 0.41996654868125916. Accuracy: 74.85079234410372\n",
      "Iteration: 7080. Loss: 0.5299760103225708. Accuracy: 74.39802428483227\n",
      "Iteration: 7090. Loss: 0.4926278591156006. Accuracy: 73.96583659189133\n",
      "Epoch:  92\n",
      "Iteration: 7100. Loss: 0.4489971399307251. Accuracy: 73.82177402757769\n",
      "Iteration: 7110. Loss: 0.41635245084762573. Accuracy: 74.33628318584071\n",
      "Iteration: 7120. Loss: 0.41355806589126587. Accuracy: 74.21280098785759\n",
      "Iteration: 7130. Loss: 0.35097336769104004. Accuracy: 74.23338135418811\n",
      "Iteration: 7140. Loss: 0.4738277792930603. Accuracy: 74.5215064828154\n",
      "Iteration: 7150. Loss: 0.339023232460022. Accuracy: 73.636550730603\n",
      "Iteration: 7160. Loss: 0.4462343454360962. Accuracy: 74.25396172051863\n",
      "Iteration: 7170. Loss: 0.4704344868659973. Accuracy: 74.48034575015436\n",
      "Epoch:  93\n",
      "Iteration: 7180. Loss: 0.3847600817680359. Accuracy: 74.4186046511628\n",
      "Iteration: 7190. Loss: 0.5758333802223206. Accuracy: 74.35686355217123\n",
      "Iteration: 7200. Loss: 0.40696433186531067. Accuracy: 74.3157028195102\n",
      "Iteration: 7210. Loss: 0.43803200125694275. Accuracy: 74.21280098785759\n",
      "Iteration: 7220. Loss: 0.3961721360683441. Accuracy: 74.78905124511216\n",
      "Iteration: 7230. Loss: 0.4881786108016968. Accuracy: 73.90409549289977\n",
      "Iteration: 7240. Loss: 0.41954898834228516. Accuracy: 73.88351512656925\n",
      "Iteration: 7250. Loss: 0.44197455048561096. Accuracy: 74.15105988886602\n",
      "Epoch:  94\n",
      "Iteration: 7260. Loss: 0.4404044449329376. Accuracy: 74.58324758180696\n",
      "Iteration: 7270. Loss: 0.47853466868400574. Accuracy: 74.25396172051863\n",
      "Iteration: 7280. Loss: 0.4234493374824524. Accuracy: 74.21280098785759\n",
      "Iteration: 7290. Loss: 0.5383830070495605. Accuracy: 74.7273101461206\n",
      "Iteration: 7300. Loss: 0.3896993398666382. Accuracy: 74.54208684914592\n",
      "Iteration: 7310. Loss: 0.3843352496623993. Accuracy: 73.92467585923029\n",
      "Iteration: 7320. Loss: 0.44023892283439636. Accuracy: 73.88351512656925\n",
      "Iteration: 7330. Loss: 0.3890371322631836. Accuracy: 73.24552377032312\n",
      "Epoch:  95\n",
      "Iteration: 7340. Loss: 0.36420366168022156. Accuracy: 74.19222062152706\n",
      "Iteration: 7350. Loss: 0.43346408009529114. Accuracy: 74.7273101461206\n",
      "Iteration: 7360. Loss: 0.4251399636268616. Accuracy: 75.48878370034987\n",
      "Iteration: 7370. Loss: 0.287875235080719. Accuracy: 74.25396172051863\n",
      "Iteration: 7380. Loss: 0.45326775312423706. Accuracy: 74.91253344309528\n",
      "Iteration: 7390. Loss: 0.4155171811580658. Accuracy: 74.3157028195102\n",
      "Iteration: 7400. Loss: 0.37089523673057556. Accuracy: 75.59168553200247\n",
      "Iteration: 7410. Loss: 0.4472939968109131. Accuracy: 73.78061329491665\n",
      "Epoch:  96\n",
      "Iteration: 7420. Loss: 0.38148027658462524. Accuracy: 74.58324758180696\n",
      "Iteration: 7430. Loss: 0.3757133185863495. Accuracy: 74.89195307676476\n",
      "Iteration: 7440. Loss: 0.4661581218242645. Accuracy: 74.45976538382384\n",
      "Iteration: 7450. Loss: 0.39388227462768555. Accuracy: 74.89195307676476\n",
      "Iteration: 7460. Loss: 0.436629980802536. Accuracy: 73.90409549289977\n",
      "Iteration: 7470. Loss: 0.3692696690559387. Accuracy: 74.76847087878164\n",
      "Iteration: 7480. Loss: 0.44185584783554077. Accuracy: 74.04815805721341\n",
      "Epoch:  97\n",
      "Iteration: 7490. Loss: 0.3457214832305908. Accuracy: 74.4186046511628\n",
      "Iteration: 7500. Loss: 0.5457926988601685. Accuracy: 74.21280098785759\n",
      "Iteration: 7510. Loss: 0.4498680830001831. Accuracy: 74.0275776908829\n",
      "Iteration: 7520. Loss: 0.3743011951446533. Accuracy: 75.05659600740893\n",
      "Iteration: 7530. Loss: 0.34066787362098694. Accuracy: 74.15105988886602\n",
      "Iteration: 7540. Loss: 0.30370351672172546. Accuracy: 74.8302119777732\n",
      "Iteration: 7550. Loss: 0.32782384753227234. Accuracy: 74.8302119777732\n",
      "Iteration: 7560. Loss: 0.44866856932640076. Accuracy: 75.24181930438361\n",
      "Epoch:  98\n",
      "Iteration: 7570. Loss: 0.4379553496837616. Accuracy: 74.25396172051863\n",
      "Iteration: 7580. Loss: 0.38568899035453796. Accuracy: 74.1304795225355\n",
      "Iteration: 7590. Loss: 0.40934377908706665. Accuracy: 74.97427454208685\n",
      "Iteration: 7600. Loss: 0.4429953992366791. Accuracy: 74.7273101461206\n",
      "Iteration: 7610. Loss: 0.3362993597984314. Accuracy: 73.98641695822185\n",
      "Iteration: 7620. Loss: 0.35025566816329956. Accuracy: 74.54208684914592\n",
      "Iteration: 7630. Loss: 0.4040074348449707. Accuracy: 74.87137271043424\n",
      "Iteration: 7640. Loss: 0.3139983117580414. Accuracy: 73.92467585923029\n",
      "Epoch:  99\n",
      "Iteration: 7650. Loss: 0.3690032660961151. Accuracy: 74.70672977979008\n",
      "Iteration: 7660. Loss: 0.4234456419944763. Accuracy: 74.76847087878164\n",
      "Iteration: 7670. Loss: 0.33320167660713196. Accuracy: 74.76847087878164\n",
      "Iteration: 7680. Loss: 0.5152198076248169. Accuracy: 74.0275776908829\n",
      "Iteration: 7690. Loss: 0.32017138600349426. Accuracy: 74.7273101461206\n",
      "Iteration: 7700. Loss: 0.36958691477775574. Accuracy: 74.78905124511216\n",
      "Iteration: 7710. Loss: 0.4152109920978546. Accuracy: 74.64498868079852\n",
      "Iteration: 7720. Loss: 0.38074827194213867. Accuracy: 74.8302119777732\n",
      "Epoch:  100\n",
      "Iteration: 7730. Loss: 0.36126378178596497. Accuracy: 75.3241407697057\n",
      "Iteration: 7740. Loss: 0.3825888931751251. Accuracy: 74.27454208684915\n",
      "Iteration: 7750. Loss: 0.40611734986305237. Accuracy: 74.8302119777732\n",
      "Iteration: 7760. Loss: 0.48186591267585754. Accuracy: 74.58324758180696\n",
      "Iteration: 7770. Loss: 0.35130149126052856. Accuracy: 75.40646223502779\n",
      "Iteration: 7780. Loss: 0.3333072364330292. Accuracy: 75.26239967071413\n",
      "Iteration: 7790. Loss: 0.3935169279575348. Accuracy: 74.3157028195102\n",
      "Iteration: 7800. Loss: 0.5143810510635376. Accuracy: 74.78905124511216\n",
      "Epoch:  101\n",
      "Iteration: 7810. Loss: 0.37671566009521484. Accuracy: 74.66556904712904\n",
      "Iteration: 7820. Loss: 0.4547818899154663. Accuracy: 75.18007820539205\n",
      "Iteration: 7830. Loss: 0.35069116950035095. Accuracy: 75.38588186869727\n",
      "Iteration: 7840. Loss: 0.35705986618995667. Accuracy: 74.15105988886602\n",
      "Iteration: 7850. Loss: 0.4571585953235626. Accuracy: 74.91253344309528\n",
      "Iteration: 7860. Loss: 0.31468722224235535. Accuracy: 75.09775674006997\n",
      "Iteration: 7870. Loss: 0.478859543800354. Accuracy: 74.85079234410372\n",
      "Epoch:  102\n",
      "Iteration: 7880. Loss: 0.41104310750961304. Accuracy: 74.76847087878164\n",
      "Iteration: 7890. Loss: 0.36878272891044617. Accuracy: 75.30356040337519\n",
      "Iteration: 7900. Loss: 0.3126905858516693. Accuracy: 75.05659600740893\n",
      "Iteration: 7910. Loss: 0.37576472759246826. Accuracy: 74.35686355217123\n",
      "Iteration: 7920. Loss: 0.37727466225624084. Accuracy: 74.624408314468\n",
      "Iteration: 7930. Loss: 0.4655570089817047. Accuracy: 74.89195307676476\n",
      "Iteration: 7940. Loss: 0.3359237015247345. Accuracy: 74.4186046511628\n",
      "Iteration: 7950. Loss: 0.39658915996551514. Accuracy: 75.22123893805309\n",
      "Epoch:  103\n",
      "Iteration: 7960. Loss: 0.3778354525566101. Accuracy: 74.50092611648488\n",
      "Iteration: 7970. Loss: 0.32301968336105347. Accuracy: 74.25396172051863\n",
      "Iteration: 7980. Loss: 0.37847501039505005. Accuracy: 75.75632846264664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7990. Loss: 0.43509775400161743. Accuracy: 75.20065857172257\n",
      "Iteration: 8000. Loss: 0.3375306725502014. Accuracy: 75.11833710640049\n",
      "Iteration: 8010. Loss: 0.37604305148124695. Accuracy: 74.66556904712904\n",
      "Iteration: 8020. Loss: 0.34562191367149353. Accuracy: 74.7273101461206\n",
      "Iteration: 8030. Loss: 0.4275910258293152. Accuracy: 75.15949783906153\n",
      "Epoch:  104\n",
      "Iteration: 8040. Loss: 0.29124295711517334. Accuracy: 74.3157028195102\n",
      "Iteration: 8050. Loss: 0.38973313570022583. Accuracy: 74.7273101461206\n",
      "Iteration: 8060. Loss: 0.38818520307540894. Accuracy: 75.01543527474789\n",
      "Iteration: 8070. Loss: 0.4208264946937561. Accuracy: 74.5215064828154\n",
      "Iteration: 8080. Loss: 0.3498830497264862. Accuracy: 74.45976538382384\n",
      "Iteration: 8090. Loss: 0.3981860876083374. Accuracy: 74.64498868079852\n",
      "Iteration: 8100. Loss: 0.3951103687286377. Accuracy: 74.35686355217123\n",
      "Iteration: 8110. Loss: 0.3784392178058624. Accuracy: 74.56266721547644\n",
      "Epoch:  105\n",
      "Iteration: 8120. Loss: 0.4474948048591614. Accuracy: 74.89195307676476\n",
      "Iteration: 8130. Loss: 0.41506773233413696. Accuracy: 75.30356040337519\n",
      "Iteration: 8140. Loss: 0.3989744782447815. Accuracy: 74.4186046511628\n",
      "Iteration: 8150. Loss: 0.416086345911026. Accuracy: 74.91253344309528\n",
      "Iteration: 8160. Loss: 0.3801323473453522. Accuracy: 75.24181930438361\n",
      "Iteration: 8170. Loss: 0.3063865005970001. Accuracy: 75.13891747273101\n",
      "Iteration: 8180. Loss: 0.2789653539657593. Accuracy: 75.34472113603623\n",
      "Iteration: 8190. Loss: 0.39032918214797974. Accuracy: 76.08561432393496\n",
      "Epoch:  106\n",
      "Iteration: 8200. Loss: 0.4100607633590698. Accuracy: 74.7273101461206\n",
      "Iteration: 8210. Loss: 0.39968952536582947. Accuracy: 75.34472113603623\n",
      "Iteration: 8220. Loss: 0.36375555396080017. Accuracy: 75.28298003704467\n",
      "Iteration: 8230. Loss: 0.3207346200942993. Accuracy: 75.36530150236675\n",
      "Iteration: 8240. Loss: 0.44746917486190796. Accuracy: 75.26239967071413\n",
      "Iteration: 8250. Loss: 0.3538706302642822. Accuracy: 74.95369417575633\n",
      "Iteration: 8260. Loss: 0.23777608573436737. Accuracy: 75.46820333401935\n",
      "Epoch:  107\n",
      "Iteration: 8270. Loss: 0.35033246874809265. Accuracy: 75.28298003704467\n",
      "Iteration: 8280. Loss: 0.3242582678794861. Accuracy: 74.9331138094258\n",
      "Iteration: 8290. Loss: 0.3238677978515625. Accuracy: 75.67400699732455\n",
      "Iteration: 8300. Loss: 0.31227678060531616. Accuracy: 75.46820333401935\n",
      "Iteration: 8310. Loss: 0.3259713351726532. Accuracy: 75.75632846264664\n",
      "Iteration: 8320. Loss: 0.42436525225639343. Accuracy: 75.30356040337519\n",
      "Iteration: 8330. Loss: 0.39084720611572266. Accuracy: 74.99485490841737\n",
      "Iteration: 8340. Loss: 0.45001673698425293. Accuracy: 74.19222062152706\n",
      "Epoch:  108\n",
      "Iteration: 8350. Loss: 0.2729799449443817. Accuracy: 75.46820333401935\n",
      "Iteration: 8360. Loss: 0.4125968813896179. Accuracy: 75.22123893805309\n",
      "Iteration: 8370. Loss: 0.3520860970020294. Accuracy: 75.26239967071413\n",
      "Iteration: 8380. Loss: 0.46527713537216187. Accuracy: 75.46820333401935\n",
      "Iteration: 8390. Loss: 0.37537869811058044. Accuracy: 74.97427454208685\n",
      "Iteration: 8400. Loss: 0.3456529974937439. Accuracy: 75.15949783906153\n",
      "Iteration: 8410. Loss: 0.3574047386646271. Accuracy: 74.68614941345956\n",
      "Iteration: 8420. Loss: 0.2430095076560974. Accuracy: 75.52994443301091\n",
      "Epoch:  109\n",
      "Iteration: 8430. Loss: 0.35540255904197693. Accuracy: 75.44762296768883\n",
      "Iteration: 8440. Loss: 0.46394434571266174. Accuracy: 75.7151677299856\n",
      "Iteration: 8450. Loss: 0.41253232955932617. Accuracy: 75.05659600740893\n",
      "Iteration: 8460. Loss: 0.3505105972290039. Accuracy: 75.05659600740893\n",
      "Iteration: 8470. Loss: 0.4869958162307739. Accuracy: 75.22123893805309\n",
      "Iteration: 8480. Loss: 0.3145780861377716. Accuracy: 75.73574809631612\n",
      "Iteration: 8490. Loss: 0.45040735602378845. Accuracy: 76.20909652191808\n",
      "Iteration: 8500. Loss: 0.34223175048828125. Accuracy: 75.28298003704467\n",
      "Epoch:  110\n",
      "Iteration: 8510. Loss: 0.2860642969608307. Accuracy: 75.07717637373945\n",
      "Iteration: 8520. Loss: 0.42096850275993347. Accuracy: 75.26239967071413\n",
      "Iteration: 8530. Loss: 0.3913215696811676. Accuracy: 75.57110516567195\n",
      "Iteration: 8540. Loss: 0.3460193872451782. Accuracy: 74.70672977979008\n",
      "Iteration: 8550. Loss: 0.4239526391029358. Accuracy: 75.87981066062976\n",
      "Iteration: 8560. Loss: 0.42084038257598877. Accuracy: 74.8302119777732\n",
      "Iteration: 8570. Loss: 0.3247501850128174. Accuracy: 75.07717637373945\n",
      "Iteration: 8580. Loss: 0.5103140473365784. Accuracy: 75.65342663099403\n",
      "Epoch:  111\n",
      "Iteration: 8590. Loss: 0.4459187388420105. Accuracy: 75.15949783906153\n",
      "Iteration: 8600. Loss: 0.29284143447875977. Accuracy: 75.15949783906153\n",
      "Iteration: 8610. Loss: 0.45787864923477173. Accuracy: 76.2296768882486\n",
      "Iteration: 8620. Loss: 0.25647422671318054. Accuracy: 75.36530150236675\n",
      "Iteration: 8630. Loss: 0.37502521276474. Accuracy: 75.18007820539205\n",
      "Iteration: 8640. Loss: 0.4717005491256714. Accuracy: 75.34472113603623\n",
      "Iteration: 8650. Loss: 0.38768935203552246. Accuracy: 76.06503395760444\n",
      "Epoch:  112\n",
      "Iteration: 8660. Loss: 0.3289758265018463. Accuracy: 74.80963161144268\n",
      "Iteration: 8670. Loss: 0.2867962121963501. Accuracy: 75.15949783906153\n",
      "Iteration: 8680. Loss: 0.326369047164917. Accuracy: 75.7151677299856\n",
      "Iteration: 8690. Loss: 0.36873915791511536. Accuracy: 75.7151677299856\n",
      "Iteration: 8700. Loss: 0.40754157304763794. Accuracy: 75.75632846264664\n",
      "Iteration: 8710. Loss: 0.4099666476249695. Accuracy: 74.89195307676476\n",
      "Iteration: 8720. Loss: 0.35198116302490234. Accuracy: 75.52994443301091\n",
      "Iteration: 8730. Loss: 0.3740732967853546. Accuracy: 75.20065857172257\n",
      "Epoch:  113\n",
      "Iteration: 8740. Loss: 0.27080461382865906. Accuracy: 75.36530150236675\n",
      "Iteration: 8750. Loss: 0.29045793414115906. Accuracy: 75.9209713932908\n",
      "Iteration: 8760. Loss: 0.3052193224430084. Accuracy: 75.90039102696028\n",
      "Iteration: 8770. Loss: 0.2846667170524597. Accuracy: 75.65342663099403\n",
      "Iteration: 8780. Loss: 0.2997148334980011. Accuracy: 75.48878370034987\n",
      "Iteration: 8790. Loss: 0.29453131556510925. Accuracy: 75.44762296768883\n",
      "Iteration: 8800. Loss: 0.3836890459060669. Accuracy: 75.42704260135831\n",
      "Iteration: 8810. Loss: 0.3897824287414551. Accuracy: 75.61226589833299\n",
      "Epoch:  114\n",
      "Iteration: 8820. Loss: 0.3050607442855835. Accuracy: 75.48878370034987\n",
      "Iteration: 8830. Loss: 0.3946669399738312. Accuracy: 75.52994443301091\n",
      "Iteration: 8840. Loss: 0.4013654887676239. Accuracy: 75.9209713932908\n",
      "Iteration: 8850. Loss: 0.3046146035194397. Accuracy: 76.06503395760444\n",
      "Iteration: 8860. Loss: 0.3080843687057495. Accuracy: 75.48878370034987\n",
      "Iteration: 8870. Loss: 0.36047127842903137. Accuracy: 75.55052479934143\n",
      "Iteration: 8880. Loss: 0.31972888112068176. Accuracy: 75.63284626466351\n",
      "Iteration: 8890. Loss: 0.27217504382133484. Accuracy: 75.61226589833299\n",
      "Epoch:  115\n",
      "Iteration: 8900. Loss: 0.32729947566986084. Accuracy: 75.40646223502779\n",
      "Iteration: 8910. Loss: 0.3454674184322357. Accuracy: 75.13891747273101\n",
      "Iteration: 8920. Loss: 0.28570741415023804. Accuracy: 75.63284626466351\n",
      "Iteration: 8930. Loss: 0.25188061594963074. Accuracy: 75.38588186869727\n",
      "Iteration: 8940. Loss: 0.34973129630088806. Accuracy: 75.85923029429924\n",
      "Iteration: 8950. Loss: 0.30339735746383667. Accuracy: 75.40646223502779\n",
      "Iteration: 8960. Loss: 0.41369977593421936. Accuracy: 75.3241407697057\n",
      "Iteration: 8970. Loss: 0.38885200023651123. Accuracy: 75.30356040337519\n",
      "Epoch:  116\n",
      "Iteration: 8980. Loss: 0.2264716774225235. Accuracy: 75.01543527474789\n",
      "Iteration: 8990. Loss: 0.29427123069763184. Accuracy: 75.24181930438361\n",
      "Iteration: 9000. Loss: 0.2769733667373657. Accuracy: 75.65342663099403\n",
      "Iteration: 9010. Loss: 0.33780789375305176. Accuracy: 75.69458736365507\n",
      "Iteration: 9020. Loss: 0.3003673255443573. Accuracy: 76.10619469026548\n",
      "Iteration: 9030. Loss: 0.40503665804862976. Accuracy: 75.48878370034987\n",
      "Iteration: 9040. Loss: 0.28161752223968506. Accuracy: 76.04445359127392\n",
      "Epoch:  117\n",
      "Iteration: 9050. Loss: 0.24776646494865417. Accuracy: 75.28298003704467\n",
      "Iteration: 9060. Loss: 0.32449930906295776. Accuracy: 75.28298003704467\n",
      "Iteration: 9070. Loss: 0.33606982231140137. Accuracy: 75.87981066062976\n",
      "Iteration: 9080. Loss: 0.32075822353363037. Accuracy: 76.04445359127392\n",
      "Iteration: 9090. Loss: 0.23984229564666748. Accuracy: 75.77690882897716\n",
      "Iteration: 9100. Loss: 0.3392820358276367. Accuracy: 75.52994443301091\n",
      "Iteration: 9110. Loss: 0.29117274284362793. Accuracy: 76.74418604651163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9120. Loss: 0.3257094919681549. Accuracy: 76.31199835357069\n",
      "Epoch:  118\n",
      "Iteration: 9130. Loss: 0.28887227177619934. Accuracy: 76.27083762090965\n",
      "Iteration: 9140. Loss: 0.4152153730392456. Accuracy: 75.42704260135831\n",
      "Iteration: 9150. Loss: 0.35553476214408875. Accuracy: 76.18851615558756\n",
      "Iteration: 9160. Loss: 0.33046597242355347. Accuracy: 75.57110516567195\n",
      "Iteration: 9170. Loss: 0.32196885347366333. Accuracy: 76.66186458118955\n",
      "Iteration: 9180. Loss: 0.3656982481479645. Accuracy: 75.83864992796872\n",
      "Iteration: 9190. Loss: 0.3408452868461609. Accuracy: 75.75632846264664\n",
      "Iteration: 9200. Loss: 0.32341858744621277. Accuracy: 75.85923029429924\n",
      "Epoch:  119\n",
      "Iteration: 9210. Loss: 0.2510550022125244. Accuracy: 76.92940934348631\n",
      "Iteration: 9220. Loss: 0.36583906412124634. Accuracy: 76.10619469026548\n",
      "Iteration: 9230. Loss: 0.2895762026309967. Accuracy: 75.7151677299856\n",
      "Iteration: 9240. Loss: 0.3305235207080841. Accuracy: 75.42704260135831\n",
      "Iteration: 9250. Loss: 0.19376499950885773. Accuracy: 75.42704260135831\n",
      "Iteration: 9260. Loss: 0.33331364393234253. Accuracy: 75.09775674006997\n",
      "Iteration: 9270. Loss: 0.3584260642528534. Accuracy: 76.49722165054538\n",
      "Iteration: 9280. Loss: 0.2945757806301117. Accuracy: 76.29141798724017\n",
      "Epoch:  120\n",
      "Iteration: 9290. Loss: 0.36378100514411926. Accuracy: 76.37373945256226\n",
      "Iteration: 9300. Loss: 0.26287370920181274. Accuracy: 75.98271249228236\n",
      "Iteration: 9310. Loss: 0.3194786310195923. Accuracy: 75.9209713932908\n",
      "Iteration: 9320. Loss: 0.3329627513885498. Accuracy: 76.14735542292652\n",
      "Iteration: 9330. Loss: 0.21879903972148895. Accuracy: 75.38588186869727\n",
      "Iteration: 9340. Loss: 0.27205997705459595. Accuracy: 75.28298003704467\n",
      "Iteration: 9350. Loss: 0.2891940772533417. Accuracy: 75.77690882897716\n",
      "Iteration: 9360. Loss: 0.29516011476516724. Accuracy: 76.37373945256226\n",
      "Epoch:  121\n",
      "Iteration: 9370. Loss: 0.3430030643939972. Accuracy: 75.8180695616382\n",
      "Iteration: 9380. Loss: 0.26435232162475586. Accuracy: 76.37373945256226\n",
      "Iteration: 9390. Loss: 0.2126259207725525. Accuracy: 75.96213212595184\n",
      "Iteration: 9400. Loss: 0.36765894293785095. Accuracy: 77.09405227413048\n",
      "Iteration: 9410. Loss: 0.3266823887825012. Accuracy: 76.35315908623174\n",
      "Iteration: 9420. Loss: 0.2838439643383026. Accuracy: 75.9209713932908\n",
      "Iteration: 9430. Loss: 0.2795349955558777. Accuracy: 75.73574809631612\n",
      "Epoch:  122\n",
      "Iteration: 9440. Loss: 0.25053727626800537. Accuracy: 75.77690882897716\n",
      "Iteration: 9450. Loss: 0.32229700684547424. Accuracy: 76.5178020168759\n",
      "Iteration: 9460. Loss: 0.39856845140457153. Accuracy: 76.14735542292652\n",
      "Iteration: 9470. Loss: 0.37252652645111084. Accuracy: 76.14735542292652\n",
      "Iteration: 9480. Loss: 0.20051254332065582. Accuracy: 76.29141798724017\n",
      "Iteration: 9490. Loss: 0.32387444376945496. Accuracy: 75.96213212595184\n",
      "Iteration: 9500. Loss: 0.30705368518829346. Accuracy: 76.35315908623174\n",
      "Iteration: 9510. Loss: 0.3510379195213318. Accuracy: 76.25025725457913\n",
      "Epoch:  123\n",
      "Iteration: 9520. Loss: 0.28216060996055603. Accuracy: 75.34472113603623\n",
      "Iteration: 9530. Loss: 0.29336175322532654. Accuracy: 76.72360568018111\n",
      "Iteration: 9540. Loss: 0.30385905504226685. Accuracy: 76.55896274953695\n",
      "Iteration: 9550. Loss: 0.28960371017456055. Accuracy: 77.0117308088084\n",
      "Iteration: 9560. Loss: 0.22411014139652252. Accuracy: 76.45606091788434\n",
      "Iteration: 9570. Loss: 0.3418719470500946. Accuracy: 76.31199835357069\n",
      "Iteration: 9580. Loss: 0.3156472444534302. Accuracy: 76.35315908623174\n",
      "Iteration: 9590. Loss: 0.2806515693664551. Accuracy: 77.07347190779996\n",
      "Epoch:  124\n",
      "Iteration: 9600. Loss: 0.26052290201187134. Accuracy: 77.15579337312204\n",
      "Iteration: 9610. Loss: 0.33619844913482666. Accuracy: 76.18851615558756\n",
      "Iteration: 9620. Loss: 0.28294146060943604. Accuracy: 76.27083762090965\n",
      "Iteration: 9630. Loss: 0.3677918314933777. Accuracy: 76.5178020168759\n",
      "Iteration: 9640. Loss: 0.3000461757183075. Accuracy: 76.90882897715579\n",
      "Iteration: 9650. Loss: 0.26454776525497437. Accuracy: 76.64128421485903\n",
      "Iteration: 9660. Loss: 0.30795028805732727. Accuracy: 76.57954311586747\n",
      "Iteration: 9670. Loss: 0.39113059639930725. Accuracy: 75.69458736365507\n",
      "Epoch:  125\n",
      "Iteration: 9680. Loss: 0.2395697385072708. Accuracy: 75.98271249228236\n",
      "Iteration: 9690. Loss: 0.23724089562892914. Accuracy: 75.94155175962132\n",
      "Iteration: 9700. Loss: 0.2856101393699646. Accuracy: 76.29141798724017\n",
      "Iteration: 9710. Loss: 0.26565468311309814. Accuracy: 76.55896274953695\n",
      "Iteration: 9720. Loss: 0.4223446249961853. Accuracy: 76.20909652191808\n",
      "Iteration: 9730. Loss: 0.3693147897720337. Accuracy: 77.19695410578308\n",
      "Iteration: 9740. Loss: 0.253425270318985. Accuracy: 75.8180695616382\n",
      "Iteration: 9750. Loss: 0.40662574768066406. Accuracy: 76.66186458118955\n",
      "Epoch:  126\n",
      "Iteration: 9760. Loss: 0.2465752512216568. Accuracy: 76.57954311586747\n",
      "Iteration: 9770. Loss: 0.29944130778312683. Accuracy: 76.5178020168759\n",
      "Iteration: 9780. Loss: 0.2121238261461258. Accuracy: 76.45606091788434\n",
      "Iteration: 9790. Loss: 0.3620765507221222. Accuracy: 77.2175344721136\n",
      "Iteration: 9800. Loss: 0.2001548409461975. Accuracy: 76.27083762090965\n",
      "Iteration: 9810. Loss: 0.36415621638298035. Accuracy: 75.94155175962132\n",
      "Iteration: 9820. Loss: 0.37583303451538086. Accuracy: 76.78534677917267\n",
      "Epoch:  127\n",
      "Iteration: 9830. Loss: 0.2144031524658203. Accuracy: 76.126775056596\n",
      "Iteration: 9840. Loss: 0.3153885006904602. Accuracy: 75.13891747273101\n",
      "Iteration: 9850. Loss: 0.33150622248649597. Accuracy: 76.14735542292652\n",
      "Iteration: 9860. Loss: 0.3129099905490875. Accuracy: 76.55896274953695\n",
      "Iteration: 9870. Loss: 0.2738015651702881. Accuracy: 76.57954311586747\n",
      "Iteration: 9880. Loss: 0.259206622838974. Accuracy: 77.13521300679152\n",
      "Iteration: 9890. Loss: 0.3356285095214844. Accuracy: 76.45606091788434\n",
      "Iteration: 9900. Loss: 0.3437063992023468. Accuracy: 76.14735542292652\n",
      "Epoch:  128\n",
      "Iteration: 9910. Loss: 0.25686898827552795. Accuracy: 76.45606091788434\n",
      "Iteration: 9920. Loss: 0.3351193368434906. Accuracy: 77.13521300679152\n",
      "Iteration: 9930. Loss: 0.3309991657733917. Accuracy: 76.25025725457913\n",
      "Iteration: 9940. Loss: 0.2739580571651459. Accuracy: 76.74418604651163\n",
      "Iteration: 9950. Loss: 0.21511399745941162. Accuracy: 76.10619469026548\n",
      "Iteration: 9960. Loss: 0.27216771245002747. Accuracy: 75.9209713932908\n",
      "Iteration: 9970. Loss: 0.2508835196495056. Accuracy: 76.49722165054538\n",
      "Iteration: 9980. Loss: 0.31552866101264954. Accuracy: 75.44762296768883\n",
      "Epoch:  129\n",
      "Iteration: 9990. Loss: 0.2464759200811386. Accuracy: 76.47664128421486\n",
      "Iteration: 10000. Loss: 0.2874947488307953. Accuracy: 76.5178020168759\n",
      "Iteration: 10010. Loss: 0.3169385492801666. Accuracy: 76.70302531385059\n",
      "Iteration: 10020. Loss: 0.36519211530685425. Accuracy: 76.76476641284215\n",
      "Iteration: 10030. Loss: 0.25730037689208984. Accuracy: 75.7151677299856\n",
      "Iteration: 10040. Loss: 0.19984054565429688. Accuracy: 76.47664128421486\n",
      "Iteration: 10050. Loss: 0.3113490641117096. Accuracy: 76.90882897715579\n",
      "Iteration: 10060. Loss: 0.31790581345558167. Accuracy: 76.39431981889278\n",
      "Epoch:  130\n",
      "Iteration: 10070. Loss: 0.27424508333206177. Accuracy: 76.18851615558756\n",
      "Iteration: 10080. Loss: 0.23584426939487457. Accuracy: 76.94998970981683\n",
      "Iteration: 10090. Loss: 0.3267500400543213. Accuracy: 76.53838238320643\n",
      "Iteration: 10100. Loss: 0.3122293949127197. Accuracy: 77.07347190779996\n",
      "Iteration: 10110. Loss: 0.3039339780807495. Accuracy: 76.16793578925704\n",
      "Iteration: 10120. Loss: 0.26481372117996216. Accuracy: 76.126775056596\n",
      "Iteration: 10130. Loss: 0.3084326386451721. Accuracy: 75.61226589833299\n",
      "Iteration: 10140. Loss: 0.2901531457901001. Accuracy: 76.47664128421486\n",
      "Epoch:  131\n",
      "Iteration: 10150. Loss: 0.24754993617534637. Accuracy: 76.16793578925704\n",
      "Iteration: 10160. Loss: 0.24773834645748138. Accuracy: 76.37373945256226\n",
      "Iteration: 10170. Loss: 0.2928691506385803. Accuracy: 76.66186458118955\n",
      "Iteration: 10180. Loss: 0.3014662563800812. Accuracy: 76.47664128421486\n",
      "Iteration: 10190. Loss: 0.2595720887184143. Accuracy: 77.09405227413048\n",
      "Iteration: 10200. Loss: 0.3037577271461487. Accuracy: 76.99115044247787\n",
      "Iteration: 10210. Loss: 0.27849358320236206. Accuracy: 76.60012348219799\n",
      "Epoch:  132\n",
      "Iteration: 10220. Loss: 0.23625966906547546. Accuracy: 76.39431981889278\n",
      "Iteration: 10230. Loss: 0.26592594385147095. Accuracy: 76.06503395760444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10240. Loss: 0.2848186194896698. Accuracy: 75.79748919530768\n",
      "Iteration: 10250. Loss: 0.204567551612854. Accuracy: 76.10619469026548\n",
      "Iteration: 10260. Loss: 0.19988416135311127. Accuracy: 76.20909652191808\n",
      "Iteration: 10270. Loss: 0.24490205943584442. Accuracy: 76.5178020168759\n",
      "Iteration: 10280. Loss: 0.2546095848083496. Accuracy: 76.29141798724017\n",
      "Iteration: 10290. Loss: 0.27695202827453613. Accuracy: 76.97057007614735\n",
      "Epoch:  133\n",
      "Iteration: 10300. Loss: 0.20409250259399414. Accuracy: 77.05289154146944\n",
      "Iteration: 10310. Loss: 0.32794225215911865. Accuracy: 76.66186458118955\n",
      "Iteration: 10320. Loss: 0.1945357322692871. Accuracy: 77.0117308088084\n",
      "Iteration: 10330. Loss: 0.33703914284706116. Accuracy: 77.114632640461\n",
      "Iteration: 10340. Loss: 0.2866426408290863. Accuracy: 76.16793578925704\n",
      "Iteration: 10350. Loss: 0.24333015084266663. Accuracy: 76.4149001852233\n",
      "Iteration: 10360. Loss: 0.24525147676467896. Accuracy: 76.88824861082527\n",
      "Iteration: 10370. Loss: 0.24871423840522766. Accuracy: 76.92940934348631\n",
      "Epoch:  134\n",
      "Iteration: 10380. Loss: 0.2361169159412384. Accuracy: 76.76476641284215\n",
      "Iteration: 10390. Loss: 0.3183521032333374. Accuracy: 76.64128421485903\n",
      "Iteration: 10400. Loss: 0.3091879189014435. Accuracy: 76.25025725457913\n",
      "Iteration: 10410. Loss: 0.32147300243377686. Accuracy: 77.2175344721136\n",
      "Iteration: 10420. Loss: 0.3860543966293335. Accuracy: 76.86766824449475\n",
      "Iteration: 10430. Loss: 0.22971531748771667. Accuracy: 76.6207038485285\n",
      "Iteration: 10440. Loss: 0.285475492477417. Accuracy: 76.76476641284215\n",
      "Iteration: 10450. Loss: 0.3272126317024231. Accuracy: 77.13521300679152\n",
      "Epoch:  135\n",
      "Iteration: 10460. Loss: 0.23543119430541992. Accuracy: 76.45606091788434\n",
      "Iteration: 10470. Loss: 0.1997753232717514. Accuracy: 76.72360568018111\n",
      "Iteration: 10480. Loss: 0.17082646489143372. Accuracy: 76.49722165054538\n",
      "Iteration: 10490. Loss: 0.2498461902141571. Accuracy: 76.20909652191808\n",
      "Iteration: 10500. Loss: 0.2589341998100281. Accuracy: 76.88824861082527\n",
      "Iteration: 10510. Loss: 0.2909238040447235. Accuracy: 76.64128421485903\n",
      "Iteration: 10520. Loss: 0.28389444947242737. Accuracy: 77.09405227413048\n",
      "Iteration: 10530. Loss: 0.3079409897327423. Accuracy: 77.46449886807986\n",
      "Epoch:  136\n",
      "Iteration: 10540. Loss: 0.24391062557697296. Accuracy: 76.68244494752007\n",
      "Iteration: 10550. Loss: 0.22447709739208221. Accuracy: 76.43548055155382\n",
      "Iteration: 10560. Loss: 0.327936589717865. Accuracy: 76.88824861082527\n",
      "Iteration: 10570. Loss: 0.22516201436519623. Accuracy: 76.76476641284215\n",
      "Iteration: 10580. Loss: 0.30806225538253784. Accuracy: 76.76476641284215\n",
      "Iteration: 10590. Loss: 0.32118839025497437. Accuracy: 76.72360568018111\n",
      "Iteration: 10600. Loss: 0.17954526841640472. Accuracy: 76.4149001852233\n",
      "Epoch:  137\n",
      "Iteration: 10610. Loss: 0.18554167449474335. Accuracy: 75.75632846264664\n",
      "Iteration: 10620. Loss: 0.25923651456832886. Accuracy: 76.70302531385059\n",
      "Iteration: 10630. Loss: 0.2393055260181427. Accuracy: 76.60012348219799\n",
      "Iteration: 10640. Loss: 0.22959277033805847. Accuracy: 77.09405227413048\n",
      "Iteration: 10650. Loss: 0.3332889676094055. Accuracy: 76.94998970981683\n",
      "Iteration: 10660. Loss: 0.39267414808273315. Accuracy: 75.98271249228236\n",
      "Iteration: 10670. Loss: 0.2597663700580597. Accuracy: 76.53838238320643\n",
      "Iteration: 10680. Loss: 0.21188968420028687. Accuracy: 76.20909652191808\n",
      "Epoch:  138\n",
      "Iteration: 10690. Loss: 0.2177257239818573. Accuracy: 76.99115044247787\n",
      "Iteration: 10700. Loss: 0.2526962161064148. Accuracy: 76.84708787816423\n",
      "Iteration: 10710. Loss: 0.2797848582267761. Accuracy: 76.94998970981683\n",
      "Iteration: 10720. Loss: 0.26226484775543213. Accuracy: 76.72360568018111\n",
      "Iteration: 10730. Loss: 0.2234691083431244. Accuracy: 76.31199835357069\n",
      "Iteration: 10740. Loss: 0.30770647525787354. Accuracy: 76.45606091788434\n",
      "Iteration: 10750. Loss: 0.2856161296367645. Accuracy: 76.16793578925704\n",
      "Iteration: 10760. Loss: 0.2558136582374573. Accuracy: 77.05289154146944\n",
      "Epoch:  139\n",
      "Iteration: 10770. Loss: 0.3100203275680542. Accuracy: 76.68244494752007\n",
      "Iteration: 10780. Loss: 0.2193969190120697. Accuracy: 76.60012348219799\n",
      "Iteration: 10790. Loss: 0.24470216035842896. Accuracy: 76.74418604651163\n",
      "Iteration: 10800. Loss: 0.25469058752059937. Accuracy: 76.82650751183371\n",
      "Iteration: 10810. Loss: 0.287031888961792. Accuracy: 77.07347190779996\n",
      "Iteration: 10820. Loss: 0.2500191926956177. Accuracy: 76.82650751183371\n",
      "Iteration: 10830. Loss: 0.20192450284957886. Accuracy: 76.97057007614735\n",
      "Iteration: 10840. Loss: 0.28906604647636414. Accuracy: 77.4027577690883\n",
      "Epoch:  140\n",
      "Iteration: 10850. Loss: 0.26456472277641296. Accuracy: 76.94998970981683\n",
      "Iteration: 10860. Loss: 0.25305262207984924. Accuracy: 77.36159703642724\n",
      "Iteration: 10870. Loss: 0.2220146358013153. Accuracy: 76.27083762090965\n",
      "Iteration: 10880. Loss: 0.2039647102355957. Accuracy: 76.78534677917267\n",
      "Iteration: 10890. Loss: 0.24617663025856018. Accuracy: 76.39431981889278\n",
      "Iteration: 10900. Loss: 0.2197105437517166. Accuracy: 76.57954311586747\n",
      "Iteration: 10910. Loss: 0.24157150089740753. Accuracy: 76.66186458118955\n",
      "Iteration: 10920. Loss: 0.22573170065879822. Accuracy: 76.33257871990122\n",
      "Epoch:  141\n",
      "Iteration: 10930. Loss: 0.2011871635913849. Accuracy: 77.13521300679152\n",
      "Iteration: 10940. Loss: 0.2630614936351776. Accuracy: 77.42333813541882\n",
      "Iteration: 10950. Loss: 0.3070615231990814. Accuracy: 77.4027577690883\n",
      "Iteration: 10960. Loss: 0.25477689504623413. Accuracy: 77.48507923441038\n",
      "Iteration: 10970. Loss: 0.25276505947113037. Accuracy: 76.29141798724017\n",
      "Iteration: 10980. Loss: 0.3646423816680908. Accuracy: 76.53838238320643\n",
      "Iteration: 10990. Loss: 0.2834576964378357. Accuracy: 77.54682033340194\n",
      "Epoch:  142\n",
      "Iteration: 11000. Loss: 0.25365254282951355. Accuracy: 76.86766824449475\n",
      "Iteration: 11010. Loss: 0.36484768986701965. Accuracy: 77.19695410578308\n",
      "Iteration: 11020. Loss: 0.26639312505722046. Accuracy: 76.76476641284215\n",
      "Iteration: 11030. Loss: 0.1781863570213318. Accuracy: 76.60012348219799\n",
      "Iteration: 11040. Loss: 0.25355806946754456. Accuracy: 76.78534677917267\n",
      "Iteration: 11050. Loss: 0.27187031507492065. Accuracy: 77.114632640461\n",
      "Iteration: 11060. Loss: 0.25402310490608215. Accuracy: 77.5056596007409\n",
      "Iteration: 11070. Loss: 0.23902550339698792. Accuracy: 77.17637373945256\n",
      "Epoch:  143\n",
      "Iteration: 11080. Loss: 0.21971596777439117. Accuracy: 77.85552582835975\n",
      "Iteration: 11090. Loss: 0.18165607750415802. Accuracy: 76.88824861082527\n",
      "Iteration: 11100. Loss: 0.2639612555503845. Accuracy: 77.114632640461\n",
      "Iteration: 11110. Loss: 0.24553073942661285. Accuracy: 76.68244494752007\n",
      "Iteration: 11120. Loss: 0.23651652038097382. Accuracy: 77.34101667009672\n",
      "Iteration: 11130. Loss: 0.23200201988220215. Accuracy: 76.90882897715579\n",
      "Iteration: 11140. Loss: 0.2376890778541565. Accuracy: 76.94998970981683\n",
      "Iteration: 11150. Loss: 0.29530999064445496. Accuracy: 77.25869520477464\n",
      "Epoch:  144\n",
      "Iteration: 11160. Loss: 0.27539822459220886. Accuracy: 77.17637373945256\n",
      "Iteration: 11170. Loss: 0.2513924837112427. Accuracy: 77.3204363037662\n",
      "Iteration: 11180. Loss: 0.22649404406547546. Accuracy: 77.19695410578308\n",
      "Iteration: 11190. Loss: 0.37971410155296326. Accuracy: 76.2296768882486\n",
      "Iteration: 11200. Loss: 0.32897284626960754. Accuracy: 76.49722165054538\n",
      "Iteration: 11210. Loss: 0.23253583908081055. Accuracy: 76.92940934348631\n",
      "Iteration: 11220. Loss: 0.3026609420776367. Accuracy: 76.76476641284215\n",
      "Iteration: 11230. Loss: 0.2381822168827057. Accuracy: 76.49722165054538\n",
      "Epoch:  145\n",
      "Iteration: 11240. Loss: 0.28090670704841614. Accuracy: 77.36159703642724\n",
      "Iteration: 11250. Loss: 0.2713305950164795. Accuracy: 77.19695410578308\n",
      "Iteration: 11260. Loss: 0.17353053390979767. Accuracy: 77.34101667009672\n",
      "Iteration: 11270. Loss: 0.33637240529060364. Accuracy: 77.75262399670714\n",
      "Iteration: 11280. Loss: 0.18838946521282196. Accuracy: 76.6207038485285\n",
      "Iteration: 11290. Loss: 0.23784935474395752. Accuracy: 76.99115044247787\n",
      "Iteration: 11300. Loss: 0.26624682545661926. Accuracy: 76.80592714550319\n",
      "Iteration: 11310. Loss: 0.21570609509944916. Accuracy: 77.48507923441038\n",
      "Epoch:  146\n",
      "Iteration: 11320. Loss: 0.26212015748023987. Accuracy: 77.89668656102079\n",
      "Iteration: 11330. Loss: 0.30501800775527954. Accuracy: 76.55896274953695\n",
      "Iteration: 11340. Loss: 0.18200275301933289. Accuracy: 76.97057007614735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11350. Loss: 0.24806606769561768. Accuracy: 75.77690882897716\n",
      "Iteration: 11360. Loss: 0.2425200194120407. Accuracy: 76.47664128421486\n",
      "Iteration: 11370. Loss: 0.2205439954996109. Accuracy: 76.43548055155382\n",
      "Iteration: 11380. Loss: 0.2148841768503189. Accuracy: 77.34101667009672\n",
      "Epoch:  147\n",
      "Iteration: 11390. Loss: 0.19040828943252563. Accuracy: 76.68244494752007\n",
      "Iteration: 11400. Loss: 0.2027454823255539. Accuracy: 76.86766824449475\n",
      "Iteration: 11410. Loss: 0.162538081407547. Accuracy: 77.93784729368183\n",
      "Iteration: 11420. Loss: 0.2300574779510498. Accuracy: 76.80592714550319\n",
      "Iteration: 11430. Loss: 0.3348125219345093. Accuracy: 76.92940934348631\n",
      "Iteration: 11440. Loss: 0.23964852094650269. Accuracy: 76.82650751183371\n",
      "Iteration: 11450. Loss: 0.25425729155540466. Accuracy: 77.27927557110516\n",
      "Iteration: 11460. Loss: 0.21185526251792908. Accuracy: 77.29985593743568\n",
      "Epoch:  148\n",
      "Iteration: 11470. Loss: 0.22225059568881989. Accuracy: 77.3204363037662\n",
      "Iteration: 11480. Loss: 0.20203711092472076. Accuracy: 77.03231117513891\n",
      "Iteration: 11490. Loss: 0.18883873522281647. Accuracy: 76.31199835357069\n",
      "Iteration: 11500. Loss: 0.16313455998897552. Accuracy: 77.23811483844412\n",
      "Iteration: 11510. Loss: 0.23858870565891266. Accuracy: 77.29985593743568\n",
      "Iteration: 11520. Loss: 0.2072448879480362. Accuracy: 77.114632640461\n",
      "Iteration: 11530. Loss: 0.17474304139614105. Accuracy: 77.44391850174934\n",
      "Iteration: 11540. Loss: 0.20709888637065887. Accuracy: 77.3204363037662\n",
      "Epoch:  149\n",
      "Iteration: 11550. Loss: 0.27588388323783875. Accuracy: 76.94998970981683\n",
      "Iteration: 11560. Loss: 0.16742897033691406. Accuracy: 77.48507923441038\n",
      "Iteration: 11570. Loss: 0.2022700011730194. Accuracy: 77.36159703642724\n",
      "Iteration: 11580. Loss: 0.20377303659915924. Accuracy: 76.90882897715579\n",
      "Iteration: 11590. Loss: 0.23990975320339203. Accuracy: 76.49722165054538\n",
      "Iteration: 11600. Loss: 0.21213842928409576. Accuracy: 77.13521300679152\n",
      "Iteration: 11610. Loss: 0.22760477662086487. Accuracy: 77.56740069973246\n",
      "Iteration: 11620. Loss: 0.19839684665203094. Accuracy: 77.13521300679152\n",
      "Epoch:  150\n",
      "Iteration: 11630. Loss: 0.1941947489976883. Accuracy: 77.42333813541882\n",
      "Iteration: 11640. Loss: 0.16376300156116486. Accuracy: 77.46449886807986\n",
      "Iteration: 11650. Loss: 0.19143712520599365. Accuracy: 76.97057007614735\n",
      "Iteration: 11660. Loss: 0.16096040606498718. Accuracy: 77.64972216505454\n",
      "Iteration: 11670. Loss: 0.2564682960510254. Accuracy: 76.92940934348631\n",
      "Iteration: 11680. Loss: 0.24352549016475677. Accuracy: 76.60012348219799\n",
      "Iteration: 11690. Loss: 0.21480412781238556. Accuracy: 77.52623996707142\n",
      "Iteration: 11700. Loss: 0.29246437549591064. Accuracy: 77.05289154146944\n",
      "Epoch:  151\n",
      "Iteration: 11710. Loss: 0.2602214217185974. Accuracy: 76.47664128421486\n",
      "Iteration: 11720. Loss: 0.25355440378189087. Accuracy: 76.70302531385059\n",
      "Iteration: 11730. Loss: 0.20410692691802979. Accuracy: 77.29985593743568\n",
      "Iteration: 11740. Loss: 0.1590922474861145. Accuracy: 76.45606091788434\n",
      "Iteration: 11750. Loss: 0.21863991022109985. Accuracy: 77.48507923441038\n",
      "Iteration: 11760. Loss: 0.21887832880020142. Accuracy: 76.94998970981683\n",
      "Iteration: 11770. Loss: 0.2082633376121521. Accuracy: 77.2175344721136\n",
      "Epoch:  152\n",
      "Iteration: 11780. Loss: 0.1932397484779358. Accuracy: 76.88824861082527\n",
      "Iteration: 11790. Loss: 0.15619103610515594. Accuracy: 77.25869520477464\n",
      "Iteration: 11800. Loss: 0.16180123388767242. Accuracy: 77.79378472936818\n",
      "Iteration: 11810. Loss: 0.2454724907875061. Accuracy: 77.48507923441038\n",
      "Iteration: 11820. Loss: 0.2420312464237213. Accuracy: 77.2175344721136\n",
      "Iteration: 11830. Loss: 0.21007943153381348. Accuracy: 76.72360568018111\n",
      "Iteration: 11840. Loss: 0.31805071234703064. Accuracy: 77.54682033340194\n",
      "Iteration: 11850. Loss: 0.24034331738948822. Accuracy: 76.82650751183371\n",
      "Epoch:  153\n",
      "Iteration: 11860. Loss: 0.1853402704000473. Accuracy: 77.44391850174934\n",
      "Iteration: 11870. Loss: 0.21846704185009003. Accuracy: 77.19695410578308\n",
      "Iteration: 11880. Loss: 0.16717715561389923. Accuracy: 76.99115044247787\n",
      "Iteration: 11890. Loss: 0.1986880600452423. Accuracy: 76.45606091788434\n",
      "Iteration: 11900. Loss: 0.24942554533481598. Accuracy: 77.56740069973246\n",
      "Iteration: 11910. Loss: 0.17816273868083954. Accuracy: 77.19695410578308\n",
      "Iteration: 11920. Loss: 0.24583731591701508. Accuracy: 77.03231117513891\n",
      "Iteration: 11930. Loss: 0.3017239272594452. Accuracy: 77.2175344721136\n",
      "Epoch:  154\n",
      "Iteration: 11940. Loss: 0.18873779475688934. Accuracy: 77.29985593743568\n",
      "Iteration: 11950. Loss: 0.15077270567417145. Accuracy: 76.92940934348631\n",
      "Iteration: 11960. Loss: 0.316685289144516. Accuracy: 77.3204363037662\n",
      "Iteration: 11970. Loss: 0.23974835872650146. Accuracy: 76.74418604651163\n",
      "Iteration: 11980. Loss: 0.21209287643432617. Accuracy: 76.55896274953695\n",
      "Iteration: 11990. Loss: 0.20930828154087067. Accuracy: 76.90882897715579\n",
      "Iteration: 12000. Loss: 0.14444968104362488. Accuracy: 77.3204363037662\n",
      "Iteration: 12010. Loss: 0.23131872713565826. Accuracy: 77.3204363037662\n",
      "Epoch:  155\n",
      "Iteration: 12020. Loss: 0.15142270922660828. Accuracy: 77.05289154146944\n",
      "Iteration: 12030. Loss: 0.15108805894851685. Accuracy: 77.114632640461\n",
      "Iteration: 12040. Loss: 0.13969407975673676. Accuracy: 77.36159703642724\n",
      "Iteration: 12050. Loss: 0.2396879345178604. Accuracy: 77.9172669273513\n",
      "Iteration: 12060. Loss: 0.16174660623073578. Accuracy: 77.73204363037662\n",
      "Iteration: 12070. Loss: 0.1512707769870758. Accuracy: 76.66186458118955\n",
      "Iteration: 12080. Loss: 0.1852950155735016. Accuracy: 77.2175344721136\n",
      "Iteration: 12090. Loss: 0.2243434488773346. Accuracy: 77.17637373945256\n",
      "Epoch:  156\n",
      "Iteration: 12100. Loss: 0.18307878077030182. Accuracy: 76.94998970981683\n",
      "Iteration: 12110. Loss: 0.21834474802017212. Accuracy: 77.69088289771558\n",
      "Iteration: 12120. Loss: 0.1981198936700821. Accuracy: 77.36159703642724\n",
      "Iteration: 12130. Loss: 0.2326672375202179. Accuracy: 76.33257871990122\n",
      "Iteration: 12140. Loss: 0.13859686255455017. Accuracy: 77.19695410578308\n",
      "Iteration: 12150. Loss: 0.1994406133890152. Accuracy: 76.53838238320643\n",
      "Iteration: 12160. Loss: 0.19306688010692596. Accuracy: 76.4149001852233\n",
      "Epoch:  157\n",
      "Iteration: 12170. Loss: 0.19513832032680511. Accuracy: 76.90882897715579\n",
      "Iteration: 12180. Loss: 0.30770930647850037. Accuracy: 77.69088289771558\n",
      "Iteration: 12190. Loss: 0.23713237047195435. Accuracy: 76.99115044247787\n",
      "Iteration: 12200. Loss: 0.1842186152935028. Accuracy: 77.13521300679152\n",
      "Iteration: 12210. Loss: 0.24078713357448578. Accuracy: 77.05289154146944\n",
      "Iteration: 12220. Loss: 0.17039340734481812. Accuracy: 77.19695410578308\n",
      "Iteration: 12230. Loss: 0.25074338912963867. Accuracy: 76.5178020168759\n",
      "Iteration: 12240. Loss: 0.24780283868312836. Accuracy: 76.86766824449475\n",
      "Epoch:  158\n",
      "Iteration: 12250. Loss: 0.17615684866905212. Accuracy: 76.80592714550319\n",
      "Iteration: 12260. Loss: 0.17444631457328796. Accuracy: 76.86766824449475\n",
      "Iteration: 12270. Loss: 0.26324573159217834. Accuracy: 77.114632640461\n",
      "Iteration: 12280. Loss: 0.21310052275657654. Accuracy: 77.6085614323935\n",
      "Iteration: 12290. Loss: 0.29807355999946594. Accuracy: 77.44391850174934\n",
      "Iteration: 12300. Loss: 0.12847119569778442. Accuracy: 76.80592714550319\n",
      "Iteration: 12310. Loss: 0.2530280649662018. Accuracy: 76.45606091788434\n",
      "Iteration: 12320. Loss: 0.21470393240451813. Accuracy: 76.27083762090965\n",
      "Epoch:  159\n",
      "Iteration: 12330. Loss: 0.31048664450645447. Accuracy: 76.72360568018111\n",
      "Iteration: 12340. Loss: 0.1446397751569748. Accuracy: 76.72360568018111\n",
      "Iteration: 12350. Loss: 0.21716395020484924. Accuracy: 77.36159703642724\n",
      "Iteration: 12360. Loss: 0.20352499186992645. Accuracy: 77.13521300679152\n",
      "Iteration: 12370. Loss: 0.25202107429504395. Accuracy: 77.2175344721136\n",
      "Iteration: 12380. Loss: 0.23153342306613922. Accuracy: 77.64972216505454\n",
      "Iteration: 12390. Loss: 0.19863584637641907. Accuracy: 77.15579337312204\n",
      "Iteration: 12400. Loss: 0.18883340060710907. Accuracy: 76.94998970981683\n",
      "Epoch:  160\n",
      "Iteration: 12410. Loss: 0.17875158786773682. Accuracy: 77.13521300679152\n",
      "Iteration: 12420. Loss: 0.2683723568916321. Accuracy: 77.54682033340194\n",
      "Iteration: 12430. Loss: 0.2913399338722229. Accuracy: 76.97057007614735\n",
      "Iteration: 12440. Loss: 0.20517858862876892. Accuracy: 78.4111957192838\n",
      "Iteration: 12450. Loss: 0.23742468655109406. Accuracy: 77.29985593743568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12460. Loss: 0.2413882464170456. Accuracy: 77.52623996707142\n",
      "Iteration: 12470. Loss: 0.173390194773674. Accuracy: 77.3204363037662\n",
      "Iteration: 12480. Loss: 0.32546430826187134. Accuracy: 76.99115044247787\n",
      "Epoch:  161\n",
      "Iteration: 12490. Loss: 0.17961479723453522. Accuracy: 77.67030253138506\n",
      "Iteration: 12500. Loss: 0.1280474066734314. Accuracy: 78.06132949166495\n",
      "Iteration: 12510. Loss: 0.2586839497089386. Accuracy: 77.48507923441038\n",
      "Iteration: 12520. Loss: 0.24412751197814941. Accuracy: 77.114632640461\n",
      "Iteration: 12530. Loss: 0.1718389242887497. Accuracy: 77.03231117513891\n",
      "Iteration: 12540. Loss: 0.18128959834575653. Accuracy: 77.89668656102079\n",
      "Iteration: 12550. Loss: 0.21386072039604187. Accuracy: 77.99958839267339\n",
      "Epoch:  162\n",
      "Iteration: 12560. Loss: 0.16391783952713013. Accuracy: 77.89668656102079\n",
      "Iteration: 12570. Loss: 0.22218570113182068. Accuracy: 77.58798106606298\n",
      "Iteration: 12580. Loss: 0.20474541187286377. Accuracy: 78.16423132331755\n",
      "Iteration: 12590. Loss: 0.16514603793621063. Accuracy: 77.52623996707142\n",
      "Iteration: 12600. Loss: 0.21025335788726807. Accuracy: 78.04074912533443\n",
      "Iteration: 12610. Loss: 0.2043335735797882. Accuracy: 76.86766824449475\n",
      "Iteration: 12620. Loss: 0.2489374876022339. Accuracy: 77.8143650956987\n",
      "Iteration: 12630. Loss: 0.15285088121891022. Accuracy: 77.03231117513891\n",
      "Epoch:  163\n",
      "Iteration: 12640. Loss: 0.15574297308921814. Accuracy: 76.82650751183371\n",
      "Iteration: 12650. Loss: 0.18894512951374054. Accuracy: 76.82650751183371\n",
      "Iteration: 12660. Loss: 0.2297554463148117. Accuracy: 77.27927557110516\n",
      "Iteration: 12670. Loss: 0.2133428156375885. Accuracy: 77.23811483844412\n",
      "Iteration: 12680. Loss: 0.34884679317474365. Accuracy: 78.08190985799547\n",
      "Iteration: 12690. Loss: 0.20490626990795135. Accuracy: 77.05289154146944\n",
      "Iteration: 12700. Loss: 0.191508948802948. Accuracy: 76.92940934348631\n",
      "Iteration: 12710. Loss: 0.19184434413909912. Accuracy: 76.72360568018111\n",
      "Epoch:  164\n",
      "Iteration: 12720. Loss: 0.2281426638364792. Accuracy: 76.78534677917267\n",
      "Iteration: 12730. Loss: 0.17546828091144562. Accuracy: 77.19695410578308\n",
      "Iteration: 12740. Loss: 0.23468612134456635. Accuracy: 77.44391850174934\n",
      "Iteration: 12750. Loss: 0.19481933116912842. Accuracy: 77.5056596007409\n",
      "Iteration: 12760. Loss: 0.29762306809425354. Accuracy: 76.74418604651163\n",
      "Iteration: 12770. Loss: 0.16538621485233307. Accuracy: 77.56740069973246\n",
      "Iteration: 12780. Loss: 0.23024921119213104. Accuracy: 76.94998970981683\n",
      "Iteration: 12790. Loss: 0.22263619303703308. Accuracy: 77.42333813541882\n",
      "Epoch:  165\n",
      "Iteration: 12800. Loss: 0.2029445916414261. Accuracy: 77.25869520477464\n",
      "Iteration: 12810. Loss: 0.11333774775266647. Accuracy: 77.54682033340194\n",
      "Iteration: 12820. Loss: 0.192353293299675. Accuracy: 77.6085614323935\n",
      "Iteration: 12830. Loss: 0.18764956295490265. Accuracy: 78.04074912533443\n",
      "Iteration: 12840. Loss: 0.22551244497299194. Accuracy: 78.6993208479111\n",
      "Iteration: 12850. Loss: 0.19887088239192963. Accuracy: 77.77320436303766\n",
      "Iteration: 12860. Loss: 0.16067209839820862. Accuracy: 76.76476641284215\n",
      "Iteration: 12870. Loss: 0.18797975778579712. Accuracy: 77.3204363037662\n",
      "Epoch:  166\n",
      "Iteration: 12880. Loss: 0.1589442789554596. Accuracy: 76.99115044247787\n",
      "Iteration: 12890. Loss: 0.1210663914680481. Accuracy: 77.52623996707142\n",
      "Iteration: 12900. Loss: 0.1978655606508255. Accuracy: 76.97057007614735\n",
      "Iteration: 12910. Loss: 0.15826185047626495. Accuracy: 76.92940934348631\n",
      "Iteration: 12920. Loss: 0.16307319700717926. Accuracy: 77.34101667009672\n",
      "Iteration: 12930. Loss: 0.2225692719221115. Accuracy: 77.09405227413048\n",
      "Iteration: 12940. Loss: 0.1747247874736786. Accuracy: 77.07347190779996\n",
      "Epoch:  167\n",
      "Iteration: 12950. Loss: 0.17517779767513275. Accuracy: 77.44391850174934\n",
      "Iteration: 12960. Loss: 0.15888503193855286. Accuracy: 76.99115044247787\n",
      "Iteration: 12970. Loss: 0.1369401514530182. Accuracy: 77.29985593743568\n",
      "Iteration: 12980. Loss: 0.1905646175146103. Accuracy: 77.15579337312204\n",
      "Iteration: 12990. Loss: 0.11576251685619354. Accuracy: 76.64128421485903\n",
      "Iteration: 13000. Loss: 0.15942297875881195. Accuracy: 76.88824861082527\n",
      "Iteration: 13010. Loss: 0.2171621024608612. Accuracy: 77.25869520477464\n",
      "Iteration: 13020. Loss: 0.15395769476890564. Accuracy: 77.8143650956987\n",
      "Epoch:  168\n",
      "Iteration: 13030. Loss: 0.16755442321300507. Accuracy: 77.5056596007409\n",
      "Iteration: 13040. Loss: 0.1506831794977188. Accuracy: 77.95842766001235\n",
      "Iteration: 13050. Loss: 0.1796119213104248. Accuracy: 77.48507923441038\n",
      "Iteration: 13060. Loss: 0.1832996904850006. Accuracy: 76.84708787816423\n",
      "Iteration: 13070. Loss: 0.198384091258049. Accuracy: 77.56740069973246\n",
      "Iteration: 13080. Loss: 0.15192726254463196. Accuracy: 77.0117308088084\n",
      "Iteration: 13090. Loss: 0.12866055965423584. Accuracy: 78.14365095698703\n",
      "Iteration: 13100. Loss: 0.20937539637088776. Accuracy: 77.93784729368183\n",
      "Epoch:  169\n",
      "Iteration: 13110. Loss: 0.1506180465221405. Accuracy: 78.28771352130067\n",
      "Iteration: 13120. Loss: 0.18760184943675995. Accuracy: 77.83494546202922\n",
      "Iteration: 13130. Loss: 0.1808314025402069. Accuracy: 77.48507923441038\n",
      "Iteration: 13140. Loss: 0.17980851233005524. Accuracy: 77.34101667009672\n",
      "Iteration: 13150. Loss: 0.21408653259277344. Accuracy: 77.69088289771558\n",
      "Iteration: 13160. Loss: 0.2107018381357193. Accuracy: 77.6085614323935\n",
      "Iteration: 13170. Loss: 0.2106168121099472. Accuracy: 77.85552582835975\n",
      "Iteration: 13180. Loss: 0.2367965281009674. Accuracy: 77.13521300679152\n",
      "Epoch:  170\n",
      "Iteration: 13190. Loss: 0.15425297617912292. Accuracy: 78.28771352130067\n",
      "Iteration: 13200. Loss: 0.1428353637456894. Accuracy: 77.48507923441038\n",
      "Iteration: 13210. Loss: 0.1635846197605133. Accuracy: 76.97057007614735\n",
      "Iteration: 13220. Loss: 0.12557712197303772. Accuracy: 77.114632640461\n",
      "Iteration: 13230. Loss: 0.18475210666656494. Accuracy: 77.48507923441038\n",
      "Iteration: 13240. Loss: 0.17255143821239471. Accuracy: 76.97057007614735\n",
      "Iteration: 13250. Loss: 0.14481234550476074. Accuracy: 77.75262399670714\n",
      "Iteration: 13260. Loss: 0.3025398254394531. Accuracy: 77.03231117513891\n",
      "Epoch:  171\n",
      "Iteration: 13270. Loss: 0.15592023730278015. Accuracy: 76.78534677917267\n",
      "Iteration: 13280. Loss: 0.12780778110027313. Accuracy: 77.99958839267339\n",
      "Iteration: 13290. Loss: 0.14101357758045197. Accuracy: 77.46449886807986\n",
      "Iteration: 13300. Loss: 0.1786169856786728. Accuracy: 77.42333813541882\n",
      "Iteration: 13310. Loss: 0.208061084151268. Accuracy: 77.83494546202922\n",
      "Iteration: 13320. Loss: 0.1568932682275772. Accuracy: 77.3204363037662\n",
      "Iteration: 13330. Loss: 0.18559318780899048. Accuracy: 78.3082938876312\n",
      "Epoch:  172\n",
      "Iteration: 13340. Loss: 0.16852325201034546. Accuracy: 77.64972216505454\n",
      "Iteration: 13350. Loss: 0.11460234969854355. Accuracy: 77.2175344721136\n",
      "Iteration: 13360. Loss: 0.21154503524303436. Accuracy: 77.73204363037662\n",
      "Iteration: 13370. Loss: 0.151165172457695. Accuracy: 77.77320436303766\n",
      "Iteration: 13380. Loss: 0.21308164298534393. Accuracy: 77.6085614323935\n",
      "Iteration: 13390. Loss: 0.13024312257766724. Accuracy: 77.69088289771558\n",
      "Iteration: 13400. Loss: 0.23293250799179077. Accuracy: 77.2175344721136\n",
      "Iteration: 13410. Loss: 0.1574791520833969. Accuracy: 77.03231117513891\n",
      "Epoch:  173\n",
      "Iteration: 13420. Loss: 0.1862015277147293. Accuracy: 77.36159703642724\n",
      "Iteration: 13430. Loss: 0.14227254688739777. Accuracy: 77.8143650956987\n",
      "Iteration: 13440. Loss: 0.26527708768844604. Accuracy: 77.0117308088084\n",
      "Iteration: 13450. Loss: 0.17113381624221802. Accuracy: 77.6085614323935\n",
      "Iteration: 13460. Loss: 0.1574292927980423. Accuracy: 78.08190985799547\n",
      "Iteration: 13470. Loss: 0.19541621208190918. Accuracy: 77.42333813541882\n",
      "Iteration: 13480. Loss: 0.14431458711624146. Accuracy: 77.05289154146944\n",
      "Iteration: 13490. Loss: 0.12221422791481018. Accuracy: 76.66186458118955\n",
      "Epoch:  174\n",
      "Iteration: 13500. Loss: 0.19913089275360107. Accuracy: 77.29985593743568\n",
      "Iteration: 13510. Loss: 0.2296103984117508. Accuracy: 78.02016875900391\n",
      "Iteration: 13520. Loss: 0.2042347937822342. Accuracy: 77.13521300679152\n",
      "Iteration: 13530. Loss: 0.16414526104927063. Accuracy: 77.25869520477464\n",
      "Iteration: 13540. Loss: 0.17477402091026306. Accuracy: 77.42333813541882\n",
      "Iteration: 13550. Loss: 0.1761225163936615. Accuracy: 78.26713315497015\n",
      "Iteration: 13560. Loss: 0.13673534989356995. Accuracy: 77.13521300679152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 13570. Loss: 0.13692940771579742. Accuracy: 77.85552582835975\n",
      "Epoch:  175\n",
      "Iteration: 13580. Loss: 0.12592022120952606. Accuracy: 77.6085614323935\n",
      "Iteration: 13590. Loss: 0.16558058559894562. Accuracy: 77.58798106606298\n",
      "Iteration: 13600. Loss: 0.12288334965705872. Accuracy: 77.83494546202922\n",
      "Iteration: 13610. Loss: 0.12660662829875946. Accuracy: 77.8143650956987\n",
      "Iteration: 13620. Loss: 0.18778230249881744. Accuracy: 76.99115044247787\n",
      "Iteration: 13630. Loss: 0.20499148964881897. Accuracy: 76.88824861082527\n",
      "Iteration: 13640. Loss: 0.16738754510879517. Accuracy: 77.75262399670714\n",
      "Iteration: 13650. Loss: 0.15791305899620056. Accuracy: 77.73204363037662\n",
      "Epoch:  176\n",
      "Iteration: 13660. Loss: 0.17090797424316406. Accuracy: 77.15579337312204\n",
      "Iteration: 13670. Loss: 0.16321124136447906. Accuracy: 77.87610619469027\n",
      "Iteration: 13680. Loss: 0.18096686899662018. Accuracy: 78.4111957192838\n",
      "Iteration: 13690. Loss: 0.14210525155067444. Accuracy: 77.54682033340194\n",
      "Iteration: 13700. Loss: 0.25033512711524963. Accuracy: 77.75262399670714\n",
      "Iteration: 13710. Loss: 0.15306468307971954. Accuracy: 77.97900802634287\n",
      "Iteration: 13720. Loss: 0.12746404111385345. Accuracy: 77.83494546202922\n",
      "Epoch:  177\n",
      "Iteration: 13730. Loss: 0.1815662831068039. Accuracy: 77.6085614323935\n",
      "Iteration: 13740. Loss: 0.20062589645385742. Accuracy: 77.69088289771558\n",
      "Iteration: 13750. Loss: 0.15500520169734955. Accuracy: 77.83494546202922\n",
      "Iteration: 13760. Loss: 0.15347181260585785. Accuracy: 77.69088289771558\n",
      "Iteration: 13770. Loss: 0.13067983090877533. Accuracy: 77.48507923441038\n",
      "Iteration: 13780. Loss: 0.18231302499771118. Accuracy: 78.10249022432599\n",
      "Iteration: 13790. Loss: 0.15308129787445068. Accuracy: 77.48507923441038\n",
      "Iteration: 13800. Loss: 0.2171902358531952. Accuracy: 77.58798106606298\n",
      "Epoch:  178\n",
      "Iteration: 13810. Loss: 0.1462176889181137. Accuracy: 78.06132949166495\n",
      "Iteration: 13820. Loss: 0.17794688045978546. Accuracy: 77.77320436303766\n",
      "Iteration: 13830. Loss: 0.1226322278380394. Accuracy: 78.10249022432599\n",
      "Iteration: 13840. Loss: 0.12118256837129593. Accuracy: 77.85552582835975\n",
      "Iteration: 13850. Loss: 0.17467831075191498. Accuracy: 77.93784729368183\n",
      "Iteration: 13860. Loss: 0.1339728683233261. Accuracy: 78.02016875900391\n",
      "Iteration: 13870. Loss: 0.15021003782749176. Accuracy: 77.58798106606298\n",
      "Iteration: 13880. Loss: 0.14675450325012207. Accuracy: 77.93784729368183\n",
      "Epoch:  179\n",
      "Iteration: 13890. Loss: 0.18086300790309906. Accuracy: 77.36159703642724\n",
      "Iteration: 13900. Loss: 0.11383263766765594. Accuracy: 77.114632640461\n",
      "Iteration: 13910. Loss: 0.08171619474887848. Accuracy: 78.02016875900391\n",
      "Iteration: 13920. Loss: 0.18811722099781036. Accuracy: 78.26713315497015\n",
      "Iteration: 13930. Loss: 0.16604480147361755. Accuracy: 78.43177608561433\n",
      "Iteration: 13940. Loss: 0.13867487013339996. Accuracy: 77.6085614323935\n",
      "Iteration: 13950. Loss: 0.2025424838066101. Accuracy: 77.5056596007409\n",
      "Iteration: 13960. Loss: 0.16280369460582733. Accuracy: 78.12307059065651\n",
      "Epoch:  180\n",
      "Iteration: 13970. Loss: 0.15784817934036255. Accuracy: 77.99958839267339\n",
      "Iteration: 13980. Loss: 0.14486466348171234. Accuracy: 78.02016875900391\n",
      "Iteration: 13990. Loss: 0.10824698209762573. Accuracy: 77.52623996707142\n",
      "Iteration: 14000. Loss: 0.23875315487384796. Accuracy: 77.75262399670714\n",
      "Iteration: 14010. Loss: 0.19518998265266418. Accuracy: 77.85552582835975\n",
      "Iteration: 14020. Loss: 0.14081180095672607. Accuracy: 77.34101667009672\n",
      "Iteration: 14030. Loss: 0.19559384882450104. Accuracy: 78.24655278863963\n",
      "Iteration: 14040. Loss: 0.22173719108104706. Accuracy: 77.7114632640461\n",
      "Epoch:  181\n",
      "Iteration: 14050. Loss: 0.19181880354881287. Accuracy: 77.6085614323935\n",
      "Iteration: 14060. Loss: 0.10428187996149063. Accuracy: 77.77320436303766\n",
      "Iteration: 14070. Loss: 0.13946421444416046. Accuracy: 77.93784729368183\n",
      "Iteration: 14080. Loss: 0.19279612600803375. Accuracy: 77.13521300679152\n",
      "Iteration: 14090. Loss: 0.24524833261966705. Accuracy: 77.7114632640461\n",
      "Iteration: 14100. Loss: 0.13781963288784027. Accuracy: 77.58798106606298\n",
      "Iteration: 14110. Loss: 0.18848533928394318. Accuracy: 78.16423132331755\n",
      "Epoch:  182\n",
      "Iteration: 14120. Loss: 0.1677318513393402. Accuracy: 77.79378472936818\n",
      "Iteration: 14130. Loss: 0.10667450726032257. Accuracy: 78.4111957192838\n",
      "Iteration: 14140. Loss: 0.1212548166513443. Accuracy: 77.89668656102079\n",
      "Iteration: 14150. Loss: 0.19944819808006287. Accuracy: 77.34101667009672\n",
      "Iteration: 14160. Loss: 0.18147969245910645. Accuracy: 77.23811483844412\n",
      "Iteration: 14170. Loss: 0.12430360168218613. Accuracy: 77.6085614323935\n",
      "Iteration: 14180. Loss: 0.20560501515865326. Accuracy: 78.26713315497015\n",
      "Iteration: 14190. Loss: 0.15090151131153107. Accuracy: 77.5056596007409\n",
      "Epoch:  183\n",
      "Iteration: 14200. Loss: 0.14317183196544647. Accuracy: 76.72360568018111\n",
      "Iteration: 14210. Loss: 0.13612747192382812. Accuracy: 77.64972216505454\n",
      "Iteration: 14220. Loss: 0.11643920838832855. Accuracy: 78.26713315497015\n",
      "Iteration: 14230. Loss: 0.1867634356021881. Accuracy: 77.99958839267339\n",
      "Iteration: 14240. Loss: 0.15856890380382538. Accuracy: 77.6085614323935\n",
      "Iteration: 14250. Loss: 0.11617672443389893. Accuracy: 77.23811483844412\n",
      "Iteration: 14260. Loss: 0.16021862626075745. Accuracy: 77.44391850174934\n",
      "Iteration: 14270. Loss: 0.20715875923633575. Accuracy: 77.73204363037662\n",
      "Epoch:  184\n",
      "Iteration: 14280. Loss: 0.1605110615491867. Accuracy: 77.79378472936818\n",
      "Iteration: 14290. Loss: 0.1117146909236908. Accuracy: 77.114632640461\n",
      "Iteration: 14300. Loss: 0.17021985352039337. Accuracy: 77.64972216505454\n",
      "Iteration: 14310. Loss: 0.14878040552139282. Accuracy: 77.62914179872402\n",
      "Iteration: 14320. Loss: 0.14207780361175537. Accuracy: 77.44391850174934\n",
      "Iteration: 14330. Loss: 0.08804444223642349. Accuracy: 78.76106194690266\n",
      "Iteration: 14340. Loss: 0.14083915948867798. Accuracy: 78.12307059065651\n",
      "Iteration: 14350. Loss: 0.1418735384941101. Accuracy: 77.62914179872402\n",
      "Epoch:  185\n",
      "Iteration: 14360. Loss: 0.17120443284511566. Accuracy: 77.99958839267339\n",
      "Iteration: 14370. Loss: 0.13292531669139862. Accuracy: 77.64972216505454\n",
      "Iteration: 14380. Loss: 0.1692202091217041. Accuracy: 78.16423132331755\n",
      "Iteration: 14390. Loss: 0.12784194946289062. Accuracy: 78.12307059065651\n",
      "Iteration: 14400. Loss: 0.17484788596630096. Accuracy: 78.6993208479111\n",
      "Iteration: 14410. Loss: 0.1697465181350708. Accuracy: 78.39061535295328\n",
      "Iteration: 14420. Loss: 0.1589309424161911. Accuracy: 78.14365095698703\n",
      "Iteration: 14430. Loss: 0.14846713840961456. Accuracy: 78.39061535295328\n",
      "Epoch:  186\n",
      "Iteration: 14440. Loss: 0.14207684993743896. Accuracy: 77.83494546202922\n",
      "Iteration: 14450. Loss: 0.18384546041488647. Accuracy: 77.85552582835975\n",
      "Iteration: 14460. Loss: 0.16344837844371796. Accuracy: 77.85552582835975\n",
      "Iteration: 14470. Loss: 0.12019824236631393. Accuracy: 78.32887425396171\n",
      "Iteration: 14480. Loss: 0.09481104463338852. Accuracy: 77.67030253138506\n",
      "Iteration: 14490. Loss: 0.1218828558921814. Accuracy: 77.77320436303766\n",
      "Iteration: 14500. Loss: 0.14193962514400482. Accuracy: 77.48507923441038\n",
      "Epoch:  187\n",
      "Iteration: 14510. Loss: 0.20489060878753662. Accuracy: 77.69088289771558\n",
      "Iteration: 14520. Loss: 0.20815250277519226. Accuracy: 77.0117308088084\n",
      "Iteration: 14530. Loss: 0.1623208224773407. Accuracy: 77.34101667009672\n",
      "Iteration: 14540. Loss: 0.20427854359149933. Accuracy: 77.54682033340194\n",
      "Iteration: 14550. Loss: 0.1988796442747116. Accuracy: 77.79378472936818\n",
      "Iteration: 14560. Loss: 0.15875978767871857. Accuracy: 77.38217740275778\n",
      "Iteration: 14570. Loss: 0.15815521776676178. Accuracy: 78.10249022432599\n",
      "Iteration: 14580. Loss: 0.1460781693458557. Accuracy: 77.93784729368183\n",
      "Epoch:  188\n",
      "Iteration: 14590. Loss: 0.12183978408575058. Accuracy: 77.64972216505454\n",
      "Iteration: 14600. Loss: 0.12289174646139145. Accuracy: 77.64972216505454\n",
      "Iteration: 14610. Loss: 0.21097902953624725. Accuracy: 77.77320436303766\n",
      "Iteration: 14620. Loss: 0.11172883957624435. Accuracy: 77.48507923441038\n",
      "Iteration: 14630. Loss: 0.1169523075222969. Accuracy: 77.75262399670714\n",
      "Iteration: 14640. Loss: 0.172805517911911. Accuracy: 77.83494546202922\n",
      "Iteration: 14650. Loss: 0.20445135235786438. Accuracy: 77.114632640461\n",
      "Iteration: 14660. Loss: 0.18722814321517944. Accuracy: 78.57583864992797\n",
      "Epoch:  189\n",
      "Iteration: 14670. Loss: 0.1535717397928238. Accuracy: 77.5056596007409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14680. Loss: 0.0913722887635231. Accuracy: 77.23811483844412\n",
      "Iteration: 14690. Loss: 0.10950259119272232. Accuracy: 77.87610619469027\n",
      "Iteration: 14700. Loss: 0.13793876767158508. Accuracy: 77.54682033340194\n",
      "Iteration: 14710. Loss: 0.11274032294750214. Accuracy: 77.73204363037662\n",
      "Iteration: 14720. Loss: 0.12669123709201813. Accuracy: 77.3204363037662\n",
      "Iteration: 14730. Loss: 0.1360563039779663. Accuracy: 77.46449886807986\n",
      "Iteration: 14740. Loss: 0.13224276900291443. Accuracy: 77.27927557110516\n",
      "Epoch:  190\n",
      "Iteration: 14750. Loss: 0.17368340492248535. Accuracy: 77.5056596007409\n",
      "Iteration: 14760. Loss: 0.12669982016086578. Accuracy: 77.48507923441038\n",
      "Iteration: 14770. Loss: 0.10398650914430618. Accuracy: 77.3204363037662\n",
      "Iteration: 14780. Loss: 0.17362277209758759. Accuracy: 78.18481168964807\n",
      "Iteration: 14790. Loss: 0.15534530580043793. Accuracy: 78.22597242230911\n",
      "Iteration: 14800. Loss: 0.19816872477531433. Accuracy: 77.54682033340194\n",
      "Iteration: 14810. Loss: 0.1572505086660385. Accuracy: 78.06132949166495\n",
      "Iteration: 14820. Loss: 0.15997588634490967. Accuracy: 77.44391850174934\n",
      "Epoch:  191\n",
      "Iteration: 14830. Loss: 0.08193042129278183. Accuracy: 77.89668656102079\n",
      "Iteration: 14840. Loss: 0.10252656787633896. Accuracy: 77.79378472936818\n",
      "Iteration: 14850. Loss: 0.12672831118106842. Accuracy: 77.73204363037662\n",
      "Iteration: 14860. Loss: 0.14295755326747894. Accuracy: 76.76476641284215\n",
      "Iteration: 14870. Loss: 0.13141058385372162. Accuracy: 78.02016875900391\n",
      "Iteration: 14880. Loss: 0.11907264590263367. Accuracy: 77.69088289771558\n",
      "Iteration: 14890. Loss: 0.1536603569984436. Accuracy: 77.114632640461\n",
      "Epoch:  192\n",
      "Iteration: 14900. Loss: 0.14050662517547607. Accuracy: 77.4027577690883\n",
      "Iteration: 14910. Loss: 0.1564697027206421. Accuracy: 77.5056596007409\n",
      "Iteration: 14920. Loss: 0.11963959038257599. Accuracy: 77.29985593743568\n",
      "Iteration: 14930. Loss: 0.1382724940776825. Accuracy: 78.26713315497015\n",
      "Iteration: 14940. Loss: 0.13637936115264893. Accuracy: 78.14365095698703\n",
      "Iteration: 14950. Loss: 0.19143952429294586. Accuracy: 77.54682033340194\n",
      "Iteration: 14960. Loss: 0.13029935956001282. Accuracy: 77.17637373945256\n",
      "Iteration: 14970. Loss: 0.15916897356510162. Accuracy: 77.87610619469027\n",
      "Epoch:  193\n",
      "Iteration: 14980. Loss: 0.1359001249074936. Accuracy: 77.36159703642724\n",
      "Iteration: 14990. Loss: 0.14552626013755798. Accuracy: 77.36159703642724\n",
      "Iteration: 15000. Loss: 0.1614658534526825. Accuracy: 77.48507923441038\n",
      "Iteration: 15010. Loss: 0.18978360295295715. Accuracy: 77.52623996707142\n",
      "Iteration: 15020. Loss: 0.14806713163852692. Accuracy: 78.22597242230911\n",
      "Iteration: 15030. Loss: 0.15127655863761902. Accuracy: 76.68244494752007\n",
      "Iteration: 15040. Loss: 0.08935636281967163. Accuracy: 78.20539205597859\n",
      "Iteration: 15050. Loss: 0.15975996851921082. Accuracy: 78.28771352130067\n",
      "Epoch:  194\n",
      "Iteration: 15060. Loss: 0.16992774605751038. Accuracy: 76.99115044247787\n",
      "Iteration: 15070. Loss: 0.10394364595413208. Accuracy: 77.83494546202922\n",
      "Iteration: 15080. Loss: 0.19108796119689941. Accuracy: 77.73204363037662\n",
      "Iteration: 15090. Loss: 0.16477994620800018. Accuracy: 78.06132949166495\n",
      "Iteration: 15100. Loss: 0.11118537932634354. Accuracy: 78.10249022432599\n",
      "Iteration: 15110. Loss: 0.16702117025852203. Accuracy: 77.83494546202922\n",
      "Iteration: 15120. Loss: 0.08632069081068039. Accuracy: 78.20539205597859\n",
      "Iteration: 15130. Loss: 0.13693314790725708. Accuracy: 77.29985593743568\n",
      "Epoch:  195\n",
      "Iteration: 15140. Loss: 0.11917624622583389. Accuracy: 78.24655278863963\n",
      "Iteration: 15150. Loss: 0.14406655728816986. Accuracy: 78.43177608561433\n",
      "Iteration: 15160. Loss: 0.16583776473999023. Accuracy: 77.29985593743568\n",
      "Iteration: 15170. Loss: 0.13054399192333221. Accuracy: 77.67030253138506\n",
      "Iteration: 15180. Loss: 0.13958066701889038. Accuracy: 77.46449886807986\n",
      "Iteration: 15190. Loss: 0.12101265788078308. Accuracy: 77.03231117513891\n",
      "Iteration: 15200. Loss: 0.13250946998596191. Accuracy: 76.43548055155382\n",
      "Iteration: 15210. Loss: 0.22190473973751068. Accuracy: 77.48507923441038\n",
      "Epoch:  196\n",
      "Iteration: 15220. Loss: 0.08662687987089157. Accuracy: 78.32887425396171\n",
      "Iteration: 15230. Loss: 0.15193188190460205. Accuracy: 77.89668656102079\n",
      "Iteration: 15240. Loss: 0.22393223643302917. Accuracy: 78.47293681827537\n",
      "Iteration: 15250. Loss: 0.08690561354160309. Accuracy: 77.67030253138506\n",
      "Iteration: 15260. Loss: 0.1863938271999359. Accuracy: 77.44391850174934\n",
      "Iteration: 15270. Loss: 0.14632344245910645. Accuracy: 78.34945462029224\n",
      "Iteration: 15280. Loss: 0.18365414440631866. Accuracy: 77.54682033340194\n",
      "Epoch:  197\n",
      "Iteration: 15290. Loss: 0.14051981270313263. Accuracy: 76.97057007614735\n",
      "Iteration: 15300. Loss: 0.1393241584300995. Accuracy: 77.8143650956987\n",
      "Iteration: 15310. Loss: 0.14227303862571716. Accuracy: 77.9172669273513\n",
      "Iteration: 15320. Loss: 0.10266924649477005. Accuracy: 78.43177608561433\n",
      "Iteration: 15330. Loss: 0.10578593611717224. Accuracy: 77.75262399670714\n",
      "Iteration: 15340. Loss: 0.0952134057879448. Accuracy: 77.73204363037662\n",
      "Iteration: 15350. Loss: 0.15913067758083344. Accuracy: 78.02016875900391\n",
      "Iteration: 15360. Loss: 0.12658275663852692. Accuracy: 77.52623996707142\n",
      "Epoch:  198\n",
      "Iteration: 15370. Loss: 0.26135796308517456. Accuracy: 76.80592714550319\n",
      "Iteration: 15380. Loss: 0.1613883078098297. Accuracy: 77.19695410578308\n",
      "Iteration: 15390. Loss: 0.08074674010276794. Accuracy: 77.17637373945256\n",
      "Iteration: 15400. Loss: 0.1430504471063614. Accuracy: 77.58798106606298\n",
      "Iteration: 15410. Loss: 0.14024025201797485. Accuracy: 77.09405227413048\n",
      "Iteration: 15420. Loss: 0.13133125007152557. Accuracy: 78.10249022432599\n",
      "Iteration: 15430. Loss: 0.16501721739768982. Accuracy: 77.3204363037662\n",
      "Iteration: 15440. Loss: 0.13078132271766663. Accuracy: 77.6085614323935\n",
      "Epoch:  199\n",
      "Iteration: 15450. Loss: 0.111333467066288. Accuracy: 77.97900802634287\n",
      "Iteration: 15460. Loss: 0.13864469528198242. Accuracy: 77.7114632640461\n",
      "Iteration: 15470. Loss: 0.10336513072252274. Accuracy: 77.2175344721136\n",
      "Iteration: 15480. Loss: 0.12515754997730255. Accuracy: 77.29985593743568\n",
      "Iteration: 15490. Loss: 0.1422196924686432. Accuracy: 77.93784729368183\n",
      "Iteration: 15500. Loss: 0.10590653121471405. Accuracy: 77.34101667009672\n",
      "Iteration: 15510. Loss: 0.11944900453090668. Accuracy: 78.4111957192838\n",
      "Iteration: 15520. Loss: 0.13339553773403168. Accuracy: 76.66186458118955\n",
      "Epoch:  200\n",
      "Iteration: 15530. Loss: 0.10265414416790009. Accuracy: 77.6085614323935\n",
      "Iteration: 15540. Loss: 0.14428189396858215. Accuracy: 77.73204363037662\n",
      "Iteration: 15550. Loss: 0.2867598235607147. Accuracy: 77.03231117513891\n",
      "Iteration: 15560. Loss: 0.10858195275068283. Accuracy: 77.6085614323935\n",
      "Iteration: 15570. Loss: 0.10577145218849182. Accuracy: 76.94998970981683\n",
      "Iteration: 15580. Loss: 0.12096512317657471. Accuracy: 76.88824861082527\n",
      "Iteration: 15590. Loss: 0.13488012552261353. Accuracy: 78.14365095698703\n",
      "Iteration: 15600. Loss: 0.19799935817718506. Accuracy: 78.12307059065651\n",
      "Epoch:  201\n",
      "Iteration: 15610. Loss: 0.11569665372371674. Accuracy: 77.8143650956987\n",
      "Iteration: 15620. Loss: 0.1317870169878006. Accuracy: 78.43177608561433\n",
      "Iteration: 15630. Loss: 0.12799377739429474. Accuracy: 77.27927557110516\n",
      "Iteration: 15640. Loss: 0.14270980656147003. Accuracy: 77.9172669273513\n",
      "Iteration: 15650. Loss: 0.1678084135055542. Accuracy: 78.24655278863963\n",
      "Iteration: 15660. Loss: 0.1279996931552887. Accuracy: 77.7114632640461\n",
      "Iteration: 15670. Loss: 0.10569826513528824. Accuracy: 78.12307059065651\n",
      "Epoch:  202\n",
      "Iteration: 15680. Loss: 0.08589974045753479. Accuracy: 77.52623996707142\n",
      "Iteration: 15690. Loss: 0.16708412766456604. Accuracy: 76.88824861082527\n",
      "Iteration: 15700. Loss: 0.1360751837491989. Accuracy: 77.23811483844412\n",
      "Iteration: 15710. Loss: 0.10971876978874207. Accuracy: 77.13521300679152\n",
      "Iteration: 15720. Loss: 0.10143172740936279. Accuracy: 76.88824861082527\n",
      "Iteration: 15730. Loss: 0.13754422962665558. Accuracy: 78.08190985799547\n",
      "Iteration: 15740. Loss: 0.095138780772686. Accuracy: 76.55896274953695\n",
      "Iteration: 15750. Loss: 0.10753800719976425. Accuracy: 77.83494546202922\n",
      "Epoch:  203\n",
      "Iteration: 15760. Loss: 0.19194509088993073. Accuracy: 77.0117308088084\n",
      "Iteration: 15770. Loss: 0.20703651010990143. Accuracy: 77.36159703642724\n",
      "Iteration: 15780. Loss: 0.17424260079860687. Accuracy: 77.7114632640461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15790. Loss: 0.21455812454223633. Accuracy: 77.75262399670714\n",
      "Iteration: 15800. Loss: 0.09796582162380219. Accuracy: 78.16423132331755\n",
      "Iteration: 15810. Loss: 0.1284082978963852. Accuracy: 77.83494546202922\n",
      "Iteration: 15820. Loss: 0.14062021672725677. Accuracy: 77.52623996707142\n",
      "Iteration: 15830. Loss: 0.13299186527729034. Accuracy: 77.46449886807986\n",
      "Epoch:  204\n",
      "Iteration: 15840. Loss: 0.12333743274211884. Accuracy: 77.77320436303766\n",
      "Iteration: 15850. Loss: 0.10556431114673615. Accuracy: 77.6085614323935\n",
      "Iteration: 15860. Loss: 0.11584071069955826. Accuracy: 77.29985593743568\n",
      "Iteration: 15870. Loss: 0.1359027773141861. Accuracy: 77.7114632640461\n",
      "Iteration: 15880. Loss: 0.14230260252952576. Accuracy: 76.6207038485285\n",
      "Iteration: 15890. Loss: 0.14525865018367767. Accuracy: 77.67030253138506\n",
      "Iteration: 15900. Loss: 0.12052303552627563. Accuracy: 77.83494546202922\n",
      "Iteration: 15910. Loss: 0.1640075445175171. Accuracy: 77.36159703642724\n",
      "Epoch:  205\n",
      "Iteration: 15920. Loss: 0.13730333745479584. Accuracy: 77.93784729368183\n",
      "Iteration: 15930. Loss: 0.0970800593495369. Accuracy: 77.58798106606298\n",
      "Iteration: 15940. Loss: 0.12277024984359741. Accuracy: 77.52623996707142\n",
      "Iteration: 15950. Loss: 0.14062651991844177. Accuracy: 77.13521300679152\n",
      "Iteration: 15960. Loss: 0.08740202337503433. Accuracy: 77.97900802634287\n",
      "Iteration: 15970. Loss: 0.10891774296760559. Accuracy: 78.3082938876312\n",
      "Iteration: 15980. Loss: 0.15459302067756653. Accuracy: 77.46449886807986\n",
      "Iteration: 15990. Loss: 0.31297117471694946. Accuracy: 78.24655278863963\n"
     ]
    }
   ],
   "source": [
    "iteration_loss = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: ', epoch + 1)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images) \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 10 == 0:        \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            iteration_loss.append(loss.item())\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        self.relu_1 = nn.ReLU()\n",
    " \n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_2 = nn.Softmax(dim=0)\n",
    " \n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_3 = nn.ReLU()\n",
    " \n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_4 = nn.ReLU()\n",
    " \n",
    "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_5= nn.ReLU()\n",
    " \n",
    "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_6 = nn.ReLU()\n",
    " \n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out  = self.linear_1(x)\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        out  = self.linear_2(out)\n",
    "        out = self.relu_2(out)\n",
    " \n",
    "        out  = self.linear_3(out)\n",
    "        out = self.relu_3(out)\n",
    " \n",
    "        out  = self.linear_4(out)\n",
    "        out = self.relu_4(out)\n",
    " \n",
    "        out  = self.linear_5(out)\n",
    "        out = self.relu_5(out)\n",
    " \n",
    "        out  = self.linear_6(out)\n",
    "        out = self.relu_6(out)\n",
    "        \n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "num_iters = 20000\n",
    "input_dim = 28*28\n",
    "num_hidden = 330\n",
    "output_dim = 10\n",
    "\n",
    "learning_rate = 0.025\n",
    "\n",
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:78\n",
      "Test dataloader:20\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=330, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (linear_2): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_2): Softmax(dim=0)\n",
       "  (linear_3): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_3): ReLU()\n",
       "  (linear_4): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_4): ReLU()\n",
       "  (linear_5): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_5): ReLU()\n",
       "  (linear_6): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_6): ReLU()\n",
       "  (linear_out): Linear(in_features=330, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Iteration: 10. Loss: 2.300269842147827. Accuracy: 9.755093640666804\n",
      "Iteration: 20. Loss: 2.268422842025757. Accuracy: 13.644782877135214\n",
      "Iteration: 30. Loss: 2.2179200649261475. Accuracy: 15.147149619263223\n",
      "Iteration: 40. Loss: 2.2251758575439453. Accuracy: 12.574603827948138\n",
      "Iteration: 50. Loss: 2.2258541584014893. Accuracy: 14.509158263017081\n",
      "Iteration: 60. Loss: 2.174614667892456. Accuracy: 17.966659806544556\n",
      "Iteration: 70. Loss: 2.1484668254852295. Accuracy: 15.599917678534679\n",
      "Epoch:  2\n",
      "Iteration: 80. Loss: 2.201634168624878. Accuracy: 17.781436509569872\n",
      "Iteration: 90. Loss: 2.133601188659668. Accuracy: 17.12286478699321\n",
      "Iteration: 100. Loss: 2.114102602005005. Accuracy: 17.678534677917266\n",
      "Iteration: 110. Loss: 2.1581265926361084. Accuracy: 19.160321053714757\n",
      "Iteration: 120. Loss: 2.0766170024871826. Accuracy: 21.36242025108047\n",
      "Iteration: 130. Loss: 2.020855188369751. Accuracy: 21.465322082733074\n",
      "Iteration: 140. Loss: 2.0635812282562256. Accuracy: 22.2885367359539\n",
      "Iteration: 150. Loss: 2.0604870319366455. Accuracy: 23.091171022844208\n",
      "Epoch:  3\n",
      "Iteration: 160. Loss: 1.961601972579956. Accuracy: 24.38773410166701\n",
      "Iteration: 170. Loss: 2.062159776687622. Accuracy: 21.650545379707758\n",
      "Iteration: 180. Loss: 1.9530659914016724. Accuracy: 23.15291212183577\n",
      "Iteration: 190. Loss: 2.0676991939544678. Accuracy: 23.23523358715785\n",
      "Iteration: 200. Loss: 1.9980000257492065. Accuracy: 23.646840913768266\n",
      "Iteration: 210. Loss: 1.946811556816101. Accuracy: 22.57666186458119\n",
      "Iteration: 220. Loss: 2.0816292762756348. Accuracy: 22.80304589421692\n",
      "Iteration: 230. Loss: 2.0619876384735107. Accuracy: 22.329697468614942\n",
      "Epoch:  4\n",
      "Iteration: 240. Loss: 1.9968738555908203. Accuracy: 23.54393908211566\n",
      "Iteration: 250. Loss: 2.0933470726013184. Accuracy: 22.432599300267544\n",
      "Iteration: 260. Loss: 2.0598998069763184. Accuracy: 23.605680181107225\n",
      "Iteration: 270. Loss: 2.014375925064087. Accuracy: 22.700144062564313\n",
      "Iteration: 280. Loss: 1.9562757015228271. Accuracy: 23.399876517802017\n",
      "Iteration: 290. Loss: 2.008596897125244. Accuracy: 24.09960897303972\n",
      "Iteration: 300. Loss: 2.050253391265869. Accuracy: 24.881662893599508\n",
      "Iteration: 310. Loss: 1.9094061851501465. Accuracy: 23.996707141387116\n",
      "Epoch:  5\n",
      "Iteration: 320. Loss: 2.048758029937744. Accuracy: 23.358715785140976\n",
      "Iteration: 330. Loss: 2.0616283416748047. Accuracy: 23.708582012759827\n",
      "Iteration: 340. Loss: 2.0765230655670166. Accuracy: 22.92652809220004\n",
      "Iteration: 350. Loss: 2.078529119491577. Accuracy: 22.494340399259105\n",
      "Iteration: 360. Loss: 1.9983491897583008. Accuracy: 22.679563696233792\n",
      "Iteration: 370. Loss: 1.9840197563171387. Accuracy: 22.59724223091171\n",
      "Iteration: 380. Loss: 1.9538620710372925. Accuracy: 23.81148384441243\n",
      "Iteration: 390. Loss: 2.0855188369750977. Accuracy: 23.091171022844208\n",
      "Epoch:  6\n",
      "Iteration: 400. Loss: 2.0223605632781982. Accuracy: 23.358715785140976\n",
      "Iteration: 410. Loss: 2.03157901763916. Accuracy: 23.23523358715785\n",
      "Iteration: 420. Loss: 2.065478801727295. Accuracy: 22.63840296357275\n",
      "Iteration: 430. Loss: 2.0743408203125. Accuracy: 22.165054537970775\n",
      "Iteration: 440. Loss: 1.9745104312896729. Accuracy: 23.17349248816629\n",
      "Iteration: 450. Loss: 2.020437717437744. Accuracy: 22.885367359539\n",
      "Iteration: 460. Loss: 1.9298583269119263. Accuracy: 22.988269191191602\n",
      "Epoch:  7\n",
      "Iteration: 470. Loss: 1.9709964990615845. Accuracy: 23.050010290183167\n",
      "Iteration: 480. Loss: 2.0239768028259277. Accuracy: 22.741304795225354\n",
      "Iteration: 490. Loss: 2.0402750968933105. Accuracy: 22.59724223091171\n",
      "Iteration: 500. Loss: 1.9604357481002808. Accuracy: 22.30911710228442\n",
      "Iteration: 510. Loss: 2.127568244934082. Accuracy: 20.353982300884955\n",
      "Iteration: 520. Loss: 2.15037202835083. Accuracy: 21.012554023461618\n",
      "Iteration: 530. Loss: 2.005143404006958. Accuracy: 21.568223914385676\n",
      "Iteration: 540. Loss: 2.122985601425171. Accuracy: 21.197777320436305\n",
      "Epoch:  8\n",
      "Iteration: 550. Loss: 2.032676935195923. Accuracy: 20.76558962749537\n",
      "Iteration: 560. Loss: 2.0978617668151855. Accuracy: 21.238938053097346\n",
      "Iteration: 570. Loss: 2.033726215362549. Accuracy: 21.547643548055156\n",
      "Iteration: 580. Loss: 2.089468479156494. Accuracy: 20.84791109281745\n",
      "Iteration: 590. Loss: 2.074186325073242. Accuracy: 20.683268162173288\n",
      "Iteration: 600. Loss: 2.1489996910095215. Accuracy: 21.03313438979214\n",
      "Iteration: 610. Loss: 2.0818445682525635. Accuracy: 20.251080469232352\n",
      "Iteration: 620. Loss: 2.1915950775146484. Accuracy: 19.860053508952458\n",
      "Epoch:  9\n",
      "Iteration: 630. Loss: 2.0801026821136475. Accuracy: 20.53920559785964\n",
      "Iteration: 640. Loss: 2.0262303352355957. Accuracy: 20.971393290800577\n",
      "Iteration: 650. Loss: 2.1384084224700928. Accuracy: 21.321259518419428\n",
      "Iteration: 660. Loss: 2.1123251914978027. Accuracy: 21.012554023461618\n",
      "Iteration: 670. Loss: 2.06811785697937. Accuracy: 21.238938053097346\n",
      "Iteration: 680. Loss: 2.1048600673675537. Accuracy: 21.568223914385676\n",
      "Iteration: 690. Loss: 2.0567171573638916. Accuracy: 20.41572339987652\n",
      "Iteration: 700. Loss: 2.5879709720611572. Accuracy: 20.333401934554434\n",
      "Epoch:  10\n",
      "Iteration: 710. Loss: 2.085536241531372. Accuracy: 19.07799958839267\n",
      "Iteration: 720. Loss: 2.116502523422241. Accuracy: 19.921794607944022\n",
      "Iteration: 730. Loss: 2.0987191200256348. Accuracy: 19.180901420045277\n",
      "Iteration: 740. Loss: 2.214359998703003. Accuracy: 19.88063387528298\n",
      "Iteration: 750. Loss: 2.1514644622802734. Accuracy: 19.510187281333607\n",
      "Iteration: 760. Loss: 2.1013123989105225. Accuracy: 19.489606915003087\n",
      "Iteration: 770. Loss: 2.1391942501068115. Accuracy: 19.962955340605063\n",
      "Iteration: 780. Loss: 2.163158893585205. Accuracy: 19.386705083350485\n",
      "Epoch:  11\n",
      "Iteration: 790. Loss: 2.1239817142486572. Accuracy: 19.736571310969335\n",
      "Iteration: 800. Loss: 2.101712703704834. Accuracy: 19.613089112986213\n",
      "Iteration: 810. Loss: 2.1136763095855713. Accuracy: 19.839473142621937\n",
      "Iteration: 820. Loss: 2.1166956424713135. Accuracy: 20.230500102901832\n",
      "Iteration: 830. Loss: 2.075686454772949. Accuracy: 19.551348013994648\n",
      "Iteration: 840. Loss: 2.1244699954986572. Accuracy: 19.921794607944022\n",
      "Iteration: 850. Loss: 2.0890824794769287. Accuracy: 19.715990944638815\n",
      "Epoch:  12\n",
      "Iteration: 860. Loss: 2.1165878772735596. Accuracy: 19.88063387528298\n",
      "Iteration: 870. Loss: 2.1552867889404297. Accuracy: 19.098579954723196\n",
      "Iteration: 880. Loss: 2.124345302581787. Accuracy: 19.695410578308294\n",
      "Iteration: 890. Loss: 2.0748465061187744. Accuracy: 19.757151677299856\n",
      "Iteration: 900. Loss: 2.1216487884521484. Accuracy: 20.43630376620704\n",
      "Iteration: 910. Loss: 2.0016188621520996. Accuracy: 19.654249845647254\n",
      "Iteration: 920. Loss: 2.1518406867980957. Accuracy: 19.962955340605063\n",
      "Iteration: 930. Loss: 2.0771961212158203. Accuracy: 19.757151677299856\n",
      "Epoch:  13\n",
      "Iteration: 940. Loss: 2.110701084136963. Accuracy: 19.715990944638815\n",
      "Iteration: 950. Loss: 2.1929848194122314. Accuracy: 19.448446182342046\n",
      "Iteration: 960. Loss: 2.1001527309417725. Accuracy: 19.28380325169788\n",
      "Iteration: 970. Loss: 2.1647136211395264. Accuracy: 19.57192838032517\n",
      "Iteration: 980. Loss: 2.0629899501800537. Accuracy: 19.119160321053716\n",
      "Iteration: 990. Loss: 2.1410341262817383. Accuracy: 20.312821568223914\n",
      "Iteration: 1000. Loss: 2.0907251834869385. Accuracy: 19.860053508952458\n",
      "Iteration: 1010. Loss: 2.1028754711151123. Accuracy: 20.086437538588186\n",
      "Epoch:  14\n",
      "Iteration: 1020. Loss: 2.1167919635772705. Accuracy: 20.51862523152912\n",
      "Iteration: 1030. Loss: 2.092710256576538. Accuracy: 20.395143033546\n",
      "Iteration: 1040. Loss: 2.1593551635742188. Accuracy: 20.230500102901832\n",
      "Iteration: 1050. Loss: 2.120049238204956. Accuracy: 19.88063387528298\n",
      "Iteration: 1060. Loss: 2.0505571365356445. Accuracy: 19.798312409960896\n",
      "Iteration: 1070. Loss: 2.1196396350860596. Accuracy: 20.70384852850381\n",
      "Iteration: 1080. Loss: 2.14117169380188. Accuracy: 21.197777320436305\n",
      "Iteration: 1090. Loss: 2.092438220977783. Accuracy: 20.45688413253756\n",
      "Epoch:  15\n",
      "Iteration: 1100. Loss: 2.062299966812134. Accuracy: 20.18933937024079\n",
      "Iteration: 1110. Loss: 2.07787823677063. Accuracy: 21.05371475612266\n",
      "Iteration: 1120. Loss: 2.1035192012786865. Accuracy: 20.72442889483433\n",
      "Iteration: 1130. Loss: 2.1063103675842285. Accuracy: 20.76558962749537\n",
      "Iteration: 1140. Loss: 2.181098699569702. Accuracy: 21.321259518419428\n",
      "Iteration: 1150. Loss: 2.0386648178100586. Accuracy: 20.559785964190162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1160. Loss: 2.1097445487976074. Accuracy: 20.909652191809013\n",
      "Iteration: 1170. Loss: 2.0135200023651123. Accuracy: 20.74500926116485\n",
      "Epoch:  16\n",
      "Iteration: 1180. Loss: 2.100720167160034. Accuracy: 21.856349043012965\n",
      "Iteration: 1190. Loss: 2.0435452461242676. Accuracy: 21.609384647046717\n",
      "Iteration: 1200. Loss: 2.086543560028076. Accuracy: 20.600946696851203\n",
      "Iteration: 1210. Loss: 2.1061642169952393. Accuracy: 21.012554023461618\n",
      "Iteration: 1220. Loss: 2.0520739555358887. Accuracy: 20.621527063181723\n",
      "Iteration: 1230. Loss: 2.1405558586120605. Accuracy: 20.76558962749537\n",
      "Iteration: 1240. Loss: 2.199652671813965. Accuracy: 21.05371475612266\n",
      "Epoch:  17\n",
      "Iteration: 1250. Loss: 2.1322741508483887. Accuracy: 20.662687795842768\n",
      "Iteration: 1260. Loss: 2.1177456378936768. Accuracy: 20.86849145914797\n",
      "Iteration: 1270. Loss: 2.146432876586914. Accuracy: 20.889071825478492\n",
      "Iteration: 1280. Loss: 2.2417538166046143. Accuracy: 20.72442889483433\n",
      "Iteration: 1290. Loss: 2.0585317611694336. Accuracy: 20.559785964190162\n",
      "Iteration: 1300. Loss: 2.102283239364624. Accuracy: 20.74500926116485\n",
      "Iteration: 1310. Loss: 2.0402166843414307. Accuracy: 20.78616999382589\n",
      "Iteration: 1320. Loss: 2.0784502029418945. Accuracy: 21.485902449063595\n",
      "Epoch:  18\n",
      "Iteration: 1330. Loss: 2.0340874195098877. Accuracy: 22.103313438979214\n",
      "Iteration: 1340. Loss: 2.1508569717407227. Accuracy: 21.588804280716197\n",
      "Iteration: 1350. Loss: 2.127629280090332. Accuracy: 21.876929409343486\n",
      "Iteration: 1360. Loss: 2.0829310417175293. Accuracy: 20.76558962749537\n",
      "Iteration: 1370. Loss: 2.157313823699951. Accuracy: 21.11545585511422\n",
      "Iteration: 1380. Loss: 2.1274824142456055. Accuracy: 20.642107429512244\n",
      "Iteration: 1390. Loss: 2.1143369674682617. Accuracy: 21.527063181724635\n",
      "Iteration: 1400. Loss: 2.211836338043213. Accuracy: 20.086437538588186\n",
      "Epoch:  19\n",
      "Iteration: 1410. Loss: 2.1235861778259277. Accuracy: 21.11545585511422\n",
      "Iteration: 1420. Loss: 2.0970637798309326. Accuracy: 20.76558962749537\n",
      "Iteration: 1430. Loss: 2.1316957473754883. Accuracy: 20.76558962749537\n",
      "Iteration: 1440. Loss: 2.103748083114624. Accuracy: 20.72442889483433\n",
      "Iteration: 1450. Loss: 2.1255617141723633. Accuracy: 20.971393290800577\n",
      "Iteration: 1460. Loss: 2.09740948677063. Accuracy: 21.05371475612266\n",
      "Iteration: 1470. Loss: 2.117760181427002. Accuracy: 20.43630376620704\n",
      "Iteration: 1480. Loss: 2.033139228820801. Accuracy: 20.80675036015641\n",
      "Epoch:  20\n",
      "Iteration: 1490. Loss: 2.037554979324341. Accuracy: 20.251080469232352\n",
      "Iteration: 1500. Loss: 2.0662758350372314. Accuracy: 20.76558962749537\n",
      "Iteration: 1510. Loss: 2.054048776626587. Accuracy: 21.15661658777526\n",
      "Iteration: 1520. Loss: 2.0832979679107666. Accuracy: 21.05371475612266\n",
      "Iteration: 1530. Loss: 2.017714023590088. Accuracy: 20.353982300884955\n",
      "Iteration: 1540. Loss: 2.1060304641723633. Accuracy: 21.40358098374151\n",
      "Iteration: 1550. Loss: 2.1327364444732666. Accuracy: 21.280098785758387\n",
      "Iteration: 1560. Loss: 2.032325506210327. Accuracy: 21.38300061741099\n",
      "Epoch:  21\n",
      "Iteration: 1570. Loss: 2.045513868331909. Accuracy: 21.465322082733074\n",
      "Iteration: 1580. Loss: 1.993597388267517. Accuracy: 21.506482815394115\n",
      "Iteration: 1590. Loss: 2.1073222160339355. Accuracy: 20.84791109281745\n",
      "Iteration: 1600. Loss: 2.1057791709899902. Accuracy: 22.103313438979214\n",
      "Iteration: 1610. Loss: 2.1035258769989014. Accuracy: 21.485902449063595\n",
      "Iteration: 1620. Loss: 2.102553367614746. Accuracy: 21.0948754887837\n",
      "Iteration: 1630. Loss: 2.068418502807617. Accuracy: 20.353982300884955\n",
      "Epoch:  22\n",
      "Iteration: 1640. Loss: 2.122835159301758. Accuracy: 20.74500926116485\n",
      "Iteration: 1650. Loss: 2.090640068054199. Accuracy: 20.251080469232352\n",
      "Iteration: 1660. Loss: 2.024336099624634. Accuracy: 20.14817863757975\n",
      "Iteration: 1670. Loss: 2.125520944595337. Accuracy: 21.38300061741099\n",
      "Iteration: 1680. Loss: 2.1678640842437744. Accuracy: 19.860053508952458\n",
      "Iteration: 1690. Loss: 2.109267473220825. Accuracy: 20.642107429512244\n",
      "Iteration: 1700. Loss: 2.0706231594085693. Accuracy: 20.374562667215475\n",
      "Iteration: 1710. Loss: 2.1605782508850098. Accuracy: 20.20991973657131\n",
      "Epoch:  23\n",
      "Iteration: 1720. Loss: 2.0760695934295654. Accuracy: 20.580366330520683\n",
      "Iteration: 1730. Loss: 2.113116502761841. Accuracy: 20.70384852850381\n",
      "Iteration: 1740. Loss: 2.0489916801452637. Accuracy: 20.51862523152912\n",
      "Iteration: 1750. Loss: 2.0695626735687256. Accuracy: 21.0948754887837\n",
      "Iteration: 1760. Loss: 2.0372557640075684. Accuracy: 20.600946696851203\n",
      "Iteration: 1770. Loss: 2.009756088256836. Accuracy: 20.78616999382589\n",
      "Iteration: 1780. Loss: 2.0674023628234863. Accuracy: 20.47746449886808\n",
      "Iteration: 1790. Loss: 2.0226426124572754. Accuracy: 20.889071825478492\n",
      "Epoch:  24\n",
      "Iteration: 1800. Loss: 2.097250461578369. Accuracy: 20.86849145914797\n",
      "Iteration: 1810. Loss: 2.1152844429016113. Accuracy: 20.312821568223914\n",
      "Iteration: 1820. Loss: 2.0767626762390137. Accuracy: 20.20991973657131\n",
      "Iteration: 1830. Loss: 2.0445103645324707. Accuracy: 20.230500102901832\n",
      "Iteration: 1840. Loss: 2.065972089767456. Accuracy: 22.329697468614942\n",
      "Iteration: 1850. Loss: 2.083012342453003. Accuracy: 21.0948754887837\n",
      "Iteration: 1860. Loss: 2.1186909675598145. Accuracy: 20.395143033546\n",
      "Iteration: 1870. Loss: 2.12243914604187. Accuracy: 20.80675036015641\n",
      "Epoch:  25\n",
      "Iteration: 1880. Loss: 2.0938894748687744. Accuracy: 19.839473142621937\n",
      "Iteration: 1890. Loss: 2.102945566177368. Accuracy: 19.469026548672566\n",
      "Iteration: 1900. Loss: 2.0642082691192627. Accuracy: 20.230500102901832\n",
      "Iteration: 1910. Loss: 2.0885658264160156. Accuracy: 20.107017904918706\n",
      "Iteration: 1920. Loss: 2.0301854610443115. Accuracy: 20.41572339987652\n",
      "Iteration: 1930. Loss: 2.087324380874634. Accuracy: 20.20991973657131\n",
      "Iteration: 1940. Loss: 2.085845470428467. Accuracy: 20.82733072648693\n",
      "Iteration: 1950. Loss: 2.0882980823516846. Accuracy: 20.70384852850381\n",
      "Epoch:  26\n",
      "Iteration: 1960. Loss: 2.091874361038208. Accuracy: 20.621527063181723\n",
      "Iteration: 1970. Loss: 2.0450456142425537. Accuracy: 20.80675036015641\n",
      "Iteration: 1980. Loss: 2.1304454803466797. Accuracy: 20.662687795842768\n",
      "Iteration: 1990. Loss: 2.072317123413086. Accuracy: 20.84791109281745\n",
      "Iteration: 2000. Loss: 2.1701102256774902. Accuracy: 20.53920559785964\n",
      "Iteration: 2010. Loss: 2.065995931625366. Accuracy: 20.662687795842768\n",
      "Iteration: 2020. Loss: 2.1492104530334473. Accuracy: 20.889071825478492\n",
      "Epoch:  27\n",
      "Iteration: 2030. Loss: 2.0965700149536133. Accuracy: 20.292241201893393\n",
      "Iteration: 2040. Loss: 2.1012179851531982. Accuracy: 20.374562667215475\n",
      "Iteration: 2050. Loss: 2.0253348350524902. Accuracy: 20.76558962749537\n",
      "Iteration: 2060. Loss: 2.0951180458068848. Accuracy: 21.197777320436305\n",
      "Iteration: 2070. Loss: 2.0428977012634277. Accuracy: 20.53920559785964\n",
      "Iteration: 2080. Loss: 2.0523300170898438. Accuracy: 20.045276805927145\n",
      "Iteration: 2090. Loss: 2.068638563156128. Accuracy: 19.962955340605063\n",
      "Iteration: 2100. Loss: 2.1242780685424805. Accuracy: 21.0948754887837\n",
      "Epoch:  28\n",
      "Iteration: 2110. Loss: 2.1337966918945312. Accuracy: 20.82733072648693\n",
      "Iteration: 2120. Loss: 2.041795492172241. Accuracy: 20.74500926116485\n",
      "Iteration: 2130. Loss: 2.060215950012207. Accuracy: 20.72442889483433\n",
      "Iteration: 2140. Loss: 2.040404796600342. Accuracy: 20.84791109281745\n",
      "Iteration: 2150. Loss: 2.097405195236206. Accuracy: 20.43630376620704\n",
      "Iteration: 2160. Loss: 2.097355604171753. Accuracy: 20.971393290800577\n",
      "Iteration: 2170. Loss: 2.082329034805298. Accuracy: 20.971393290800577\n",
      "Iteration: 2180. Loss: 2.07344388961792. Accuracy: 20.86849145914797\n",
      "Epoch:  29\n",
      "Iteration: 2190. Loss: 2.1291067600250244. Accuracy: 21.17719695410578\n",
      "Iteration: 2200. Loss: 2.0775046348571777. Accuracy: 20.43630376620704\n",
      "Iteration: 2210. Loss: 2.1939051151275635. Accuracy: 20.72442889483433\n",
      "Iteration: 2220. Loss: 2.115703582763672. Accuracy: 20.600946696851203\n",
      "Iteration: 2230. Loss: 2.0763282775878906. Accuracy: 20.642107429512244\n",
      "Iteration: 2240. Loss: 2.0434601306915283. Accuracy: 20.70384852850381\n",
      "Iteration: 2250. Loss: 2.0727784633636475. Accuracy: 21.218357686766826\n",
      "Iteration: 2260. Loss: 2.0902504920959473. Accuracy: 21.238938053097346\n",
      "Epoch:  30\n",
      "Iteration: 2270. Loss: 2.049914598464966. Accuracy: 20.82733072648693\n",
      "Iteration: 2280. Loss: 2.0794434547424316. Accuracy: 21.42416135007203\n",
      "Iteration: 2290. Loss: 2.0973894596099854. Accuracy: 21.712286478699323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2300. Loss: 2.1113789081573486. Accuracy: 20.374562667215475\n",
      "Iteration: 2310. Loss: 2.0937485694885254. Accuracy: 20.909652191809013\n",
      "Iteration: 2320. Loss: 2.2059364318847656. Accuracy: 20.004116073266104\n",
      "Iteration: 2330. Loss: 2.098573684692383. Accuracy: 21.07429512245318\n",
      "Iteration: 2340. Loss: 2.0547962188720703. Accuracy: 21.07429512245318\n",
      "Epoch:  31\n",
      "Iteration: 2350. Loss: 2.065044641494751. Accuracy: 20.14817863757975\n",
      "Iteration: 2360. Loss: 2.0674219131469727. Accuracy: 20.230500102901832\n",
      "Iteration: 2370. Loss: 2.0908827781677246. Accuracy: 20.78616999382589\n",
      "Iteration: 2380. Loss: 2.077765464782715. Accuracy: 19.07799958839267\n",
      "Iteration: 2390. Loss: 2.148162364959717. Accuracy: 19.469026548672566\n",
      "Iteration: 2400. Loss: 2.059203863143921. Accuracy: 19.695410578308294\n",
      "Iteration: 2410. Loss: 2.078510046005249. Accuracy: 20.4980448651986\n",
      "Epoch:  32\n",
      "Iteration: 2420. Loss: 2.0146729946136475. Accuracy: 20.024696439596624\n",
      "Iteration: 2430. Loss: 2.0866730213165283. Accuracy: 19.962955340605063\n",
      "Iteration: 2440. Loss: 2.092883586883545. Accuracy: 21.07429512245318\n",
      "Iteration: 2450. Loss: 2.5504870414733887. Accuracy: 20.024696439596624\n",
      "Iteration: 2460. Loss: 2.081841468811035. Accuracy: 19.510187281333607\n",
      "Iteration: 2470. Loss: 2.0700571537017822. Accuracy: 20.683268162173288\n",
      "Iteration: 2480. Loss: 2.1317992210388184. Accuracy: 19.757151677299856\n",
      "Iteration: 2490. Loss: 2.110750198364258. Accuracy: 19.448446182342046\n",
      "Epoch:  33\n",
      "Iteration: 2500. Loss: 2.110968589782715. Accuracy: 20.14817863757975\n",
      "Iteration: 2510. Loss: 2.096116542816162. Accuracy: 20.889071825478492\n",
      "Iteration: 2520. Loss: 2.031928062438965. Accuracy: 19.818892776291417\n",
      "Iteration: 2530. Loss: 2.0821313858032227. Accuracy: 20.84791109281745\n",
      "Iteration: 2540. Loss: 2.036442756652832. Accuracy: 19.757151677299856\n",
      "Iteration: 2550. Loss: 2.177811622619629. Accuracy: 20.107017904918706\n",
      "Iteration: 2560. Loss: 2.0843708515167236. Accuracy: 20.4980448651986\n",
      "Iteration: 2570. Loss: 2.068437099456787. Accuracy: 20.127598271249227\n",
      "Epoch:  34\n",
      "Iteration: 2580. Loss: 2.1215944290161133. Accuracy: 20.86849145914797\n",
      "Iteration: 2590. Loss: 2.19293212890625. Accuracy: 19.674830211977774\n",
      "Iteration: 2600. Loss: 2.0735583305358887. Accuracy: 19.510187281333607\n",
      "Iteration: 2610. Loss: 2.1569621562957764. Accuracy: 19.674830211977774\n",
      "Iteration: 2620. Loss: 2.080596923828125. Accuracy: 19.119160321053716\n",
      "Iteration: 2630. Loss: 2.0987918376922607. Accuracy: 19.777732043630376\n",
      "Iteration: 2640. Loss: 2.156740665435791. Accuracy: 19.777732043630376\n",
      "Iteration: 2650. Loss: 2.1353278160095215. Accuracy: 20.292241201893393\n",
      "Epoch:  35\n",
      "Iteration: 2660. Loss: 2.0553481578826904. Accuracy: 20.559785964190162\n",
      "Iteration: 2670. Loss: 2.043956995010376. Accuracy: 20.004116073266104\n",
      "Iteration: 2680. Loss: 2.0598692893981934. Accuracy: 19.715990944638815\n",
      "Iteration: 2690. Loss: 2.1369378566741943. Accuracy: 19.839473142621937\n",
      "Iteration: 2700. Loss: 2.0864927768707275. Accuracy: 19.757151677299856\n",
      "Iteration: 2710. Loss: 2.075004816055298. Accuracy: 19.901214241613502\n",
      "Iteration: 2720. Loss: 2.0534255504608154. Accuracy: 19.57192838032517\n",
      "Iteration: 2730. Loss: 2.102725028991699. Accuracy: 20.45688413253756\n",
      "Epoch:  36\n",
      "Iteration: 2740. Loss: 2.1097114086151123. Accuracy: 20.43630376620704\n",
      "Iteration: 2750. Loss: 2.119828224182129. Accuracy: 20.72442889483433\n",
      "Iteration: 2760. Loss: 2.1158454418182373. Accuracy: 19.736571310969335\n",
      "Iteration: 2770. Loss: 2.0788488388061523. Accuracy: 19.407285449681005\n",
      "Iteration: 2780. Loss: 2.196274757385254. Accuracy: 19.59250874665569\n",
      "Iteration: 2790. Loss: 2.1426990032196045. Accuracy: 19.469026548672566\n",
      "Iteration: 2800. Loss: 2.146707534790039. Accuracy: 20.271660835562873\n",
      "Epoch:  37\n",
      "Iteration: 2810. Loss: 2.133681058883667. Accuracy: 20.251080469232352\n",
      "Iteration: 2820. Loss: 2.0650532245635986. Accuracy: 20.76558962749537\n",
      "Iteration: 2830. Loss: 2.0679922103881836. Accuracy: 20.78616999382589\n",
      "Iteration: 2840. Loss: 2.105443000793457. Accuracy: 19.695410578308294\n",
      "Iteration: 2850. Loss: 2.0843703746795654. Accuracy: 19.530767647664128\n",
      "Iteration: 2860. Loss: 2.0831151008605957. Accuracy: 19.489606915003087\n",
      "Iteration: 2870. Loss: 2.1114115715026855. Accuracy: 20.251080469232352\n",
      "Iteration: 2880. Loss: 2.10292911529541. Accuracy: 20.70384852850381\n",
      "Epoch:  38\n",
      "Iteration: 2890. Loss: 2.070521354675293. Accuracy: 20.353982300884955\n",
      "Iteration: 2900. Loss: 2.1677215099334717. Accuracy: 20.271660835562873\n",
      "Iteration: 2910. Loss: 2.091601610183716. Accuracy: 19.654249845647254\n",
      "Iteration: 2920. Loss: 2.091779947280884. Accuracy: 19.983535706935584\n",
      "Iteration: 2930. Loss: 2.138171672821045. Accuracy: 20.14817863757975\n",
      "Iteration: 2940. Loss: 2.115933895111084. Accuracy: 20.271660835562873\n",
      "Iteration: 2950. Loss: 2.121940851211548. Accuracy: 20.251080469232352\n",
      "Iteration: 2960. Loss: 2.0921196937561035. Accuracy: 19.860053508952458\n",
      "Epoch:  39\n",
      "Iteration: 2970. Loss: 2.072770357131958. Accuracy: 19.839473142621937\n",
      "Iteration: 2980. Loss: 2.064284563064575. Accuracy: 19.839473142621937\n",
      "Iteration: 2990. Loss: 2.0494673252105713. Accuracy: 19.88063387528298\n",
      "Iteration: 3000. Loss: 2.1522274017333984. Accuracy: 19.921794607944022\n",
      "Iteration: 3010. Loss: 2.063204765319824. Accuracy: 19.88063387528298\n",
      "Iteration: 3020. Loss: 2.1215033531188965. Accuracy: 19.921794607944022\n",
      "Iteration: 3030. Loss: 2.063913345336914. Accuracy: 20.662687795842768\n",
      "Iteration: 3040. Loss: 2.1570703983306885. Accuracy: 19.59250874665569\n",
      "Epoch:  40\n",
      "Iteration: 3050. Loss: 2.1381587982177734. Accuracy: 20.51862523152912\n",
      "Iteration: 3060. Loss: 2.0526270866394043. Accuracy: 20.53920559785964\n",
      "Iteration: 3070. Loss: 2.0762746334075928. Accuracy: 20.47746449886808\n",
      "Iteration: 3080. Loss: 2.037372350692749. Accuracy: 20.024696439596624\n",
      "Iteration: 3090. Loss: 2.083294153213501. Accuracy: 20.127598271249227\n",
      "Iteration: 3100. Loss: 2.0620391368865967. Accuracy: 19.201481786375798\n",
      "Iteration: 3110. Loss: 2.0632033348083496. Accuracy: 20.353982300884955\n",
      "Iteration: 3120. Loss: 2.0816612243652344. Accuracy: 20.51862523152912\n",
      "Epoch:  41\n",
      "Iteration: 3130. Loss: 2.0110223293304443. Accuracy: 20.76558962749537\n",
      "Iteration: 3140. Loss: 2.117988348007202. Accuracy: 20.43630376620704\n",
      "Iteration: 3150. Loss: 2.139967441558838. Accuracy: 20.065857172257665\n",
      "Iteration: 3160. Loss: 2.0630528926849365. Accuracy: 20.395143033546\n",
      "Iteration: 3170. Loss: 2.113184928894043. Accuracy: 19.489606915003087\n",
      "Iteration: 3180. Loss: 2.046851396560669. Accuracy: 20.353982300884955\n",
      "Iteration: 3190. Loss: 2.1064059734344482. Accuracy: 20.107017904918706\n",
      "Epoch:  42\n",
      "Iteration: 3200. Loss: 2.0953314304351807. Accuracy: 20.580366330520683\n",
      "Iteration: 3210. Loss: 2.1028261184692383. Accuracy: 20.909652191809013\n",
      "Iteration: 3220. Loss: 2.098766803741455. Accuracy: 21.05371475612266\n",
      "Iteration: 3230. Loss: 2.0986244678497314. Accuracy: 20.20991973657131\n",
      "Iteration: 3240. Loss: 2.068131685256958. Accuracy: 20.16875900391027\n",
      "Iteration: 3250. Loss: 2.0285074710845947. Accuracy: 20.76558962749537\n",
      "Iteration: 3260. Loss: 2.159585952758789. Accuracy: 20.82733072648693\n",
      "Iteration: 3270. Loss: 2.0222697257995605. Accuracy: 20.51862523152912\n",
      "Epoch:  43\n",
      "Iteration: 3280. Loss: 2.1247951984405518. Accuracy: 20.559785964190162\n",
      "Iteration: 3290. Loss: 2.1214191913604736. Accuracy: 20.16875900391027\n",
      "Iteration: 3300. Loss: 2.106369972229004. Accuracy: 20.950812924470057\n",
      "Iteration: 3310. Loss: 2.0322563648223877. Accuracy: 20.312821568223914\n",
      "Iteration: 3320. Loss: 2.069591760635376. Accuracy: 21.17719695410578\n",
      "Iteration: 3330. Loss: 2.0625932216644287. Accuracy: 21.07429512245318\n",
      "Iteration: 3340. Loss: 2.12196683883667. Accuracy: 20.20991973657131\n",
      "Iteration: 3350. Loss: 2.03085994720459. Accuracy: 20.70384852850381\n",
      "Epoch:  44\n",
      "Iteration: 3360. Loss: 2.1305227279663086. Accuracy: 19.88063387528298\n",
      "Iteration: 3370. Loss: 2.0766196250915527. Accuracy: 20.395143033546\n",
      "Iteration: 3380. Loss: 2.172799825668335. Accuracy: 20.72442889483433\n",
      "Iteration: 3390. Loss: 2.1435062885284424. Accuracy: 20.395143033546\n",
      "Iteration: 3400. Loss: 2.046330690383911. Accuracy: 19.24264251903684\n",
      "Iteration: 3410. Loss: 2.0518853664398193. Accuracy: 20.580366330520683\n",
      "Iteration: 3420. Loss: 2.0881080627441406. Accuracy: 21.05371475612266\n",
      "Iteration: 3430. Loss: 2.0357160568237305. Accuracy: 19.983535706935584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  45\n",
      "Iteration: 3440. Loss: 2.052098035812378. Accuracy: 20.971393290800577\n",
      "Iteration: 3450. Loss: 2.0808310508728027. Accuracy: 20.41572339987652\n",
      "Iteration: 3460. Loss: 2.104686975479126. Accuracy: 20.127598271249227\n",
      "Iteration: 3470. Loss: 2.0558509826660156. Accuracy: 20.292241201893393\n",
      "Iteration: 3480. Loss: 2.089967966079712. Accuracy: 20.374562667215475\n",
      "Iteration: 3490. Loss: 2.134585380554199. Accuracy: 20.47746449886808\n",
      "Iteration: 3500. Loss: 2.001024007797241. Accuracy: 19.160321053714757\n",
      "Iteration: 3510. Loss: 2.0582339763641357. Accuracy: 20.642107429512244\n",
      "Epoch:  46\n",
      "Iteration: 3520. Loss: 2.048985242843628. Accuracy: 20.353982300884955\n",
      "Iteration: 3530. Loss: 2.091308116912842. Accuracy: 20.909652191809013\n",
      "Iteration: 3540. Loss: 2.134420871734619. Accuracy: 20.72442889483433\n",
      "Iteration: 3550. Loss: 2.0692057609558105. Accuracy: 20.41572339987652\n",
      "Iteration: 3560. Loss: 2.135984420776367. Accuracy: 19.962955340605063\n",
      "Iteration: 3570. Loss: 2.066547155380249. Accuracy: 20.930232558139537\n",
      "Iteration: 3580. Loss: 2.122284173965454. Accuracy: 21.197777320436305\n",
      "Epoch:  47\n",
      "Iteration: 3590. Loss: 2.1688239574432373. Accuracy: 20.683268162173288\n",
      "Iteration: 3600. Loss: 2.031812906265259. Accuracy: 19.427865816011526\n",
      "Iteration: 3610. Loss: 2.110703945159912. Accuracy: 19.24264251903684\n",
      "Iteration: 3620. Loss: 2.1668758392333984. Accuracy: 20.53920559785964\n",
      "Iteration: 3630. Loss: 2.1087417602539062. Accuracy: 20.127598271249227\n",
      "Iteration: 3640. Loss: 2.09794282913208. Accuracy: 20.72442889483433\n",
      "Iteration: 3650. Loss: 2.042006015777588. Accuracy: 20.683268162173288\n",
      "Iteration: 3660. Loss: 2.1185343265533447. Accuracy: 19.695410578308294\n",
      "Epoch:  48\n",
      "Iteration: 3670. Loss: 2.0600080490112305. Accuracy: 19.510187281333607\n",
      "Iteration: 3680. Loss: 2.104769229888916. Accuracy: 20.127598271249227\n",
      "Iteration: 3690. Loss: 2.10062313079834. Accuracy: 20.292241201893393\n",
      "Iteration: 3700. Loss: 2.1383092403411865. Accuracy: 20.41572339987652\n",
      "Iteration: 3710. Loss: 2.076869487762451. Accuracy: 21.856349043012965\n",
      "Iteration: 3720. Loss: 2.0814945697784424. Accuracy: 21.465322082733074\n",
      "Iteration: 3730. Loss: 2.1037065982818604. Accuracy: 20.14817863757975\n",
      "Iteration: 3740. Loss: 2.0545990467071533. Accuracy: 20.271660835562873\n",
      "Epoch:  49\n",
      "Iteration: 3750. Loss: 2.139035701751709. Accuracy: 20.41572339987652\n",
      "Iteration: 3760. Loss: 2.0330207347869873. Accuracy: 20.909652191809013\n",
      "Iteration: 3770. Loss: 2.0377283096313477. Accuracy: 18.91335665774851\n",
      "Iteration: 3780. Loss: 2.132643461227417. Accuracy: 20.78616999382589\n",
      "Iteration: 3790. Loss: 2.116250514984131. Accuracy: 20.4980448651986\n",
      "Iteration: 3800. Loss: 2.0504090785980225. Accuracy: 20.51862523152912\n",
      "Iteration: 3810. Loss: 2.1195123195648193. Accuracy: 21.17719695410578\n",
      "Iteration: 3820. Loss: 2.0374293327331543. Accuracy: 20.18933937024079\n",
      "Epoch:  50\n",
      "Iteration: 3830. Loss: 2.1699979305267334. Accuracy: 21.321259518419428\n",
      "Iteration: 3840. Loss: 2.0755696296691895. Accuracy: 21.0948754887837\n",
      "Iteration: 3850. Loss: 2.1043410301208496. Accuracy: 20.78616999382589\n",
      "Iteration: 3860. Loss: 2.1151952743530273. Accuracy: 21.259518419427867\n",
      "Iteration: 3870. Loss: 2.1178104877471924. Accuracy: 21.650545379707758\n",
      "Iteration: 3880. Loss: 2.0941128730773926. Accuracy: 20.78616999382589\n",
      "Iteration: 3890. Loss: 2.043515920639038. Accuracy: 21.238938053097346\n",
      "Iteration: 3900. Loss: 2.0788991451263428. Accuracy: 20.930232558139537\n",
      "Epoch:  51\n",
      "Iteration: 3910. Loss: 2.1832661628723145. Accuracy: 20.86849145914797\n",
      "Iteration: 3920. Loss: 2.021257162094116. Accuracy: 21.300679152088907\n",
      "Iteration: 3930. Loss: 2.113443613052368. Accuracy: 20.47746449886808\n",
      "Iteration: 3940. Loss: 2.0888822078704834. Accuracy: 20.72442889483433\n",
      "Iteration: 3950. Loss: 2.0157954692840576. Accuracy: 20.909652191809013\n",
      "Iteration: 3960. Loss: 2.0598928928375244. Accuracy: 21.44474171640255\n",
      "Iteration: 3970. Loss: 2.0759389400482178. Accuracy: 20.80675036015641\n",
      "Epoch:  52\n",
      "Iteration: 3980. Loss: 2.081307888031006. Accuracy: 21.321259518419428\n",
      "Iteration: 3990. Loss: 2.0916929244995117. Accuracy: 21.07429512245318\n",
      "Iteration: 4000. Loss: 2.109858751296997. Accuracy: 21.6917061123688\n",
      "Iteration: 4010. Loss: 2.0635342597961426. Accuracy: 21.506482815394115\n",
      "Iteration: 4020. Loss: 2.122932195663452. Accuracy: 21.03313438979214\n",
      "Iteration: 4030. Loss: 2.195524215698242. Accuracy: 20.251080469232352\n",
      "Iteration: 4040. Loss: 2.0629642009735107. Accuracy: 21.05371475612266\n",
      "Iteration: 4050. Loss: 2.0784318447113037. Accuracy: 21.67112574603828\n",
      "Epoch:  53\n",
      "Iteration: 4060. Loss: 2.0374016761779785. Accuracy: 21.959250874665567\n",
      "Iteration: 4070. Loss: 2.059770107269287. Accuracy: 20.72442889483433\n",
      "Iteration: 4080. Loss: 2.0995965003967285. Accuracy: 21.13603622144474\n",
      "Iteration: 4090. Loss: 2.1124367713928223. Accuracy: 21.0948754887837\n",
      "Iteration: 4100. Loss: 2.1129977703094482. Accuracy: 21.732866845029843\n",
      "Iteration: 4110. Loss: 2.0689053535461426. Accuracy: 22.2885367359539\n",
      "Iteration: 4120. Loss: 2.126932382583618. Accuracy: 21.38300061741099\n",
      "Iteration: 4130. Loss: 2.0820631980895996. Accuracy: 21.629965013377237\n",
      "Epoch:  54\n",
      "Iteration: 4140. Loss: 2.1283230781555176. Accuracy: 21.753447211360363\n",
      "Iteration: 4150. Loss: 2.0321238040924072. Accuracy: 21.280098785758387\n",
      "Iteration: 4160. Loss: 2.079281806945801. Accuracy: 21.44474171640255\n",
      "Iteration: 4170. Loss: 2.0989346504211426. Accuracy: 21.876929409343486\n",
      "Iteration: 4180. Loss: 2.0938947200775146. Accuracy: 21.17719695410578\n",
      "Iteration: 4190. Loss: 2.092574119567871. Accuracy: 20.333401934554434\n",
      "Iteration: 4200. Loss: 2.086146831512451. Accuracy: 21.815188310351925\n",
      "Iteration: 4210. Loss: 2.0980453491210938. Accuracy: 21.42416135007203\n",
      "Epoch:  55\n",
      "Iteration: 4220. Loss: 2.097608804702759. Accuracy: 21.629965013377237\n",
      "Iteration: 4230. Loss: 2.048861265182495. Accuracy: 21.856349043012965\n",
      "Iteration: 4240. Loss: 2.0916502475738525. Accuracy: 21.609384647046717\n",
      "Iteration: 4250. Loss: 2.0782110691070557. Accuracy: 22.226795636962336\n",
      "Iteration: 4260. Loss: 2.0631167888641357. Accuracy: 21.876929409343486\n",
      "Iteration: 4270. Loss: 2.0898518562316895. Accuracy: 21.527063181724635\n",
      "Iteration: 4280. Loss: 2.0415124893188477. Accuracy: 20.80675036015641\n",
      "Iteration: 4290. Loss: 2.0015597343444824. Accuracy: 20.76558962749537\n",
      "Epoch:  56\n",
      "Iteration: 4300. Loss: 2.0819461345672607. Accuracy: 20.621527063181723\n",
      "Iteration: 4310. Loss: 2.0603768825531006. Accuracy: 21.485902449063595\n",
      "Iteration: 4320. Loss: 2.0359580516815186. Accuracy: 21.07429512245318\n",
      "Iteration: 4330. Loss: 2.0215249061584473. Accuracy: 21.07429512245318\n",
      "Iteration: 4340. Loss: 2.007809638977051. Accuracy: 20.991973657131098\n",
      "Iteration: 4350. Loss: 2.044928550720215. Accuracy: 21.11545585511422\n",
      "Iteration: 4360. Loss: 2.078033447265625. Accuracy: 21.588804280716197\n",
      "Epoch:  57\n",
      "Iteration: 4370. Loss: 2.0852043628692627. Accuracy: 20.889071825478492\n",
      "Iteration: 4380. Loss: 2.0469067096710205. Accuracy: 21.588804280716197\n",
      "Iteration: 4390. Loss: 2.1426568031311035. Accuracy: 21.05371475612266\n",
      "Iteration: 4400. Loss: 2.047842264175415. Accuracy: 21.259518419427867\n",
      "Iteration: 4410. Loss: 2.005746603012085. Accuracy: 21.36242025108047\n",
      "Iteration: 4420. Loss: 2.1021382808685303. Accuracy: 21.259518419427867\n",
      "Iteration: 4430. Loss: 2.055795907974243. Accuracy: 21.259518419427867\n",
      "Iteration: 4440. Loss: 2.1190035343170166. Accuracy: 19.901214241613502\n",
      "Epoch:  58\n",
      "Iteration: 4450. Loss: 2.1117312908172607. Accuracy: 20.230500102901832\n",
      "Iteration: 4460. Loss: 2.0951616764068604. Accuracy: 19.654249845647254\n",
      "Iteration: 4470. Loss: 2.0988690853118896. Accuracy: 21.13603622144474\n",
      "Iteration: 4480. Loss: 2.137310266494751. Accuracy: 20.271660835562873\n",
      "Iteration: 4490. Loss: 2.1410388946533203. Accuracy: 21.15661658777526\n",
      "Iteration: 4500. Loss: 2.074685573577881. Accuracy: 21.300679152088907\n",
      "Iteration: 4510. Loss: 2.060609817504883. Accuracy: 20.662687795842768\n",
      "Iteration: 4520. Loss: 2.1082489490509033. Accuracy: 21.13603622144474\n",
      "Epoch:  59\n",
      "Iteration: 4530. Loss: 2.1200430393218994. Accuracy: 20.230500102901832\n",
      "Iteration: 4540. Loss: 2.062014102935791. Accuracy: 20.4980448651986\n",
      "Iteration: 4550. Loss: 2.1087379455566406. Accuracy: 20.353982300884955\n",
      "Iteration: 4560. Loss: 2.057786703109741. Accuracy: 20.374562667215475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4570. Loss: 2.1350631713867188. Accuracy: 21.609384647046717\n",
      "Iteration: 4580. Loss: 2.0629076957702637. Accuracy: 21.465322082733074\n",
      "Iteration: 4590. Loss: 2.055434226989746. Accuracy: 20.51862523152912\n",
      "Iteration: 4600. Loss: 2.06595778465271. Accuracy: 20.086437538588186\n",
      "Epoch:  60\n",
      "Iteration: 4610. Loss: 2.0757665634155273. Accuracy: 20.51862523152912\n",
      "Iteration: 4620. Loss: 2.133754253387451. Accuracy: 20.80675036015641\n",
      "Iteration: 4630. Loss: 2.0404908657073975. Accuracy: 20.76558962749537\n",
      "Iteration: 4640. Loss: 2.1168875694274902. Accuracy: 20.374562667215475\n",
      "Iteration: 4650. Loss: 2.084959030151367. Accuracy: 20.395143033546\n",
      "Iteration: 4660. Loss: 2.0783045291900635. Accuracy: 20.600946696851203\n",
      "Iteration: 4670. Loss: 2.0678653717041016. Accuracy: 20.559785964190162\n",
      "Iteration: 4680. Loss: 2.138256311416626. Accuracy: 20.41572339987652\n",
      "Epoch:  61\n",
      "Iteration: 4690. Loss: 2.0734174251556396. Accuracy: 21.07429512245318\n",
      "Iteration: 4700. Loss: 2.0335118770599365. Accuracy: 20.74500926116485\n",
      "Iteration: 4710. Loss: 2.07887601852417. Accuracy: 20.86849145914797\n",
      "Iteration: 4720. Loss: 2.147879123687744. Accuracy: 20.78616999382589\n",
      "Iteration: 4730. Loss: 2.1176564693450928. Accuracy: 20.47746449886808\n",
      "Iteration: 4740. Loss: 1.9910672903060913. Accuracy: 20.930232558139537\n",
      "Iteration: 4750. Loss: 2.145066499710083. Accuracy: 20.600946696851203\n",
      "Epoch:  62\n",
      "Iteration: 4760. Loss: 2.124199867248535. Accuracy: 20.53920559785964\n",
      "Iteration: 4770. Loss: 2.0839948654174805. Accuracy: 20.662687795842768\n",
      "Iteration: 4780. Loss: 2.0309596061706543. Accuracy: 21.40358098374151\n",
      "Iteration: 4790. Loss: 2.0215306282043457. Accuracy: 20.662687795842768\n",
      "Iteration: 4800. Loss: 2.0296740531921387. Accuracy: 20.86849145914797\n",
      "Iteration: 4810. Loss: 2.0575928688049316. Accuracy: 20.950812924470057\n",
      "Iteration: 4820. Loss: 2.042302131652832. Accuracy: 20.045276805927145\n",
      "Iteration: 4830. Loss: 2.0448904037475586. Accuracy: 20.621527063181723\n",
      "Epoch:  63\n",
      "Iteration: 4840. Loss: 2.117725133895874. Accuracy: 20.950812924470057\n",
      "Iteration: 4850. Loss: 2.06864333152771. Accuracy: 21.0948754887837\n",
      "Iteration: 4860. Loss: 2.0629770755767822. Accuracy: 21.238938053097346\n",
      "Iteration: 4870. Loss: 2.09678053855896. Accuracy: 19.901214241613502\n",
      "Iteration: 4880. Loss: 2.1342480182647705. Accuracy: 20.889071825478492\n",
      "Iteration: 4890. Loss: 2.105053424835205. Accuracy: 20.374562667215475\n",
      "Iteration: 4900. Loss: 2.0848915576934814. Accuracy: 19.901214241613502\n",
      "Iteration: 4910. Loss: 2.088702917098999. Accuracy: 21.17719695410578\n",
      "Epoch:  64\n",
      "Iteration: 4920. Loss: 2.100404977798462. Accuracy: 20.374562667215475\n",
      "Iteration: 4930. Loss: 2.117734670639038. Accuracy: 20.82733072648693\n",
      "Iteration: 4940. Loss: 2.060093402862549. Accuracy: 20.004116073266104\n",
      "Iteration: 4950. Loss: 2.0289793014526367. Accuracy: 20.51862523152912\n",
      "Iteration: 4960. Loss: 2.044429063796997. Accuracy: 20.80675036015641\n",
      "Iteration: 4970. Loss: 2.1210474967956543. Accuracy: 20.41572339987652\n",
      "Iteration: 4980. Loss: 2.1416027545928955. Accuracy: 19.88063387528298\n",
      "Iteration: 4990. Loss: 2.1331052780151367. Accuracy: 19.798312409960896\n",
      "Epoch:  65\n",
      "Iteration: 5000. Loss: 2.1457743644714355. Accuracy: 19.407285449681005\n",
      "Iteration: 5010. Loss: 2.00028657913208. Accuracy: 19.427865816011526\n",
      "Iteration: 5020. Loss: 2.0844130516052246. Accuracy: 20.559785964190162\n",
      "Iteration: 5030. Loss: 2.0683982372283936. Accuracy: 20.53920559785964\n",
      "Iteration: 5040. Loss: 2.0959229469299316. Accuracy: 20.353982300884955\n",
      "Iteration: 5050. Loss: 2.0825605392456055. Accuracy: 20.333401934554434\n",
      "Iteration: 5060. Loss: 2.135545253753662. Accuracy: 19.942374974274543\n",
      "Iteration: 5070. Loss: 2.0084850788116455. Accuracy: 19.510187281333607\n",
      "Epoch:  66\n",
      "Iteration: 5080. Loss: 2.033571720123291. Accuracy: 20.41572339987652\n",
      "Iteration: 5090. Loss: 2.0321385860443115. Accuracy: 20.45688413253756\n",
      "Iteration: 5100. Loss: 2.0835752487182617. Accuracy: 19.818892776291417\n",
      "Iteration: 5110. Loss: 2.154228687286377. Accuracy: 19.901214241613502\n",
      "Iteration: 5120. Loss: 2.110581159591675. Accuracy: 20.53920559785964\n",
      "Iteration: 5130. Loss: 2.053685188293457. Accuracy: 20.127598271249227\n",
      "Iteration: 5140. Loss: 2.075639247894287. Accuracy: 20.045276805927145\n",
      "Epoch:  67\n",
      "Iteration: 5150. Loss: 2.07068133354187. Accuracy: 19.921794607944022\n",
      "Iteration: 5160. Loss: 2.0570342540740967. Accuracy: 19.654249845647254\n",
      "Iteration: 5170. Loss: 2.109893321990967. Accuracy: 19.32496398435892\n",
      "Iteration: 5180. Loss: 2.1623780727386475. Accuracy: 20.065857172257665\n",
      "Iteration: 5190. Loss: 2.0646157264709473. Accuracy: 20.107017904918706\n",
      "Iteration: 5200. Loss: 2.0878331661224365. Accuracy: 19.674830211977774\n",
      "Iteration: 5210. Loss: 2.0915873050689697. Accuracy: 20.662687795842768\n",
      "Iteration: 5220. Loss: 2.1335432529449463. Accuracy: 19.88063387528298\n",
      "Epoch:  68\n",
      "Iteration: 5230. Loss: 2.143209218978882. Accuracy: 20.16875900391027\n",
      "Iteration: 5240. Loss: 2.0510120391845703. Accuracy: 19.777732043630376\n",
      "Iteration: 5250. Loss: 2.0181519985198975. Accuracy: 19.489606915003087\n",
      "Iteration: 5260. Loss: 2.100615978240967. Accuracy: 19.57192838032517\n",
      "Iteration: 5270. Loss: 2.113892078399658. Accuracy: 20.4980448651986\n",
      "Iteration: 5280. Loss: 2.0596163272857666. Accuracy: 19.798312409960896\n",
      "Iteration: 5290. Loss: 2.101529836654663. Accuracy: 19.962955340605063\n",
      "Iteration: 5300. Loss: 2.1035194396972656. Accuracy: 19.777732043630376\n",
      "Epoch:  69\n",
      "Iteration: 5310. Loss: 2.0916926860809326. Accuracy: 19.942374974274543\n",
      "Iteration: 5320. Loss: 2.1338305473327637. Accuracy: 19.921794607944022\n",
      "Iteration: 5330. Loss: 2.0536699295043945. Accuracy: 20.230500102901832\n",
      "Iteration: 5340. Loss: 2.1372716426849365. Accuracy: 19.839473142621937\n",
      "Iteration: 5350. Loss: 2.073195219039917. Accuracy: 19.427865816011526\n",
      "Iteration: 5360. Loss: 2.061462640762329. Accuracy: 18.68697262811278\n",
      "Iteration: 5370. Loss: 2.0909345149993896. Accuracy: 19.715990944638815\n",
      "Iteration: 5380. Loss: 2.1200599670410156. Accuracy: 18.831035192426427\n",
      "Epoch:  70\n",
      "Iteration: 5390. Loss: 2.098813772201538. Accuracy: 19.160321053714757\n",
      "Iteration: 5400. Loss: 2.0889313220977783. Accuracy: 19.345544350689444\n",
      "Iteration: 5410. Loss: 2.185173273086548. Accuracy: 19.633669479316733\n",
      "Iteration: 5420. Loss: 2.139923095703125. Accuracy: 19.818892776291417\n",
      "Iteration: 5430. Loss: 2.1562013626098633. Accuracy: 19.57192838032517\n",
      "Iteration: 5440. Loss: 2.0858418941497803. Accuracy: 19.448446182342046\n",
      "Iteration: 5450. Loss: 2.067683696746826. Accuracy: 18.93393702407903\n",
      "Iteration: 5460. Loss: 2.0684814453125. Accuracy: 19.366124717019964\n",
      "Epoch:  71\n",
      "Iteration: 5470. Loss: 2.1073837280273438. Accuracy: 19.798312409960896\n",
      "Iteration: 5480. Loss: 2.069937229156494. Accuracy: 19.777732043630376\n",
      "Iteration: 5490. Loss: 2.1681361198425293. Accuracy: 19.88063387528298\n",
      "Iteration: 5500. Loss: 2.06656551361084. Accuracy: 19.695410578308294\n",
      "Iteration: 5510. Loss: 2.1253511905670166. Accuracy: 19.469026548672566\n",
      "Iteration: 5520. Loss: 2.1232876777648926. Accuracy: 19.530767647664128\n",
      "Iteration: 5530. Loss: 2.1024892330169678. Accuracy: 19.962955340605063\n",
      "Epoch:  72\n",
      "Iteration: 5540. Loss: 2.0828540325164795. Accuracy: 20.127598271249227\n",
      "Iteration: 5550. Loss: 2.0308549404144287. Accuracy: 19.222062152706318\n",
      "Iteration: 5560. Loss: 2.100170612335205. Accuracy: 19.633669479316733\n",
      "Iteration: 5570. Loss: 2.0496888160705566. Accuracy: 20.004116073266104\n",
      "Iteration: 5580. Loss: 2.1180193424224854. Accuracy: 19.757151677299856\n",
      "Iteration: 5590. Loss: 2.0591869354248047. Accuracy: 18.851615558756947\n",
      "Iteration: 5600. Loss: 2.0940639972686768. Accuracy: 18.91335665774851\n",
      "Iteration: 5610. Loss: 2.0862314701080322. Accuracy: 19.921794607944022\n",
      "Epoch:  73\n",
      "Iteration: 5620. Loss: 2.1164565086364746. Accuracy: 19.613089112986213\n",
      "Iteration: 5630. Loss: 2.0970637798309326. Accuracy: 19.28380325169788\n",
      "Iteration: 5640. Loss: 2.193974256515503. Accuracy: 19.448446182342046\n",
      "Iteration: 5650. Loss: 2.116185188293457. Accuracy: 19.715990944638815\n",
      "Iteration: 5660. Loss: 2.146965503692627. Accuracy: 19.427865816011526\n",
      "Iteration: 5670. Loss: 2.1240131855010986. Accuracy: 19.469026548672566\n",
      "Iteration: 5680. Loss: 2.121330976486206. Accuracy: 19.139740687384236\n",
      "Iteration: 5690. Loss: 2.0090320110321045. Accuracy: 18.58407079646018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  74\n",
      "Iteration: 5700. Loss: 2.1111977100372314. Accuracy: 18.810454826095903\n",
      "Iteration: 5710. Loss: 2.0711941719055176. Accuracy: 19.674830211977774\n",
      "Iteration: 5720. Loss: 2.0558207035064697. Accuracy: 19.901214241613502\n",
      "Iteration: 5730. Loss: 2.1123528480529785. Accuracy: 19.962955340605063\n",
      "Iteration: 5740. Loss: 2.0545623302459717. Accuracy: 18.93393702407903\n",
      "Iteration: 5750. Loss: 2.0766618251800537. Accuracy: 20.004116073266104\n",
      "Iteration: 5760. Loss: 2.0705490112304688. Accuracy: 18.99567812307059\n",
      "Iteration: 5770. Loss: 2.146219253540039. Accuracy: 20.395143033546\n",
      "Epoch:  75\n",
      "Iteration: 5780. Loss: 2.038382053375244. Accuracy: 19.139740687384236\n",
      "Iteration: 5790. Loss: 2.118889808654785. Accuracy: 20.024696439596624\n",
      "Iteration: 5800. Loss: 2.0731942653656006. Accuracy: 20.47746449886808\n",
      "Iteration: 5810. Loss: 2.1422810554504395. Accuracy: 19.654249845647254\n",
      "Iteration: 5820. Loss: 2.138732433319092. Accuracy: 20.045276805927145\n",
      "Iteration: 5830. Loss: 2.0932552814483643. Accuracy: 19.839473142621937\n",
      "Iteration: 5840. Loss: 2.1642329692840576. Accuracy: 20.086437538588186\n",
      "Iteration: 5850. Loss: 2.0958824157714844. Accuracy: 20.18933937024079\n",
      "Epoch:  76\n",
      "Iteration: 5860. Loss: 2.0156075954437256. Accuracy: 19.469026548672566\n",
      "Iteration: 5870. Loss: 2.1233742237091064. Accuracy: 19.839473142621937\n",
      "Iteration: 5880. Loss: 2.0702621936798096. Accuracy: 19.59250874665569\n",
      "Iteration: 5890. Loss: 2.0721535682678223. Accuracy: 19.05741922206215\n",
      "Iteration: 5900. Loss: 2.07004451751709. Accuracy: 20.086437538588186\n",
      "Iteration: 5910. Loss: 2.1555404663085938. Accuracy: 19.860053508952458\n",
      "Iteration: 5920. Loss: 2.1542863845825195. Accuracy: 19.901214241613502\n",
      "Epoch:  77\n",
      "Iteration: 5930. Loss: 2.0475778579711914. Accuracy: 19.469026548672566\n",
      "Iteration: 5940. Loss: 2.0716402530670166. Accuracy: 20.600946696851203\n",
      "Iteration: 5950. Loss: 2.062558174133301. Accuracy: 20.024696439596624\n",
      "Iteration: 5960. Loss: 2.0587387084960938. Accuracy: 20.14817863757975\n",
      "Iteration: 5970. Loss: 2.1193156242370605. Accuracy: 20.374562667215475\n",
      "Iteration: 5980. Loss: 2.144724130630493. Accuracy: 20.82733072648693\n",
      "Iteration: 5990. Loss: 2.0903940200805664. Accuracy: 20.024696439596624\n",
      "Iteration: 6000. Loss: 2.0275182723999023. Accuracy: 19.613089112986213\n",
      "Epoch:  78\n",
      "Iteration: 6010. Loss: 2.1291491985321045. Accuracy: 20.14817863757975\n",
      "Iteration: 6020. Loss: 2.0653562545776367. Accuracy: 19.654249845647254\n",
      "Iteration: 6030. Loss: 2.11883544921875. Accuracy: 19.613089112986213\n",
      "Iteration: 6040. Loss: 2.190253257751465. Accuracy: 20.353982300884955\n",
      "Iteration: 6050. Loss: 2.0594165325164795. Accuracy: 20.45688413253756\n",
      "Iteration: 6060. Loss: 2.088006019592285. Accuracy: 20.230500102901832\n",
      "Iteration: 6070. Loss: 2.0384461879730225. Accuracy: 19.777732043630376\n",
      "Iteration: 6080. Loss: 2.0411250591278076. Accuracy: 19.613089112986213\n",
      "Epoch:  79\n",
      "Iteration: 6090. Loss: 2.030992269515991. Accuracy: 20.621527063181723\n",
      "Iteration: 6100. Loss: 2.0600717067718506. Accuracy: 20.41572339987652\n",
      "Iteration: 6110. Loss: 2.0470504760742188. Accuracy: 19.921794607944022\n",
      "Iteration: 6120. Loss: 2.067509412765503. Accuracy: 20.45688413253756\n",
      "Iteration: 6130. Loss: 2.0805928707122803. Accuracy: 19.3043836180284\n",
      "Iteration: 6140. Loss: 2.0832948684692383. Accuracy: 20.127598271249227\n",
      "Iteration: 6150. Loss: 2.0066211223602295. Accuracy: 19.654249845647254\n",
      "Iteration: 6160. Loss: 2.1238083839416504. Accuracy: 20.14817863757975\n",
      "Epoch:  80\n",
      "Iteration: 6170. Loss: 2.0969302654266357. Accuracy: 20.024696439596624\n",
      "Iteration: 6180. Loss: 2.106222629547119. Accuracy: 20.024696439596624\n",
      "Iteration: 6190. Loss: 2.024069309234619. Accuracy: 19.57192838032517\n",
      "Iteration: 6200. Loss: 2.002199649810791. Accuracy: 18.810454826095903\n",
      "Iteration: 6210. Loss: 2.1150646209716797. Accuracy: 19.839473142621937\n",
      "Iteration: 6220. Loss: 2.085084915161133. Accuracy: 19.366124717019964\n",
      "Iteration: 6230. Loss: 2.12373948097229. Accuracy: 20.086437538588186\n",
      "Iteration: 6240. Loss: 2.1408634185791016. Accuracy: 20.086437538588186\n",
      "Epoch:  81\n",
      "Iteration: 6250. Loss: 2.0790412425994873. Accuracy: 20.45688413253756\n",
      "Iteration: 6260. Loss: 2.0088112354278564. Accuracy: 20.333401934554434\n",
      "Iteration: 6270. Loss: 2.07725191116333. Accuracy: 20.991973657131098\n",
      "Iteration: 6280. Loss: 2.0915722846984863. Accuracy: 20.251080469232352\n",
      "Iteration: 6290. Loss: 2.1214396953582764. Accuracy: 19.921794607944022\n",
      "Iteration: 6300. Loss: 2.082571029663086. Accuracy: 19.798312409960896\n",
      "Iteration: 6310. Loss: 2.1143362522125244. Accuracy: 20.621527063181723\n",
      "Epoch:  82\n",
      "Iteration: 6320. Loss: 2.184937000274658. Accuracy: 20.45688413253756\n",
      "Iteration: 6330. Loss: 2.1038782596588135. Accuracy: 19.386705083350485\n",
      "Iteration: 6340. Loss: 2.1798341274261475. Accuracy: 20.600946696851203\n",
      "Iteration: 6350. Loss: 2.024822950363159. Accuracy: 20.271660835562873\n",
      "Iteration: 6360. Loss: 2.0861525535583496. Accuracy: 20.80675036015641\n",
      "Iteration: 6370. Loss: 2.0878446102142334. Accuracy: 20.47746449886808\n",
      "Iteration: 6380. Loss: 2.1243062019348145. Accuracy: 20.86849145914797\n",
      "Iteration: 6390. Loss: 2.109135627746582. Accuracy: 21.17719695410578\n",
      "Epoch:  83\n",
      "Iteration: 6400. Loss: 2.1006267070770264. Accuracy: 20.230500102901832\n",
      "Iteration: 6410. Loss: 2.024745464324951. Accuracy: 20.065857172257665\n",
      "Iteration: 6420. Loss: 2.10994291305542. Accuracy: 19.736571310969335\n",
      "Iteration: 6430. Loss: 2.0392985343933105. Accuracy: 19.860053508952458\n",
      "Iteration: 6440. Loss: 2.0888516902923584. Accuracy: 20.600946696851203\n",
      "Iteration: 6450. Loss: 2.0800940990448. Accuracy: 20.43630376620704\n",
      "Iteration: 6460. Loss: 2.1306655406951904. Accuracy: 20.353982300884955\n",
      "Iteration: 6470. Loss: 2.040666103363037. Accuracy: 20.086437538588186\n",
      "Epoch:  84\n",
      "Iteration: 6480. Loss: 2.1984283924102783. Accuracy: 20.374562667215475\n",
      "Iteration: 6490. Loss: 2.1387274265289307. Accuracy: 19.921794607944022\n",
      "Iteration: 6500. Loss: 2.025110960006714. Accuracy: 19.860053508952458\n",
      "Iteration: 6510. Loss: 2.1103415489196777. Accuracy: 20.024696439596624\n",
      "Iteration: 6520. Loss: 2.087812662124634. Accuracy: 20.086437538588186\n",
      "Iteration: 6530. Loss: 2.0853843688964844. Accuracy: 21.012554023461618\n",
      "Iteration: 6540. Loss: 2.167829990386963. Accuracy: 20.16875900391027\n",
      "Iteration: 6550. Loss: 2.0624494552612305. Accuracy: 20.580366330520683\n",
      "Epoch:  85\n",
      "Iteration: 6560. Loss: 2.0812628269195557. Accuracy: 20.107017904918706\n",
      "Iteration: 6570. Loss: 2.0334951877593994. Accuracy: 20.53920559785964\n",
      "Iteration: 6580. Loss: 2.1102089881896973. Accuracy: 20.045276805927145\n",
      "Iteration: 6590. Loss: 2.145927667617798. Accuracy: 19.32496398435892\n",
      "Iteration: 6600. Loss: 2.031665325164795. Accuracy: 19.839473142621937\n",
      "Iteration: 6610. Loss: 2.132913589477539. Accuracy: 20.41572339987652\n",
      "Iteration: 6620. Loss: 2.021845817565918. Accuracy: 19.921794607944022\n",
      "Iteration: 6630. Loss: 2.106070041656494. Accuracy: 20.559785964190162\n",
      "Epoch:  86\n",
      "Iteration: 6640. Loss: 2.0292012691497803. Accuracy: 20.4980448651986\n",
      "Iteration: 6650. Loss: 2.082721471786499. Accuracy: 19.921794607944022\n",
      "Iteration: 6660. Loss: 2.1149699687957764. Accuracy: 20.78616999382589\n",
      "Iteration: 6670. Loss: 2.0714025497436523. Accuracy: 20.72442889483433\n",
      "Iteration: 6680. Loss: 2.1064772605895996. Accuracy: 20.683268162173288\n",
      "Iteration: 6690. Loss: 2.0226962566375732. Accuracy: 20.333401934554434\n",
      "Iteration: 6700. Loss: 2.0559582710266113. Accuracy: 20.559785964190162\n",
      "Epoch:  87\n",
      "Iteration: 6710. Loss: 2.023776054382324. Accuracy: 20.065857172257665\n",
      "Iteration: 6720. Loss: 2.0518441200256348. Accuracy: 20.82733072648693\n",
      "Iteration: 6730. Loss: 2.0721423625946045. Accuracy: 20.78616999382589\n",
      "Iteration: 6740. Loss: 2.0721042156219482. Accuracy: 20.580366330520683\n",
      "Iteration: 6750. Loss: 2.1334919929504395. Accuracy: 20.353982300884955\n",
      "Iteration: 6760. Loss: 2.022944688796997. Accuracy: 20.024696439596624\n",
      "Iteration: 6770. Loss: 2.054619073867798. Accuracy: 20.18933937024079\n",
      "Iteration: 6780. Loss: 2.080221652984619. Accuracy: 19.88063387528298\n",
      "Epoch:  88\n",
      "Iteration: 6790. Loss: 2.076037883758545. Accuracy: 19.180901420045277\n",
      "Iteration: 6800. Loss: 2.0694336891174316. Accuracy: 19.674830211977774\n",
      "Iteration: 6810. Loss: 2.043229341506958. Accuracy: 19.818892776291417\n",
      "Iteration: 6820. Loss: 2.142364025115967. Accuracy: 19.983535706935584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6830. Loss: 2.0794148445129395. Accuracy: 20.107017904918706\n",
      "Iteration: 6840. Loss: 2.0798757076263428. Accuracy: 19.983535706935584\n",
      "Iteration: 6850. Loss: 2.1014084815979004. Accuracy: 20.580366330520683\n",
      "Iteration: 6860. Loss: 2.1061298847198486. Accuracy: 20.4980448651986\n",
      "Epoch:  89\n",
      "Iteration: 6870. Loss: 2.020493507385254. Accuracy: 19.777732043630376\n",
      "Iteration: 6880. Loss: 2.15134334564209. Accuracy: 19.777732043630376\n",
      "Iteration: 6890. Loss: 2.0714004039764404. Accuracy: 20.312821568223914\n",
      "Iteration: 6900. Loss: 2.0867667198181152. Accuracy: 19.818892776291417\n",
      "Iteration: 6910. Loss: 2.0026025772094727. Accuracy: 19.983535706935584\n",
      "Iteration: 6920. Loss: 1.9870595932006836. Accuracy: 20.621527063181723\n",
      "Iteration: 6930. Loss: 2.133812665939331. Accuracy: 20.580366330520683\n",
      "Iteration: 6940. Loss: 2.123732089996338. Accuracy: 20.230500102901832\n",
      "Epoch:  90\n",
      "Iteration: 6950. Loss: 2.028122663497925. Accuracy: 20.580366330520683\n",
      "Iteration: 6960. Loss: 2.0598180294036865. Accuracy: 20.909652191809013\n",
      "Iteration: 6970. Loss: 2.0161962509155273. Accuracy: 20.909652191809013\n",
      "Iteration: 6980. Loss: 2.1122896671295166. Accuracy: 20.950812924470057\n",
      "Iteration: 6990. Loss: 2.035116195678711. Accuracy: 20.86849145914797\n",
      "Iteration: 7000. Loss: 2.0770506858825684. Accuracy: 20.4980448651986\n",
      "Iteration: 7010. Loss: 2.0543501377105713. Accuracy: 20.333401934554434\n",
      "Iteration: 7020. Loss: 2.0240225791931152. Accuracy: 20.292241201893393\n",
      "Epoch:  91\n",
      "Iteration: 7030. Loss: 2.0814270973205566. Accuracy: 20.53920559785964\n",
      "Iteration: 7040. Loss: 2.0764718055725098. Accuracy: 20.127598271249227\n",
      "Iteration: 7050. Loss: 2.1039533615112305. Accuracy: 20.621527063181723\n",
      "Iteration: 7060. Loss: 2.0716452598571777. Accuracy: 20.292241201893393\n",
      "Iteration: 7070. Loss: 2.078260898590088. Accuracy: 20.909652191809013\n",
      "Iteration: 7080. Loss: 2.009658098220825. Accuracy: 20.230500102901832\n",
      "Iteration: 7090. Loss: 1.9703104496002197. Accuracy: 20.20991973657131\n",
      "Epoch:  92\n",
      "Iteration: 7100. Loss: 2.0172133445739746. Accuracy: 20.80675036015641\n",
      "Iteration: 7110. Loss: 2.060765027999878. Accuracy: 20.16875900391027\n",
      "Iteration: 7120. Loss: 2.1778781414031982. Accuracy: 19.180901420045277\n",
      "Iteration: 7130. Loss: 2.101478099822998. Accuracy: 20.14817863757975\n",
      "Iteration: 7140. Loss: 2.0618796348571777. Accuracy: 19.633669479316733\n",
      "Iteration: 7150. Loss: 1.9437512159347534. Accuracy: 19.962955340605063\n",
      "Iteration: 7160. Loss: 2.0867764949798584. Accuracy: 20.312821568223914\n",
      "Iteration: 7170. Loss: 2.107790470123291. Accuracy: 20.16875900391027\n",
      "Epoch:  93\n",
      "Iteration: 7180. Loss: 2.0629472732543945. Accuracy: 20.930232558139537\n",
      "Iteration: 7190. Loss: 2.0864479541778564. Accuracy: 20.70384852850381\n",
      "Iteration: 7200. Loss: 2.0590717792510986. Accuracy: 19.695410578308294\n",
      "Iteration: 7210. Loss: 2.0164566040039062. Accuracy: 19.427865816011526\n",
      "Iteration: 7220. Loss: 2.067974328994751. Accuracy: 20.292241201893393\n",
      "Iteration: 7230. Loss: 2.0167911052703857. Accuracy: 20.045276805927145\n",
      "Iteration: 7240. Loss: 2.113140821456909. Accuracy: 20.642107429512244\n",
      "Iteration: 7250. Loss: 2.109795570373535. Accuracy: 20.683268162173288\n",
      "Epoch:  94\n",
      "Iteration: 7260. Loss: 2.0795702934265137. Accuracy: 20.271660835562873\n",
      "Iteration: 7270. Loss: 2.1014773845672607. Accuracy: 20.82733072648693\n",
      "Iteration: 7280. Loss: 2.0725114345550537. Accuracy: 20.72442889483433\n",
      "Iteration: 7290. Loss: 2.019538640975952. Accuracy: 20.76558962749537\n",
      "Iteration: 7300. Loss: 2.090752601623535. Accuracy: 19.695410578308294\n",
      "Iteration: 7310. Loss: 2.053628444671631. Accuracy: 20.333401934554434\n",
      "Iteration: 7320. Loss: 2.1456093788146973. Accuracy: 19.798312409960896\n",
      "Iteration: 7330. Loss: 2.0975253582000732. Accuracy: 21.05371475612266\n",
      "Epoch:  95\n",
      "Iteration: 7340. Loss: 2.085291862487793. Accuracy: 20.70384852850381\n",
      "Iteration: 7350. Loss: 2.1011996269226074. Accuracy: 20.312821568223914\n",
      "Iteration: 7360. Loss: 2.0595343112945557. Accuracy: 19.757151677299856\n",
      "Iteration: 7370. Loss: 1.9623252153396606. Accuracy: 21.712286478699323\n",
      "Iteration: 7380. Loss: 2.115827798843384. Accuracy: 20.271660835562873\n",
      "Iteration: 7390. Loss: 2.0536231994628906. Accuracy: 20.107017904918706\n",
      "Iteration: 7400. Loss: 2.065788984298706. Accuracy: 20.16875900391027\n",
      "Iteration: 7410. Loss: 2.161541700363159. Accuracy: 20.271660835562873\n",
      "Epoch:  96\n",
      "Iteration: 7420. Loss: 2.126962184906006. Accuracy: 20.045276805927145\n",
      "Iteration: 7430. Loss: 2.1365225315093994. Accuracy: 20.662687795842768\n",
      "Iteration: 7440. Loss: 2.0732953548431396. Accuracy: 20.024696439596624\n",
      "Iteration: 7450. Loss: 2.0938284397125244. Accuracy: 20.76558962749537\n",
      "Iteration: 7460. Loss: 2.068591356277466. Accuracy: 20.43630376620704\n",
      "Iteration: 7470. Loss: 2.102374792098999. Accuracy: 19.695410578308294\n",
      "Iteration: 7480. Loss: 2.131375551223755. Accuracy: 20.70384852850381\n",
      "Epoch:  97\n",
      "Iteration: 7490. Loss: 2.0330746173858643. Accuracy: 20.642107429512244\n",
      "Iteration: 7500. Loss: 2.121938467025757. Accuracy: 20.74500926116485\n",
      "Iteration: 7510. Loss: 2.09208083152771. Accuracy: 19.901214241613502\n",
      "Iteration: 7520. Loss: 2.074655532836914. Accuracy: 20.292241201893393\n",
      "Iteration: 7530. Loss: 2.076422929763794. Accuracy: 20.086437538588186\n",
      "Iteration: 7540. Loss: 2.1516637802124023. Accuracy: 20.353982300884955\n",
      "Iteration: 7550. Loss: 2.0904924869537354. Accuracy: 20.47746449886808\n",
      "Iteration: 7560. Loss: 2.064100980758667. Accuracy: 20.41572339987652\n",
      "Epoch:  98\n",
      "Iteration: 7570. Loss: 2.1577751636505127. Accuracy: 19.654249845647254\n",
      "Iteration: 7580. Loss: 2.0654613971710205. Accuracy: 19.962955340605063\n",
      "Iteration: 7590. Loss: 2.0796284675598145. Accuracy: 20.333401934554434\n",
      "Iteration: 7600. Loss: 2.1807384490966797. Accuracy: 19.26322288536736\n",
      "Iteration: 7610. Loss: 2.0751688480377197. Accuracy: 19.818892776291417\n",
      "Iteration: 7620. Loss: 2.0859155654907227. Accuracy: 20.086437538588186\n",
      "Iteration: 7630. Loss: 2.116989850997925. Accuracy: 19.983535706935584\n",
      "Iteration: 7640. Loss: 2.0025582313537598. Accuracy: 20.43630376620704\n",
      "Epoch:  99\n",
      "Iteration: 7650. Loss: 2.086742639541626. Accuracy: 19.983535706935584\n",
      "Iteration: 7660. Loss: 2.080353021621704. Accuracy: 20.45688413253756\n",
      "Iteration: 7670. Loss: 1.989029049873352. Accuracy: 20.395143033546\n",
      "Iteration: 7680. Loss: 2.106851816177368. Accuracy: 20.74500926116485\n",
      "Iteration: 7690. Loss: 2.11537504196167. Accuracy: 20.930232558139537\n",
      "Iteration: 7700. Loss: 2.1433815956115723. Accuracy: 20.353982300884955\n",
      "Iteration: 7710. Loss: 1.967071771621704. Accuracy: 20.74500926116485\n",
      "Iteration: 7720. Loss: 2.0397753715515137. Accuracy: 20.86849145914797\n",
      "Epoch:  100\n",
      "Iteration: 7730. Loss: 2.0758588314056396. Accuracy: 21.11545585511422\n",
      "Iteration: 7740. Loss: 2.0868637561798096. Accuracy: 20.333401934554434\n",
      "Iteration: 7750. Loss: 2.076093912124634. Accuracy: 20.230500102901832\n",
      "Iteration: 7760. Loss: 2.1462254524230957. Accuracy: 20.76558962749537\n",
      "Iteration: 7770. Loss: 2.0973050594329834. Accuracy: 19.942374974274543\n",
      "Iteration: 7780. Loss: 2.062690258026123. Accuracy: 20.045276805927145\n",
      "Iteration: 7790. Loss: 2.0985584259033203. Accuracy: 20.292241201893393\n",
      "Iteration: 7800. Loss: 2.075657367706299. Accuracy: 20.127598271249227\n",
      "Epoch:  101\n",
      "Iteration: 7810. Loss: 2.1248137950897217. Accuracy: 20.18933937024079\n",
      "Iteration: 7820. Loss: 2.101670742034912. Accuracy: 20.72442889483433\n",
      "Iteration: 7830. Loss: 2.093026876449585. Accuracy: 20.374562667215475\n",
      "Iteration: 7840. Loss: 2.123997449874878. Accuracy: 20.950812924470057\n",
      "Iteration: 7850. Loss: 2.0364484786987305. Accuracy: 20.41572339987652\n",
      "Iteration: 7860. Loss: 2.0448596477508545. Accuracy: 20.43630376620704\n",
      "Iteration: 7870. Loss: 2.0635251998901367. Accuracy: 20.4980448651986\n",
      "Epoch:  102\n",
      "Iteration: 7880. Loss: 2.0831449031829834. Accuracy: 20.70384852850381\n",
      "Iteration: 7890. Loss: 2.083890914916992. Accuracy: 20.683268162173288\n",
      "Iteration: 7900. Loss: 2.0889759063720703. Accuracy: 20.312821568223914\n",
      "Iteration: 7910. Loss: 2.0946152210235596. Accuracy: 20.41572339987652\n",
      "Iteration: 7920. Loss: 2.0749685764312744. Accuracy: 20.16875900391027\n",
      "Iteration: 7930. Loss: 2.0418546199798584. Accuracy: 20.024696439596624\n",
      "Iteration: 7940. Loss: 2.050570249557495. Accuracy: 19.777732043630376\n",
      "Iteration: 7950. Loss: 2.073786735534668. Accuracy: 20.41572339987652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  103\n",
      "Iteration: 7960. Loss: 2.120312452316284. Accuracy: 19.32496398435892\n",
      "Iteration: 7970. Loss: 2.0377860069274902. Accuracy: 19.489606915003087\n",
      "Iteration: 7980. Loss: 2.0810282230377197. Accuracy: 20.600946696851203\n",
      "Iteration: 7990. Loss: 2.058884859085083. Accuracy: 20.16875900391027\n",
      "Iteration: 8000. Loss: 2.09651255607605. Accuracy: 20.559785964190162\n",
      "Iteration: 8010. Loss: 2.087402105331421. Accuracy: 20.20991973657131\n",
      "Iteration: 8020. Loss: 2.0598366260528564. Accuracy: 20.82733072648693\n",
      "Iteration: 8030. Loss: 2.085491895675659. Accuracy: 19.839473142621937\n",
      "Epoch:  104\n",
      "Iteration: 8040. Loss: 2.1330771446228027. Accuracy: 20.333401934554434\n",
      "Iteration: 8050. Loss: 1.9752509593963623. Accuracy: 20.559785964190162\n",
      "Iteration: 8060. Loss: 2.0851383209228516. Accuracy: 21.03313438979214\n",
      "Iteration: 8070. Loss: 2.0765011310577393. Accuracy: 20.78616999382589\n",
      "Iteration: 8080. Loss: 2.05792498588562. Accuracy: 20.84791109281745\n",
      "Iteration: 8090. Loss: 2.0673277378082275. Accuracy: 20.41572339987652\n",
      "Iteration: 8100. Loss: 2.1140472888946533. Accuracy: 20.53920559785964\n",
      "Iteration: 8110. Loss: 2.0912959575653076. Accuracy: 19.860053508952458\n",
      "Epoch:  105\n",
      "Iteration: 8120. Loss: 2.1173579692840576. Accuracy: 20.683268162173288\n",
      "Iteration: 8130. Loss: 2.095339298248291. Accuracy: 21.15661658777526\n",
      "Iteration: 8140. Loss: 2.0470049381256104. Accuracy: 20.47746449886808\n",
      "Iteration: 8150. Loss: 2.076960563659668. Accuracy: 20.292241201893393\n",
      "Iteration: 8160. Loss: 2.0749402046203613. Accuracy: 20.662687795842768\n",
      "Iteration: 8170. Loss: 2.070314407348633. Accuracy: 20.70384852850381\n",
      "Iteration: 8180. Loss: 2.038616180419922. Accuracy: 20.45688413253756\n",
      "Iteration: 8190. Loss: 2.0888750553131104. Accuracy: 20.374562667215475\n",
      "Epoch:  106\n",
      "Iteration: 8200. Loss: 2.1470260620117188. Accuracy: 20.930232558139537\n",
      "Iteration: 8210. Loss: 2.060756206512451. Accuracy: 21.15661658777526\n",
      "Iteration: 8220. Loss: 2.0755114555358887. Accuracy: 20.930232558139537\n",
      "Iteration: 8230. Loss: 2.0295190811157227. Accuracy: 21.03313438979214\n",
      "Iteration: 8240. Loss: 2.0143353939056396. Accuracy: 21.259518419427867\n",
      "Iteration: 8250. Loss: 2.1785330772399902. Accuracy: 18.39884749948549\n",
      "Iteration: 8260. Loss: 2.115623950958252. Accuracy: 20.683268162173288\n",
      "Epoch:  107\n",
      "Iteration: 8270. Loss: 2.0669784545898438. Accuracy: 21.012554023461618\n",
      "Iteration: 8280. Loss: 2.0793046951293945. Accuracy: 19.757151677299856\n",
      "Iteration: 8290. Loss: 2.0697219371795654. Accuracy: 20.4980448651986\n",
      "Iteration: 8300. Loss: 2.1017322540283203. Accuracy: 20.45688413253756\n",
      "Iteration: 8310. Loss: 2.0846986770629883. Accuracy: 20.600946696851203\n",
      "Iteration: 8320. Loss: 2.067768096923828. Accuracy: 21.40358098374151\n",
      "Iteration: 8330. Loss: 2.0731284618377686. Accuracy: 19.777732043630376\n",
      "Iteration: 8340. Loss: 2.075092077255249. Accuracy: 20.4980448651986\n",
      "Epoch:  108\n",
      "Iteration: 8350. Loss: 2.063655376434326. Accuracy: 20.312821568223914\n",
      "Iteration: 8360. Loss: 2.081861734390259. Accuracy: 20.86849145914797\n",
      "Iteration: 8370. Loss: 2.0664684772491455. Accuracy: 21.300679152088907\n",
      "Iteration: 8380. Loss: 2.074772834777832. Accuracy: 20.086437538588186\n",
      "Iteration: 8390. Loss: 2.0991976261138916. Accuracy: 21.44474171640255\n",
      "Iteration: 8400. Loss: 2.0954089164733887. Accuracy: 20.971393290800577\n",
      "Iteration: 8410. Loss: 2.0969889163970947. Accuracy: 20.024696439596624\n",
      "Iteration: 8420. Loss: 2.0284082889556885. Accuracy: 21.15661658777526\n",
      "Epoch:  109\n",
      "Iteration: 8430. Loss: 2.0860493183135986. Accuracy: 20.4980448651986\n",
      "Iteration: 8440. Loss: 2.107480525970459. Accuracy: 19.715990944638815\n",
      "Iteration: 8450. Loss: 2.1294989585876465. Accuracy: 19.633669479316733\n",
      "Iteration: 8460. Loss: 2.1254944801330566. Accuracy: 19.633669479316733\n",
      "Iteration: 8470. Loss: 2.0839481353759766. Accuracy: 19.201481786375798\n",
      "Iteration: 8480. Loss: 2.0942912101745605. Accuracy: 20.18933937024079\n",
      "Iteration: 8490. Loss: 2.0971670150756836. Accuracy: 21.11545585511422\n",
      "Iteration: 8500. Loss: 2.014413356781006. Accuracy: 21.238938053097346\n",
      "Epoch:  110\n",
      "Iteration: 8510. Loss: 2.0672192573547363. Accuracy: 21.218357686766826\n",
      "Iteration: 8520. Loss: 2.1435294151306152. Accuracy: 20.930232558139537\n",
      "Iteration: 8530. Loss: 2.069960832595825. Accuracy: 19.860053508952458\n",
      "Iteration: 8540. Loss: 2.0660252571105957. Accuracy: 20.683268162173288\n",
      "Iteration: 8550. Loss: 2.08760929107666. Accuracy: 20.80675036015641\n",
      "Iteration: 8560. Loss: 2.0559892654418945. Accuracy: 20.889071825478492\n",
      "Iteration: 8570. Loss: 2.023071765899658. Accuracy: 20.950812924470057\n",
      "Iteration: 8580. Loss: 2.132206916809082. Accuracy: 20.683268162173288\n",
      "Epoch:  111\n",
      "Iteration: 8590. Loss: 2.1133992671966553. Accuracy: 20.78616999382589\n",
      "Iteration: 8600. Loss: 2.0766522884368896. Accuracy: 21.36242025108047\n",
      "Iteration: 8610. Loss: 2.016752004623413. Accuracy: 20.374562667215475\n",
      "Iteration: 8620. Loss: 2.0973095893859863. Accuracy: 20.84791109281745\n",
      "Iteration: 8630. Loss: 2.142302989959717. Accuracy: 20.18933937024079\n",
      "Iteration: 8640. Loss: 2.0452544689178467. Accuracy: 20.004116073266104\n",
      "Iteration: 8650. Loss: 2.0263214111328125. Accuracy: 21.321259518419428\n",
      "Epoch:  112\n",
      "Iteration: 8660. Loss: 2.0109646320343018. Accuracy: 20.662687795842768\n",
      "Iteration: 8670. Loss: 2.053786516189575. Accuracy: 20.80675036015641\n",
      "Iteration: 8680. Loss: 2.0377542972564697. Accuracy: 19.427865816011526\n",
      "Iteration: 8690. Loss: 2.0483169555664062. Accuracy: 21.259518419427867\n",
      "Iteration: 8700. Loss: 2.0721540451049805. Accuracy: 21.238938053097346\n",
      "Iteration: 8710. Loss: 2.0894031524658203. Accuracy: 21.11545585511422\n",
      "Iteration: 8720. Loss: 2.080538511276245. Accuracy: 21.629965013377237\n",
      "Iteration: 8730. Loss: 2.0626189708709717. Accuracy: 20.621527063181723\n",
      "Epoch:  113\n",
      "Iteration: 8740. Loss: 2.06990909576416. Accuracy: 21.44474171640255\n",
      "Iteration: 8750. Loss: 2.0809311866760254. Accuracy: 21.300679152088907\n",
      "Iteration: 8760. Loss: 2.1264843940734863. Accuracy: 21.07429512245318\n",
      "Iteration: 8770. Loss: 2.0619046688079834. Accuracy: 21.0948754887837\n",
      "Iteration: 8780. Loss: 2.0362024307250977. Accuracy: 20.353982300884955\n",
      "Iteration: 8790. Loss: 1.9839117527008057. Accuracy: 20.78616999382589\n",
      "Iteration: 8800. Loss: 2.040072202682495. Accuracy: 21.0948754887837\n",
      "Iteration: 8810. Loss: 2.052034616470337. Accuracy: 21.259518419427867\n",
      "Epoch:  114\n",
      "Iteration: 8820. Loss: 2.0498368740081787. Accuracy: 20.930232558139537\n",
      "Iteration: 8830. Loss: 2.060426950454712. Accuracy: 21.11545585511422\n",
      "Iteration: 8840. Loss: 2.1424720287323. Accuracy: 21.280098785758387\n",
      "Iteration: 8850. Loss: 2.175668716430664. Accuracy: 20.909652191809013\n",
      "Iteration: 8860. Loss: 2.078720808029175. Accuracy: 20.86849145914797\n",
      "Iteration: 8870. Loss: 2.0650086402893066. Accuracy: 21.05371475612266\n",
      "Iteration: 8880. Loss: 1.9977947473526. Accuracy: 21.280098785758387\n",
      "Iteration: 8890. Loss: 2.035891532897949. Accuracy: 20.53920559785964\n",
      "Epoch:  115\n",
      "Iteration: 8900. Loss: 2.079066514968872. Accuracy: 20.45688413253756\n",
      "Iteration: 8910. Loss: 2.0802831649780273. Accuracy: 20.51862523152912\n",
      "Iteration: 8920. Loss: 2.0985589027404785. Accuracy: 20.14817863757975\n",
      "Iteration: 8930. Loss: 2.08892822265625. Accuracy: 20.559785964190162\n",
      "Iteration: 8940. Loss: 2.102069139480591. Accuracy: 21.506482815394115\n",
      "Iteration: 8950. Loss: 2.072941780090332. Accuracy: 20.683268162173288\n",
      "Iteration: 8960. Loss: 2.0233089923858643. Accuracy: 20.14817863757975\n",
      "Iteration: 8970. Loss: 2.1043307781219482. Accuracy: 21.259518419427867\n",
      "Epoch:  116\n",
      "Iteration: 8980. Loss: 2.090466260910034. Accuracy: 21.05371475612266\n",
      "Iteration: 8990. Loss: 2.047118902206421. Accuracy: 21.44474171640255\n",
      "Iteration: 9000. Loss: 2.0642249584198. Accuracy: 21.547643548055156\n",
      "Iteration: 9010. Loss: 2.0445423126220703. Accuracy: 21.67112574603828\n",
      "Iteration: 9020. Loss: 2.070568799972534. Accuracy: 21.197777320436305\n",
      "Iteration: 9030. Loss: 2.1007492542266846. Accuracy: 20.84791109281745\n",
      "Iteration: 9040. Loss: 2.0834829807281494. Accuracy: 20.950812924470057\n",
      "Epoch:  117\n",
      "Iteration: 9050. Loss: 2.05325984954834. Accuracy: 20.950812924470057\n",
      "Iteration: 9060. Loss: 2.0765349864959717. Accuracy: 21.03313438979214\n",
      "Iteration: 9070. Loss: 2.0342652797698975. Accuracy: 20.251080469232352\n",
      "Iteration: 9080. Loss: 2.0561022758483887. Accuracy: 20.84791109281745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9090. Loss: 2.0660505294799805. Accuracy: 21.341839884749948\n",
      "Iteration: 9100. Loss: 2.1207644939422607. Accuracy: 21.17719695410578\n",
      "Iteration: 9110. Loss: 2.1041343212127686. Accuracy: 21.11545585511422\n",
      "Iteration: 9120. Loss: 2.0800371170043945. Accuracy: 20.950812924470057\n",
      "Epoch:  118\n",
      "Iteration: 9130. Loss: 2.0564804077148438. Accuracy: 21.13603622144474\n",
      "Iteration: 9140. Loss: 2.0975260734558105. Accuracy: 21.897509775674006\n",
      "Iteration: 9150. Loss: 2.062699556350708. Accuracy: 20.889071825478492\n",
      "Iteration: 9160. Loss: 2.03029465675354. Accuracy: 21.07429512245318\n",
      "Iteration: 9170. Loss: 2.064419984817505. Accuracy: 21.485902449063595\n",
      "Iteration: 9180. Loss: 2.0729572772979736. Accuracy: 21.794607944021404\n",
      "Iteration: 9190. Loss: 2.00508713722229. Accuracy: 20.971393290800577\n",
      "Iteration: 9200. Loss: 2.11482310295105. Accuracy: 20.950812924470057\n",
      "Epoch:  119\n",
      "Iteration: 9210. Loss: 2.038890838623047. Accuracy: 21.13603622144474\n",
      "Iteration: 9220. Loss: 2.083251476287842. Accuracy: 20.991973657131098\n",
      "Iteration: 9230. Loss: 2.072568655014038. Accuracy: 20.20991973657131\n",
      "Iteration: 9240. Loss: 2.1435396671295166. Accuracy: 21.732866845029843\n",
      "Iteration: 9250. Loss: 2.0720667839050293. Accuracy: 21.07429512245318\n",
      "Iteration: 9260. Loss: 2.068481683731079. Accuracy: 21.321259518419428\n",
      "Iteration: 9270. Loss: 2.1576874256134033. Accuracy: 20.230500102901832\n",
      "Iteration: 9280. Loss: 2.0779216289520264. Accuracy: 20.47746449886808\n",
      "Epoch:  120\n",
      "Iteration: 9290. Loss: 2.069831371307373. Accuracy: 21.05371475612266\n",
      "Iteration: 9300. Loss: 2.0781774520874023. Accuracy: 20.559785964190162\n",
      "Iteration: 9310. Loss: 2.0494627952575684. Accuracy: 20.78616999382589\n",
      "Iteration: 9320. Loss: 2.0284767150878906. Accuracy: 21.012554023461618\n",
      "Iteration: 9330. Loss: 2.1211371421813965. Accuracy: 21.0948754887837\n",
      "Iteration: 9340. Loss: 2.0008304119110107. Accuracy: 21.197777320436305\n",
      "Iteration: 9350. Loss: 2.011521339416504. Accuracy: 21.300679152088907\n",
      "Iteration: 9360. Loss: 1.9856425523757935. Accuracy: 21.40358098374151\n",
      "Epoch:  121\n",
      "Iteration: 9370. Loss: 2.018656015396118. Accuracy: 20.84791109281745\n",
      "Iteration: 9380. Loss: 2.1281113624572754. Accuracy: 20.53920559785964\n",
      "Iteration: 9390. Loss: 2.064938545227051. Accuracy: 21.40358098374151\n",
      "Iteration: 9400. Loss: 2.1384329795837402. Accuracy: 20.580366330520683\n",
      "Iteration: 9410. Loss: 2.1196658611297607. Accuracy: 20.4980448651986\n",
      "Iteration: 9420. Loss: 1.9958254098892212. Accuracy: 21.44474171640255\n",
      "Iteration: 9430. Loss: 2.0466456413269043. Accuracy: 20.80675036015641\n",
      "Epoch:  122\n",
      "Iteration: 9440. Loss: 2.0039522647857666. Accuracy: 20.662687795842768\n",
      "Iteration: 9450. Loss: 2.0394747257232666. Accuracy: 21.321259518419428\n",
      "Iteration: 9460. Loss: 2.019375801086426. Accuracy: 20.991973657131098\n",
      "Iteration: 9470. Loss: 2.0374648571014404. Accuracy: 20.395143033546\n",
      "Iteration: 9480. Loss: 2.092379093170166. Accuracy: 20.230500102901832\n",
      "Iteration: 9490. Loss: 2.0466768741607666. Accuracy: 20.86849145914797\n",
      "Iteration: 9500. Loss: 2.1259028911590576. Accuracy: 21.609384647046717\n",
      "Iteration: 9510. Loss: 2.0578296184539795. Accuracy: 20.662687795842768\n",
      "Epoch:  123\n",
      "Iteration: 9520. Loss: 2.053332805633545. Accuracy: 20.621527063181723\n",
      "Iteration: 9530. Loss: 2.0739405155181885. Accuracy: 21.650545379707758\n",
      "Iteration: 9540. Loss: 2.1305582523345947. Accuracy: 21.238938053097346\n",
      "Iteration: 9550. Loss: 2.070786476135254. Accuracy: 21.0948754887837\n",
      "Iteration: 9560. Loss: 2.07761549949646. Accuracy: 20.82733072648693\n",
      "Iteration: 9570. Loss: 2.043018341064453. Accuracy: 20.950812924470057\n",
      "Iteration: 9580. Loss: 2.1361145973205566. Accuracy: 20.84791109281745\n",
      "Iteration: 9590. Loss: 2.084918737411499. Accuracy: 21.13603622144474\n",
      "Epoch:  124\n",
      "Iteration: 9600. Loss: 2.009798526763916. Accuracy: 21.547643548055156\n",
      "Iteration: 9610. Loss: 2.0289306640625. Accuracy: 20.45688413253756\n",
      "Iteration: 9620. Loss: 2.013392210006714. Accuracy: 20.70384852850381\n",
      "Iteration: 9630. Loss: 2.085120677947998. Accuracy: 21.42416135007203\n",
      "Iteration: 9640. Loss: 1.9885683059692383. Accuracy: 20.683268162173288\n",
      "Iteration: 9650. Loss: 2.086111307144165. Accuracy: 20.950812924470057\n",
      "Iteration: 9660. Loss: 2.055540084838867. Accuracy: 20.4980448651986\n",
      "Iteration: 9670. Loss: 2.0630199909210205. Accuracy: 20.20991973657131\n",
      "Epoch:  125\n",
      "Iteration: 9680. Loss: 2.103715181350708. Accuracy: 20.580366330520683\n",
      "Iteration: 9690. Loss: 2.0233240127563477. Accuracy: 20.024696439596624\n",
      "Iteration: 9700. Loss: 2.0314414501190186. Accuracy: 20.86849145914797\n",
      "Iteration: 9710. Loss: 2.115018606185913. Accuracy: 20.621527063181723\n",
      "Iteration: 9720. Loss: 2.063018798828125. Accuracy: 20.4980448651986\n",
      "Iteration: 9730. Loss: 2.092912435531616. Accuracy: 19.222062152706318\n",
      "Iteration: 9740. Loss: 2.132495403289795. Accuracy: 20.41572339987652\n",
      "Iteration: 9750. Loss: 2.1253764629364014. Accuracy: 21.856349043012965\n",
      "Epoch:  126\n",
      "Iteration: 9760. Loss: 2.077266216278076. Accuracy: 21.197777320436305\n",
      "Iteration: 9770. Loss: 2.0420243740081787. Accuracy: 21.07429512245318\n",
      "Iteration: 9780. Loss: 2.0799036026000977. Accuracy: 20.74500926116485\n",
      "Iteration: 9790. Loss: 2.082307815551758. Accuracy: 22.226795636962336\n",
      "Iteration: 9800. Loss: 2.0828967094421387. Accuracy: 21.465322082733074\n",
      "Iteration: 9810. Loss: 1.9680203199386597. Accuracy: 21.506482815394115\n",
      "Iteration: 9820. Loss: 1.9673904180526733. Accuracy: 21.876929409343486\n",
      "Epoch:  127\n",
      "Iteration: 9830. Loss: 2.0323939323425293. Accuracy: 21.938670508335047\n",
      "Iteration: 9840. Loss: 2.064195156097412. Accuracy: 21.712286478699323\n",
      "Iteration: 9850. Loss: 2.0685830116271973. Accuracy: 21.280098785758387\n",
      "Iteration: 9860. Loss: 2.048217535018921. Accuracy: 21.218357686766826\n",
      "Iteration: 9870. Loss: 2.007504940032959. Accuracy: 21.17719695410578\n",
      "Iteration: 9880. Loss: 2.064502000808716. Accuracy: 20.82733072648693\n",
      "Iteration: 9890. Loss: 2.0472826957702637. Accuracy: 20.84791109281745\n",
      "Iteration: 9900. Loss: 2.1196751594543457. Accuracy: 21.05371475612266\n",
      "Epoch:  128\n",
      "Iteration: 9910. Loss: 2.0965681076049805. Accuracy: 20.72442889483433\n",
      "Iteration: 9920. Loss: 2.030911922454834. Accuracy: 20.20991973657131\n",
      "Iteration: 9930. Loss: 2.0409417152404785. Accuracy: 21.03313438979214\n",
      "Iteration: 9940. Loss: 2.0894417762756348. Accuracy: 20.642107429512244\n",
      "Iteration: 9950. Loss: 2.10058331489563. Accuracy: 20.662687795842768\n",
      "Iteration: 9960. Loss: 2.012118101119995. Accuracy: 21.40358098374151\n",
      "Iteration: 9970. Loss: 2.042879343032837. Accuracy: 21.40358098374151\n",
      "Iteration: 9980. Loss: 2.047639846801758. Accuracy: 21.609384647046717\n",
      "Epoch:  129\n",
      "Iteration: 9990. Loss: 2.0305838584899902. Accuracy: 21.753447211360363\n",
      "Iteration: 10000. Loss: 2.088432788848877. Accuracy: 21.11545585511422\n",
      "Iteration: 10010. Loss: 1.987547516822815. Accuracy: 21.774027577690884\n",
      "Iteration: 10020. Loss: 2.114365577697754. Accuracy: 21.938670508335047\n",
      "Iteration: 10030. Loss: 1.9820562601089478. Accuracy: 21.321259518419428\n",
      "Iteration: 10040. Loss: 2.006028175354004. Accuracy: 21.341839884749948\n",
      "Iteration: 10050. Loss: 2.0301644802093506. Accuracy: 20.991973657131098\n",
      "Iteration: 10060. Loss: 2.0955393314361572. Accuracy: 21.732866845029843\n",
      "Epoch:  130\n",
      "Iteration: 10070. Loss: 2.0018019676208496. Accuracy: 20.600946696851203\n",
      "Iteration: 10080. Loss: 2.0669336318969727. Accuracy: 21.218357686766826\n",
      "Iteration: 10090. Loss: 2.146892547607422. Accuracy: 21.835768676682445\n",
      "Iteration: 10100. Loss: 2.004497766494751. Accuracy: 21.341839884749948\n",
      "Iteration: 10110. Loss: 2.0130856037139893. Accuracy: 21.321259518419428\n",
      "Iteration: 10120. Loss: 2.1049387454986572. Accuracy: 21.774027577690884\n",
      "Iteration: 10130. Loss: 2.1128146648406982. Accuracy: 21.938670508335047\n",
      "Iteration: 10140. Loss: 2.024249792098999. Accuracy: 20.889071825478492\n",
      "Epoch:  131\n",
      "Iteration: 10150. Loss: 2.042598009109497. Accuracy: 21.835768676682445\n",
      "Iteration: 10160. Loss: 1.9907132387161255. Accuracy: 21.40358098374151\n",
      "Iteration: 10170. Loss: 2.043992757797241. Accuracy: 20.82733072648693\n",
      "Iteration: 10180. Loss: 2.0687241554260254. Accuracy: 21.650545379707758\n",
      "Iteration: 10190. Loss: 2.025682210922241. Accuracy: 21.97983124099609\n",
      "Iteration: 10200. Loss: 2.0264296531677246. Accuracy: 22.123893805309734\n",
      "Iteration: 10210. Loss: 2.021331310272217. Accuracy: 21.300679152088907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  132\n",
      "Iteration: 10220. Loss: 2.019340753555298. Accuracy: 21.67112574603828\n",
      "Iteration: 10230. Loss: 2.0262038707733154. Accuracy: 21.218357686766826\n",
      "Iteration: 10240. Loss: 2.0502774715423584. Accuracy: 21.38300061741099\n",
      "Iteration: 10250. Loss: 1.9752607345581055. Accuracy: 21.568223914385676\n",
      "Iteration: 10260. Loss: 2.0956978797912598. Accuracy: 20.971393290800577\n",
      "Iteration: 10270. Loss: 1.9817239046096802. Accuracy: 20.559785964190162\n",
      "Iteration: 10280. Loss: 2.0496933460235596. Accuracy: 20.580366330520683\n",
      "Iteration: 10290. Loss: 1.9664353132247925. Accuracy: 20.72442889483433\n",
      "Epoch:  133\n",
      "Iteration: 10300. Loss: 2.053462028503418. Accuracy: 21.238938053097346\n",
      "Iteration: 10310. Loss: 2.099984884262085. Accuracy: 21.0948754887837\n",
      "Iteration: 10320. Loss: 2.0155279636383057. Accuracy: 20.86849145914797\n",
      "Iteration: 10330. Loss: 2.0433833599090576. Accuracy: 20.312821568223914\n",
      "Iteration: 10340. Loss: 2.1596920490264893. Accuracy: 20.80675036015641\n",
      "Iteration: 10350. Loss: 2.011384963989258. Accuracy: 20.950812924470057\n",
      "Iteration: 10360. Loss: 2.0525128841400146. Accuracy: 21.42416135007203\n",
      "Iteration: 10370. Loss: 2.122857093811035. Accuracy: 20.84791109281745\n",
      "Epoch:  134\n",
      "Iteration: 10380. Loss: 2.016639232635498. Accuracy: 20.374562667215475\n",
      "Iteration: 10390. Loss: 2.098400831222534. Accuracy: 21.218357686766826\n",
      "Iteration: 10400. Loss: 2.034733295440674. Accuracy: 20.86849145914797\n",
      "Iteration: 10410. Loss: 2.0177810192108154. Accuracy: 21.280098785758387\n",
      "Iteration: 10420. Loss: 2.0401864051818848. Accuracy: 21.280098785758387\n",
      "Iteration: 10430. Loss: 2.137594699859619. Accuracy: 21.36242025108047\n",
      "Iteration: 10440. Loss: 1.9817516803741455. Accuracy: 20.889071825478492\n",
      "Iteration: 10450. Loss: 2.0799288749694824. Accuracy: 20.621527063181723\n",
      "Epoch:  135\n",
      "Iteration: 10460. Loss: 2.0600264072418213. Accuracy: 20.18933937024079\n",
      "Iteration: 10470. Loss: 2.0987043380737305. Accuracy: 20.600946696851203\n",
      "Iteration: 10480. Loss: 2.09586501121521. Accuracy: 20.395143033546\n",
      "Iteration: 10490. Loss: 2.106088399887085. Accuracy: 21.712286478699323\n",
      "Iteration: 10500. Loss: 1.9995025396347046. Accuracy: 22.000411607326612\n",
      "Iteration: 10510. Loss: 2.02565336227417. Accuracy: 21.11545585511422\n",
      "Iteration: 10520. Loss: 2.063839912414551. Accuracy: 20.950812924470057\n",
      "Iteration: 10530. Loss: 1.9760781526565552. Accuracy: 20.70384852850381\n",
      "Epoch:  136\n",
      "Iteration: 10540. Loss: 2.0643908977508545. Accuracy: 21.012554023461618\n",
      "Iteration: 10550. Loss: 2.080603837966919. Accuracy: 20.580366330520683\n",
      "Iteration: 10560. Loss: 2.1292531490325928. Accuracy: 21.547643548055156\n",
      "Iteration: 10570. Loss: 2.032238483428955. Accuracy: 21.527063181724635\n",
      "Iteration: 10580. Loss: 2.0150344371795654. Accuracy: 21.40358098374151\n",
      "Iteration: 10590. Loss: 2.040719985961914. Accuracy: 21.05371475612266\n",
      "Iteration: 10600. Loss: 2.0585412979125977. Accuracy: 21.321259518419428\n",
      "Epoch:  137\n",
      "Iteration: 10610. Loss: 2.0738625526428223. Accuracy: 20.70384852850381\n",
      "Iteration: 10620. Loss: 2.036254405975342. Accuracy: 21.280098785758387\n",
      "Iteration: 10630. Loss: 2.031789541244507. Accuracy: 21.05371475612266\n",
      "Iteration: 10640. Loss: 2.0662224292755127. Accuracy: 20.580366330520683\n",
      "Iteration: 10650. Loss: 2.0790324211120605. Accuracy: 20.84791109281745\n",
      "Iteration: 10660. Loss: 2.0934031009674072. Accuracy: 20.642107429512244\n",
      "Iteration: 10670. Loss: 1.95087730884552. Accuracy: 20.642107429512244\n",
      "Iteration: 10680. Loss: 2.074429988861084. Accuracy: 19.88063387528298\n",
      "Epoch:  138\n",
      "Iteration: 10690. Loss: 2.028740644454956. Accuracy: 21.341839884749948\n",
      "Iteration: 10700. Loss: 2.10770845413208. Accuracy: 21.012554023461618\n",
      "Iteration: 10710. Loss: 2.014303207397461. Accuracy: 21.732866845029843\n",
      "Iteration: 10720. Loss: 2.049837350845337. Accuracy: 20.72442889483433\n",
      "Iteration: 10730. Loss: 2.0737366676330566. Accuracy: 21.0948754887837\n",
      "Iteration: 10740. Loss: 2.115391492843628. Accuracy: 21.341839884749948\n",
      "Iteration: 10750. Loss: 2.024043083190918. Accuracy: 21.0948754887837\n",
      "Iteration: 10760. Loss: 2.0266411304473877. Accuracy: 21.05371475612266\n",
      "Epoch:  139\n",
      "Iteration: 10770. Loss: 2.1248180866241455. Accuracy: 20.47746449886808\n",
      "Iteration: 10780. Loss: 1.9938100576400757. Accuracy: 20.51862523152912\n",
      "Iteration: 10790. Loss: 2.064833402633667. Accuracy: 21.218357686766826\n",
      "Iteration: 10800. Loss: 2.0503201484680176. Accuracy: 20.930232558139537\n",
      "Iteration: 10810. Loss: 2.0026943683624268. Accuracy: 20.4980448651986\n",
      "Iteration: 10820. Loss: 2.0699543952941895. Accuracy: 21.03313438979214\n",
      "Iteration: 10830. Loss: 2.0436770915985107. Accuracy: 20.74500926116485\n",
      "Iteration: 10840. Loss: 2.07658052444458. Accuracy: 20.41572339987652\n",
      "Epoch:  140\n",
      "Iteration: 10850. Loss: 2.0359251499176025. Accuracy: 20.086437538588186\n",
      "Iteration: 10860. Loss: 2.0179738998413086. Accuracy: 20.84791109281745\n",
      "Iteration: 10870. Loss: 2.0623385906219482. Accuracy: 20.45688413253756\n",
      "Iteration: 10880. Loss: 2.0913469791412354. Accuracy: 20.600946696851203\n",
      "Iteration: 10890. Loss: 2.067340135574341. Accuracy: 21.11545585511422\n",
      "Iteration: 10900. Loss: 2.065558671951294. Accuracy: 20.86849145914797\n",
      "Iteration: 10910. Loss: 2.0158939361572266. Accuracy: 20.76558962749537\n",
      "Iteration: 10920. Loss: 2.0094358921051025. Accuracy: 21.197777320436305\n",
      "Epoch:  141\n",
      "Iteration: 10930. Loss: 2.081739902496338. Accuracy: 20.70384852850381\n",
      "Iteration: 10940. Loss: 2.048159122467041. Accuracy: 21.0948754887837\n",
      "Iteration: 10950. Loss: 2.115657329559326. Accuracy: 20.950812924470057\n",
      "Iteration: 10960. Loss: 2.0832760334014893. Accuracy: 20.683268162173288\n",
      "Iteration: 10970. Loss: 2.0679714679718018. Accuracy: 20.47746449886808\n",
      "Iteration: 10980. Loss: 2.089402437210083. Accuracy: 19.983535706935584\n",
      "Iteration: 10990. Loss: 2.0293734073638916. Accuracy: 20.20991973657131\n",
      "Epoch:  142\n",
      "Iteration: 11000. Loss: 2.037076234817505. Accuracy: 20.84791109281745\n",
      "Iteration: 11010. Loss: 2.2130208015441895. Accuracy: 21.012554023461618\n",
      "Iteration: 11020. Loss: 2.1451027393341064. Accuracy: 22.103313438979214\n",
      "Iteration: 11030. Loss: 2.0815589427948. Accuracy: 19.839473142621937\n",
      "Iteration: 11040. Loss: 2.1331214904785156. Accuracy: 21.38300061741099\n",
      "Iteration: 11050. Loss: 2.046661853790283. Accuracy: 20.74500926116485\n",
      "Iteration: 11060. Loss: 2.0077786445617676. Accuracy: 21.341839884749948\n",
      "Iteration: 11070. Loss: 2.067579746246338. Accuracy: 21.465322082733074\n",
      "Epoch:  143\n",
      "Iteration: 11080. Loss: 2.100382089614868. Accuracy: 19.736571310969335\n",
      "Iteration: 11090. Loss: 2.044393301010132. Accuracy: 20.600946696851203\n",
      "Iteration: 11100. Loss: 2.0173280239105225. Accuracy: 19.860053508952458\n",
      "Iteration: 11110. Loss: 2.126544952392578. Accuracy: 20.51862523152912\n",
      "Iteration: 11120. Loss: 2.028001308441162. Accuracy: 21.218357686766826\n",
      "Iteration: 11130. Loss: 2.0911309719085693. Accuracy: 20.642107429512244\n",
      "Iteration: 11140. Loss: 2.0581226348876953. Accuracy: 20.16875900391027\n",
      "Iteration: 11150. Loss: 2.062164068222046. Accuracy: 20.18933937024079\n",
      "Epoch:  144\n",
      "Iteration: 11160. Loss: 2.0599496364593506. Accuracy: 20.683268162173288\n",
      "Iteration: 11170. Loss: 2.1353752613067627. Accuracy: 20.353982300884955\n",
      "Iteration: 11180. Loss: 2.051973342895508. Accuracy: 20.353982300884955\n",
      "Iteration: 11190. Loss: 2.1679375171661377. Accuracy: 20.004116073266104\n",
      "Iteration: 11200. Loss: 2.0629172325134277. Accuracy: 20.271660835562873\n",
      "Iteration: 11210. Loss: 2.07072377204895. Accuracy: 20.45688413253756\n",
      "Iteration: 11220. Loss: 2.0717835426330566. Accuracy: 20.82733072648693\n",
      "Iteration: 11230. Loss: 2.1454174518585205. Accuracy: 19.921794607944022\n",
      "Epoch:  145\n",
      "Iteration: 11240. Loss: 2.11356520652771. Accuracy: 20.271660835562873\n",
      "Iteration: 11250. Loss: 2.0430748462677. Accuracy: 20.333401934554434\n",
      "Iteration: 11260. Loss: 2.0103743076324463. Accuracy: 21.012554023461618\n",
      "Iteration: 11270. Loss: 2.0998408794403076. Accuracy: 20.683268162173288\n",
      "Iteration: 11280. Loss: 2.086625099182129. Accuracy: 20.53920559785964\n",
      "Iteration: 11290. Loss: 2.0825719833374023. Accuracy: 20.18933937024079\n",
      "Iteration: 11300. Loss: 2.105196475982666. Accuracy: 20.14817863757975\n",
      "Iteration: 11310. Loss: 2.054053783416748. Accuracy: 20.78616999382589\n",
      "Epoch:  146\n",
      "Iteration: 11320. Loss: 2.0793251991271973. Accuracy: 20.271660835562873\n",
      "Iteration: 11330. Loss: 2.089374303817749. Accuracy: 19.3043836180284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11340. Loss: 2.0518243312835693. Accuracy: 19.57192838032517\n",
      "Iteration: 11350. Loss: 2.030020236968994. Accuracy: 20.930232558139537\n",
      "Iteration: 11360. Loss: 2.06306529045105. Accuracy: 21.17719695410578\n",
      "Iteration: 11370. Loss: 2.069193124771118. Accuracy: 20.065857172257665\n",
      "Iteration: 11380. Loss: 2.0450263023376465. Accuracy: 20.70384852850381\n",
      "Epoch:  147\n",
      "Iteration: 11390. Loss: 2.0596086978912354. Accuracy: 20.271660835562873\n",
      "Iteration: 11400. Loss: 2.0691561698913574. Accuracy: 20.642107429512244\n",
      "Iteration: 11410. Loss: 2.1050190925598145. Accuracy: 21.03313438979214\n",
      "Iteration: 11420. Loss: 2.048875570297241. Accuracy: 20.70384852850381\n",
      "Iteration: 11430. Loss: 2.079634189605713. Accuracy: 20.930232558139537\n",
      "Iteration: 11440. Loss: 2.0864455699920654. Accuracy: 20.086437538588186\n",
      "Iteration: 11450. Loss: 2.0957133769989014. Accuracy: 20.53920559785964\n",
      "Iteration: 11460. Loss: 2.0630791187286377. Accuracy: 21.44474171640255\n",
      "Epoch:  148\n",
      "Iteration: 11470. Loss: 2.0484302043914795. Accuracy: 21.259518419427867\n",
      "Iteration: 11480. Loss: 2.025811195373535. Accuracy: 21.238938053097346\n",
      "Iteration: 11490. Loss: 2.1101131439208984. Accuracy: 20.559785964190162\n",
      "Iteration: 11500. Loss: 2.0777344703674316. Accuracy: 20.4980448651986\n",
      "Iteration: 11510. Loss: 2.0503323078155518. Accuracy: 20.971393290800577\n",
      "Iteration: 11520. Loss: 2.0331974029541016. Accuracy: 20.84791109281745\n",
      "Iteration: 11530. Loss: 2.0538549423217773. Accuracy: 20.086437538588186\n",
      "Iteration: 11540. Loss: 2.0436460971832275. Accuracy: 20.271660835562873\n",
      "Epoch:  149\n",
      "Iteration: 11550. Loss: 2.1124107837677. Accuracy: 20.70384852850381\n",
      "Iteration: 11560. Loss: 2.069302558898926. Accuracy: 20.82733072648693\n",
      "Iteration: 11570. Loss: 2.045276641845703. Accuracy: 20.971393290800577\n",
      "Iteration: 11580. Loss: 2.0543458461761475. Accuracy: 20.086437538588186\n",
      "Iteration: 11590. Loss: 2.085817337036133. Accuracy: 20.909652191809013\n",
      "Iteration: 11600. Loss: 2.074439287185669. Accuracy: 20.127598271249227\n",
      "Iteration: 11610. Loss: 2.1081418991088867. Accuracy: 20.621527063181723\n",
      "Iteration: 11620. Loss: 2.118764638900757. Accuracy: 20.662687795842768\n",
      "Epoch:  150\n",
      "Iteration: 11630. Loss: 2.0920956134796143. Accuracy: 20.53920559785964\n",
      "Iteration: 11640. Loss: 2.070909023284912. Accuracy: 20.600946696851203\n",
      "Iteration: 11650. Loss: 1.9905418157577515. Accuracy: 20.971393290800577\n",
      "Iteration: 11660. Loss: 2.107008218765259. Accuracy: 19.88063387528298\n",
      "Iteration: 11670. Loss: 2.053764581680298. Accuracy: 21.15661658777526\n",
      "Iteration: 11680. Loss: 2.147305727005005. Accuracy: 20.14817863757975\n",
      "Iteration: 11690. Loss: 2.044398784637451. Accuracy: 20.78616999382589\n",
      "Iteration: 11700. Loss: 2.0463545322418213. Accuracy: 20.353982300884955\n",
      "Epoch:  151\n",
      "Iteration: 11710. Loss: 2.071319580078125. Accuracy: 19.695410578308294\n",
      "Iteration: 11720. Loss: 2.020890951156616. Accuracy: 20.53920559785964\n",
      "Iteration: 11730. Loss: 2.0686452388763428. Accuracy: 20.86849145914797\n",
      "Iteration: 11740. Loss: 2.0758893489837646. Accuracy: 20.086437538588186\n",
      "Iteration: 11750. Loss: 2.0291621685028076. Accuracy: 20.82733072648693\n",
      "Iteration: 11760. Loss: 2.067018747329712. Accuracy: 20.971393290800577\n",
      "Iteration: 11770. Loss: 2.082867383956909. Accuracy: 21.13603622144474\n",
      "Epoch:  152\n",
      "Iteration: 11780. Loss: 2.050605297088623. Accuracy: 20.642107429512244\n",
      "Iteration: 11790. Loss: 2.01916241645813. Accuracy: 21.465322082733074\n",
      "Iteration: 11800. Loss: 2.033704996109009. Accuracy: 20.683268162173288\n",
      "Iteration: 11810. Loss: 2.115612506866455. Accuracy: 21.17719695410578\n",
      "Iteration: 11820. Loss: 2.1057159900665283. Accuracy: 20.47746449886808\n",
      "Iteration: 11830. Loss: 2.0574278831481934. Accuracy: 19.613089112986213\n",
      "Iteration: 11840. Loss: 2.0525894165039062. Accuracy: 20.621527063181723\n",
      "Iteration: 11850. Loss: 2.091665267944336. Accuracy: 20.78616999382589\n",
      "Epoch:  153\n",
      "Iteration: 11860. Loss: 1.981485366821289. Accuracy: 20.395143033546\n",
      "Iteration: 11870. Loss: 2.0778543949127197. Accuracy: 20.662687795842768\n",
      "Iteration: 11880. Loss: 2.136134624481201. Accuracy: 20.51862523152912\n",
      "Iteration: 11890. Loss: 2.0572280883789062. Accuracy: 21.07429512245318\n",
      "Iteration: 11900. Loss: 2.1012635231018066. Accuracy: 20.971393290800577\n",
      "Iteration: 11910. Loss: 2.090118169784546. Accuracy: 21.42416135007203\n",
      "Iteration: 11920. Loss: 2.039314031600952. Accuracy: 20.991973657131098\n",
      "Iteration: 11930. Loss: 2.082228899002075. Accuracy: 20.82733072648693\n",
      "Epoch:  154\n",
      "Iteration: 11940. Loss: 2.0353498458862305. Accuracy: 19.674830211977774\n",
      "Iteration: 11950. Loss: 2.0411531925201416. Accuracy: 20.18933937024079\n",
      "Iteration: 11960. Loss: 2.079798936843872. Accuracy: 20.395143033546\n",
      "Iteration: 11970. Loss: 2.138746738433838. Accuracy: 20.41572339987652\n",
      "Iteration: 11980. Loss: 2.1015894412994385. Accuracy: 19.715990944638815\n",
      "Iteration: 11990. Loss: 2.020189046859741. Accuracy: 20.127598271249227\n",
      "Iteration: 12000. Loss: 2.0978665351867676. Accuracy: 21.03313438979214\n",
      "Iteration: 12010. Loss: 2.0638513565063477. Accuracy: 21.17719695410578\n",
      "Epoch:  155\n",
      "Iteration: 12020. Loss: 2.095452070236206. Accuracy: 21.012554023461618\n",
      "Iteration: 12030. Loss: 2.0450024604797363. Accuracy: 20.559785964190162\n",
      "Iteration: 12040. Loss: 2.070849895477295. Accuracy: 21.05371475612266\n",
      "Iteration: 12050. Loss: 2.0837786197662354. Accuracy: 20.74500926116485\n",
      "Iteration: 12060. Loss: 2.0551319122314453. Accuracy: 20.662687795842768\n",
      "Iteration: 12070. Loss: 2.187486410140991. Accuracy: 20.045276805927145\n",
      "Iteration: 12080. Loss: 2.1303517818450928. Accuracy: 19.901214241613502\n",
      "Iteration: 12090. Loss: 2.1313703060150146. Accuracy: 20.18933937024079\n",
      "Epoch:  156\n",
      "Iteration: 12100. Loss: 2.045135736465454. Accuracy: 19.633669479316733\n",
      "Iteration: 12110. Loss: 2.1060221195220947. Accuracy: 20.559785964190162\n",
      "Iteration: 12120. Loss: 2.051619291305542. Accuracy: 20.642107429512244\n",
      "Iteration: 12130. Loss: 2.1030361652374268. Accuracy: 20.4980448651986\n",
      "Iteration: 12140. Loss: 2.0870935916900635. Accuracy: 21.280098785758387\n",
      "Iteration: 12150. Loss: 2.0574357509613037. Accuracy: 20.971393290800577\n",
      "Iteration: 12160. Loss: 2.0579142570495605. Accuracy: 20.662687795842768\n",
      "Epoch:  157\n",
      "Iteration: 12170. Loss: 2.037224292755127. Accuracy: 21.42416135007203\n",
      "Iteration: 12180. Loss: 2.087308406829834. Accuracy: 19.942374974274543\n",
      "Iteration: 12190. Loss: 2.0854969024658203. Accuracy: 19.983535706935584\n",
      "Iteration: 12200. Loss: 2.0914466381073. Accuracy: 20.74500926116485\n",
      "Iteration: 12210. Loss: 2.056608200073242. Accuracy: 20.374562667215475\n",
      "Iteration: 12220. Loss: 2.1015119552612305. Accuracy: 20.47746449886808\n",
      "Iteration: 12230. Loss: 2.087106466293335. Accuracy: 20.230500102901832\n",
      "Iteration: 12240. Loss: 2.055229425430298. Accuracy: 20.374562667215475\n",
      "Epoch:  158\n",
      "Iteration: 12250. Loss: 2.117112398147583. Accuracy: 20.74500926116485\n",
      "Iteration: 12260. Loss: 2.0604031085968018. Accuracy: 20.53920559785964\n",
      "Iteration: 12270. Loss: 2.0737597942352295. Accuracy: 20.127598271249227\n",
      "Iteration: 12280. Loss: 2.10029673576355. Accuracy: 21.15661658777526\n",
      "Iteration: 12290. Loss: 2.0439794063568115. Accuracy: 20.991973657131098\n",
      "Iteration: 12300. Loss: 2.0593223571777344. Accuracy: 20.580366330520683\n",
      "Iteration: 12310. Loss: 2.0931403636932373. Accuracy: 20.251080469232352\n",
      "Iteration: 12320. Loss: 2.0808582305908203. Accuracy: 20.4980448651986\n",
      "Epoch:  159\n",
      "Iteration: 12330. Loss: 2.012953758239746. Accuracy: 20.51862523152912\n",
      "Iteration: 12340. Loss: 2.084916353225708. Accuracy: 20.84791109281745\n",
      "Iteration: 12350. Loss: 2.0525741577148438. Accuracy: 20.353982300884955\n",
      "Iteration: 12360. Loss: 2.1171834468841553. Accuracy: 21.11545585511422\n",
      "Iteration: 12370. Loss: 2.0891740322113037. Accuracy: 21.321259518419428\n",
      "Iteration: 12380. Loss: 2.143538236618042. Accuracy: 20.889071825478492\n",
      "Iteration: 12390. Loss: 2.059246778488159. Accuracy: 21.05371475612266\n",
      "Iteration: 12400. Loss: 2.1000072956085205. Accuracy: 19.921794607944022\n",
      "Epoch:  160\n",
      "Iteration: 12410. Loss: 2.093855381011963. Accuracy: 20.45688413253756\n",
      "Iteration: 12420. Loss: 2.1690187454223633. Accuracy: 20.353982300884955\n",
      "Iteration: 12430. Loss: 2.05204439163208. Accuracy: 20.909652191809013\n",
      "Iteration: 12440. Loss: 2.0588858127593994. Accuracy: 19.839473142621937\n",
      "Iteration: 12450. Loss: 2.105154514312744. Accuracy: 20.70384852850381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12460. Loss: 2.1157209873199463. Accuracy: 20.16875900391027\n",
      "Iteration: 12470. Loss: 2.077383518218994. Accuracy: 19.983535706935584\n",
      "Iteration: 12480. Loss: 2.078815221786499. Accuracy: 21.012554023461618\n",
      "Epoch:  161\n",
      "Iteration: 12490. Loss: 2.0605812072753906. Accuracy: 21.07429512245318\n",
      "Iteration: 12500. Loss: 2.085608720779419. Accuracy: 20.930232558139537\n",
      "Iteration: 12510. Loss: 2.0195093154907227. Accuracy: 21.05371475612266\n",
      "Iteration: 12520. Loss: 2.0807032585144043. Accuracy: 21.012554023461618\n",
      "Iteration: 12530. Loss: 2.0596189498901367. Accuracy: 20.559785964190162\n",
      "Iteration: 12540. Loss: 2.0631823539733887. Accuracy: 20.271660835562873\n",
      "Iteration: 12550. Loss: 2.0341150760650635. Accuracy: 20.683268162173288\n",
      "Epoch:  162\n",
      "Iteration: 12560. Loss: 2.1114134788513184. Accuracy: 21.03313438979214\n",
      "Iteration: 12570. Loss: 2.0529136657714844. Accuracy: 19.386705083350485\n",
      "Iteration: 12580. Loss: 2.1168932914733887. Accuracy: 20.024696439596624\n",
      "Iteration: 12590. Loss: 2.167465925216675. Accuracy: 20.065857172257665\n",
      "Iteration: 12600. Loss: 2.1353957653045654. Accuracy: 19.860053508952458\n",
      "Iteration: 12610. Loss: 2.0773284435272217. Accuracy: 20.395143033546\n",
      "Iteration: 12620. Loss: 2.089003562927246. Accuracy: 20.74500926116485\n",
      "Iteration: 12630. Loss: 2.030484199523926. Accuracy: 20.82733072648693\n",
      "Epoch:  163\n",
      "Iteration: 12640. Loss: 2.0425987243652344. Accuracy: 20.621527063181723\n",
      "Iteration: 12650. Loss: 2.0536608695983887. Accuracy: 20.20991973657131\n",
      "Iteration: 12660. Loss: 2.067845344543457. Accuracy: 20.395143033546\n",
      "Iteration: 12670. Loss: 2.0463807582855225. Accuracy: 20.662687795842768\n",
      "Iteration: 12680. Loss: 2.0716543197631836. Accuracy: 20.74500926116485\n",
      "Iteration: 12690. Loss: 2.0591132640838623. Accuracy: 20.18933937024079\n",
      "Iteration: 12700. Loss: 2.034383535385132. Accuracy: 20.024696439596624\n",
      "Iteration: 12710. Loss: 2.0743181705474854. Accuracy: 20.292241201893393\n",
      "Epoch:  164\n",
      "Iteration: 12720. Loss: 2.09074330329895. Accuracy: 20.065857172257665\n",
      "Iteration: 12730. Loss: 2.1069717407226562. Accuracy: 20.930232558139537\n",
      "Iteration: 12740. Loss: 2.113640785217285. Accuracy: 20.74500926116485\n",
      "Iteration: 12750. Loss: 2.0386834144592285. Accuracy: 20.662687795842768\n",
      "Iteration: 12760. Loss: 2.1568164825439453. Accuracy: 20.353982300884955\n",
      "Iteration: 12770. Loss: 2.1523802280426025. Accuracy: 20.45688413253756\n",
      "Iteration: 12780. Loss: 2.1084539890289307. Accuracy: 20.065857172257665\n",
      "Iteration: 12790. Loss: 2.05423641204834. Accuracy: 19.427865816011526\n",
      "Epoch:  165\n",
      "Iteration: 12800. Loss: 2.06392765045166. Accuracy: 20.333401934554434\n",
      "Iteration: 12810. Loss: 2.0309622287750244. Accuracy: 20.045276805927145\n",
      "Iteration: 12820. Loss: 2.0652499198913574. Accuracy: 20.683268162173288\n",
      "Iteration: 12830. Loss: 2.0769107341766357. Accuracy: 20.45688413253756\n",
      "Iteration: 12840. Loss: 1.9658437967300415. Accuracy: 20.16875900391027\n",
      "Iteration: 12850. Loss: 2.154625654220581. Accuracy: 21.0948754887837\n",
      "Iteration: 12860. Loss: 2.137850284576416. Accuracy: 20.662687795842768\n",
      "Iteration: 12870. Loss: 2.2185871601104736. Accuracy: 20.86849145914797\n",
      "Epoch:  166\n",
      "Iteration: 12880. Loss: 2.054004192352295. Accuracy: 20.43630376620704\n",
      "Iteration: 12890. Loss: 2.0401875972747803. Accuracy: 21.13603622144474\n",
      "Iteration: 12900. Loss: 2.122962713241577. Accuracy: 20.80675036015641\n",
      "Iteration: 12910. Loss: 2.0097527503967285. Accuracy: 20.43630376620704\n",
      "Iteration: 12920. Loss: 2.0661511421203613. Accuracy: 20.80675036015641\n",
      "Iteration: 12930. Loss: 2.054466485977173. Accuracy: 20.45688413253756\n",
      "Iteration: 12940. Loss: 2.0436525344848633. Accuracy: 20.76558962749537\n",
      "Epoch:  167\n",
      "Iteration: 12950. Loss: 2.063661575317383. Accuracy: 20.70384852850381\n",
      "Iteration: 12960. Loss: 2.0410499572753906. Accuracy: 20.72442889483433\n",
      "Iteration: 12970. Loss: 2.0388402938842773. Accuracy: 20.580366330520683\n",
      "Iteration: 12980. Loss: 2.1052844524383545. Accuracy: 21.259518419427867\n",
      "Iteration: 12990. Loss: 2.0286996364593506. Accuracy: 20.271660835562873\n",
      "Iteration: 13000. Loss: 2.091090679168701. Accuracy: 20.74500926116485\n",
      "Iteration: 13010. Loss: 2.064765691757202. Accuracy: 20.271660835562873\n",
      "Iteration: 13020. Loss: 2.031015634536743. Accuracy: 20.004116073266104\n",
      "Epoch:  168\n",
      "Iteration: 13030. Loss: 2.0282294750213623. Accuracy: 20.950812924470057\n",
      "Iteration: 13040. Loss: 2.090468168258667. Accuracy: 20.374562667215475\n",
      "Iteration: 13050. Loss: 2.0867199897766113. Accuracy: 20.086437538588186\n",
      "Iteration: 13060. Loss: 1.9838703870773315. Accuracy: 20.271660835562873\n",
      "Iteration: 13070. Loss: 2.0159080028533936. Accuracy: 20.43630376620704\n",
      "Iteration: 13080. Loss: 2.037726879119873. Accuracy: 20.107017904918706\n",
      "Iteration: 13090. Loss: 2.0636045932769775. Accuracy: 20.251080469232352\n",
      "Iteration: 13100. Loss: 2.083144426345825. Accuracy: 20.230500102901832\n",
      "Epoch:  169\n",
      "Iteration: 13110. Loss: 2.0483386516571045. Accuracy: 20.41572339987652\n",
      "Iteration: 13120. Loss: 2.0632054805755615. Accuracy: 21.11545585511422\n",
      "Iteration: 13130. Loss: 2.078608512878418. Accuracy: 20.950812924470057\n",
      "Iteration: 13140. Loss: 2.04909086227417. Accuracy: 20.004116073266104\n",
      "Iteration: 13150. Loss: 2.1067042350769043. Accuracy: 20.78616999382589\n",
      "Iteration: 13160. Loss: 2.0886998176574707. Accuracy: 20.230500102901832\n",
      "Iteration: 13170. Loss: 2.12709641456604. Accuracy: 20.20991973657131\n",
      "Iteration: 13180. Loss: 2.113830804824829. Accuracy: 20.78616999382589\n",
      "Epoch:  170\n",
      "Iteration: 13190. Loss: 2.1129677295684814. Accuracy: 19.901214241613502\n",
      "Iteration: 13200. Loss: 2.0851004123687744. Accuracy: 20.74500926116485\n",
      "Iteration: 13210. Loss: 2.0537140369415283. Accuracy: 20.18933937024079\n",
      "Iteration: 13220. Loss: 2.0514185428619385. Accuracy: 20.683268162173288\n",
      "Iteration: 13230. Loss: 2.100783348083496. Accuracy: 20.4980448651986\n",
      "Iteration: 13240. Loss: 2.0250656604766846. Accuracy: 20.20991973657131\n",
      "Iteration: 13250. Loss: 2.0528759956359863. Accuracy: 20.374562667215475\n",
      "Iteration: 13260. Loss: 2.076970338821411. Accuracy: 20.024696439596624\n",
      "Epoch:  171\n",
      "Iteration: 13270. Loss: 2.004849433898926. Accuracy: 20.20991973657131\n",
      "Iteration: 13280. Loss: 2.027724027633667. Accuracy: 20.353982300884955\n",
      "Iteration: 13290. Loss: 2.080371618270874. Accuracy: 20.43630376620704\n",
      "Iteration: 13300. Loss: 2.0849454402923584. Accuracy: 20.78616999382589\n",
      "Iteration: 13310. Loss: 2.1383681297302246. Accuracy: 20.642107429512244\n",
      "Iteration: 13320. Loss: 2.1134767532348633. Accuracy: 19.407285449681005\n",
      "Iteration: 13330. Loss: 2.044616222381592. Accuracy: 20.004116073266104\n",
      "Epoch:  172\n",
      "Iteration: 13340. Loss: 2.094379186630249. Accuracy: 18.892776291417988\n",
      "Iteration: 13350. Loss: 2.0602657794952393. Accuracy: 20.292241201893393\n",
      "Iteration: 13360. Loss: 1.9984004497528076. Accuracy: 20.991973657131098\n",
      "Iteration: 13370. Loss: 2.0374794006347656. Accuracy: 20.41572339987652\n",
      "Iteration: 13380. Loss: 2.0551865100860596. Accuracy: 20.4980448651986\n",
      "Iteration: 13390. Loss: 2.080798625946045. Accuracy: 21.13603622144474\n",
      "Iteration: 13400. Loss: 2.1626033782958984. Accuracy: 20.230500102901832\n",
      "Iteration: 13410. Loss: 2.0508365631103516. Accuracy: 19.510187281333607\n",
      "Epoch:  173\n",
      "Iteration: 13420. Loss: 2.030224084854126. Accuracy: 20.621527063181723\n",
      "Iteration: 13430. Loss: 2.077840566635132. Accuracy: 20.353982300884955\n",
      "Iteration: 13440. Loss: 2.016895294189453. Accuracy: 20.16875900391027\n",
      "Iteration: 13450. Loss: 2.053668260574341. Accuracy: 21.03313438979214\n",
      "Iteration: 13460. Loss: 2.1437857151031494. Accuracy: 20.14817863757975\n",
      "Iteration: 13470. Loss: 2.0618770122528076. Accuracy: 19.736571310969335\n",
      "Iteration: 13480. Loss: 2.0293211936950684. Accuracy: 20.230500102901832\n",
      "Iteration: 13490. Loss: 2.052915573120117. Accuracy: 20.84791109281745\n",
      "Epoch:  174\n",
      "Iteration: 13500. Loss: 2.059502601623535. Accuracy: 20.80675036015641\n",
      "Iteration: 13510. Loss: 2.0573320388793945. Accuracy: 19.860053508952458\n",
      "Iteration: 13520. Loss: 2.0887677669525146. Accuracy: 20.41572339987652\n",
      "Iteration: 13530. Loss: 2.1035757064819336. Accuracy: 20.78616999382589\n",
      "Iteration: 13540. Loss: 2.101310968399048. Accuracy: 20.53920559785964\n",
      "Iteration: 13550. Loss: 2.0823183059692383. Accuracy: 19.983535706935584\n",
      "Iteration: 13560. Loss: 2.085745096206665. Accuracy: 20.20991973657131\n",
      "Iteration: 13570. Loss: 2.0303964614868164. Accuracy: 20.353982300884955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  175\n",
      "Iteration: 13580. Loss: 2.0857250690460205. Accuracy: 20.642107429512244\n",
      "Iteration: 13590. Loss: 2.007991075515747. Accuracy: 20.51862523152912\n",
      "Iteration: 13600. Loss: 2.0188980102539062. Accuracy: 19.983535706935584\n",
      "Iteration: 13610. Loss: 2.0899417400360107. Accuracy: 20.74500926116485\n",
      "Iteration: 13620. Loss: 2.095961093902588. Accuracy: 20.642107429512244\n",
      "Iteration: 13630. Loss: 2.114492416381836. Accuracy: 20.333401934554434\n",
      "Iteration: 13640. Loss: 2.0107614994049072. Accuracy: 20.065857172257665\n",
      "Iteration: 13650. Loss: 2.0516960620880127. Accuracy: 20.889071825478492\n",
      "Epoch:  176\n",
      "Iteration: 13660. Loss: 2.022587299346924. Accuracy: 20.53920559785964\n",
      "Iteration: 13670. Loss: 2.0709261894226074. Accuracy: 20.991973657131098\n",
      "Iteration: 13680. Loss: 2.1374197006225586. Accuracy: 20.600946696851203\n",
      "Iteration: 13690. Loss: 2.057224750518799. Accuracy: 20.107017904918706\n",
      "Iteration: 13700. Loss: 2.124976634979248. Accuracy: 20.14817863757975\n",
      "Iteration: 13710. Loss: 2.021336555480957. Accuracy: 20.374562667215475\n",
      "Iteration: 13720. Loss: 1.999626636505127. Accuracy: 20.086437538588186\n",
      "Epoch:  177\n",
      "Iteration: 13730. Loss: 2.0644187927246094. Accuracy: 20.251080469232352\n",
      "Iteration: 13740. Loss: 2.1084768772125244. Accuracy: 20.333401934554434\n",
      "Iteration: 13750. Loss: 2.0417890548706055. Accuracy: 20.930232558139537\n",
      "Iteration: 13760. Loss: 2.0328259468078613. Accuracy: 20.642107429512244\n",
      "Iteration: 13770. Loss: 2.0512304306030273. Accuracy: 20.683268162173288\n",
      "Iteration: 13780. Loss: 2.0330069065093994. Accuracy: 20.559785964190162\n",
      "Iteration: 13790. Loss: 2.0782828330993652. Accuracy: 20.271660835562873\n",
      "Iteration: 13800. Loss: 2.091067314147949. Accuracy: 21.259518419427867\n",
      "Epoch:  178\n",
      "Iteration: 13810. Loss: 2.0837278366088867. Accuracy: 20.930232558139537\n",
      "Iteration: 13820. Loss: 2.0497562885284424. Accuracy: 20.395143033546\n",
      "Iteration: 13830. Loss: 2.0724844932556152. Accuracy: 19.798312409960896\n",
      "Iteration: 13840. Loss: 2.0870418548583984. Accuracy: 19.860053508952458\n",
      "Iteration: 13850. Loss: 2.0284626483917236. Accuracy: 19.962955340605063\n",
      "Iteration: 13860. Loss: 2.0312366485595703. Accuracy: 20.84791109281745\n",
      "Iteration: 13870. Loss: 2.054629325866699. Accuracy: 20.600946696851203\n",
      "Iteration: 13880. Loss: 2.108013153076172. Accuracy: 20.76558962749537\n",
      "Epoch:  179\n",
      "Iteration: 13890. Loss: 2.0964879989624023. Accuracy: 20.78616999382589\n",
      "Iteration: 13900. Loss: 2.061976432800293. Accuracy: 20.43630376620704\n",
      "Iteration: 13910. Loss: 2.0479238033294678. Accuracy: 20.74500926116485\n",
      "Iteration: 13920. Loss: 2.063958168029785. Accuracy: 20.395143033546\n",
      "Iteration: 13930. Loss: 2.1145529747009277. Accuracy: 19.715990944638815\n",
      "Iteration: 13940. Loss: 2.0622246265411377. Accuracy: 19.386705083350485\n",
      "Iteration: 13950. Loss: 1.991765022277832. Accuracy: 20.353982300884955\n",
      "Iteration: 13960. Loss: 2.072906494140625. Accuracy: 20.41572339987652\n",
      "Epoch:  180\n",
      "Iteration: 13970. Loss: 2.123075246810913. Accuracy: 20.53920559785964\n",
      "Iteration: 13980. Loss: 2.0924837589263916. Accuracy: 19.59250874665569\n",
      "Iteration: 13990. Loss: 2.0088119506835938. Accuracy: 20.662687795842768\n",
      "Iteration: 14000. Loss: 1.9924840927124023. Accuracy: 20.84791109281745\n",
      "Iteration: 14010. Loss: 2.0581040382385254. Accuracy: 21.321259518419428\n",
      "Iteration: 14020. Loss: 2.0433902740478516. Accuracy: 21.13603622144474\n",
      "Iteration: 14030. Loss: 2.00925874710083. Accuracy: 20.312821568223914\n",
      "Iteration: 14040. Loss: 2.084336280822754. Accuracy: 20.642107429512244\n",
      "Epoch:  181\n",
      "Iteration: 14050. Loss: 2.0974767208099365. Accuracy: 20.43630376620704\n",
      "Iteration: 14060. Loss: 2.103508472442627. Accuracy: 19.736571310969335\n",
      "Iteration: 14070. Loss: 2.1512880325317383. Accuracy: 20.395143033546\n",
      "Iteration: 14080. Loss: 2.0658223628997803. Accuracy: 20.74500926116485\n",
      "Iteration: 14090. Loss: 2.105830669403076. Accuracy: 20.312821568223914\n",
      "Iteration: 14100. Loss: 2.111205816268921. Accuracy: 20.024696439596624\n",
      "Iteration: 14110. Loss: 2.088599920272827. Accuracy: 20.086437538588186\n",
      "Epoch:  182\n",
      "Iteration: 14120. Loss: 2.0857677459716797. Accuracy: 20.107017904918706\n",
      "Iteration: 14130. Loss: 2.032810926437378. Accuracy: 20.230500102901832\n",
      "Iteration: 14140. Loss: 2.0942609310150146. Accuracy: 19.777732043630376\n",
      "Iteration: 14150. Loss: 2.0777225494384766. Accuracy: 19.654249845647254\n",
      "Iteration: 14160. Loss: 2.0917129516601562. Accuracy: 20.045276805927145\n",
      "Iteration: 14170. Loss: 2.0410165786743164. Accuracy: 20.395143033546\n",
      "Iteration: 14180. Loss: 2.141812562942505. Accuracy: 20.82733072648693\n",
      "Iteration: 14190. Loss: 2.0255424976348877. Accuracy: 20.930232558139537\n",
      "Epoch:  183\n",
      "Iteration: 14200. Loss: 2.143085241317749. Accuracy: 20.930232558139537\n",
      "Iteration: 14210. Loss: 2.005937337875366. Accuracy: 20.374562667215475\n",
      "Iteration: 14220. Loss: 2.010096549987793. Accuracy: 20.395143033546\n",
      "Iteration: 14230. Loss: 2.169719696044922. Accuracy: 20.76558962749537\n",
      "Iteration: 14240. Loss: 2.0045418739318848. Accuracy: 20.16875900391027\n",
      "Iteration: 14250. Loss: 1.9943037033081055. Accuracy: 20.065857172257665\n",
      "Iteration: 14260. Loss: 1.9945306777954102. Accuracy: 20.065857172257665\n",
      "Iteration: 14270. Loss: 2.0670645236968994. Accuracy: 20.683268162173288\n",
      "Epoch:  184\n",
      "Iteration: 14280. Loss: 2.034766435623169. Accuracy: 20.580366330520683\n",
      "Iteration: 14290. Loss: 2.007406711578369. Accuracy: 20.47746449886808\n",
      "Iteration: 14300. Loss: 2.046740770339966. Accuracy: 20.889071825478492\n",
      "Iteration: 14310. Loss: 2.0734519958496094. Accuracy: 20.51862523152912\n",
      "Iteration: 14320. Loss: 2.0961551666259766. Accuracy: 20.271660835562873\n",
      "Iteration: 14330. Loss: 2.0640134811401367. Accuracy: 20.53920559785964\n",
      "Iteration: 14340. Loss: 2.036822557449341. Accuracy: 21.03313438979214\n",
      "Iteration: 14350. Loss: 1.9362802505493164. Accuracy: 20.683268162173288\n",
      "Epoch:  185\n",
      "Iteration: 14360. Loss: 2.051354169845581. Accuracy: 20.580366330520683\n",
      "Iteration: 14370. Loss: 2.119231700897217. Accuracy: 20.53920559785964\n",
      "Iteration: 14380. Loss: 2.0565428733825684. Accuracy: 20.662687795842768\n",
      "Iteration: 14390. Loss: 2.0586845874786377. Accuracy: 20.86849145914797\n",
      "Iteration: 14400. Loss: 2.043087959289551. Accuracy: 19.715990944638815\n",
      "Iteration: 14410. Loss: 2.0593132972717285. Accuracy: 20.230500102901832\n",
      "Iteration: 14420. Loss: 2.067962408065796. Accuracy: 19.839473142621937\n",
      "Iteration: 14430. Loss: 1.9705731868743896. Accuracy: 19.942374974274543\n",
      "Epoch:  186\n",
      "Iteration: 14440. Loss: 2.05068302154541. Accuracy: 20.312821568223914\n",
      "Iteration: 14450. Loss: 2.0523853302001953. Accuracy: 20.642107429512244\n",
      "Iteration: 14460. Loss: 2.0366666316986084. Accuracy: 19.88063387528298\n",
      "Iteration: 14470. Loss: 2.1523642539978027. Accuracy: 20.621527063181723\n",
      "Iteration: 14480. Loss: 2.005772113800049. Accuracy: 20.662687795842768\n",
      "Iteration: 14490. Loss: 2.052452802658081. Accuracy: 20.47746449886808\n",
      "Iteration: 14500. Loss: 2.1768829822540283. Accuracy: 20.374562667215475\n",
      "Epoch:  187\n",
      "Iteration: 14510. Loss: 2.075209856033325. Accuracy: 20.004116073266104\n",
      "Iteration: 14520. Loss: 2.0727055072784424. Accuracy: 19.818892776291417\n",
      "Iteration: 14530. Loss: 2.029215097427368. Accuracy: 19.798312409960896\n",
      "Iteration: 14540. Loss: 2.0782880783081055. Accuracy: 19.448446182342046\n",
      "Iteration: 14550. Loss: 2.0397732257843018. Accuracy: 20.14817863757975\n",
      "Iteration: 14560. Loss: 2.0801541805267334. Accuracy: 20.16875900391027\n",
      "Iteration: 14570. Loss: 2.1087629795074463. Accuracy: 21.05371475612266\n",
      "Iteration: 14580. Loss: 2.0183544158935547. Accuracy: 20.909652191809013\n",
      "Epoch:  188\n",
      "Iteration: 14590. Loss: 2.020453453063965. Accuracy: 20.20991973657131\n",
      "Iteration: 14600. Loss: 2.082212448120117. Accuracy: 20.47746449886808\n",
      "Iteration: 14610. Loss: 2.0305333137512207. Accuracy: 20.47746449886808\n",
      "Iteration: 14620. Loss: 2.0836527347564697. Accuracy: 20.84791109281745\n",
      "Iteration: 14630. Loss: 2.0526649951934814. Accuracy: 20.004116073266104\n",
      "Iteration: 14640. Loss: 2.065603256225586. Accuracy: 19.983535706935584\n",
      "Iteration: 14650. Loss: 2.1292312145233154. Accuracy: 19.489606915003087\n",
      "Iteration: 14660. Loss: 2.134540319442749. Accuracy: 19.469026548672566\n",
      "Epoch:  189\n",
      "Iteration: 14670. Loss: 2.079983711242676. Accuracy: 20.18933937024079\n",
      "Iteration: 14680. Loss: 2.018322229385376. Accuracy: 20.14817863757975\n",
      "Iteration: 14690. Loss: 2.0950355529785156. Accuracy: 20.74500926116485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 14700. Loss: 2.081249952316284. Accuracy: 19.633669479316733\n",
      "Iteration: 14710. Loss: 2.110952615737915. Accuracy: 18.97509775674007\n",
      "Iteration: 14720. Loss: 2.10105299949646. Accuracy: 20.82733072648693\n",
      "Iteration: 14730. Loss: 2.0844125747680664. Accuracy: 20.600946696851203\n",
      "Iteration: 14740. Loss: 2.1192777156829834. Accuracy: 20.683268162173288\n",
      "Epoch:  190\n",
      "Iteration: 14750. Loss: 2.1030027866363525. Accuracy: 20.395143033546\n",
      "Iteration: 14760. Loss: 2.120687484741211. Accuracy: 20.353982300884955\n",
      "Iteration: 14770. Loss: 2.008877754211426. Accuracy: 19.839473142621937\n",
      "Iteration: 14780. Loss: 2.0412380695343018. Accuracy: 20.76558962749537\n",
      "Iteration: 14790. Loss: 2.099250555038452. Accuracy: 20.045276805927145\n",
      "Iteration: 14800. Loss: 2.0680930614471436. Accuracy: 19.736571310969335\n",
      "Iteration: 14810. Loss: 2.1021246910095215. Accuracy: 20.78616999382589\n",
      "Iteration: 14820. Loss: 1.9987388849258423. Accuracy: 20.395143033546\n",
      "Epoch:  191\n",
      "Iteration: 14830. Loss: 2.0609846115112305. Accuracy: 20.82733072648693\n",
      "Iteration: 14840. Loss: 2.1226539611816406. Accuracy: 20.353982300884955\n",
      "Iteration: 14850. Loss: 2.1105029582977295. Accuracy: 19.942374974274543\n",
      "Iteration: 14860. Loss: 2.1294796466827393. Accuracy: 19.633669479316733\n",
      "Iteration: 14870. Loss: 2.0927672386169434. Accuracy: 21.36242025108047\n",
      "Iteration: 14880. Loss: 2.055518865585327. Accuracy: 20.909652191809013\n",
      "Iteration: 14890. Loss: 2.0903160572052. Accuracy: 21.238938053097346\n",
      "Epoch:  192\n",
      "Iteration: 14900. Loss: 2.0850727558135986. Accuracy: 20.600946696851203\n",
      "Iteration: 14910. Loss: 2.099363327026367. Accuracy: 20.72442889483433\n",
      "Iteration: 14920. Loss: 2.114544153213501. Accuracy: 20.559785964190162\n",
      "Iteration: 14930. Loss: 2.0836234092712402. Accuracy: 20.47746449886808\n",
      "Iteration: 14940. Loss: 2.188988208770752. Accuracy: 20.72442889483433\n",
      "Iteration: 14950. Loss: 2.143463134765625. Accuracy: 20.86849145914797\n",
      "Iteration: 14960. Loss: 2.0643672943115234. Accuracy: 21.15661658777526\n",
      "Iteration: 14970. Loss: 2.0734803676605225. Accuracy: 21.05371475612266\n",
      "Epoch:  193\n",
      "Iteration: 14980. Loss: 2.009939432144165. Accuracy: 20.4980448651986\n",
      "Iteration: 14990. Loss: 2.036461591720581. Accuracy: 21.13603622144474\n",
      "Iteration: 15000. Loss: 2.078352928161621. Accuracy: 21.197777320436305\n",
      "Iteration: 15010. Loss: 2.043302059173584. Accuracy: 21.03313438979214\n",
      "Iteration: 15020. Loss: 2.0407614707946777. Accuracy: 20.20991973657131\n",
      "Iteration: 15030. Loss: 2.098686456680298. Accuracy: 20.82733072648693\n",
      "Iteration: 15040. Loss: 2.0412633419036865. Accuracy: 20.024696439596624\n",
      "Iteration: 15050. Loss: 2.0357894897460938. Accuracy: 20.374562667215475\n",
      "Epoch:  194\n",
      "Iteration: 15060. Loss: 2.136038303375244. Accuracy: 20.889071825478492\n",
      "Iteration: 15070. Loss: 2.060061454772949. Accuracy: 21.0948754887837\n",
      "Iteration: 15080. Loss: 2.04736065864563. Accuracy: 20.41572339987652\n",
      "Iteration: 15090. Loss: 2.101254940032959. Accuracy: 20.74500926116485\n",
      "Iteration: 15100. Loss: 2.059912919998169. Accuracy: 20.909652191809013\n",
      "Iteration: 15110. Loss: 2.1336984634399414. Accuracy: 20.559785964190162\n",
      "Iteration: 15120. Loss: 2.029714822769165. Accuracy: 20.251080469232352\n",
      "Iteration: 15130. Loss: 2.023995876312256. Accuracy: 20.642107429512244\n",
      "Epoch:  195\n",
      "Iteration: 15140. Loss: 2.0990304946899414. Accuracy: 20.395143033546\n",
      "Iteration: 15150. Loss: 2.0152177810668945. Accuracy: 20.930232558139537\n",
      "Iteration: 15160. Loss: 1.975090742111206. Accuracy: 20.4980448651986\n",
      "Iteration: 15170. Loss: 2.115009069442749. Accuracy: 20.18933937024079\n",
      "Iteration: 15180. Loss: 2.1463260650634766. Accuracy: 21.11545585511422\n",
      "Iteration: 15190. Loss: 2.0995242595672607. Accuracy: 20.950812924470057\n",
      "Iteration: 15200. Loss: 2.035440683364868. Accuracy: 19.818892776291417\n",
      "Iteration: 15210. Loss: 2.0187528133392334. Accuracy: 21.321259518419428\n",
      "Epoch:  196\n",
      "Iteration: 15220. Loss: 2.124786615371704. Accuracy: 20.683268162173288\n",
      "Iteration: 15230. Loss: 2.053668260574341. Accuracy: 19.901214241613502\n",
      "Iteration: 15240. Loss: 2.0741164684295654. Accuracy: 20.642107429512244\n",
      "Iteration: 15250. Loss: 2.0465519428253174. Accuracy: 21.588804280716197\n",
      "Iteration: 15260. Loss: 2.0507864952087402. Accuracy: 20.47746449886808\n",
      "Iteration: 15270. Loss: 2.082878351211548. Accuracy: 21.13603622144474\n",
      "Iteration: 15280. Loss: 2.1036453247070312. Accuracy: 20.086437538588186\n",
      "Epoch:  197\n",
      "Iteration: 15290. Loss: 2.0249903202056885. Accuracy: 19.407285449681005\n",
      "Iteration: 15300. Loss: 2.0918877124786377. Accuracy: 20.353982300884955\n",
      "Iteration: 15310. Loss: 2.024895668029785. Accuracy: 21.0948754887837\n",
      "Iteration: 15320. Loss: 2.0561256408691406. Accuracy: 21.280098785758387\n",
      "Iteration: 15330. Loss: 2.163404703140259. Accuracy: 21.012554023461618\n",
      "Iteration: 15340. Loss: 2.0473508834838867. Accuracy: 20.889071825478492\n",
      "Iteration: 15350. Loss: 2.1331913471221924. Accuracy: 21.300679152088907\n",
      "Iteration: 15360. Loss: 2.0734047889709473. Accuracy: 20.47746449886808\n",
      "Epoch:  198\n",
      "Iteration: 15370. Loss: 2.232527256011963. Accuracy: 20.353982300884955\n",
      "Iteration: 15380. Loss: 2.1085360050201416. Accuracy: 20.683268162173288\n",
      "Iteration: 15390. Loss: 2.048475742340088. Accuracy: 20.991973657131098\n",
      "Iteration: 15400. Loss: 2.0574653148651123. Accuracy: 20.4980448651986\n",
      "Iteration: 15410. Loss: 2.08505916595459. Accuracy: 20.271660835562873\n",
      "Iteration: 15420. Loss: 2.052196502685547. Accuracy: 20.662687795842768\n",
      "Iteration: 15430. Loss: 2.163686990737915. Accuracy: 19.798312409960896\n",
      "Iteration: 15440. Loss: 2.113332986831665. Accuracy: 21.0948754887837\n",
      "Epoch:  199\n",
      "Iteration: 15450. Loss: 2.087476968765259. Accuracy: 20.292241201893393\n",
      "Iteration: 15460. Loss: 2.033738374710083. Accuracy: 19.57192838032517\n",
      "Iteration: 15470. Loss: 2.0622496604919434. Accuracy: 20.53920559785964\n",
      "Iteration: 15480. Loss: 2.0348775386810303. Accuracy: 21.03313438979214\n",
      "Iteration: 15490. Loss: 2.0517208576202393. Accuracy: 20.600946696851203\n",
      "Iteration: 15500. Loss: 2.1488380432128906. Accuracy: 20.642107429512244\n",
      "Iteration: 15510. Loss: 2.132467269897461. Accuracy: 20.107017904918706\n",
      "Iteration: 15520. Loss: 2.0729169845581055. Accuracy: 20.4980448651986\n",
      "Epoch:  200\n",
      "Iteration: 15530. Loss: 2.06484055519104. Accuracy: 20.374562667215475\n",
      "Iteration: 15540. Loss: 2.0969455242156982. Accuracy: 21.0948754887837\n",
      "Iteration: 15550. Loss: 2.0458059310913086. Accuracy: 20.642107429512244\n",
      "Iteration: 15560. Loss: 2.0713870525360107. Accuracy: 20.930232558139537\n",
      "Iteration: 15570. Loss: 2.059619665145874. Accuracy: 20.621527063181723\n",
      "Iteration: 15580. Loss: 2.096071720123291. Accuracy: 20.74500926116485\n",
      "Iteration: 15590. Loss: 2.0827159881591797. Accuracy: 20.580366330520683\n",
      "Iteration: 15600. Loss: 1.923506498336792. Accuracy: 21.44474171640255\n",
      "Epoch:  201\n",
      "Iteration: 15610. Loss: 2.0562491416931152. Accuracy: 20.70384852850381\n",
      "Iteration: 15620. Loss: 2.015878677368164. Accuracy: 20.991973657131098\n",
      "Iteration: 15630. Loss: 2.0993893146514893. Accuracy: 20.107017904918706\n",
      "Iteration: 15640. Loss: 2.070427179336548. Accuracy: 21.0948754887837\n",
      "Iteration: 15650. Loss: 2.102100372314453. Accuracy: 20.47746449886808\n",
      "Iteration: 15660. Loss: 2.1435725688934326. Accuracy: 20.971393290800577\n",
      "Iteration: 15670. Loss: 2.0087451934814453. Accuracy: 21.03313438979214\n",
      "Epoch:  202\n",
      "Iteration: 15680. Loss: 2.108837604522705. Accuracy: 19.05741922206215\n",
      "Iteration: 15690. Loss: 2.0782225131988525. Accuracy: 20.045276805927145\n",
      "Iteration: 15700. Loss: 2.1086747646331787. Accuracy: 20.374562667215475\n",
      "Iteration: 15710. Loss: 2.124502658843994. Accuracy: 20.683268162173288\n",
      "Iteration: 15720. Loss: 2.0555171966552734. Accuracy: 20.251080469232352\n",
      "Iteration: 15730. Loss: 2.0460994243621826. Accuracy: 21.38300061741099\n",
      "Iteration: 15740. Loss: 2.06616473197937. Accuracy: 21.629965013377237\n",
      "Iteration: 15750. Loss: 2.076218843460083. Accuracy: 20.14817863757975\n",
      "Epoch:  203\n",
      "Iteration: 15760. Loss: 2.0342533588409424. Accuracy: 20.333401934554434\n",
      "Iteration: 15770. Loss: 2.0952939987182617. Accuracy: 19.860053508952458\n",
      "Iteration: 15780. Loss: 2.0273993015289307. Accuracy: 20.230500102901832\n",
      "Iteration: 15790. Loss: 2.0297484397888184. Accuracy: 20.41572339987652\n",
      "Iteration: 15800. Loss: 2.0140163898468018. Accuracy: 21.03313438979214\n",
      "Iteration: 15810. Loss: 2.024897336959839. Accuracy: 20.78616999382589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15820. Loss: 2.652163505554199. Accuracy: 20.70384852850381\n",
      "Iteration: 15830. Loss: 2.0596463680267334. Accuracy: 20.4980448651986\n",
      "Epoch:  204\n",
      "Iteration: 15840. Loss: 2.0529074668884277. Accuracy: 20.47746449886808\n",
      "Iteration: 15850. Loss: 2.0167839527130127. Accuracy: 20.70384852850381\n",
      "Iteration: 15860. Loss: 2.106201171875. Accuracy: 20.024696439596624\n",
      "Iteration: 15870. Loss: 2.0654795169830322. Accuracy: 20.086437538588186\n",
      "Iteration: 15880. Loss: 2.101109504699707. Accuracy: 20.065857172257665\n",
      "Iteration: 15890. Loss: 2.1614208221435547. Accuracy: 21.0948754887837\n",
      "Iteration: 15900. Loss: 2.0471160411834717. Accuracy: 20.395143033546\n",
      "Iteration: 15910. Loss: 2.062629461288452. Accuracy: 20.621527063181723\n",
      "Epoch:  205\n",
      "Iteration: 15920. Loss: 2.1058216094970703. Accuracy: 20.53920559785964\n",
      "Iteration: 15930. Loss: 2.071117639541626. Accuracy: 20.662687795842768\n",
      "Iteration: 15940. Loss: 2.1207990646362305. Accuracy: 20.251080469232352\n",
      "Iteration: 15950. Loss: 2.06204891204834. Accuracy: 20.41572339987652\n",
      "Iteration: 15960. Loss: 2.084763765335083. Accuracy: 20.642107429512244\n",
      "Iteration: 15970. Loss: 2.1403071880340576. Accuracy: 20.51862523152912\n",
      "Iteration: 15980. Loss: 2.0766944885253906. Accuracy: 20.72442889483433\n",
      "Iteration: 15990. Loss: 2.084167957305908. Accuracy: 20.43630376620704\n"
     ]
    }
   ],
   "source": [
    "iteration_loss1 = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: ', epoch + 1)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images) \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 10 == 0:        \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            iteration_loss1.append(loss.item())\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
