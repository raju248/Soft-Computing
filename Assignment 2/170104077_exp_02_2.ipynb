{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "4UMKTgRoeqfW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from zipfile import ZipFile\n",
    "import os\n",
    "from os import path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "id": "RManlEUee0_s"
   },
   "outputs": [],
   "source": [
    "url = 'Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "id": "HC1Mh0lIGogh"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Dataset/Dataset A.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-183-870a146dd597>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdataset_A\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'Dataset A.zip'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m   \u001b[0mzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mL:\\Anaconda\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Dataset/Dataset A.zip'"
     ]
    }
   ],
   "source": [
    "dataset_A = url + 'Dataset A.zip'\n",
    "with ZipFile(dataset_A, 'r') as zip:\n",
    "  zip.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "id": "xy-Cey0sf9Fz",
    "outputId": "f9c9fdb1-de0d-4cd5-fea2-36834ce2cf65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24298, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>digit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c00000.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c00001.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c00002.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c00003.png</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c00004.png</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  digit\n",
       "0  c00000.png      6\n",
       "1  c00001.png      1\n",
       "2  c00002.png      3\n",
       "3  c00003.png      2\n",
       "4  c00004.png      7"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'Dataset/'\n",
    "data_labels = pd.read_csv(PATH + 'training-c.csv', usecols = ['filename', 'digit'])\n",
    "print(data_labels.shape)\n",
    "data_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "id": "hTJ2ocEEHVGA"
   },
   "outputs": [],
   "source": [
    "# TRAIN_PATH = url + 'Train'\n",
    "# os.mkdir(TRAIN_PATH)\n",
    "\n",
    "# def processImages(folder_name):\n",
    "#   src = PATH + folder_name + '/'\n",
    "#   dir_folders = os.listdir(src)\n",
    "#   for dir_name in dir_folders:\n",
    "#     file_name = os.path.join(src, dir_name)\n",
    "#     if os.path.isfile(file_name):\n",
    "#       shutil.copy(file_name, TRAIN_PATH) \n",
    "\n",
    "# processImages('training-a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = url + 'training-c'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "id": "zmE05jA4kTDU"
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df, root, transform=None):\n",
    "        self.data = df\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data.iloc[index]\n",
    "        \n",
    "        path = self.root + \"/\" + item[0]\n",
    "        image = Image.open(path).convert('L')\n",
    "        label = item[1]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "adaZ60Uik-eb",
    "outputId": "8e66fb67-e670-485f-ac11-b60d2a5a3ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainig Samples:  24298\n"
     ]
    }
   ],
   "source": [
    "mean = [0.5,]\n",
    "std = [0.5, ]\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(28),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.Resize(28),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_data  = Dataset(data_labels, TRAIN_PATH, train_transform)\n",
    "test_data = Dataset(data_labels, TRAIN_PATH, test_transform)\n",
    "\n",
    "print(\"Trainig Samples: \", len(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8htM9w2LmUVl"
   },
   "source": [
    "# **Base Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IGG3l4vrmkI3",
    "outputId": "6a36b17c-57fd-45a9-f19d-4f4416f51407"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    }
   ],
   "source": [
    "batch_size = 460\n",
    "num_iters = 20000\n",
    "input_dim = 28*28\n",
    "num_hidden = 330\n",
    "output_dim = 10\n",
    "\n",
    "learning_rate = 0.28\n",
    "\n",
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lsSesapsltZF",
    "outputId": "72b5fe74-6eaa-4c18-b642-a52ddb0f99d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:43\n",
      "Test dataloader:11\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "id": "6jCcU8giniGS"
   },
   "outputs": [],
   "source": [
    "class DeepNeuralNetworkModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, num_hidden):\n",
    "        super().__init__()\n",
    "       \n",
    "        self.linear_1 = nn.Linear(input_size, num_hidden)\n",
    "        self.relu_1 = nn.ELU()\n",
    "#         self.softmax_1 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_2 = nn.Softmax(dim=0)\n",
    "#         self.softmax_2 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_3 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_3 = nn.ELU()\n",
    "#         self.softmax_3 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_4 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_4 = nn.ELU()\n",
    "#         self.softmax_4 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_5= nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_5= nn.ELU()\n",
    "#         self.softmax_5 = nn.Softmax(dim=1)\n",
    " \n",
    "        self.linear_6 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_6 = nn.ELU()\n",
    "        \n",
    "        self.linear_7 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.relu_7 = nn.ELU()\n",
    " \n",
    "        self.linear_out = nn.Linear(num_hidden, num_classes)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out  = self.linear_1(x)\n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "        out  = self.linear_2(out)\n",
    "        out = self.relu_2(out)\n",
    " \n",
    "        out  = self.linear_3(out)\n",
    "        out = self.relu_3(out)\n",
    " \n",
    "        out  = self.linear_4(out)\n",
    "        out = self.relu_4(out)\n",
    " \n",
    "        out  = self.linear_5(out)\n",
    "        out = self.relu_5(out)\n",
    " \n",
    "        out  = self.linear_6(out)\n",
    "        out = self.relu_6(out)\n",
    "        \n",
    "        out  = self.linear_7(out)\n",
    "        out = self.relu_7(out)\n",
    "        \n",
    "        probas  = self.linear_out(out)\n",
    "        return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q23HotHio42L",
    "outputId": "1171c191-3742-47e9-fe29-daf9130927c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=330, bias=True)\n",
       "  (relu_1): ELU(alpha=1.0)\n",
       "  (linear_2): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_2): Softmax(dim=0)\n",
       "  (linear_3): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_3): ELU(alpha=1.0)\n",
       "  (linear_4): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_4): ELU(alpha=1.0)\n",
       "  (linear_5): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_5): ELU(alpha=1.0)\n",
       "  (linear_6): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_6): ELU(alpha=1.0)\n",
       "  (linear_7): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_7): ELU(alpha=1.0)\n",
       "  (linear_out): Linear(in_features=330, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "id": "V1YagXSipEth"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6VJ_sYCMp2l9",
    "outputId": "1566b22e-45ca-4019-fcdc-424e3c20f11b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Iteration: 10. Loss: 2.3031530380249023. Accuracy: 9.857995472319407\n",
      "Iteration: 20. Loss: 2.3043460845947266. Accuracy: 9.775674006997324\n",
      "Iteration: 30. Loss: 2.3038766384124756. Accuracy: 9.590450710022639\n",
      "Iteration: 40. Loss: 2.2653415203094482. Accuracy: 15.311792549907388\n",
      "Epoch:  2\n",
      "Iteration: 50. Loss: 2.228445291519165. Accuracy: 15.167729985593743\n",
      "Iteration: 60. Loss: 2.123638868331909. Accuracy: 17.555052479934144\n",
      "Iteration: 70. Loss: 2.173280954360962. Accuracy: 17.431570281951018\n",
      "Iteration: 80. Loss: 2.112790822982788. Accuracy: 18.501749331138093\n",
      "Epoch:  3\n",
      "Iteration: 90. Loss: 2.1765248775482178. Accuracy: 16.56719489606915\n",
      "Iteration: 100. Loss: 2.1119139194488525. Accuracy: 18.58407079646018\n",
      "Iteration: 110. Loss: 2.104520082473755. Accuracy: 17.575632846264664\n",
      "Iteration: 120. Loss: 2.0569252967834473. Accuracy: 19.551348013994648\n",
      "Epoch:  4\n",
      "Iteration: 130. Loss: 2.1079978942871094. Accuracy: 17.781436509569872\n",
      "Iteration: 140. Loss: 2.02129864692688. Accuracy: 24.6758592302943\n",
      "Iteration: 150. Loss: 1.901497483253479. Accuracy: 26.137065239761267\n",
      "Iteration: 160. Loss: 1.932432770729065. Accuracy: 26.83679769499897\n",
      "Iteration: 170. Loss: 1.8025413751602173. Accuracy: 30.7470672977979\n",
      "Epoch:  5\n",
      "Iteration: 180. Loss: 1.9576255083084106. Accuracy: 28.030458942169172\n",
      "Iteration: 190. Loss: 1.910561203956604. Accuracy: 30.314879604856966\n",
      "Iteration: 200. Loss: 1.820465326309204. Accuracy: 32.33175550524799\n",
      "Iteration: 210. Loss: 1.8324670791625977. Accuracy: 31.92014817863758\n",
      "Epoch:  6\n",
      "Iteration: 220. Loss: 1.9106459617614746. Accuracy: 28.771352130067914\n",
      "Iteration: 230. Loss: 1.811011791229248. Accuracy: 31.837826713315497\n",
      "Iteration: 240. Loss: 1.834259271621704. Accuracy: 34.780819098579954\n",
      "Iteration: 250. Loss: 1.7167420387268066. Accuracy: 34.842560197571515\n",
      "Epoch:  7\n",
      "Iteration: 260. Loss: 1.8241839408874512. Accuracy: 27.557110516567196\n",
      "Iteration: 270. Loss: 1.733518362045288. Accuracy: 32.22885367359539\n",
      "Iteration: 280. Loss: 1.8398329019546509. Accuracy: 36.69479316731838\n",
      "Iteration: 290. Loss: 1.734735369682312. Accuracy: 37.64149001852233\n",
      "Iteration: 300. Loss: 1.6966779232025146. Accuracy: 37.106400493928795\n",
      "Epoch:  8\n",
      "Iteration: 310. Loss: 1.7333734035491943. Accuracy: 37.600329285861285\n",
      "Iteration: 320. Loss: 1.566197395324707. Accuracy: 39.040954928997735\n",
      "Iteration: 330. Loss: 1.5406967401504517. Accuracy: 41.798724017287505\n",
      "Iteration: 340. Loss: 1.510119915008545. Accuracy: 42.80716196748302\n",
      "Epoch:  9\n",
      "Iteration: 350. Loss: 1.5708332061767578. Accuracy: 38.5058654044042\n",
      "Iteration: 360. Loss: 1.5260155200958252. Accuracy: 43.3834122247376\n",
      "Iteration: 370. Loss: 1.419560432434082. Accuracy: 44.53591273924676\n",
      "Iteration: 380. Loss: 1.438417911529541. Accuracy: 44.26836797694999\n",
      "Epoch:  10\n",
      "Iteration: 390. Loss: 1.4699018001556396. Accuracy: 43.280510393084995\n",
      "Iteration: 400. Loss: 1.3723416328430176. Accuracy: 43.198188927762914\n",
      "Iteration: 410. Loss: 1.45710289478302. Accuracy: 45.1739040954929\n",
      "Iteration: 420. Loss: 1.4486781358718872. Accuracy: 47.21136036221445\n",
      "Iteration: 430. Loss: 2.316460609436035. Accuracy: 44.59765383823832\n",
      "Epoch:  11\n",
      "Iteration: 440. Loss: 1.434361219406128. Accuracy: 48.075735748096314\n",
      "Iteration: 450. Loss: 1.4207475185394287. Accuracy: 47.00555669890924\n",
      "Iteration: 460. Loss: 1.3601036071777344. Accuracy: 51.34801399464911\n",
      "Iteration: 470. Loss: 1.243581771850586. Accuracy: 51.656719489606914\n",
      "Epoch:  12\n",
      "Iteration: 480. Loss: 1.269171118736267. Accuracy: 50.17493311380942\n",
      "Iteration: 490. Loss: 1.3113294839859009. Accuracy: 50.339576044453594\n",
      "Iteration: 500. Loss: 1.2036372423171997. Accuracy: 53.117925499073884\n",
      "Iteration: 510. Loss: 1.1084238290786743. Accuracy: 55.03189956781231\n",
      "Epoch:  13\n",
      "Iteration: 520. Loss: 1.2266336679458618. Accuracy: 48.79604856966454\n",
      "Iteration: 530. Loss: 1.2714663743972778. Accuracy: 52.521094875488785\n",
      "Iteration: 540. Loss: 1.1212464570999146. Accuracy: 53.4266309940317\n",
      "Iteration: 550. Loss: 1.2984851598739624. Accuracy: 53.879399053303146\n",
      "Epoch:  14\n",
      "Iteration: 560. Loss: 1.0859047174453735. Accuracy: 51.039308499691295\n",
      "Iteration: 570. Loss: 1.1558146476745605. Accuracy: 55.17596213212595\n",
      "Iteration: 580. Loss: 1.1668391227722168. Accuracy: 56.081498250668865\n",
      "Iteration: 590. Loss: 1.152305006980896. Accuracy: 56.84297180489813\n",
      "Iteration: 600. Loss: 1.0928378105163574. Accuracy: 58.28359744803458\n",
      "Epoch:  15\n",
      "Iteration: 610. Loss: 1.0397998094558716. Accuracy: 56.98703436921177\n",
      "Iteration: 620. Loss: 1.0647178888320923. Accuracy: 58.654044041983944\n",
      "Iteration: 630. Loss: 1.0422987937927246. Accuracy: 58.42766001234822\n",
      "Iteration: 640. Loss: 1.005084753036499. Accuracy: 59.02449063593332\n",
      "Epoch:  16\n",
      "Iteration: 650. Loss: 1.0167028903961182. Accuracy: 59.7036427248405\n",
      "Iteration: 660. Loss: 0.9323525428771973. Accuracy: 59.99176785346779\n",
      "Iteration: 670. Loss: 0.9592559337615967. Accuracy: 62.54373327845236\n",
      "Iteration: 680. Loss: 0.939501166343689. Accuracy: 62.62605474377444\n",
      "Epoch:  17\n",
      "Iteration: 690. Loss: 1.0153214931488037. Accuracy: 59.209713932908\n",
      "Iteration: 700. Loss: 0.9821241497993469. Accuracy: 60.81498250668862\n",
      "Iteration: 710. Loss: 0.8932273387908936. Accuracy: 63.2846264663511\n",
      "Iteration: 720. Loss: 0.8769835829734802. Accuracy: 63.675653426630994\n",
      "Iteration: 730. Loss: 1.036132574081421. Accuracy: 64.70467174315702\n",
      "Epoch:  18\n",
      "Iteration: 740. Loss: 0.8157591223716736. Accuracy: 62.00864375385882\n",
      "Iteration: 750. Loss: 0.9703607559204102. Accuracy: 63.46984976332579\n",
      "Iteration: 760. Loss: 0.8800994753837585. Accuracy: 63.675653426630994\n",
      "Iteration: 770. Loss: 0.8440461158752441. Accuracy: 64.16958221856349\n",
      "Epoch:  19\n",
      "Iteration: 780. Loss: 0.9370862245559692. Accuracy: 63.3875282980037\n",
      "Iteration: 790. Loss: 0.8500074148178101. Accuracy: 64.99279687178432\n",
      "Iteration: 800. Loss: 0.8718163967132568. Accuracy: 65.2809220004116\n",
      "Iteration: 810. Loss: 0.7645472884178162. Accuracy: 65.01337723811484\n",
      "Epoch:  20\n",
      "Iteration: 820. Loss: 1.0187819004058838. Accuracy: 61.47355422926528\n",
      "Iteration: 830. Loss: 0.9125189185142517. Accuracy: 62.852438773410164\n",
      "Iteration: 840. Loss: 0.9904233813285828. Accuracy: 64.25190368388557\n",
      "Iteration: 850. Loss: 0.8389627933502197. Accuracy: 66.43342251492076\n",
      "Iteration: 860. Loss: 1.3046365976333618. Accuracy: 65.36324346573369\n",
      "Epoch:  21\n",
      "Iteration: 870. Loss: 0.7187325954437256. Accuracy: 66.45400288125128\n",
      "Iteration: 880. Loss: 0.8465017676353455. Accuracy: 65.91891335665775\n",
      "Iteration: 890. Loss: 0.8193798661231995. Accuracy: 66.41284214859024\n",
      "Iteration: 900. Loss: 0.7962177991867065. Accuracy: 66.51574398024285\n",
      "Epoch:  22\n",
      "Iteration: 910. Loss: 0.8962096571922302. Accuracy: 65.7748507923441\n",
      "Iteration: 920. Loss: 0.7821381092071533. Accuracy: 66.3716814159292\n",
      "Iteration: 930. Loss: 0.636026918888092. Accuracy: 68.59436097962543\n",
      "Iteration: 940. Loss: 0.8230443596839905. Accuracy: 67.81230705906565\n",
      "Epoch:  23\n",
      "Iteration: 950. Loss: 0.7726300358772278. Accuracy: 66.51574398024285\n",
      "Iteration: 960. Loss: 0.7986375093460083. Accuracy: 67.81230705906565\n",
      "Iteration: 970. Loss: 0.640605092048645. Accuracy: 69.12945050421898\n",
      "Iteration: 980. Loss: 0.738615095615387. Accuracy: 69.87034369211771\n",
      "Epoch:  24\n",
      "Iteration: 990. Loss: 0.6726057529449463. Accuracy: 68.36797694998971\n",
      "Iteration: 1000. Loss: 0.6992738842964172. Accuracy: 67.79172669273512\n",
      "Iteration: 1010. Loss: 0.712192177772522. Accuracy: 68.30623585099815\n",
      "Iteration: 1020. Loss: 0.6169694066047668. Accuracy: 69.31467380119366\n",
      "Iteration: 1030. Loss: 0.7131761908531189. Accuracy: 68.84132537559168\n",
      "Epoch:  25\n",
      "Iteration: 1040. Loss: 0.6865469217300415. Accuracy: 67.42128009878576\n",
      "Iteration: 1050. Loss: 0.7597590088844299. Accuracy: 69.87034369211771\n",
      "Iteration: 1060. Loss: 0.6961367130279541. Accuracy: 69.54105783082939\n",
      "Iteration: 1070. Loss: 0.6606661677360535. Accuracy: 69.4587363655073\n",
      "Epoch:  26\n",
      "Iteration: 1080. Loss: 0.7038230299949646. Accuracy: 67.44186046511628\n",
      "Iteration: 1090. Loss: 0.7951817512512207. Accuracy: 68.24449475200659\n",
      "Iteration: 1100. Loss: 0.7387277483940125. Accuracy: 70.19962955340606\n",
      "Iteration: 1110. Loss: 0.7854244112968445. Accuracy: 70.01440625643137\n",
      "Epoch:  27\n",
      "Iteration: 1120. Loss: 0.5913735628128052. Accuracy: 69.58221856349043\n",
      "Iteration: 1130. Loss: 0.5909423828125. Accuracy: 70.69355834533854\n",
      "Iteration: 1140. Loss: 0.6734076738357544. Accuracy: 71.51677299855938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1150. Loss: 0.6562007665634155. Accuracy: 72.09302325581395\n",
      "Iteration: 1160. Loss: 0.6141814589500427. Accuracy: 71.8460588598477\n",
      "Epoch:  28\n",
      "Iteration: 1170. Loss: 0.773618221282959. Accuracy: 69.21177196954106\n",
      "Iteration: 1180. Loss: 0.6287664771080017. Accuracy: 70.03498662276189\n",
      "Iteration: 1190. Loss: 0.5285555124282837. Accuracy: 70.87878164231323\n",
      "Iteration: 1200. Loss: 0.64312744140625. Accuracy: 70.3436921177197\n",
      "Epoch:  29\n",
      "Iteration: 1210. Loss: 0.5432794690132141. Accuracy: 71.04342457295739\n",
      "Iteration: 1220. Loss: 0.5284004807472229. Accuracy: 72.40172875077177\n",
      "Iteration: 1230. Loss: 0.4896419942378998. Accuracy: 72.31940728544969\n",
      "Iteration: 1240. Loss: 0.48154690861701965. Accuracy: 73.67771146326405\n",
      "Epoch:  30\n",
      "Iteration: 1250. Loss: 0.6465417742729187. Accuracy: 72.44288948343281\n",
      "Iteration: 1260. Loss: 0.46484458446502686. Accuracy: 71.66083556287302\n",
      "Iteration: 1270. Loss: 0.5173174142837524. Accuracy: 72.99855937435686\n",
      "Iteration: 1280. Loss: 0.5416873097419739. Accuracy: 73.78061329491665\n",
      "Iteration: 1290. Loss: 0.7341839671134949. Accuracy: 73.59538999794196\n",
      "Epoch:  31\n",
      "Iteration: 1300. Loss: 0.5410326719284058. Accuracy: 73.24552377032312\n",
      "Iteration: 1310. Loss: 0.5235045552253723. Accuracy: 74.37744391850175\n",
      "Iteration: 1320. Loss: 0.5215771794319153. Accuracy: 73.84235439390821\n",
      "Iteration: 1330. Loss: 0.47479650378227234. Accuracy: 74.4186046511628\n",
      "Epoch:  32\n",
      "Iteration: 1340. Loss: 0.4833139479160309. Accuracy: 73.71887219592509\n",
      "Iteration: 1350. Loss: 0.4597058892250061. Accuracy: 74.78905124511216\n",
      "Iteration: 1360. Loss: 0.5475851893424988. Accuracy: 73.88351512656925\n",
      "Iteration: 1370. Loss: 0.42967087030410767. Accuracy: 74.45976538382384\n",
      "Epoch:  33\n",
      "Iteration: 1380. Loss: 0.4156843423843384. Accuracy: 73.47190779995884\n",
      "Iteration: 1390. Loss: 0.43970558047294617. Accuracy: 74.66556904712904\n",
      "Iteration: 1400. Loss: 0.495061993598938. Accuracy: 74.35686355217123\n",
      "Iteration: 1410. Loss: 0.42055562138557434. Accuracy: 75.65342663099403\n",
      "Epoch:  34\n",
      "Iteration: 1420. Loss: 0.4074088931083679. Accuracy: 75.07717637373945\n",
      "Iteration: 1430. Loss: 0.4980162978172302. Accuracy: 74.50092611648488\n",
      "Iteration: 1440. Loss: 0.476071834564209. Accuracy: 75.59168553200247\n",
      "Iteration: 1450. Loss: 0.4667384624481201. Accuracy: 74.99485490841737\n",
      "Iteration: 1460. Loss: 0.429205060005188. Accuracy: 75.9209713932908\n",
      "Epoch:  35\n",
      "Iteration: 1470. Loss: 0.4096432030200958. Accuracy: 74.3157028195102\n",
      "Iteration: 1480. Loss: 0.42356038093566895. Accuracy: 75.85923029429924\n",
      "Iteration: 1490. Loss: 0.3875509202480316. Accuracy: 75.01543527474789\n",
      "Iteration: 1500. Loss: 0.4771789312362671. Accuracy: 75.87981066062976\n",
      "Epoch:  36\n",
      "Iteration: 1510. Loss: 0.3683488965034485. Accuracy: 75.40646223502779\n",
      "Iteration: 1520. Loss: 0.42920559644699097. Accuracy: 76.04445359127392\n",
      "Iteration: 1530. Loss: 0.3241051435470581. Accuracy: 77.0117308088084\n",
      "Iteration: 1540. Loss: 0.4117262363433838. Accuracy: 76.4149001852233\n",
      "Epoch:  37\n",
      "Iteration: 1550. Loss: 0.38796672224998474. Accuracy: 76.126775056596\n",
      "Iteration: 1560. Loss: 0.3768640160560608. Accuracy: 75.69458736365507\n",
      "Iteration: 1570. Loss: 0.35622236132621765. Accuracy: 77.27927557110516\n",
      "Iteration: 1580. Loss: 0.3470757305622101. Accuracy: 76.49722165054538\n",
      "Iteration: 1590. Loss: 0.3935009241104126. Accuracy: 77.23811483844412\n",
      "Epoch:  38\n",
      "Iteration: 1600. Loss: 0.39581093192100525. Accuracy: 75.8180695616382\n",
      "Iteration: 1610. Loss: 0.3638567328453064. Accuracy: 76.80592714550319\n",
      "Iteration: 1620. Loss: 0.37336617708206177. Accuracy: 77.03231117513891\n",
      "Iteration: 1630. Loss: 0.37507104873657227. Accuracy: 78.20539205597859\n",
      "Epoch:  39\n",
      "Iteration: 1640. Loss: 0.2698887586593628. Accuracy: 76.97057007614735\n",
      "Iteration: 1650. Loss: 0.41765096783638. Accuracy: 77.67030253138506\n",
      "Iteration: 1660. Loss: 0.38523629307746887. Accuracy: 77.29985593743568\n",
      "Iteration: 1670. Loss: 0.38838082551956177. Accuracy: 77.09405227413048\n",
      "Epoch:  40\n",
      "Iteration: 1680. Loss: 0.4165829122066498. Accuracy: 77.13521300679152\n",
      "Iteration: 1690. Loss: 0.30824002623558044. Accuracy: 77.75262399670714\n",
      "Iteration: 1700. Loss: 0.3134957253932953. Accuracy: 77.75262399670714\n",
      "Iteration: 1710. Loss: 0.2945707142353058. Accuracy: 77.23811483844412\n",
      "Iteration: 1720. Loss: 0.8601957559585571. Accuracy: 76.80592714550319\n",
      "Epoch:  41\n",
      "Iteration: 1730. Loss: 0.2874284088611603. Accuracy: 76.72360568018111\n",
      "Iteration: 1740. Loss: 0.3506176471710205. Accuracy: 78.12307059065651\n",
      "Iteration: 1750. Loss: 0.35748884081840515. Accuracy: 78.26713315497015\n",
      "Iteration: 1760. Loss: 0.35372355580329895. Accuracy: 77.4027577690883\n",
      "Epoch:  42\n",
      "Iteration: 1770. Loss: 0.3109712302684784. Accuracy: 77.9172669273513\n",
      "Iteration: 1780. Loss: 0.37343305349349976. Accuracy: 76.66186458118955\n",
      "Iteration: 1790. Loss: 0.26715466380119324. Accuracy: 77.4027577690883\n",
      "Iteration: 1800. Loss: 0.3113000988960266. Accuracy: 77.54682033340194\n",
      "Epoch:  43\n",
      "Iteration: 1810. Loss: 0.2881009876728058. Accuracy: 77.27927557110516\n",
      "Iteration: 1820. Loss: 0.2971513867378235. Accuracy: 78.08190985799547\n",
      "Iteration: 1830. Loss: 0.2709808349609375. Accuracy: 78.57583864992797\n",
      "Iteration: 1840. Loss: 0.26109179854393005. Accuracy: 77.69088289771558\n",
      "Epoch:  44\n",
      "Iteration: 1850. Loss: 0.2680096924304962. Accuracy: 77.25869520477464\n",
      "Iteration: 1860. Loss: 0.2722409665584564. Accuracy: 76.49722165054538\n",
      "Iteration: 1870. Loss: 0.3332543671131134. Accuracy: 78.5964190162585\n",
      "Iteration: 1880. Loss: 0.26593053340911865. Accuracy: 79.23441037250463\n",
      "Iteration: 1890. Loss: 0.2791985273361206. Accuracy: 78.65816011525006\n",
      "Epoch:  45\n",
      "Iteration: 1900. Loss: 0.27464696764945984. Accuracy: 77.15579337312204\n",
      "Iteration: 1910. Loss: 0.2639485001564026. Accuracy: 77.99958839267339\n",
      "Iteration: 1920. Loss: 0.26177752017974854. Accuracy: 79.25499073883515\n",
      "Iteration: 1930. Loss: 0.2857489585876465. Accuracy: 79.48137476847089\n",
      "Epoch:  46\n",
      "Iteration: 1940. Loss: 0.29943880438804626. Accuracy: 77.46449886807986\n",
      "Iteration: 1950. Loss: 0.26426824927330017. Accuracy: 77.99958839267339\n",
      "Iteration: 1960. Loss: 0.29742950201034546. Accuracy: 78.18481168964807\n",
      "Iteration: 1970. Loss: 0.2856154441833496. Accuracy: 78.20539205597859\n",
      "Epoch:  47\n",
      "Iteration: 1980. Loss: 0.26901963353157043. Accuracy: 78.37003498662276\n",
      "Iteration: 1990. Loss: 0.254823237657547. Accuracy: 78.10249022432599\n",
      "Iteration: 2000. Loss: 0.3078150749206543. Accuracy: 79.2138300061741\n",
      "Iteration: 2010. Loss: 0.2380947470664978. Accuracy: 79.06976744186046\n",
      "Iteration: 2020. Loss: 0.3006457984447479. Accuracy: 79.25499073883515\n",
      "Epoch:  48\n",
      "Iteration: 2030. Loss: 0.17945373058319092. Accuracy: 78.10249022432599\n",
      "Iteration: 2040. Loss: 0.26506805419921875. Accuracy: 79.35789257048775\n",
      "Iteration: 2050. Loss: 0.22054226696491241. Accuracy: 79.33731220415723\n",
      "Iteration: 2060. Loss: 0.2513965666294098. Accuracy: 79.83124099608973\n",
      "Epoch:  49\n",
      "Iteration: 2070. Loss: 0.24300141632556915. Accuracy: 78.5964190162585\n",
      "Iteration: 2080. Loss: 0.19840359687805176. Accuracy: 79.27557110516567\n",
      "Iteration: 2090. Loss: 0.19126255810260773. Accuracy: 78.86396377855526\n",
      "Iteration: 2100. Loss: 0.168076291680336. Accuracy: 79.25499073883515\n",
      "Epoch:  50\n",
      "Iteration: 2110. Loss: 0.17324687540531158. Accuracy: 77.97900802634287\n",
      "Iteration: 2120. Loss: 0.20082692801952362. Accuracy: 78.78164231323318\n",
      "Iteration: 2130. Loss: 0.17485620081424713. Accuracy: 79.2138300061741\n",
      "Iteration: 2140. Loss: 0.25355371832847595. Accuracy: 79.54311586746245\n",
      "Iteration: 2150. Loss: 0.3482893109321594. Accuracy: 79.23441037250463\n",
      "Epoch:  51\n",
      "Iteration: 2160. Loss: 0.2166626751422882. Accuracy: 79.5019551348014\n",
      "Iteration: 2170. Loss: 0.31900089979171753. Accuracy: 79.41963366947931\n",
      "Iteration: 2180. Loss: 0.20667782425880432. Accuracy: 79.72833916443713\n",
      "Iteration: 2190. Loss: 0.17804354429244995. Accuracy: 79.93414282774233\n",
      "Epoch:  52\n",
      "Iteration: 2200. Loss: 0.2591448724269867. Accuracy: 77.93784729368183\n",
      "Iteration: 2210. Loss: 0.28025850653648376. Accuracy: 78.9051245112163\n",
      "Iteration: 2220. Loss: 0.2261505424976349. Accuracy: 79.91356246141181\n",
      "Iteration: 2230. Loss: 0.19511353969573975. Accuracy: 79.37847293681827\n",
      "Epoch:  53\n",
      "Iteration: 2240. Loss: 0.16041798889636993. Accuracy: 79.17266927351307\n",
      "Iteration: 2250. Loss: 0.20384259521961212. Accuracy: 79.04918707552994\n",
      "Iteration: 2260. Loss: 0.21443712711334229. Accuracy: 79.62543733278453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2270. Loss: 0.2229611873626709. Accuracy: 79.95472319407286\n",
      "Epoch:  54\n",
      "Iteration: 2280. Loss: 0.16594736278057098. Accuracy: 80.03704465939494\n",
      "Iteration: 2290. Loss: 0.21415136754512787. Accuracy: 80.01646429306442\n",
      "Iteration: 2300. Loss: 0.17093145847320557. Accuracy: 80.32516978802222\n",
      "Iteration: 2310. Loss: 0.2426336407661438. Accuracy: 78.96686561020786\n",
      "Iteration: 2320. Loss: 0.20441584289073944. Accuracy: 78.76106194690266\n",
      "Epoch:  55\n",
      "Iteration: 2330. Loss: 0.21555553376674652. Accuracy: 79.37847293681827\n",
      "Iteration: 2340. Loss: 0.14210999011993408. Accuracy: 78.86396377855526\n",
      "Iteration: 2350. Loss: 0.15308713912963867. Accuracy: 80.7985182136242\n",
      "Iteration: 2360. Loss: 0.23297330737113953. Accuracy: 80.07820539205598\n",
      "Epoch:  56\n",
      "Iteration: 2370. Loss: 0.25076228380203247. Accuracy: 78.94628524387734\n",
      "Iteration: 2380. Loss: 0.14125113189220428. Accuracy: 79.39905330314879\n",
      "Iteration: 2390. Loss: 0.194580078125. Accuracy: 79.58427660012349\n",
      "Iteration: 2400. Loss: 0.20696097612380981. Accuracy: 79.70775879810661\n",
      "Epoch:  57\n",
      "Iteration: 2410. Loss: 0.17731186747550964. Accuracy: 79.46079440214035\n",
      "Iteration: 2420. Loss: 0.21694378554821014. Accuracy: 78.86396377855526\n",
      "Iteration: 2430. Loss: 0.1410520374774933. Accuracy: 80.01646429306442\n",
      "Iteration: 2440. Loss: 0.22763514518737793. Accuracy: 79.79008026342869\n",
      "Iteration: 2450. Loss: 0.18659736216068268. Accuracy: 79.76949989709817\n",
      "Epoch:  58\n",
      "Iteration: 2460. Loss: 0.2196049690246582. Accuracy: 79.48137476847089\n",
      "Iteration: 2470. Loss: 0.31314200162887573. Accuracy: 78.8022226795637\n",
      "Iteration: 2480. Loss: 0.13567635416984558. Accuracy: 80.75735748096317\n",
      "Iteration: 2490. Loss: 0.18663789331912994. Accuracy: 80.77793784729369\n",
      "Epoch:  59\n",
      "Iteration: 2500. Loss: 0.15670551359653473. Accuracy: 79.31673183782671\n",
      "Iteration: 2510. Loss: 0.1762840449810028. Accuracy: 79.8929820950813\n",
      "Iteration: 2520. Loss: 0.15301445126533508. Accuracy: 79.93414282774233\n",
      "Iteration: 2530. Loss: 0.1577725112438202. Accuracy: 80.46923235233587\n",
      "Epoch:  60\n",
      "Iteration: 2540. Loss: 0.16568566858768463. Accuracy: 80.4074912533443\n",
      "Iteration: 2550. Loss: 0.13807769119739532. Accuracy: 80.11936612471702\n",
      "Iteration: 2560. Loss: 0.16488607227802277. Accuracy: 79.64601769911505\n",
      "Iteration: 2570. Loss: 0.16366110742092133. Accuracy: 80.36633052068326\n",
      "Iteration: 2580. Loss: 0.3318491578102112. Accuracy: 79.66659806544557\n",
      "Epoch:  61\n",
      "Iteration: 2590. Loss: 0.1984306126832962. Accuracy: 78.6993208479111\n",
      "Iteration: 2600. Loss: 0.2140265554189682. Accuracy: 79.39905330314879\n",
      "Iteration: 2610. Loss: 0.12798796594142914. Accuracy: 79.83124099608973\n",
      "Iteration: 2620. Loss: 0.19454902410507202. Accuracy: 79.64601769911505\n",
      "Epoch:  62\n",
      "Iteration: 2630. Loss: 0.15319597721099854. Accuracy: 79.8929820950813\n",
      "Iteration: 2640. Loss: 0.12867416441440582. Accuracy: 79.97530356040338\n",
      "Iteration: 2650. Loss: 0.13744647800922394. Accuracy: 79.85182136242025\n",
      "Iteration: 2660. Loss: 0.13813678920269012. Accuracy: 81.08664334225149\n",
      "Epoch:  63\n",
      "Iteration: 2670. Loss: 0.14808723330497742. Accuracy: 80.01646429306442\n",
      "Iteration: 2680. Loss: 0.13327065110206604. Accuracy: 80.07820539205598\n",
      "Iteration: 2690. Loss: 0.20674724876880646. Accuracy: 79.83124099608973\n",
      "Iteration: 2700. Loss: 0.13629688322544098. Accuracy: 80.26342868903066\n",
      "Epoch:  64\n",
      "Iteration: 2710. Loss: 0.14856597781181335. Accuracy: 79.27557110516567\n",
      "Epoch:  66\n",
      "Iteration: 2800. Loss: 0.173702672123909. Accuracy: 78.63757974891953\n",
      "Iteration: 2810. Loss: 0.1250087022781372. Accuracy: 80.0987857583865\n",
      "Iteration: 2820. Loss: 0.15999828279018402. Accuracy: 80.22226795636962\n",
      "Iteration: 2830. Loss: 0.1534670740365982. Accuracy: 80.44865198600534\n",
      "Epoch:  67\n",
      "Iteration: 2840. Loss: 0.15194320678710938. Accuracy: 79.60485696645401\n",
      "Iteration: 2850. Loss: 0.17424538731575012. Accuracy: 80.86025931261577\n",
      "Iteration: 2860. Loss: 0.11123546957969666. Accuracy: 80.16052685737806\n",
      "Iteration: 2870. Loss: 0.16599325835704803. Accuracy: 80.86025931261577\n",
      "Iteration: 2880. Loss: 0.10944143682718277. Accuracy: 80.65445564931056\n",
      "Epoch:  68\n",
      "Iteration: 2890. Loss: 0.13692855834960938. Accuracy: 79.79008026342869\n",
      "Iteration: 2900. Loss: 0.13279883563518524. Accuracy: 80.94258077793785\n",
      "Iteration: 2910. Loss: 0.1274634450674057. Accuracy: 79.8929820950813\n",
      "Iteration: 2920. Loss: 0.08737008273601532. Accuracy: 79.93414282774233\n",
      "Epoch:  69\n",
      "Iteration: 2930. Loss: 0.12130013853311539. Accuracy: 79.95472319407286\n",
      "Iteration: 2940. Loss: 0.15898790955543518. Accuracy: 80.55155381765796\n",
      "Iteration: 2950. Loss: 0.0872003361582756. Accuracy: 79.64601769911505\n",
      "Iteration: 2960. Loss: 0.18190398812294006. Accuracy: 80.28400905536118\n",
      "Epoch:  70\n",
      "Iteration: 2970. Loss: 0.1443721055984497. Accuracy: 79.64601769911505\n",
      "Iteration: 2980. Loss: 0.17198941111564636. Accuracy: 80.2016875900391\n",
      "Iteration: 2990. Loss: 0.15639902651309967. Accuracy: 80.94258077793785\n",
      "Iteration: 3000. Loss: 0.14257578551769257. Accuracy: 81.25128627289565\n",
      "Iteration: 3010. Loss: 0.3178168535232544. Accuracy: 80.3045894216917\n",
      "Epoch:  71\n",
      "Iteration: 3020. Loss: 0.1804935485124588. Accuracy: 79.76949989709817\n",
      "Iteration: 3030. Loss: 0.10037651658058167. Accuracy: 80.5103930849969\n",
      "Iteration: 3040. Loss: 0.16256915032863617. Accuracy: 79.8929820950813\n",
      "Iteration: 3050. Loss: 0.1817912608385086. Accuracy: 79.37847293681827\n",
      "Epoch:  72\n",
      "Iteration: 3060. Loss: 0.1789967119693756. Accuracy: 80.18110722370858\n",
      "Iteration: 3070. Loss: 0.15950074791908264. Accuracy: 80.0987857583865\n",
      "Iteration: 3080. Loss: 0.08143645524978638. Accuracy: 80.5103930849969\n",
      "Iteration: 3090. Loss: 0.08240810036659241. Accuracy: 80.63387528298004\n",
      "Epoch:  73\n",
      "Iteration: 3100. Loss: 0.12439456582069397. Accuracy: 80.11936612471702\n",
      "Iteration: 3110. Loss: 0.13105222582817078. Accuracy: 80.07820539205598\n",
      "Iteration: 3120. Loss: 0.08959139138460159. Accuracy: 80.71619674830212\n",
      "Iteration: 3130. Loss: 0.09267893433570862. Accuracy: 80.83967894628525\n",
      "Epoch:  74\n",
      "Iteration: 3140. Loss: 0.04540408030152321. Accuracy: 80.03704465939494\n",
      "Iteration: 3150. Loss: 0.13177956640720367. Accuracy: 79.81066062975921\n",
      "Iteration: 3160. Loss: 0.09558036178350449. Accuracy: 80.48981271866639\n",
      "Iteration: 3170. Loss: 0.16396614909172058. Accuracy: 80.48981271866639\n",
      "Iteration: 3180. Loss: 0.09258487075567245. Accuracy: 80.65445564931056\n",
      "Epoch:  75\n",
      "Iteration: 3190. Loss: 0.11095510423183441. Accuracy: 80.0987857583865\n",
      "Iteration: 3200. Loss: 0.08080807328224182. Accuracy: 80.46923235233587\n",
      "Iteration: 3210. Loss: 0.13831159472465515. Accuracy: 80.4074912533443\n",
      "Iteration: 3220. Loss: 0.10223662108182907. Accuracy: 80.16052685737806\n",
      "Epoch:  76\n",
      "Iteration: 3230. Loss: 0.11625451594591141. Accuracy: 80.65445564931056\n",
      "Iteration: 3240. Loss: 0.11926208436489105. Accuracy: 80.07820539205598\n",
      "Iteration: 3250. Loss: 0.12176503241062164. Accuracy: 80.6956163819716\n",
      "Iteration: 3260. Loss: 0.14884673058986664. Accuracy: 80.34575015435274\n",
      "Epoch:  77\n",
      "Iteration: 3270. Loss: 0.13233639299869537. Accuracy: 79.0080263428689\n",
      "Iteration: 3280. Loss: 0.09754520654678345. Accuracy: 80.0987857583865\n",
      "Iteration: 3290. Loss: 0.05741773173213005. Accuracy: 81.02490224325993\n",
      "Iteration: 3300. Loss: 0.0840839073061943. Accuracy: 80.32516978802222\n",
      "Iteration: 3310. Loss: 0.09316404908895493. Accuracy: 81.53941140152294\n",
      "Epoch:  78\n",
      "Iteration: 3320. Loss: 0.1438060998916626. Accuracy: 80.61329491664952\n",
      "Iteration: 3330. Loss: 0.12142159789800644. Accuracy: 80.83967894628525\n",
      "Iteration: 3340. Loss: 0.08207292854785919. Accuracy: 81.23070590656513\n",
      "Iteration: 3350. Loss: 0.08562785387039185. Accuracy: 81.02490224325993\n",
      "Epoch:  79\n",
      "Iteration: 3360. Loss: 0.11496564000844955. Accuracy: 79.27557110516567\n",
      "Iteration: 3370. Loss: 0.17822518944740295. Accuracy: 79.81066062975921\n",
      "Iteration: 3380. Loss: 0.08640705049037933. Accuracy: 80.61329491664952\n",
      "Iteration: 3390. Loss: 0.08246386796236038. Accuracy: 81.31302737188722\n",
      "Epoch:  80\n",
      "Iteration: 3400. Loss: 0.134019136428833. Accuracy: 79.25499073883515\n",
      "Iteration: 3410. Loss: 0.13029707968235016. Accuracy: 80.53097345132744\n",
      "Iteration: 3420. Loss: 0.16437529027462006. Accuracy: 80.01646429306442\n",
      "Iteration: 3430. Loss: 0.12462878227233887. Accuracy: 80.6956163819716\n",
      "Iteration: 3440. Loss: 0.2984968423843384. Accuracy: 81.06606297592097\n",
      "Epoch:  81\n",
      "Iteration: 3450. Loss: 0.12124783545732498. Accuracy: 80.3045894216917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3460. Loss: 0.17518965899944305. Accuracy: 80.46923235233587\n",
      "Iteration: 3470. Loss: 0.0703493058681488. Accuracy: 80.42807161967482\n",
      "Iteration: 3480. Loss: 0.14141543209552765. Accuracy: 80.2016875900391\n",
      "Epoch:  82\n",
      "Iteration: 3490. Loss: 0.16564230620861053. Accuracy: 79.74891953076765\n",
      "Iteration: 3500. Loss: 0.08166506886482239. Accuracy: 80.44865198600534\n",
      "Iteration: 3510. Loss: 0.0664437860250473. Accuracy: 80.77793784729369\n",
      "Iteration: 3520. Loss: 0.19341717660427094. Accuracy: 80.7985182136242\n",
      "Epoch:  83\n",
      "Iteration: 3530. Loss: 0.06092234328389168. Accuracy: 79.95472319407286\n",
      "Iteration: 3540. Loss: 0.08138827979564667. Accuracy: 79.66659806544557\n",
      "Iteration: 3550. Loss: 0.0977540835738182. Accuracy: 81.08664334225149\n",
      "Iteration: 3560. Loss: 0.056659795343875885. Accuracy: 81.3953488372093\n",
      "Epoch:  84\n",
      "Iteration: 3570. Loss: 0.04483826085925102. Accuracy: 80.44865198600534\n",
      "Iteration: 3580. Loss: 0.11965283006429672. Accuracy: 79.41963366947931\n",
      "Iteration: 3590. Loss: 0.09873320907354355. Accuracy: 79.72833916443713\n",
      "Iteration: 3600. Loss: 0.08389836549758911. Accuracy: 80.92200041160733\n",
      "Iteration: 3610. Loss: 0.09232450276613235. Accuracy: 80.36633052068326\n",
      "Epoch:  85\n",
      "Iteration: 3620. Loss: 0.0725603848695755. Accuracy: 80.0987857583865\n",
      "Iteration: 3630. Loss: 0.07877277582883835. Accuracy: 81.55999176785346\n",
      "Iteration: 3640. Loss: 0.053236059844493866. Accuracy: 80.3045894216917\n",
      "Iteration: 3650. Loss: 0.1488521248102188. Accuracy: 80.32516978802222\n",
      "Epoch:  86\n",
      "Iteration: 3660. Loss: 0.1960732340812683. Accuracy: 79.19324963984359\n",
      "Iteration: 3670. Loss: 0.1338513195514679. Accuracy: 79.25499073883515\n",
      "Iteration: 3680. Loss: 0.12505552172660828. Accuracy: 79.41963366947931\n",
      "Iteration: 3690. Loss: 0.14028823375701904. Accuracy: 80.55155381765796\n",
      "Epoch:  87\n",
      "Iteration: 3700. Loss: 0.07189617305994034. Accuracy: 78.94628524387734\n",
      "Iteration: 3710. Loss: 0.11823201179504395. Accuracy: 79.09034780819098\n",
      "Iteration: 3720. Loss: 0.08375421911478043. Accuracy: 80.83967894628525\n",
      "Iteration: 3730. Loss: 0.1511194258928299. Accuracy: 80.16052685737806\n",
      "Iteration: 3740. Loss: 0.08919991552829742. Accuracy: 80.65445564931056\n",
      "Epoch:  88\n",
      "Iteration: 3750. Loss: 0.06685493886470795. Accuracy: 81.35418810454826\n",
      "Iteration: 3760. Loss: 0.06384911388158798. Accuracy: 81.21012554023461\n",
      "Iteration: 3770. Loss: 0.05596192553639412. Accuracy: 81.80695616381972\n",
      "Iteration: 3780. Loss: 0.10230129957199097. Accuracy: 81.37476847087878\n",
      "Epoch:  89\n",
      "Iteration: 3790. Loss: 0.06743833422660828. Accuracy: 80.83967894628525\n",
      "Iteration: 3800. Loss: 0.07254165410995483. Accuracy: 80.90142004527681\n",
      "Iteration: 3810. Loss: 0.07059524208307266. Accuracy: 81.64231323317556\n",
      "Iteration: 3820. Loss: 0.03741594776511192. Accuracy: 81.12780407491253\n",
      "Epoch:  90\n",
      "Iteration: 3830. Loss: 0.15214765071868896. Accuracy: 81.1895451739041\n",
      "Iteration: 3840. Loss: 0.061247892677783966. Accuracy: 80.6956163819716\n",
      "Iteration: 3850. Loss: 0.06466537714004517. Accuracy: 80.57213418398848\n",
      "Iteration: 3860. Loss: 0.054986048489809036. Accuracy: 80.65445564931056\n",
      "Iteration: 3870. Loss: 0.6099209785461426. Accuracy: 81.35418810454826\n",
      "Epoch:  91\n",
      "Iteration: 3880. Loss: 0.15809981524944305. Accuracy: 79.68717843177609\n",
      "Iteration: 3890. Loss: 0.06755655258893967. Accuracy: 79.68717843177609\n",
      "Iteration: 3900. Loss: 0.14017073810100555. Accuracy: 80.38691088701378\n",
      "Iteration: 3910. Loss: 0.06960829347372055. Accuracy: 80.63387528298004\n",
      "Epoch:  92\n",
      "Iteration: 3920. Loss: 0.10392597317695618. Accuracy: 80.13994649104754\n",
      "Iteration: 3930. Loss: 0.15484829246997833. Accuracy: 79.54311586746245\n",
      "Iteration: 3940. Loss: 0.13675978779792786. Accuracy: 81.1895451739041\n",
      "Iteration: 3950. Loss: 0.05974431335926056. Accuracy: 80.55155381765796\n",
      "Epoch:  93\n",
      "Iteration: 3960. Loss: 0.10129959136247635. Accuracy: 80.34575015435274\n",
      "Iteration: 3970. Loss: 0.05884392932057381. Accuracy: 81.23070590656513\n",
      "Iteration: 3980. Loss: 0.05033915489912033. Accuracy: 80.44865198600534\n",
      "Iteration: 3990. Loss: 0.06142701581120491. Accuracy: 80.81909857995473\n",
      "Epoch:  94\n",
      "Iteration: 4000. Loss: 0.05954895168542862. Accuracy: 79.8929820950813\n",
      "Iteration: 4010. Loss: 0.038981158286333084. Accuracy: 80.5103930849969\n",
      "Iteration: 4020. Loss: 0.05731687694787979. Accuracy: 80.34575015435274\n",
      "Iteration: 4030. Loss: 0.06086312606930733. Accuracy: 80.77793784729369\n",
      "Iteration: 4040. Loss: 0.050680190324783325. Accuracy: 81.3953488372093\n",
      "Epoch:  95\n",
      "Iteration: 4050. Loss: 0.09032457321882248. Accuracy: 80.75735748096317\n",
      "Iteration: 4060. Loss: 0.07578056305646896. Accuracy: 80.32516978802222\n",
      "Iteration: 4070. Loss: 0.05245155841112137. Accuracy: 81.27186663922618\n",
      "Iteration: 4080. Loss: 0.09954226762056351. Accuracy: 81.31302737188722\n",
      "Epoch:  96\n",
      "Iteration: 4090. Loss: 0.06664145737886429. Accuracy: 80.63387528298004\n",
      "Iteration: 4100. Loss: 0.09332578629255295. Accuracy: 80.6956163819716\n",
      "Iteration: 4110. Loss: 0.07366062700748444. Accuracy: 80.3045894216917\n",
      "Iteration: 4120. Loss: 0.13836488127708435. Accuracy: 80.44865198600534\n",
      "Epoch:  97\n",
      "Iteration: 4130. Loss: 0.078484907746315. Accuracy: 80.0987857583865\n",
      "Iteration: 4140. Loss: 0.1179206594824791. Accuracy: 79.17266927351307\n",
      "Iteration: 4150. Loss: 0.0710664764046669. Accuracy: 80.24284832270014\n",
      "Iteration: 4160. Loss: 0.0954187884926796. Accuracy: 81.1895451739041\n",
      "Iteration: 4170. Loss: 0.07442795485258102. Accuracy: 80.92200041160733\n",
      "Epoch:  98\n",
      "Iteration: 4180. Loss: 0.05793953314423561. Accuracy: 80.55155381765796\n",
      "Iteration: 4190. Loss: 0.06040739268064499. Accuracy: 81.60115250051452\n",
      "Iteration: 4200. Loss: 0.06140198931097984. Accuracy: 81.27186663922618\n",
      "Iteration: 4210. Loss: 0.09183746576309204. Accuracy: 80.88083967894629\n",
      "Epoch:  99\n",
      "Iteration: 4220. Loss: 0.10413933545351028. Accuracy: 81.16896480757357\n",
      "Iteration: 4230. Loss: 0.08987154066562653. Accuracy: 80.34575015435274\n",
      "Iteration: 4240. Loss: 0.11167025566101074. Accuracy: 81.12780407491253\n",
      "Iteration: 4250. Loss: 0.07394269853830338. Accuracy: 80.96316114426837\n",
      "Epoch:  100\n",
      "Iteration: 4260. Loss: 0.0643899217247963. Accuracy: 80.7985182136242\n",
      "Iteration: 4270. Loss: 0.038979921489953995. Accuracy: 81.04548260959045\n",
      "Iteration: 4280. Loss: 0.044489581137895584. Accuracy: 81.14838444124305\n",
      "Iteration: 4290. Loss: 0.057791341096162796. Accuracy: 80.96316114426837\n",
      "Iteration: 4300. Loss: 0.32471394538879395. Accuracy: 81.66289359950608\n",
      "Epoch:  101\n",
      "Iteration: 4310. Loss: 0.05384831875562668. Accuracy: 80.73677711463264\n",
      "Iteration: 4320. Loss: 0.0824994444847107. Accuracy: 81.08664334225149\n",
      "Iteration: 4330. Loss: 0.05670909211039543. Accuracy: 81.23070590656513\n",
      "Iteration: 4340. Loss: 0.05622732266783714. Accuracy: 81.3953488372093\n",
      "Epoch:  102\n",
      "Iteration: 4350. Loss: 0.06705518066883087. Accuracy: 80.592714550319\n",
      "Iteration: 4360. Loss: 0.028510682284832. Accuracy: 80.71619674830212\n",
      "Iteration: 4370. Loss: 0.061941713094711304. Accuracy: 81.66289359950608\n",
      "Iteration: 4380. Loss: 0.033474814146757126. Accuracy: 81.08664334225149\n",
      "Epoch:  103\n",
      "Iteration: 4390. Loss: 0.061252664774656296. Accuracy: 79.85182136242025\n",
      "Iteration: 4400. Loss: 0.08119967579841614. Accuracy: 80.75735748096317\n",
      "Iteration: 4410. Loss: 0.07438434660434723. Accuracy: 80.81909857995473\n",
      "Iteration: 4420. Loss: 0.044764745980501175. Accuracy: 80.65445564931056\n",
      "Epoch:  104\n",
      "Iteration: 4430. Loss: 0.05297168716788292. Accuracy: 80.88083967894629\n",
      "Iteration: 4440. Loss: 0.06761312484741211. Accuracy: 81.1895451739041\n",
      "Iteration: 4450. Loss: 0.059918876737356186. Accuracy: 80.53097345132744\n",
      "Iteration: 4460. Loss: 0.06074680760502815. Accuracy: 81.41592920353982\n",
      "Iteration: 4470. Loss: 0.025060007348656654. Accuracy: 81.31302737188722\n",
      "Epoch:  105\n",
      "Iteration: 4480. Loss: 0.12795116007328033. Accuracy: 77.58798106606298\n",
      "Iteration: 4490. Loss: 0.09505380690097809. Accuracy: 79.27557110516567\n",
      "Iteration: 4500. Loss: 0.09222085028886795. Accuracy: 80.28400905536118\n",
      "Iteration: 4510. Loss: 0.1252690553665161. Accuracy: 81.23070590656513\n",
      "Epoch:  106\n",
      "Iteration: 4520. Loss: 0.06350421160459518. Accuracy: 80.81909857995473\n",
      "Iteration: 4530. Loss: 0.08434867858886719. Accuracy: 80.96316114426837\n",
      "Iteration: 4540. Loss: 0.03695644065737724. Accuracy: 80.7985182136242\n",
      "Iteration: 4550. Loss: 0.07472308725118637. Accuracy: 80.98374151059889\n",
      "Epoch:  107\n",
      "Iteration: 4560. Loss: 0.05310270935297012. Accuracy: 80.71619674830212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4570. Loss: 0.08849899470806122. Accuracy: 79.91356246141181\n",
      "Iteration: 4580. Loss: 0.06273341178894043. Accuracy: 80.67503601564108\n",
      "Iteration: 4590. Loss: 0.05072811245918274. Accuracy: 81.31302737188722\n",
      "Iteration: 4600. Loss: 0.12162528187036514. Accuracy: 80.94258077793785\n",
      "Epoch:  108\n",
      "Iteration: 4610. Loss: 0.07441921532154083. Accuracy: 80.44865198600534\n",
      "Iteration: 4620. Loss: 0.07330082356929779. Accuracy: 81.06606297592097\n",
      "Iteration: 4630. Loss: 0.057243380695581436. Accuracy: 80.63387528298004\n",
      "Iteration: 4640. Loss: 0.04069254919886589. Accuracy: 81.35418810454826\n",
      "Epoch:  109\n",
      "Iteration: 4650. Loss: 0.08844846487045288. Accuracy: 80.42807161967482\n",
      "Iteration: 4660. Loss: 0.13955143094062805. Accuracy: 80.36633052068326\n",
      "Iteration: 4670. Loss: 0.05640894174575806. Accuracy: 80.53097345132744\n",
      "Iteration: 4680. Loss: 0.07122880220413208. Accuracy: 81.41592920353982\n",
      "Epoch:  110\n",
      "Iteration: 4690. Loss: 0.09973937273025513. Accuracy: 79.68717843177609\n",
      "Iteration: 4700. Loss: 0.1374518871307373. Accuracy: 79.64601769911505\n",
      "Iteration: 4710. Loss: 0.06859146058559418. Accuracy: 80.67503601564108\n",
      "Iteration: 4720. Loss: 0.041574876755476. Accuracy: 80.88083967894629\n",
      "Iteration: 4730. Loss: 0.3142363429069519. Accuracy: 81.47767030253138\n",
      "Epoch:  111\n",
      "Iteration: 4740. Loss: 0.10757718980312347. Accuracy: 80.4074912533443\n",
      "Iteration: 4750. Loss: 0.09129485487937927. Accuracy: 80.67503601564108\n",
      "Iteration: 4760. Loss: 0.041016604751348495. Accuracy: 81.580572134184\n",
      "Iteration: 4770. Loss: 0.07816935330629349. Accuracy: 80.71619674830212\n",
      "Epoch:  112\n",
      "Iteration: 4780. Loss: 0.045756060630083084. Accuracy: 80.92200041160733\n",
      "Iteration: 4790. Loss: 0.06001908704638481. Accuracy: 81.16896480757357\n",
      "Iteration: 4800. Loss: 0.021594252437353134. Accuracy: 81.3953488372093\n",
      "Iteration: 4810. Loss: 0.017554068937897682. Accuracy: 81.21012554023461\n",
      "Epoch:  113\n",
      "Iteration: 4820. Loss: 0.05583609640598297. Accuracy: 81.37476847087878\n",
      "Iteration: 4830. Loss: 0.035784170031547546. Accuracy: 81.4982506688619\n",
      "Iteration: 4840. Loss: 0.049237556755542755. Accuracy: 80.75735748096317\n",
      "Iteration: 4850. Loss: 0.04820720851421356. Accuracy: 81.00432187692941\n",
      "Epoch:  114\n",
      "Iteration: 4860. Loss: 0.024115215986967087. Accuracy: 80.88083967894629\n",
      "Iteration: 4870. Loss: 0.11004220694303513. Accuracy: 80.13994649104754\n",
      "Iteration: 4880. Loss: 0.07576341181993484. Accuracy: 79.83124099608973\n",
      "Iteration: 4890. Loss: 0.07686054706573486. Accuracy: 80.83967894628525\n",
      "Iteration: 4900. Loss: 0.05990450084209442. Accuracy: 81.02490224325993\n",
      "Epoch:  115\n",
      "Iteration: 4910. Loss: 0.0833660140633583. Accuracy: 80.2016875900391\n",
      "Iteration: 4920. Loss: 0.03310425952076912. Accuracy: 80.44865198600534\n",
      "Iteration: 4930. Loss: 0.0349106639623642. Accuracy: 81.04548260959045\n",
      "Iteration: 4940. Loss: 0.05333463102579117. Accuracy: 80.73677711463264\n",
      "Epoch:  116\n",
      "Iteration: 4950. Loss: 0.037000760436058044. Accuracy: 80.48981271866639\n",
      "Iteration: 4960. Loss: 0.03696485981345177. Accuracy: 80.26342868903066\n",
      "Iteration: 4970. Loss: 0.07424286007881165. Accuracy: 80.90142004527681\n",
      "Iteration: 4980. Loss: 0.034822914749383926. Accuracy: 81.43650956987034\n",
      "Epoch:  117\n",
      "Iteration: 4990. Loss: 0.05257931724190712. Accuracy: 80.26342868903066\n",
      "Iteration: 5000. Loss: 0.03109130449593067. Accuracy: 81.3953488372093\n",
      "Iteration: 5010. Loss: 0.059026412665843964. Accuracy: 81.16896480757357\n",
      "Iteration: 5020. Loss: 0.03314271569252014. Accuracy: 81.00432187692941\n",
      "Iteration: 5030. Loss: 0.04999179393053055. Accuracy: 81.14838444124305\n",
      "Epoch:  118\n",
      "Iteration: 5040. Loss: 0.0510118305683136. Accuracy: 80.96316114426837\n",
      "Iteration: 5050. Loss: 0.01691785641014576. Accuracy: 80.77793784729369\n",
      "Iteration: 5060. Loss: 0.07383470982313156. Accuracy: 80.98374151059889\n",
      "Iteration: 5070. Loss: 0.060748517513275146. Accuracy: 80.57213418398848\n",
      "Epoch:  119\n",
      "Iteration: 5080. Loss: 0.07175954431295395. Accuracy: 80.05762502572546\n",
      "Iteration: 5090. Loss: 0.0938098356127739. Accuracy: 80.22226795636962\n",
      "Iteration: 5100. Loss: 0.09008560329675674. Accuracy: 80.38691088701378\n",
      "Iteration: 5110. Loss: 0.07396314293146133. Accuracy: 81.04548260959045\n",
      "Epoch:  120\n",
      "Iteration: 5120. Loss: 0.054166585206985474. Accuracy: 80.07820539205598\n",
      "Iteration: 5130. Loss: 0.10296602547168732. Accuracy: 80.42807161967482\n",
      "Iteration: 5140. Loss: 0.041079554706811905. Accuracy: 80.61329491664952\n",
      "Iteration: 5150. Loss: 0.05515787750482559. Accuracy: 80.83967894628525\n",
      "Iteration: 5160. Loss: 0.1285114586353302. Accuracy: 81.2924470055567\n",
      "Epoch:  121\n",
      "Iteration: 5170. Loss: 0.06267660111188889. Accuracy: 80.71619674830212\n",
      "Iteration: 5180. Loss: 0.049453288316726685. Accuracy: 80.48981271866639\n",
      "Iteration: 5190. Loss: 0.051527492702007294. Accuracy: 81.4982506688619\n",
      "Iteration: 5200. Loss: 0.03931638225913048. Accuracy: 81.27186663922618\n",
      "Epoch:  122\n",
      "Iteration: 5210. Loss: 0.030092915520071983. Accuracy: 81.25128627289565\n",
      "Iteration: 5220. Loss: 0.021526789292693138. Accuracy: 80.5103930849969\n",
      "Iteration: 5230. Loss: 0.02312282659113407. Accuracy: 81.12780407491253\n",
      "Iteration: 5240. Loss: 0.04484539479017258. Accuracy: 81.31302737188722\n",
      "Epoch:  123\n",
      "Iteration: 5250. Loss: 0.026048213243484497. Accuracy: 79.5019551348014\n",
      "Iteration: 5260. Loss: 0.06950423121452332. Accuracy: 81.35418810454826\n",
      "Iteration: 5270. Loss: 0.06482689827680588. Accuracy: 81.35418810454826\n",
      "Iteration: 5280. Loss: 0.09092961996793747. Accuracy: 81.12780407491253\n",
      "Epoch:  124\n",
      "Iteration: 5290. Loss: 0.06498127430677414. Accuracy: 80.07820539205598\n",
      "Iteration: 5300. Loss: 0.06317566335201263. Accuracy: 80.57213418398848\n",
      "Iteration: 5310. Loss: 0.07937517762184143. Accuracy: 81.51883103519242\n",
      "Iteration: 5320. Loss: 0.04738249629735947. Accuracy: 80.71619674830212\n",
      "Iteration: 5330. Loss: 0.0604451484978199. Accuracy: 81.580572134184\n",
      "Epoch:  125\n",
      "Iteration: 5340. Loss: 0.07685345411300659. Accuracy: 80.57213418398848\n",
      "Iteration: 5350. Loss: 0.027935488149523735. Accuracy: 80.28400905536118\n",
      "Iteration: 5360. Loss: 0.042780522257089615. Accuracy: 81.12780407491253\n",
      "Iteration: 5370. Loss: 0.03864355757832527. Accuracy: 81.84811689648076\n",
      "Epoch:  126\n",
      "Iteration: 5380. Loss: 0.021820202469825745. Accuracy: 81.51883103519242\n",
      "Iteration: 5390. Loss: 0.017257850617170334. Accuracy: 80.4074912533443\n",
      "Iteration: 5400. Loss: 0.05100522190332413. Accuracy: 80.88083967894629\n",
      "Iteration: 5410. Loss: 0.027353590354323387. Accuracy: 80.92200041160733\n",
      "Epoch:  127\n",
      "Iteration: 5420. Loss: 0.01570657081902027. Accuracy: 80.77793784729369\n",
      "Iteration: 5430. Loss: 0.03509720414876938. Accuracy: 81.33360773821774\n",
      "Iteration: 5440. Loss: 0.017338206991553307. Accuracy: 81.16896480757357\n",
      "Iteration: 5450. Loss: 0.024501889944076538. Accuracy: 81.41592920353982\n",
      "Iteration: 5460. Loss: 0.036056339740753174. Accuracy: 81.80695616381972\n",
      "Epoch:  128\n",
      "Iteration: 5470. Loss: 0.07447311282157898. Accuracy: 78.6993208479111\n",
      "Iteration: 5480. Loss: 0.019410090520977974. Accuracy: 80.592714550319\n",
      "Iteration: 5490. Loss: 0.02389821968972683. Accuracy: 81.33360773821774\n",
      "Iteration: 5500. Loss: 0.05710837244987488. Accuracy: 80.88083967894629\n",
      "Epoch:  129\n",
      "Iteration: 5510. Loss: 0.04151608794927597. Accuracy: 80.55155381765796\n",
      "Iteration: 5520. Loss: 0.05929609760642052. Accuracy: 80.98374151059889\n",
      "Iteration: 5530. Loss: 0.018234875053167343. Accuracy: 81.10722370858201\n",
      "Iteration: 5540. Loss: 0.014681677334010601. Accuracy: 81.12780407491253\n",
      "Epoch:  130\n",
      "Iteration: 5550. Loss: 0.036392129957675934. Accuracy: 80.03704465939494\n",
      "Iteration: 5560. Loss: 0.059636469930410385. Accuracy: 81.25128627289565\n",
      "Iteration: 5570. Loss: 0.044796209782361984. Accuracy: 80.77793784729369\n",
      "Iteration: 5580. Loss: 0.027741072699427605. Accuracy: 81.27186663922618\n",
      "Iteration: 5590. Loss: 0.26887941360473633. Accuracy: 80.94258077793785\n",
      "Epoch:  131\n",
      "Iteration: 5600. Loss: 0.07818256318569183. Accuracy: 81.06606297592097\n",
      "Iteration: 5610. Loss: 0.031100884079933167. Accuracy: 81.27186663922618\n",
      "Iteration: 5620. Loss: 0.061095837503671646. Accuracy: 81.70405433216712\n",
      "Iteration: 5630. Loss: 0.020641261711716652. Accuracy: 81.2924470055567\n",
      "Epoch:  132\n",
      "Iteration: 5640. Loss: 0.11069947481155396. Accuracy: 80.05762502572546\n",
      "Iteration: 5650. Loss: 0.048998184502124786. Accuracy: 80.88083967894629\n",
      "Iteration: 5660. Loss: 0.07694312185049057. Accuracy: 79.74891953076765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5670. Loss: 0.05140196159482002. Accuracy: 80.86025931261577\n",
      "Epoch:  133\n",
      "Iteration: 5680. Loss: 0.11906826496124268. Accuracy: 80.46923235233587\n",
      "Iteration: 5690. Loss: 0.06690113991498947. Accuracy: 80.2016875900391\n",
      "Iteration: 5700. Loss: 0.0508376844227314. Accuracy: 80.6956163819716\n",
      "Iteration: 5710. Loss: 0.037089332938194275. Accuracy: 81.10722370858201\n",
      "Epoch:  134\n",
      "Iteration: 5720. Loss: 0.019375991076231003. Accuracy: 80.86025931261577\n",
      "Iteration: 5730. Loss: 0.06955717504024506. Accuracy: 81.00432187692941\n",
      "Iteration: 5740. Loss: 0.028639018535614014. Accuracy: 81.3953488372093\n",
      "Iteration: 5750. Loss: 0.021603718400001526. Accuracy: 80.83967894628525\n",
      "Iteration: 5760. Loss: 0.035396866500377655. Accuracy: 81.08664334225149\n",
      "Epoch:  135\n",
      "Iteration: 5770. Loss: 0.030011147260665894. Accuracy: 81.90985799547232\n",
      "Iteration: 5780. Loss: 0.025143973529338837. Accuracy: 80.96316114426837\n",
      "Iteration: 5790. Loss: 0.01964988373219967. Accuracy: 81.37476847087878\n",
      "Iteration: 5800. Loss: 0.025822628289461136. Accuracy: 80.77793784729369\n",
      "Epoch:  136\n",
      "Iteration: 5810. Loss: 0.05325804650783539. Accuracy: 80.36633052068326\n",
      "Iteration: 5820. Loss: 0.08468042314052582. Accuracy: 80.65445564931056\n",
      "Iteration: 5830. Loss: 0.04583388939499855. Accuracy: 79.62543733278453\n",
      "Iteration: 5840. Loss: 0.018452180549502373. Accuracy: 81.47767030253138\n",
      "Epoch:  137\n",
      "Iteration: 5850. Loss: 0.007246006280183792. Accuracy: 81.1895451739041\n",
      "Iteration: 5860. Loss: 0.02114824205636978. Accuracy: 81.43650956987034\n",
      "Iteration: 5870. Loss: 0.014422675594687462. Accuracy: 81.08664334225149\n",
      "Iteration: 5880. Loss: 0.024717969819903374. Accuracy: 80.86025931261577\n",
      "Iteration: 5890. Loss: 0.009170680306851864. Accuracy: 81.37476847087878\n",
      "Epoch:  138\n",
      "Iteration: 5900. Loss: 0.0548015832901001. Accuracy: 80.2016875900391\n",
      "Iteration: 5910. Loss: 0.027026580646634102. Accuracy: 80.75735748096317\n",
      "Iteration: 5920. Loss: 0.02546994388103485. Accuracy: 80.83967894628525\n",
      "Iteration: 5930. Loss: 0.021191805601119995. Accuracy: 81.3953488372093\n",
      "Epoch:  139\n",
      "Iteration: 5940. Loss: 0.057260289788246155. Accuracy: 81.14838444124305\n",
      "Iteration: 5950. Loss: 0.02680203877389431. Accuracy: 80.32516978802222\n",
      "Iteration: 5960. Loss: 0.04542781040072441. Accuracy: 80.7985182136242\n",
      "Iteration: 5970. Loss: 0.0366339311003685. Accuracy: 80.53097345132744\n",
      "Epoch:  140\n",
      "Iteration: 5980. Loss: 0.029482509940862656. Accuracy: 80.96316114426837\n",
      "Iteration: 5990. Loss: 0.04886604845523834. Accuracy: 80.24284832270014\n",
      "Iteration: 6000. Loss: 0.041505809873342514. Accuracy: 81.10722370858201\n",
      "Iteration: 6010. Loss: 0.039718981832265854. Accuracy: 80.53097345132744\n",
      "Iteration: 6020. Loss: 0.16169878840446472. Accuracy: 80.73677711463264\n",
      "Epoch:  141\n",
      "Iteration: 6030. Loss: 0.06400591135025024. Accuracy: 80.77793784729369\n",
      "Iteration: 6040. Loss: 0.04406590759754181. Accuracy: 81.2924470055567\n",
      "Iteration: 6050. Loss: 0.03476589545607567. Accuracy: 80.55155381765796\n",
      "Iteration: 6060. Loss: 0.04889241233468056. Accuracy: 80.77793784729369\n",
      "Epoch:  142\n",
      "Iteration: 6070. Loss: 0.02297919988632202. Accuracy: 81.31302737188722\n",
      "Iteration: 6080. Loss: 0.04959549009799957. Accuracy: 80.4074912533443\n",
      "Iteration: 6090. Loss: 0.010850967839360237. Accuracy: 81.45708993620086\n",
      "Iteration: 6100. Loss: 0.010874591767787933. Accuracy: 81.02490224325993\n",
      "Epoch:  143\n",
      "Iteration: 6110. Loss: 0.02744225785136223. Accuracy: 80.6956163819716\n",
      "Iteration: 6120. Loss: 0.04567256197333336. Accuracy: 81.08664334225149\n",
      "Iteration: 6130. Loss: 0.07981404662132263. Accuracy: 81.37476847087878\n",
      "Iteration: 6140. Loss: 0.03032011352479458. Accuracy: 80.36633052068326\n",
      "Epoch:  144\n",
      "Iteration: 6150. Loss: 0.026333283632993698. Accuracy: 81.10722370858201\n",
      "Iteration: 6160. Loss: 0.055513303726911545. Accuracy: 80.75735748096317\n",
      "Iteration: 6170. Loss: 0.033402521163225174. Accuracy: 80.18110722370858\n",
      "Iteration: 6180. Loss: 0.036539748311042786. Accuracy: 80.24284832270014\n",
      "Iteration: 6190. Loss: 0.029711643233895302. Accuracy: 80.6956163819716\n",
      "Epoch:  145\n",
      "Iteration: 6200. Loss: 0.06449246406555176. Accuracy: 80.46923235233587\n",
      "Iteration: 6210. Loss: 0.09500869363546371. Accuracy: 80.71619674830212\n",
      "Iteration: 6220. Loss: 0.01862993650138378. Accuracy: 80.86025931261577\n",
      "Iteration: 6230. Loss: 0.05639929696917534. Accuracy: 80.88083967894629\n",
      "Epoch:  146\n",
      "Iteration: 6240. Loss: 0.02176721580326557. Accuracy: 81.37476847087878\n",
      "Iteration: 6250. Loss: 0.024005219340324402. Accuracy: 81.06606297592097\n",
      "Iteration: 6260. Loss: 0.03825938701629639. Accuracy: 80.96316114426837\n",
      "Iteration: 6270. Loss: 0.029293902218341827. Accuracy: 81.02490224325993\n",
      "Epoch:  147\n",
      "Iteration: 6280. Loss: 0.017736496403813362. Accuracy: 80.34575015435274\n",
      "Iteration: 6290. Loss: 0.03473629057407379. Accuracy: 80.24284832270014\n",
      "Iteration: 6300. Loss: 0.03845076635479927. Accuracy: 80.6956163819716\n",
      "Iteration: 6310. Loss: 0.03787022829055786. Accuracy: 80.73677711463264\n",
      "Iteration: 6320. Loss: 0.049389053136110306. Accuracy: 81.41592920353982\n",
      "Epoch:  148\n",
      "Iteration: 6330. Loss: 0.04042121767997742. Accuracy: 80.55155381765796\n",
      "Iteration: 6340. Loss: 0.04932960122823715. Accuracy: 81.10722370858201\n",
      "Iteration: 6350. Loss: 0.04250650107860565. Accuracy: 81.10722370858201\n",
      "Iteration: 6360. Loss: 0.021268948912620544. Accuracy: 80.71619674830212\n",
      "Epoch:  149\n",
      "Iteration: 6370. Loss: 0.025099987164139748. Accuracy: 80.36633052068326\n",
      "Iteration: 6380. Loss: 0.01834753341972828. Accuracy: 80.44865198600534\n",
      "Iteration: 6390. Loss: 0.0411098413169384. Accuracy: 80.94258077793785\n",
      "Iteration: 6400. Loss: 0.03697699308395386. Accuracy: 80.592714550319\n",
      "Epoch:  150\n",
      "Iteration: 6410. Loss: 0.04456270858645439. Accuracy: 79.97530356040338\n",
      "Iteration: 6420. Loss: 0.007572014816105366. Accuracy: 80.98374151059889\n",
      "Iteration: 6430. Loss: 0.023329351097345352. Accuracy: 81.08664334225149\n",
      "Iteration: 6440. Loss: 0.014697756618261337. Accuracy: 80.75735748096317\n",
      "Iteration: 6450. Loss: 0.03888622671365738. Accuracy: 80.63387528298004\n",
      "Epoch:  151\n",
      "Iteration: 6460. Loss: 0.021172886714339256. Accuracy: 80.96316114426837\n",
      "Iteration: 6470. Loss: 0.014804063364863396. Accuracy: 80.90142004527681\n",
      "Iteration: 6480. Loss: 0.02023807168006897. Accuracy: 81.4982506688619\n",
      "Iteration: 6490. Loss: 0.02557452581822872. Accuracy: 81.23070590656513\n",
      "Epoch:  152\n",
      "Iteration: 6500. Loss: 0.040882375091314316. Accuracy: 80.5103930849969\n",
      "Iteration: 6510. Loss: 0.02297336421906948. Accuracy: 80.34575015435274\n",
      "Iteration: 6520. Loss: 0.019576694816350937. Accuracy: 80.34575015435274\n",
      "Iteration: 6530. Loss: 0.056762855499982834. Accuracy: 80.92200041160733\n",
      "Epoch:  153\n",
      "Iteration: 6540. Loss: 0.11913745105266571. Accuracy: 79.64601769911505\n",
      "Iteration: 6550. Loss: 0.15356962382793427. Accuracy: 79.41963366947931\n",
      "Iteration: 6560. Loss: 0.028527718037366867. Accuracy: 80.53097345132744\n",
      "Iteration: 6570. Loss: 0.05682026222348213. Accuracy: 81.33360773821774\n",
      "Epoch:  154\n",
      "Iteration: 6580. Loss: 0.025317523628473282. Accuracy: 80.5103930849969\n",
      "Iteration: 6590. Loss: 0.03865741565823555. Accuracy: 81.06606297592097\n",
      "Iteration: 6600. Loss: 0.06905414164066315. Accuracy: 81.4982506688619\n",
      "Iteration: 6610. Loss: 0.030583754181861877. Accuracy: 80.61329491664952\n",
      "Iteration: 6620. Loss: 0.021911561489105225. Accuracy: 80.92200041160733\n",
      "Epoch:  155\n",
      "Iteration: 6630. Loss: 0.1338839828968048. Accuracy: 80.42807161967482\n",
      "Iteration: 6640. Loss: 0.047207679599523544. Accuracy: 80.86025931261577\n",
      "Iteration: 6650. Loss: 0.030090857297182083. Accuracy: 80.81909857995473\n",
      "Iteration: 6660. Loss: 0.039612192660570145. Accuracy: 80.86025931261577\n",
      "Epoch:  156\n",
      "Iteration: 6670. Loss: 0.09642710536718369. Accuracy: 80.13994649104754\n",
      "Iteration: 6680. Loss: 0.07257480919361115. Accuracy: 78.98744597653838\n",
      "Iteration: 6690. Loss: 0.033343177288770676. Accuracy: 79.91356246141181\n",
      "Iteration: 6700. Loss: 0.0347408726811409. Accuracy: 80.81909857995473\n",
      "Epoch:  157\n",
      "Iteration: 6710. Loss: 0.04699544608592987. Accuracy: 79.33731220415723\n",
      "Iteration: 6720. Loss: 0.01836239919066429. Accuracy: 80.36633052068326\n",
      "Iteration: 6730. Loss: 0.019268963485956192. Accuracy: 81.08664334225149\n",
      "Iteration: 6740. Loss: 0.05603741481900215. Accuracy: 79.72833916443713\n",
      "Iteration: 6750. Loss: 0.039016544818878174. Accuracy: 80.77793784729369\n",
      "Epoch:  158\n",
      "Iteration: 6760. Loss: 0.05779591575264931. Accuracy: 80.5103930849969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6770. Loss: 0.02487354353070259. Accuracy: 79.2138300061741\n",
      "Iteration: 6780. Loss: 0.036082830280065536. Accuracy: 80.48981271866639\n",
      "Iteration: 6790. Loss: 0.01980743557214737. Accuracy: 81.08664334225149\n",
      "Epoch:  159\n",
      "Iteration: 6800. Loss: 0.017506349831819534. Accuracy: 80.01646429306442\n",
      "Iteration: 6810. Loss: 0.022159148007631302. Accuracy: 80.55155381765796\n",
      "Iteration: 6820. Loss: 0.0515725277364254. Accuracy: 80.5103930849969\n",
      "Iteration: 6830. Loss: 0.03143877908587456. Accuracy: 80.77793784729369\n",
      "Epoch:  160\n",
      "Iteration: 6840. Loss: 0.028200190514326096. Accuracy: 81.14838444124305\n",
      "Iteration: 6850. Loss: 0.04195889085531235. Accuracy: 80.73677711463264\n",
      "Iteration: 6860. Loss: 0.016426296904683113. Accuracy: 80.48981271866639\n",
      "Iteration: 6870. Loss: 0.020067239180207253. Accuracy: 81.10722370858201\n",
      "Iteration: 6880. Loss: 0.3008769154548645. Accuracy: 80.3045894216917\n",
      "Epoch:  161\n",
      "Iteration: 6890. Loss: 0.05073004215955734. Accuracy: 80.16052685737806\n",
      "Iteration: 6900. Loss: 0.03689225763082504. Accuracy: 79.66659806544557\n",
      "Iteration: 6910. Loss: 0.012081285007297993. Accuracy: 80.77793784729369\n",
      "Iteration: 6920. Loss: 0.02675243653357029. Accuracy: 80.61329491664952\n",
      "Epoch:  162\n",
      "Iteration: 6930. Loss: 0.02637760527431965. Accuracy: 80.48981271866639\n",
      "Iteration: 6940. Loss: 0.073420450091362. Accuracy: 80.4074912533443\n",
      "Iteration: 6950. Loss: 0.06012224778532982. Accuracy: 80.83967894628525\n",
      "Iteration: 6960. Loss: 0.012565642595291138. Accuracy: 80.81909857995473\n",
      "Epoch:  163\n",
      "Iteration: 6970. Loss: 0.010930176824331284. Accuracy: 80.88083967894629\n",
      "Iteration: 6980. Loss: 0.004393408540636301. Accuracy: 81.2924470055567\n",
      "Iteration: 6990. Loss: 0.06228163093328476. Accuracy: 81.31302737188722\n",
      "Iteration: 7000. Loss: 0.01953515224158764. Accuracy: 80.92200041160733\n",
      "Epoch:  164\n",
      "Iteration: 7010. Loss: 0.0054787686094641685. Accuracy: 80.6956163819716\n",
      "Iteration: 7020. Loss: 0.033373963087797165. Accuracy: 81.27186663922618\n",
      "Iteration: 7030. Loss: 0.009938523173332214. Accuracy: 80.90142004527681\n",
      "Iteration: 7040. Loss: 0.024843454360961914. Accuracy: 80.7985182136242\n",
      "Iteration: 7050. Loss: 0.01120286900550127. Accuracy: 80.03704465939494\n",
      "Epoch:  165\n",
      "Iteration: 7060. Loss: 0.05378195643424988. Accuracy: 80.73677711463264\n",
      "Iteration: 7070. Loss: 0.037459682673215866. Accuracy: 80.42807161967482\n",
      "Iteration: 7080. Loss: 0.041557006537914276. Accuracy: 80.73677711463264\n",
      "Iteration: 7090. Loss: 0.043028295040130615. Accuracy: 81.08664334225149\n",
      "Epoch:  166\n",
      "Iteration: 7100. Loss: 0.09000304341316223. Accuracy: 79.19324963984359\n",
      "Iteration: 7110. Loss: 0.023081809282302856. Accuracy: 79.95472319407286\n",
      "Iteration: 7120. Loss: 0.09173517674207687. Accuracy: 80.57213418398848\n",
      "Iteration: 7130. Loss: 0.05332763120532036. Accuracy: 80.88083967894629\n",
      "Epoch:  167\n",
      "Iteration: 7140. Loss: 0.033736418932676315. Accuracy: 79.95472319407286\n",
      "Iteration: 7150. Loss: 0.04015154391527176. Accuracy: 81.00432187692941\n",
      "Iteration: 7160. Loss: 0.03079625964164734. Accuracy: 81.1895451739041\n",
      "Iteration: 7170. Loss: 0.011700655333697796. Accuracy: 81.10722370858201\n",
      "Iteration: 7180. Loss: 0.04251012206077576. Accuracy: 80.53097345132744\n",
      "Epoch:  168\n",
      "Iteration: 7190. Loss: 0.02668207697570324. Accuracy: 80.98374151059889\n",
      "Iteration: 7200. Loss: 0.006027093157172203. Accuracy: 80.81909857995473\n",
      "Iteration: 7210. Loss: 0.014834457077085972. Accuracy: 81.33360773821774\n",
      "Iteration: 7220. Loss: 0.0381028912961483. Accuracy: 80.83967894628525\n",
      "Epoch:  169\n",
      "Iteration: 7230. Loss: 0.048115964978933334. Accuracy: 80.05762502572546\n",
      "Iteration: 7240. Loss: 0.04213687404990196. Accuracy: 80.18110722370858\n",
      "Iteration: 7250. Loss: 0.05697247385978699. Accuracy: 80.90142004527681\n",
      "Iteration: 7260. Loss: 0.04377763345837593. Accuracy: 80.77793784729369\n",
      "Epoch:  170\n",
      "Iteration: 7270. Loss: 0.06754797697067261. Accuracy: 80.4074912533443\n",
      "Iteration: 7280. Loss: 0.05132368579506874. Accuracy: 80.24284832270014\n",
      "Iteration: 7290. Loss: 0.09205025434494019. Accuracy: 80.16052685737806\n",
      "Iteration: 7300. Loss: 0.03467119112610817. Accuracy: 80.92200041160733\n",
      "Iteration: 7310. Loss: 0.19137133657932281. Accuracy: 81.31302737188722\n",
      "Epoch:  171\n",
      "Iteration: 7320. Loss: 0.09028731286525726. Accuracy: 80.34575015435274\n",
      "Iteration: 7330. Loss: 0.014144373126327991. Accuracy: 80.86025931261577\n",
      "Iteration: 7340. Loss: 0.03622055798768997. Accuracy: 80.83967894628525\n",
      "Iteration: 7350. Loss: 0.0366465225815773. Accuracy: 81.70405433216712\n",
      "Epoch:  172\n",
      "Iteration: 7360. Loss: 0.06893376260995865. Accuracy: 80.71619674830212\n",
      "Iteration: 7370. Loss: 0.020587705075740814. Accuracy: 81.04548260959045\n",
      "Iteration: 7380. Loss: 0.020380135625600815. Accuracy: 81.23070590656513\n",
      "Iteration: 7390. Loss: 0.027002645656466484. Accuracy: 80.75735748096317\n",
      "Epoch:  173\n",
      "Iteration: 7400. Loss: 0.036807429045438766. Accuracy: 81.35418810454826\n",
      "Iteration: 7410. Loss: 0.03459664061665535. Accuracy: 81.12780407491253\n",
      "Iteration: 7420. Loss: 0.027723047882318497. Accuracy: 80.98374151059889\n",
      "Iteration: 7430. Loss: 0.026058917865157127. Accuracy: 80.81909857995473\n",
      "Epoch:  174\n",
      "Iteration: 7440. Loss: 0.013468951918184757. Accuracy: 81.12780407491253\n",
      "Iteration: 7450. Loss: 0.029613427817821503. Accuracy: 80.65445564931056\n",
      "Iteration: 7460. Loss: 0.031420592218637466. Accuracy: 79.83124099608973\n",
      "Iteration: 7470. Loss: 0.017053809016942978. Accuracy: 81.12780407491253\n",
      "Iteration: 7480. Loss: 0.03377138078212738. Accuracy: 81.60115250051452\n",
      "Epoch:  175\n",
      "Iteration: 7490. Loss: 0.04249133914709091. Accuracy: 81.90985799547232\n",
      "Iteration: 7500. Loss: 0.015817753970623016. Accuracy: 81.02490224325993\n",
      "Iteration: 7510. Loss: 0.024877261370420456. Accuracy: 81.47767030253138\n",
      "Iteration: 7520. Loss: 0.04279192164540291. Accuracy: 81.37476847087878\n",
      "Epoch:  176\n",
      "Iteration: 7530. Loss: 0.023187650367617607. Accuracy: 81.31302737188722\n",
      "Iteration: 7540. Loss: 0.025378938764333725. Accuracy: 80.73677711463264\n",
      "Iteration: 7550. Loss: 0.03484160825610161. Accuracy: 81.16896480757357\n",
      "Iteration: 7560. Loss: 0.023543449118733406. Accuracy: 81.4982506688619\n",
      "Epoch:  177\n",
      "Iteration: 7570. Loss: 0.015431561507284641. Accuracy: 81.04548260959045\n",
      "Iteration: 7580. Loss: 0.04344973340630531. Accuracy: 80.57213418398848\n",
      "Iteration: 7590. Loss: 0.014576750807464123. Accuracy: 81.51883103519242\n",
      "Iteration: 7600. Loss: 0.006823839619755745. Accuracy: 81.12780407491253\n",
      "Iteration: 7610. Loss: 0.029696952551603317. Accuracy: 81.10722370858201\n",
      "Epoch:  178\n",
      "Iteration: 7620. Loss: 0.022055182605981827. Accuracy: 81.10722370858201\n",
      "Iteration: 7630. Loss: 0.04533643275499344. Accuracy: 80.6956163819716\n",
      "Iteration: 7640. Loss: 0.03577890247106552. Accuracy: 80.94258077793785\n",
      "Iteration: 7650. Loss: 0.005431863013654947. Accuracy: 80.592714550319\n",
      "Epoch:  179\n",
      "Iteration: 7660. Loss: 0.007376282010227442. Accuracy: 80.28400905536118\n",
      "Iteration: 7670. Loss: 0.036304835230112076. Accuracy: 80.90142004527681\n",
      "Iteration: 7680. Loss: 0.02756175398826599. Accuracy: 79.95472319407286\n",
      "Iteration: 7690. Loss: 0.023499812930822372. Accuracy: 80.38691088701378\n",
      "Epoch:  180\n",
      "Iteration: 7700. Loss: 0.01019530463963747. Accuracy: 81.06606297592097\n",
      "Iteration: 7710. Loss: 0.01395522989332676. Accuracy: 81.08664334225149\n",
      "Iteration: 7720. Loss: 0.021885547786951065. Accuracy: 80.83967894628525\n",
      "Iteration: 7730. Loss: 0.027304982766509056. Accuracy: 81.33360773821774\n",
      "Iteration: 7740. Loss: 0.4467688500881195. Accuracy: 81.72463469849764\n",
      "Epoch:  181\n",
      "Iteration: 7750. Loss: 0.07102914899587631. Accuracy: 79.66659806544557\n",
      "Iteration: 7760. Loss: 0.03202008083462715. Accuracy: 79.97530356040338\n",
      "Iteration: 7770. Loss: 0.05635134130716324. Accuracy: 80.88083967894629\n",
      "Iteration: 7780. Loss: 0.02786322869360447. Accuracy: 79.64601769911505\n",
      "Epoch:  182\n",
      "Iteration: 7790. Loss: 0.08734503388404846. Accuracy: 80.4074912533443\n",
      "Iteration: 7800. Loss: 0.024170640856027603. Accuracy: 81.00432187692941\n",
      "Iteration: 7810. Loss: 0.04350831359624863. Accuracy: 81.45708993620086\n",
      "Iteration: 7820. Loss: 0.025961291044950485. Accuracy: 81.45708993620086\n",
      "Epoch:  183\n",
      "Iteration: 7830. Loss: 0.029299600049853325. Accuracy: 79.54311586746245\n",
      "Iteration: 7840. Loss: 0.038438037037849426. Accuracy: 80.34575015435274\n",
      "Iteration: 7850. Loss: 0.093804270029068. Accuracy: 80.42807161967482\n",
      "Iteration: 7860. Loss: 0.028300678357481956. Accuracy: 80.71619674830212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  184\n",
      "Iteration: 7870. Loss: 0.014192447066307068. Accuracy: 80.48981271866639\n",
      "Iteration: 7880. Loss: 0.046362683176994324. Accuracy: 80.63387528298004\n",
      "Iteration: 7890. Loss: 0.045600999146699905. Accuracy: 80.44865198600534\n",
      "Iteration: 7900. Loss: 0.011471040546894073. Accuracy: 80.98374151059889\n",
      "Iteration: 7910. Loss: 0.06257516145706177. Accuracy: 81.55999176785346\n",
      "Epoch:  185\n",
      "Iteration: 7920. Loss: 0.03131682053208351. Accuracy: 81.35418810454826\n",
      "Iteration: 7930. Loss: 0.03263212367892265. Accuracy: 80.65445564931056\n",
      "Iteration: 7940. Loss: 0.02064715512096882. Accuracy: 81.2924470055567\n",
      "Iteration: 7950. Loss: 0.034522879868745804. Accuracy: 82.095081292447\n",
      "Epoch:  186\n",
      "Iteration: 7960. Loss: 0.05511404573917389. Accuracy: 81.31302737188722\n",
      "Iteration: 7970. Loss: 0.03211225941777229. Accuracy: 81.14838444124305\n",
      "Iteration: 7980. Loss: 0.01671433262526989. Accuracy: 81.55999176785346\n",
      "Iteration: 7990. Loss: 0.025743523612618446. Accuracy: 81.97159909446388\n",
      "Epoch:  187\n",
      "Iteration: 8000. Loss: 0.025534948334097862. Accuracy: 81.27186663922618\n",
      "Iteration: 8010. Loss: 0.02647067792713642. Accuracy: 81.06606297592097\n",
      "Iteration: 8020. Loss: 0.03923867642879486. Accuracy: 81.27186663922618\n",
      "Iteration: 8030. Loss: 0.03376421704888344. Accuracy: 81.21012554023461\n",
      "Iteration: 8040. Loss: 0.04515114799141884. Accuracy: 81.41592920353982\n",
      "Epoch:  188\n",
      "Iteration: 8050. Loss: 0.06467319279909134. Accuracy: 80.92200041160733\n",
      "Iteration: 8060. Loss: 0.049357108771800995. Accuracy: 80.7985182136242\n",
      "Iteration: 8070. Loss: 0.06812933832406998. Accuracy: 81.580572134184\n",
      "Iteration: 8080. Loss: 0.015947282314300537. Accuracy: 82.03334019345544\n",
      "Epoch:  189\n",
      "Iteration: 8090. Loss: 0.09468928724527359. Accuracy: 81.31302737188722\n",
      "Iteration: 8100. Loss: 0.04720695689320564. Accuracy: 81.53941140152294\n",
      "Iteration: 8110. Loss: 0.018617257475852966. Accuracy: 81.74521506482816\n",
      "Iteration: 8120. Loss: 0.02983170934021473. Accuracy: 81.10722370858201\n",
      "Epoch:  190\n",
      "Iteration: 8130. Loss: 0.016504809260368347. Accuracy: 80.92200041160733\n",
      "Iteration: 8140. Loss: 0.053531575947999954. Accuracy: 80.07820539205598\n",
      "Iteration: 8150. Loss: 0.03995678201317787. Accuracy: 80.3045894216917\n",
      "Iteration: 8160. Loss: 0.04306267201900482. Accuracy: 80.96316114426837\n",
      "Iteration: 8170. Loss: 0.14611029624938965. Accuracy: 81.23070590656513\n",
      "Epoch:  191\n",
      "Iteration: 8180. Loss: 0.017394915223121643. Accuracy: 81.23070590656513\n",
      "Iteration: 8190. Loss: 0.014985598623752594. Accuracy: 81.12780407491253\n",
      "Iteration: 8200. Loss: 0.019207347184419632. Accuracy: 80.0987857583865\n",
      "Iteration: 8210. Loss: 0.009770235978066921. Accuracy: 81.31302737188722\n",
      "Epoch:  192\n",
      "Iteration: 8220. Loss: 0.011115195229649544. Accuracy: 80.94258077793785\n",
      "Iteration: 8230. Loss: 0.03439762443304062. Accuracy: 80.48981271866639\n",
      "Iteration: 8240. Loss: 0.016570640727877617. Accuracy: 81.16896480757357\n",
      "Iteration: 8250. Loss: 0.010910440236330032. Accuracy: 81.12780407491253\n",
      "Epoch:  193\n",
      "Iteration: 8260. Loss: 0.008073057048022747. Accuracy: 81.55999176785346\n",
      "Iteration: 8270. Loss: 0.024677257984876633. Accuracy: 81.41592920353982\n",
      "Iteration: 8280. Loss: 0.015904460102319717. Accuracy: 81.55999176785346\n",
      "Iteration: 8290. Loss: 0.012651571072638035. Accuracy: 81.16896480757357\n",
      "Epoch:  194\n",
      "Iteration: 8300. Loss: 0.007501060608774424. Accuracy: 80.96316114426837\n",
      "Iteration: 8310. Loss: 0.051507726311683655. Accuracy: 80.44865198600534\n",
      "Iteration: 8320. Loss: 0.0112773347645998. Accuracy: 81.2924470055567\n",
      "Iteration: 8330. Loss: 0.016348419710993767. Accuracy: 81.66289359950608\n",
      "Iteration: 8340. Loss: 0.007855803705751896. Accuracy: 81.2924470055567\n",
      "Epoch:  195\n",
      "Iteration: 8350. Loss: 0.01839977689087391. Accuracy: 80.92200041160733\n",
      "Iteration: 8360. Loss: 0.008193486370146275. Accuracy: 80.26342868903066\n",
      "Iteration: 8370. Loss: 0.021341808140277863. Accuracy: 81.3953488372093\n",
      "Iteration: 8380. Loss: 0.0082186758518219. Accuracy: 81.35418810454826\n",
      "Epoch:  196\n",
      "Iteration: 8390. Loss: 0.028367144986987114. Accuracy: 81.27186663922618\n",
      "Iteration: 8400. Loss: 0.004540754947811365. Accuracy: 81.04548260959045\n",
      "Iteration: 8410. Loss: 0.018025558441877365. Accuracy: 81.47767030253138\n",
      "Iteration: 8420. Loss: 0.009044777601957321. Accuracy: 81.9921794607944\n",
      "Epoch:  197\n",
      "Iteration: 8430. Loss: 0.008358471095561981. Accuracy: 81.16896480757357\n",
      "Iteration: 8440. Loss: 0.035577066242694855. Accuracy: 81.08664334225149\n",
      "Iteration: 8450. Loss: 0.018155798316001892. Accuracy: 81.16896480757357\n",
      "Iteration: 8460. Loss: 0.021883102133870125. Accuracy: 81.64231323317556\n",
      "Iteration: 8470. Loss: 0.003546725260093808. Accuracy: 80.63387528298004\n",
      "Epoch:  198\n",
      "Iteration: 8480. Loss: 0.00657327426597476. Accuracy: 81.12780407491253\n",
      "Iteration: 8490. Loss: 0.01637881249189377. Accuracy: 80.94258077793785\n",
      "Iteration: 8500. Loss: 0.013997300527989864. Accuracy: 80.7985182136242\n",
      "Iteration: 8510. Loss: 0.02173403836786747. Accuracy: 81.12780407491253\n",
      "Epoch:  199\n",
      "Iteration: 8520. Loss: 0.05790004879236221. Accuracy: 80.90142004527681\n",
      "Iteration: 8530. Loss: 0.036409828811883926. Accuracy: 80.592714550319\n",
      "Iteration: 8540. Loss: 0.027569163590669632. Accuracy: 81.55999176785346\n",
      "Iteration: 8550. Loss: 0.02862035110592842. Accuracy: 80.98374151059889\n",
      "Epoch:  200\n",
      "Iteration: 8560. Loss: 0.057803235948085785. Accuracy: 80.83967894628525\n",
      "Iteration: 8570. Loss: 0.028950970619916916. Accuracy: 80.67503601564108\n",
      "Iteration: 8580. Loss: 0.02459525316953659. Accuracy: 80.73677711463264\n",
      "Iteration: 8590. Loss: 0.0027536186389625072. Accuracy: 80.44865198600534\n",
      "Iteration: 8600. Loss: 0.12323346734046936. Accuracy: 80.592714550319\n",
      "Epoch:  201\n",
      "Iteration: 8610. Loss: 0.040003687143325806. Accuracy: 80.73677711463264\n",
      "Iteration: 8620. Loss: 0.038552094250917435. Accuracy: 81.06606297592097\n",
      "Iteration: 8630. Loss: 0.024048779159784317. Accuracy: 81.41592920353982\n",
      "Iteration: 8640. Loss: 0.022946208715438843. Accuracy: 81.35418810454826\n",
      "Epoch:  202\n",
      "Iteration: 8650. Loss: 0.03059210069477558. Accuracy: 80.16052685737806\n",
      "Iteration: 8660. Loss: 0.028705425560474396. Accuracy: 80.46923235233587\n",
      "Iteration: 8670. Loss: 0.04382224753499031. Accuracy: 80.96316114426837\n",
      "Iteration: 8680. Loss: 0.05017288029193878. Accuracy: 80.28400905536118\n",
      "Epoch:  203\n",
      "Iteration: 8690. Loss: 0.03691839054226875. Accuracy: 80.46923235233587\n",
      "Iteration: 8700. Loss: 0.07828011363744736. Accuracy: 79.06976744186046\n",
      "Iteration: 8710. Loss: 0.0835176631808281. Accuracy: 79.39905330314879\n",
      "Iteration: 8720. Loss: 0.04793839156627655. Accuracy: 81.33360773821774\n",
      "Epoch:  204\n",
      "Iteration: 8730. Loss: 0.028608333319425583. Accuracy: 80.86025931261577\n",
      "Iteration: 8740. Loss: 0.02148810401558876. Accuracy: 80.38691088701378\n",
      "Iteration: 8750. Loss: 0.07367655634880066. Accuracy: 81.04548260959045\n",
      "Iteration: 8760. Loss: 0.018416617065668106. Accuracy: 80.63387528298004\n",
      "Iteration: 8770. Loss: 0.04876793920993805. Accuracy: 81.66289359950608\n",
      "Epoch:  205\n",
      "Iteration: 8780. Loss: 0.01676856353878975. Accuracy: 80.65445564931056\n",
      "Iteration: 8790. Loss: 0.03198316693305969. Accuracy: 80.98374151059889\n",
      "Iteration: 8800. Loss: 0.017053840681910515. Accuracy: 81.51883103519242\n",
      "Iteration: 8810. Loss: 0.02344023436307907. Accuracy: 81.62173286684504\n",
      "Epoch:  206\n",
      "Iteration: 8820. Loss: 0.022159792482852936. Accuracy: 81.53941140152294\n",
      "Iteration: 8830. Loss: 0.027664875611662865. Accuracy: 80.46923235233587\n",
      "Iteration: 8840. Loss: 0.016495121642947197. Accuracy: 81.16896480757357\n",
      "Iteration: 8850. Loss: 0.02343170903623104. Accuracy: 80.38691088701378\n",
      "Epoch:  207\n",
      "Iteration: 8860. Loss: 0.02704193815588951. Accuracy: 81.04548260959045\n",
      "Iteration: 8870. Loss: 0.017478059977293015. Accuracy: 80.24284832270014\n",
      "Iteration: 8880. Loss: 0.02194427140057087. Accuracy: 80.6956163819716\n",
      "Iteration: 8890. Loss: 0.023603588342666626. Accuracy: 81.21012554023461\n",
      "Iteration: 8900. Loss: 0.014142422936856747. Accuracy: 81.37476847087878\n",
      "Epoch:  208\n",
      "Iteration: 8910. Loss: 0.01798703894019127. Accuracy: 81.37476847087878\n",
      "Iteration: 8920. Loss: 0.031176438555121422. Accuracy: 80.48981271866639\n",
      "Iteration: 8930. Loss: 0.015599063597619534. Accuracy: 80.7985182136242\n",
      "Iteration: 8940. Loss: 0.019350625574588776. Accuracy: 81.14838444124305\n",
      "Epoch:  209\n",
      "Iteration: 8950. Loss: 0.0405288003385067. Accuracy: 80.4074912533443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 8960. Loss: 0.05069632828235626. Accuracy: 79.70775879810661\n",
      "Iteration: 8970. Loss: 0.012198084034025669. Accuracy: 80.44865198600534\n",
      "Iteration: 8980. Loss: 0.015600097365677357. Accuracy: 80.63387528298004\n",
      "Epoch:  210\n",
      "Iteration: 8990. Loss: 0.010481791570782661. Accuracy: 80.32516978802222\n",
      "Iteration: 9000. Loss: 0.024804847314953804. Accuracy: 80.26342868903066\n",
      "Iteration: 9010. Loss: 0.014634172432124615. Accuracy: 81.10722370858201\n",
      "Iteration: 9020. Loss: 0.01937040314078331. Accuracy: 81.00432187692941\n",
      "Iteration: 9030. Loss: 0.08263186365365982. Accuracy: 80.61329491664952\n",
      "Epoch:  211\n",
      "Iteration: 9040. Loss: 0.011696475557982922. Accuracy: 80.38691088701378\n",
      "Iteration: 9050. Loss: 0.030648190528154373. Accuracy: 80.63387528298004\n",
      "Iteration: 9060. Loss: 0.02495841309428215. Accuracy: 81.16896480757357\n",
      "Iteration: 9070. Loss: 0.01833888702094555. Accuracy: 81.16896480757357\n",
      "Epoch:  212\n",
      "Iteration: 9080. Loss: 0.07565813511610031. Accuracy: 80.77793784729369\n",
      "Iteration: 9090. Loss: 0.08527792245149612. Accuracy: 80.73677711463264\n",
      "Iteration: 9100. Loss: 0.11451765894889832. Accuracy: 80.32516978802222\n",
      "Iteration: 9110. Loss: 0.057121649384498596. Accuracy: 80.55155381765796\n",
      "Epoch:  213\n",
      "Iteration: 9120. Loss: 0.030075697228312492. Accuracy: 80.18110722370858\n",
      "Iteration: 9130. Loss: 0.05396987125277519. Accuracy: 81.55999176785346\n",
      "Iteration: 9140. Loss: 0.08438989520072937. Accuracy: 81.3953488372093\n",
      "Iteration: 9150. Loss: 0.0177727360278368. Accuracy: 81.86869726281128\n",
      "Epoch:  214\n",
      "Iteration: 9160. Loss: 0.00847588386386633. Accuracy: 81.1895451739041\n",
      "Iteration: 9170. Loss: 0.024594273418188095. Accuracy: 80.44865198600534\n",
      "Iteration: 9180. Loss: 0.03985985741019249. Accuracy: 80.61329491664952\n",
      "Iteration: 9190. Loss: 0.028812916949391365. Accuracy: 81.43650956987034\n",
      "Iteration: 9200. Loss: 0.035241853445768356. Accuracy: 80.28400905536118\n",
      "Epoch:  215\n",
      "Iteration: 9210. Loss: 0.016024716198444366. Accuracy: 80.77793784729369\n",
      "Iteration: 9220. Loss: 0.02379339002072811. Accuracy: 81.08664334225149\n",
      "Iteration: 9230. Loss: 0.024981806054711342. Accuracy: 80.77793784729369\n",
      "Iteration: 9240. Loss: 0.027629103511571884. Accuracy: 81.45708993620086\n",
      "Epoch:  216\n",
      "Iteration: 9250. Loss: 0.022277863696217537. Accuracy: 80.77793784729369\n",
      "Iteration: 9260. Loss: 0.018915068358182907. Accuracy: 80.73677711463264\n",
      "Iteration: 9270. Loss: 0.041482698172330856. Accuracy: 81.31302737188722\n",
      "Iteration: 9280. Loss: 0.04460526630282402. Accuracy: 81.23070590656513\n",
      "Epoch:  217\n",
      "Iteration: 9290. Loss: 0.04428955912590027. Accuracy: 80.61329491664952\n",
      "Iteration: 9300. Loss: 0.06262218952178955. Accuracy: 79.81066062975921\n",
      "Iteration: 9310. Loss: 0.059466373175382614. Accuracy: 80.73677711463264\n",
      "Iteration: 9320. Loss: 0.04809599742293358. Accuracy: 81.23070590656513\n",
      "Iteration: 9330. Loss: 0.04041127488017082. Accuracy: 80.88083967894629\n",
      "Epoch:  218\n",
      "Iteration: 9340. Loss: 0.03308339789509773. Accuracy: 81.27186663922618\n",
      "Iteration: 9350. Loss: 0.014879616908729076. Accuracy: 80.592714550319\n",
      "Iteration: 9360. Loss: 0.02509501576423645. Accuracy: 81.37476847087878\n",
      "Iteration: 9370. Loss: 0.02529694139957428. Accuracy: 81.64231323317556\n",
      "Epoch:  219\n",
      "Iteration: 9380. Loss: 0.00482956413179636. Accuracy: 81.08664334225149\n",
      "Iteration: 9390. Loss: 0.026023894548416138. Accuracy: 81.41592920353982\n",
      "Iteration: 9400. Loss: 0.002731229644268751. Accuracy: 81.31302737188722\n",
      "Iteration: 9410. Loss: 0.0120492372661829. Accuracy: 80.98374151059889\n",
      "Epoch:  220\n",
      "Iteration: 9420. Loss: 0.022285738959908485. Accuracy: 81.37476847087878\n",
      "Iteration: 9430. Loss: 0.007957343012094498. Accuracy: 80.77793784729369\n",
      "Iteration: 9440. Loss: 0.019187359139323235. Accuracy: 80.73677711463264\n",
      "Iteration: 9450. Loss: 0.01794864423573017. Accuracy: 80.94258077793785\n",
      "Iteration: 9460. Loss: 0.07860628515481949. Accuracy: 80.6956163819716\n",
      "Epoch:  221\n",
      "Iteration: 9470. Loss: 0.052670493721961975. Accuracy: 80.77793784729369\n",
      "Iteration: 9480. Loss: 0.05134354531764984. Accuracy: 80.57213418398848\n",
      "Iteration: 9490. Loss: 0.02654438279569149. Accuracy: 81.70405433216712\n",
      "Iteration: 9500. Loss: 0.025598060339689255. Accuracy: 82.25972422309117\n",
      "Epoch:  222\n",
      "Iteration: 9510. Loss: 0.03237446770071983. Accuracy: 79.93414282774233\n",
      "Iteration: 9520. Loss: 0.009295294992625713. Accuracy: 81.82753653015024\n",
      "Iteration: 9530. Loss: 0.04678526520729065. Accuracy: 82.13624202510805\n",
      "Iteration: 9540. Loss: 0.020734131336212158. Accuracy: 81.08664334225149\n",
      "Epoch:  223\n",
      "Iteration: 9550. Loss: 0.011523710563778877. Accuracy: 81.16896480757357\n",
      "Iteration: 9560. Loss: 0.0128407571464777. Accuracy: 81.580572134184\n",
      "Iteration: 9570. Loss: 0.02181308902800083. Accuracy: 81.62173286684504\n",
      "Iteration: 9580. Loss: 0.0047789569944143295. Accuracy: 80.92200041160733\n",
      "Epoch:  224\n",
      "Iteration: 9590. Loss: 0.0025387934874743223. Accuracy: 81.64231323317556\n",
      "Iteration: 9600. Loss: 0.05718603730201721. Accuracy: 81.06606297592097\n",
      "Iteration: 9610. Loss: 0.03658216446638107. Accuracy: 81.12780407491253\n",
      "Iteration: 9620. Loss: 0.0027270251885056496. Accuracy: 81.37476847087878\n",
      "Iteration: 9630. Loss: 0.009729236364364624. Accuracy: 81.37476847087878\n",
      "Epoch:  225\n",
      "Iteration: 9640. Loss: 0.007626185193657875. Accuracy: 80.90142004527681\n",
      "Iteration: 9650. Loss: 0.019631559029221535. Accuracy: 81.55999176785346\n",
      "Iteration: 9660. Loss: 0.010725637897849083. Accuracy: 81.21012554023461\n",
      "Iteration: 9670. Loss: 0.018320299685001373. Accuracy: 81.76579543115868\n",
      "Epoch:  226\n",
      "Iteration: 9680. Loss: 0.03347598388791084. Accuracy: 81.60115250051452\n",
      "Iteration: 9690. Loss: 0.05244547128677368. Accuracy: 80.98374151059889\n",
      "Iteration: 9700. Loss: 0.027221348136663437. Accuracy: 80.81909857995473\n",
      "Iteration: 9710. Loss: 0.003413408063352108. Accuracy: 81.43650956987034\n",
      "Epoch:  227\n",
      "Iteration: 9720. Loss: 0.0553063340485096. Accuracy: 81.33360773821774\n",
      "Iteration: 9730. Loss: 0.013172784820199013. Accuracy: 80.75735748096317\n",
      "Iteration: 9740. Loss: 0.03146912530064583. Accuracy: 81.00432187692941\n",
      "Iteration: 9750. Loss: 0.018847350031137466. Accuracy: 81.43650956987034\n",
      "Iteration: 9760. Loss: 0.026884907856583595. Accuracy: 81.47767030253138\n",
      "Epoch:  228\n",
      "Iteration: 9770. Loss: 0.0433332622051239. Accuracy: 80.90142004527681\n",
      "Iteration: 9780. Loss: 0.021512413397431374. Accuracy: 81.08664334225149\n",
      "Iteration: 9790. Loss: 0.019398028030991554. Accuracy: 81.10722370858201\n",
      "Iteration: 9800. Loss: 0.03148951753973961. Accuracy: 81.27186663922618\n",
      "Epoch:  229\n",
      "Iteration: 9810. Loss: 0.021897926926612854. Accuracy: 81.3953488372093\n",
      "Iteration: 9820. Loss: 0.0446917749941349. Accuracy: 81.10722370858201\n",
      "Iteration: 9830. Loss: 0.023391511291265488. Accuracy: 81.93043836180284\n",
      "Iteration: 9840. Loss: 0.008885118179023266. Accuracy: 80.83967894628525\n",
      "Epoch:  230\n",
      "Iteration: 9850. Loss: 0.05058090016245842. Accuracy: 79.62543733278453\n",
      "Iteration: 9860. Loss: 0.046596139669418335. Accuracy: 80.5103930849969\n",
      "Iteration: 9870. Loss: 0.028068233281373978. Accuracy: 80.53097345132744\n",
      "Iteration: 9880. Loss: 0.047745537012815475. Accuracy: 81.23070590656513\n",
      "Iteration: 9890. Loss: 0.03798356652259827. Accuracy: 81.37476847087878\n",
      "Epoch:  231\n",
      "Iteration: 9900. Loss: 0.011561217717826366. Accuracy: 80.92200041160733\n",
      "Iteration: 9910. Loss: 0.027958393096923828. Accuracy: 81.27186663922618\n",
      "Iteration: 9920. Loss: 0.019296132028102875. Accuracy: 81.72463469849764\n",
      "Iteration: 9930. Loss: 0.015446178615093231. Accuracy: 81.64231323317556\n",
      "Epoch:  232\n",
      "Iteration: 9940. Loss: 0.042369890958070755. Accuracy: 80.36633052068326\n",
      "Iteration: 9950. Loss: 0.023356342688202858. Accuracy: 80.77793784729369\n",
      "Iteration: 9960. Loss: 0.029140911996364594. Accuracy: 81.8892776291418\n",
      "Iteration: 9970. Loss: 0.021586081013083458. Accuracy: 81.64231323317556\n",
      "Epoch:  233\n",
      "Iteration: 9980. Loss: 0.007437140680849552. Accuracy: 80.81909857995473\n",
      "Iteration: 9990. Loss: 0.0069473907351493835. Accuracy: 81.2924470055567\n",
      "Iteration: 10000. Loss: 0.013121183030307293. Accuracy: 81.41592920353982\n",
      "Iteration: 10010. Loss: 0.010772863402962685. Accuracy: 81.16896480757357\n",
      "Epoch:  234\n",
      "Iteration: 10020. Loss: 0.015162531286478043. Accuracy: 81.47767030253138\n",
      "Iteration: 10030. Loss: 0.0873408243060112. Accuracy: 80.53097345132744\n",
      "Iteration: 10040. Loss: 0.023751934990286827. Accuracy: 81.60115250051452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10050. Loss: 0.00842352770268917. Accuracy: 81.4982506688619\n",
      "Iteration: 10060. Loss: 0.011947720311582088. Accuracy: 81.35418810454826\n",
      "Epoch:  235\n",
      "Iteration: 10070. Loss: 0.01633962243795395. Accuracy: 79.48137476847089\n",
      "Iteration: 10080. Loss: 0.009049850516021252. Accuracy: 81.02490224325993\n",
      "Iteration: 10090. Loss: 0.03149827942252159. Accuracy: 81.47767030253138\n",
      "Iteration: 10100. Loss: 0.03285852074623108. Accuracy: 81.08664334225149\n",
      "Epoch:  236\n",
      "Iteration: 10110. Loss: 0.05790668725967407. Accuracy: 79.60485696645401\n",
      "Iteration: 10120. Loss: 0.048421796411275864. Accuracy: 80.3045894216917\n",
      "Iteration: 10130. Loss: 0.030110225081443787. Accuracy: 80.11936612471702\n",
      "Iteration: 10140. Loss: 0.11031288653612137. Accuracy: 79.1109281745215\n",
      "Epoch:  237\n",
      "Iteration: 10150. Loss: 0.028645731508731842. Accuracy: 80.71619674830212\n",
      "Iteration: 10160. Loss: 0.05911105126142502. Accuracy: 80.88083967894629\n",
      "Iteration: 10170. Loss: 0.015119070187211037. Accuracy: 80.34575015435274\n",
      "Iteration: 10180. Loss: 0.02159418910741806. Accuracy: 80.4074912533443\n",
      "Iteration: 10190. Loss: 0.025818677619099617. Accuracy: 80.28400905536118\n",
      "Epoch:  238\n",
      "Iteration: 10200. Loss: 0.024912437424063683. Accuracy: 81.06606297592097\n",
      "Iteration: 10210. Loss: 0.03889048472046852. Accuracy: 81.00432187692941\n",
      "Iteration: 10220. Loss: 0.01705235429108143. Accuracy: 80.34575015435274\n",
      "Iteration: 10230. Loss: 0.03376239538192749. Accuracy: 81.37476847087878\n",
      "Epoch:  239\n",
      "Iteration: 10240. Loss: 0.014689136296510696. Accuracy: 81.33360773821774\n",
      "Iteration: 10250. Loss: 0.021213626489043236. Accuracy: 80.94258077793785\n",
      "Iteration: 10260. Loss: 0.031879644840955734. Accuracy: 81.37476847087878\n",
      "Iteration: 10270. Loss: 0.014992967247962952. Accuracy: 81.90985799547232\n",
      "Epoch:  240\n",
      "Iteration: 10280. Loss: 0.004629030823707581. Accuracy: 81.25128627289565\n",
      "Iteration: 10290. Loss: 0.03872368857264519. Accuracy: 80.92200041160733\n",
      "Iteration: 10300. Loss: 0.01984560303390026. Accuracy: 81.2924470055567\n",
      "Iteration: 10310. Loss: 0.03180098906159401. Accuracy: 79.64601769911505\n",
      "Iteration: 10320. Loss: 0.246996209025383. Accuracy: 80.73677711463264\n",
      "Epoch:  241\n",
      "Iteration: 10330. Loss: 0.018013520166277885. Accuracy: 80.57213418398848\n",
      "Iteration: 10340. Loss: 0.02773149125277996. Accuracy: 81.10722370858201\n",
      "Iteration: 10350. Loss: 0.03778885677456856. Accuracy: 80.65445564931056\n",
      "Iteration: 10360. Loss: 0.02174670621752739. Accuracy: 80.44865198600534\n",
      "Epoch:  242\n",
      "Iteration: 10370. Loss: 0.03578632324934006. Accuracy: 79.39905330314879\n",
      "Iteration: 10380. Loss: 0.010255164466798306. Accuracy: 80.26342868903066\n",
      "Iteration: 10390. Loss: 0.01216957438737154. Accuracy: 80.96316114426837\n",
      "Iteration: 10400. Loss: 0.020239977166056633. Accuracy: 80.94258077793785\n",
      "Epoch:  243\n",
      "Iteration: 10410. Loss: 0.019148364663124084. Accuracy: 80.46923235233587\n",
      "Iteration: 10420. Loss: 0.013708950951695442. Accuracy: 81.60115250051452\n",
      "Iteration: 10430. Loss: 0.008612047880887985. Accuracy: 81.7863757974892\n",
      "Iteration: 10440. Loss: 0.02212541736662388. Accuracy: 81.45708993620086\n",
      "Epoch:  244\n",
      "Iteration: 10450. Loss: 0.007962072268128395. Accuracy: 80.92200041160733\n",
      "Iteration: 10460. Loss: 0.013750504702329636. Accuracy: 80.77793784729369\n",
      "Iteration: 10470. Loss: 0.05204655975103378. Accuracy: 80.28400905536118\n",
      "Iteration: 10480. Loss: 0.017281536012887955. Accuracy: 80.96316114426837\n",
      "Iteration: 10490. Loss: 0.017253227531909943. Accuracy: 81.1895451739041\n",
      "Epoch:  245\n",
      "Iteration: 10500. Loss: 0.02592059224843979. Accuracy: 80.46923235233587\n",
      "Iteration: 10510. Loss: 0.016415342688560486. Accuracy: 81.10722370858201\n",
      "Iteration: 10520. Loss: 0.01219397597014904. Accuracy: 81.3953488372093\n",
      "Iteration: 10530. Loss: 0.01651345193386078. Accuracy: 81.3953488372093\n",
      "Epoch:  246\n",
      "Iteration: 10540. Loss: 0.041892264038324356. Accuracy: 80.4074912533443\n",
      "Iteration: 10550. Loss: 0.043968066573143005. Accuracy: 80.32516978802222\n",
      "Iteration: 10560. Loss: 0.04677047207951546. Accuracy: 80.90142004527681\n",
      "Iteration: 10570. Loss: 0.025019608438014984. Accuracy: 81.08664334225149\n",
      "Epoch:  247\n",
      "Iteration: 10580. Loss: 0.03541671857237816. Accuracy: 80.4074912533443\n",
      "Iteration: 10590. Loss: 0.015032126568257809. Accuracy: 80.86025931261577\n",
      "Iteration: 10600. Loss: 0.013863951899111271. Accuracy: 81.33360773821774\n",
      "Iteration: 10610. Loss: 0.031093887984752655. Accuracy: 81.43650956987034\n",
      "Iteration: 10620. Loss: 0.01229733508080244. Accuracy: 81.47767030253138\n",
      "Epoch:  248\n",
      "Iteration: 10630. Loss: 0.030861245468258858. Accuracy: 80.18110722370858\n",
      "Iteration: 10640. Loss: 0.031157715246081352. Accuracy: 81.25128627289565\n",
      "Iteration: 10650. Loss: 0.020296327769756317. Accuracy: 81.08664334225149\n",
      "Iteration: 10660. Loss: 0.03569190576672554. Accuracy: 81.53941140152294\n",
      "Epoch:  249\n",
      "Iteration: 10670. Loss: 0.01911969855427742. Accuracy: 81.580572134184\n",
      "Iteration: 10680. Loss: 0.03678101673722267. Accuracy: 80.98374151059889\n",
      "Iteration: 10690. Loss: 0.022155560553073883. Accuracy: 80.77793784729369\n",
      "Iteration: 10700. Loss: 0.010771271772682667. Accuracy: 80.73677711463264\n",
      "Epoch:  250\n",
      "Iteration: 10710. Loss: 0.026192789897322655. Accuracy: 81.43650956987034\n",
      "Iteration: 10720. Loss: 0.026376985013484955. Accuracy: 80.28400905536118\n",
      "Iteration: 10730. Loss: 0.0174734964966774. Accuracy: 81.04548260959045\n",
      "Iteration: 10740. Loss: 0.026975398883223534. Accuracy: 80.75735748096317\n",
      "Iteration: 10750. Loss: 0.035778045654296875. Accuracy: 81.70405433216712\n",
      "Epoch:  251\n",
      "Iteration: 10760. Loss: 0.036010731011629105. Accuracy: 81.2924470055567\n",
      "Iteration: 10770. Loss: 0.03322184085845947. Accuracy: 80.57213418398848\n",
      "Iteration: 10780. Loss: 0.007729831151664257. Accuracy: 81.9921794607944\n",
      "Iteration: 10790. Loss: 0.008889172226190567. Accuracy: 80.44865198600534\n",
      "Epoch:  252\n",
      "Iteration: 10800. Loss: 0.047400008887052536. Accuracy: 81.06606297592097\n",
      "Iteration: 10810. Loss: 0.08169209212064743. Accuracy: 80.46923235233587\n",
      "Iteration: 10820. Loss: 0.010809097439050674. Accuracy: 81.4982506688619\n",
      "Iteration: 10830. Loss: 0.028183884918689728. Accuracy: 80.65445564931056\n",
      "Epoch:  253\n",
      "Iteration: 10840. Loss: 0.036547426134347916. Accuracy: 81.14838444124305\n",
      "Iteration: 10850. Loss: 0.011379032395780087. Accuracy: 81.08664334225149\n",
      "Iteration: 10860. Loss: 0.02496316097676754. Accuracy: 81.04548260959045\n",
      "Iteration: 10870. Loss: 0.03790001943707466. Accuracy: 81.70405433216712\n",
      "Epoch:  254\n",
      "Iteration: 10880. Loss: 0.0052574798464775085. Accuracy: 80.96316114426837\n",
      "Iteration: 10890. Loss: 0.028506936505436897. Accuracy: 80.73677711463264\n",
      "Iteration: 10900. Loss: 0.02339114062488079. Accuracy: 80.592714550319\n",
      "Iteration: 10910. Loss: 0.04105221852660179. Accuracy: 81.35418810454826\n",
      "Iteration: 10920. Loss: 0.03102097474038601. Accuracy: 80.81909857995473\n",
      "Epoch:  255\n",
      "Iteration: 10930. Loss: 0.011796247214078903. Accuracy: 81.21012554023461\n",
      "Iteration: 10940. Loss: 0.010093715973198414. Accuracy: 80.67503601564108\n",
      "Iteration: 10950. Loss: 0.017714790999889374. Accuracy: 80.55155381765796\n",
      "Iteration: 10960. Loss: 0.005994231905788183. Accuracy: 81.45708993620086\n",
      "Epoch:  256\n",
      "Iteration: 10970. Loss: 0.011520752683281898. Accuracy: 81.12780407491253\n",
      "Iteration: 10980. Loss: 0.025364257395267487. Accuracy: 81.74521506482816\n",
      "Iteration: 10990. Loss: 0.028755519539117813. Accuracy: 81.21012554023461\n",
      "Iteration: 11000. Loss: 0.00771603686735034. Accuracy: 81.37476847087878\n",
      "Epoch:  257\n",
      "Iteration: 11010. Loss: 0.002436082810163498. Accuracy: 81.27186663922618\n",
      "Iteration: 11020. Loss: 0.021723637357354164. Accuracy: 81.08664334225149\n",
      "Iteration: 11030. Loss: 0.018632672727108. Accuracy: 81.43650956987034\n",
      "Iteration: 11040. Loss: 0.013137194328010082. Accuracy: 81.27186663922618\n",
      "Iteration: 11050. Loss: 0.010520589537918568. Accuracy: 81.72463469849764\n",
      "Epoch:  258\n",
      "Iteration: 11060. Loss: 0.006441854871809483. Accuracy: 81.27186663922618\n",
      "Iteration: 11070. Loss: 0.031977564096450806. Accuracy: 81.27186663922618\n",
      "Iteration: 11080. Loss: 0.008312777616083622. Accuracy: 80.94258077793785\n",
      "Iteration: 11090. Loss: 0.0029066409915685654. Accuracy: 81.43650956987034\n",
      "Epoch:  259\n",
      "Iteration: 11100. Loss: 0.07631077617406845. Accuracy: 79.87240172875077\n",
      "Iteration: 11110. Loss: 0.05547843500971794. Accuracy: 80.98374151059889\n",
      "Iteration: 11120. Loss: 0.041955314576625824. Accuracy: 80.83967894628525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11130. Loss: 0.026589766144752502. Accuracy: 80.3045894216917\n",
      "Epoch:  260\n",
      "Iteration: 11140. Loss: 0.04492296651005745. Accuracy: 80.94258077793785\n",
      "Iteration: 11150. Loss: 0.05087239295244217. Accuracy: 80.34575015435274\n",
      "Iteration: 11160. Loss: 0.02332797646522522. Accuracy: 81.53941140152294\n",
      "Iteration: 11170. Loss: 0.042077112942934036. Accuracy: 81.7863757974892\n",
      "Iteration: 11180. Loss: 0.12028271704912186. Accuracy: 81.1895451739041\n",
      "Epoch:  261\n",
      "Iteration: 11190. Loss: 0.009259544312953949. Accuracy: 81.60115250051452\n",
      "Iteration: 11200. Loss: 0.0042384616099298. Accuracy: 81.51883103519242\n",
      "Iteration: 11210. Loss: 0.009639431722462177. Accuracy: 81.90985799547232\n",
      "Iteration: 11220. Loss: 0.009757774882018566. Accuracy: 80.98374151059889\n",
      "Epoch:  262\n",
      "Iteration: 11230. Loss: 0.021247057244181633. Accuracy: 80.7985182136242\n",
      "Iteration: 11240. Loss: 0.009625044651329517. Accuracy: 81.76579543115868\n",
      "Iteration: 11250. Loss: 0.0024635044392198324. Accuracy: 81.31302737188722\n",
      "Iteration: 11260. Loss: 0.011435288935899734. Accuracy: 81.45708993620086\n",
      "Epoch:  263\n",
      "Iteration: 11270. Loss: 0.03772648796439171. Accuracy: 80.28400905536118\n",
      "Iteration: 11280. Loss: 0.03153437003493309. Accuracy: 80.36633052068326\n",
      "Iteration: 11290. Loss: 0.030104124918580055. Accuracy: 80.36633052068326\n",
      "Iteration: 11300. Loss: 0.029184695333242416. Accuracy: 80.81909857995473\n",
      "Epoch:  264\n",
      "Iteration: 11310. Loss: 0.017896531149744987. Accuracy: 80.83967894628525\n",
      "Iteration: 11320. Loss: 0.04163474962115288. Accuracy: 80.86025931261577\n",
      "Iteration: 11330. Loss: 0.03827692195773125. Accuracy: 81.37476847087878\n",
      "Iteration: 11340. Loss: 0.014657769352197647. Accuracy: 80.98374151059889\n",
      "Iteration: 11350. Loss: 0.012280316092073917. Accuracy: 81.66289359950608\n",
      "Epoch:  265\n",
      "Iteration: 11360. Loss: 0.00974817480891943. Accuracy: 81.51883103519242\n",
      "Iteration: 11370. Loss: 0.009036977775394917. Accuracy: 81.53941140152294\n",
      "Iteration: 11380. Loss: 0.009437507949769497. Accuracy: 81.51883103519242\n",
      "Iteration: 11390. Loss: 0.008001076057553291. Accuracy: 81.580572134184\n",
      "Epoch:  266\n",
      "Iteration: 11400. Loss: 0.007492376025766134. Accuracy: 81.10722370858201\n",
      "Iteration: 11410. Loss: 0.00791690219193697. Accuracy: 81.33360773821774\n",
      "Iteration: 11420. Loss: 0.01720212772488594. Accuracy: 80.77793784729369\n",
      "Iteration: 11430. Loss: 0.003639530623331666. Accuracy: 80.71619674830212\n",
      "Epoch:  267\n",
      "Iteration: 11440. Loss: 0.012179468758404255. Accuracy: 80.86025931261577\n",
      "Iteration: 11450. Loss: 0.009818490594625473. Accuracy: 81.31302737188722\n",
      "Iteration: 11460. Loss: 0.003883152501657605. Accuracy: 81.27186663922618\n",
      "Iteration: 11470. Loss: 0.004732692148536444. Accuracy: 81.47767030253138\n",
      "Iteration: 11480. Loss: 0.012456860393285751. Accuracy: 82.13624202510805\n",
      "Epoch:  268\n",
      "Iteration: 11490. Loss: 0.03742814436554909. Accuracy: 80.96316114426837\n",
      "Iteration: 11500. Loss: 0.03984769061207771. Accuracy: 80.36633052068326\n",
      "Iteration: 11510. Loss: 0.024024564772844315. Accuracy: 80.75735748096317\n",
      "Iteration: 11520. Loss: 0.011176006868481636. Accuracy: 80.67503601564108\n",
      "Epoch:  269\n",
      "Iteration: 11530. Loss: 0.030188843607902527. Accuracy: 81.08664334225149\n",
      "Iteration: 11540. Loss: 0.0352897010743618. Accuracy: 81.62173286684504\n",
      "Iteration: 11550. Loss: 0.0270107202231884. Accuracy: 81.35418810454826\n",
      "Iteration: 11560. Loss: 0.0066102417185902596. Accuracy: 82.03334019345544\n",
      "Epoch:  270\n",
      "Iteration: 11570. Loss: 0.029752610251307487. Accuracy: 80.75735748096317\n",
      "Iteration: 11580. Loss: 0.029131004586815834. Accuracy: 81.06606297592097\n",
      "Iteration: 11590. Loss: 0.010138891637325287. Accuracy: 81.1895451739041\n",
      "Iteration: 11600. Loss: 0.034452833235263824. Accuracy: 81.45708993620086\n",
      "Iteration: 11610. Loss: 0.20377153158187866. Accuracy: 81.51883103519242\n",
      "Epoch:  271\n",
      "Iteration: 11620. Loss: 0.03548101708292961. Accuracy: 79.76949989709817\n",
      "Iteration: 11630. Loss: 0.049248628318309784. Accuracy: 81.23070590656513\n",
      "Iteration: 11640. Loss: 0.03256473317742348. Accuracy: 81.21012554023461\n",
      "Iteration: 11650. Loss: 0.0534406416118145. Accuracy: 81.41592920353982\n",
      "Epoch:  272\n",
      "Iteration: 11660. Loss: 0.014470874331891537. Accuracy: 81.51883103519242\n",
      "Iteration: 11670. Loss: 0.0558759905397892. Accuracy: 80.592714550319\n",
      "Iteration: 11680. Loss: 0.05210241302847862. Accuracy: 80.81909857995473\n",
      "Iteration: 11690. Loss: 0.020363686606287956. Accuracy: 81.37476847087878\n",
      "Epoch:  273\n",
      "Iteration: 11700. Loss: 0.042438142001628876. Accuracy: 81.580572134184\n",
      "Iteration: 11710. Loss: 0.022092141211032867. Accuracy: 80.96316114426837\n",
      "Iteration: 11720. Loss: 0.0341896191239357. Accuracy: 81.45708993620086\n",
      "Iteration: 11730. Loss: 0.0135194081813097. Accuracy: 81.9921794607944\n",
      "Epoch:  274\n",
      "Iteration: 11740. Loss: 0.013883577659726143. Accuracy: 81.580572134184\n",
      "Iteration: 11750. Loss: 0.021875547245144844. Accuracy: 81.14838444124305\n",
      "Iteration: 11760. Loss: 0.06193939223885536. Accuracy: 81.10722370858201\n",
      "Iteration: 11770. Loss: 0.011551621370017529. Accuracy: 81.64231323317556\n",
      "Iteration: 11780. Loss: 0.004366474226117134. Accuracy: 80.92200041160733\n",
      "Epoch:  275\n",
      "Iteration: 11790. Loss: 0.0058982656337320805. Accuracy: 81.3953488372093\n",
      "Iteration: 11800. Loss: 0.00872767623513937. Accuracy: 81.45708993620086\n",
      "Iteration: 11810. Loss: 0.00375439808703959. Accuracy: 81.8892776291418\n",
      "Iteration: 11820. Loss: 0.002428196370601654. Accuracy: 81.72463469849764\n",
      "Epoch:  276\n",
      "Iteration: 11830. Loss: 0.010956844314932823. Accuracy: 81.66289359950608\n",
      "Iteration: 11840. Loss: 0.037415146827697754. Accuracy: 81.53941140152294\n",
      "Iteration: 11850. Loss: 0.007117093540728092. Accuracy: 81.70405433216712\n",
      "Iteration: 11860. Loss: 0.00897802785038948. Accuracy: 80.11936612471702\n",
      "Epoch:  277\n",
      "Iteration: 11870. Loss: 0.008813529275357723. Accuracy: 81.37476847087878\n",
      "Iteration: 11880. Loss: 0.06886023283004761. Accuracy: 80.63387528298004\n",
      "Iteration: 11890. Loss: 0.04503050446510315. Accuracy: 80.61329491664952\n",
      "Iteration: 11900. Loss: 0.008618145249783993. Accuracy: 81.06606297592097\n",
      "Iteration: 11910. Loss: 0.015633344650268555. Accuracy: 80.90142004527681\n",
      "Epoch:  278\n",
      "Iteration: 11920. Loss: 0.02764882706105709. Accuracy: 80.34575015435274\n",
      "Iteration: 11930. Loss: 0.00525040365755558. Accuracy: 81.31302737188722\n",
      "Iteration: 11940. Loss: 0.01786271296441555. Accuracy: 81.72463469849764\n",
      "Iteration: 11950. Loss: 0.005435252096503973. Accuracy: 81.37476847087878\n",
      "Epoch:  279\n",
      "Iteration: 11960. Loss: 0.00567250233143568. Accuracy: 80.73677711463264\n",
      "Iteration: 11970. Loss: 0.00648832181468606. Accuracy: 79.93414282774233\n",
      "Iteration: 11980. Loss: 0.0071982042863965034. Accuracy: 81.04548260959045\n",
      "Iteration: 11990. Loss: 0.005223305895924568. Accuracy: 81.6834739658366\n",
      "Epoch:  280\n",
      "Iteration: 12000. Loss: 0.028750456869602203. Accuracy: 80.92200041160733\n",
      "Iteration: 12010. Loss: 0.025667745620012283. Accuracy: 80.42807161967482\n",
      "Iteration: 12020. Loss: 0.0039493367075920105. Accuracy: 80.0987857583865\n",
      "Iteration: 12030. Loss: 0.008971883915364742. Accuracy: 81.80695616381972\n",
      "Iteration: 12040. Loss: 0.0509435199201107. Accuracy: 81.43650956987034\n",
      "Epoch:  281\n",
      "Iteration: 12050. Loss: 0.0013832247350364923. Accuracy: 81.27186663922618\n",
      "Iteration: 12060. Loss: 0.05530978739261627. Accuracy: 80.26342868903066\n",
      "Iteration: 12070. Loss: 0.013375034555792809. Accuracy: 80.05762502572546\n",
      "Iteration: 12080. Loss: 0.04628274589776993. Accuracy: 80.75735748096317\n",
      "Epoch:  282\n",
      "Iteration: 12090. Loss: 0.0412481464445591. Accuracy: 79.91356246141181\n",
      "Iteration: 12100. Loss: 0.008373305201530457. Accuracy: 80.71619674830212\n",
      "Iteration: 12110. Loss: 0.049642205238342285. Accuracy: 80.6956163819716\n",
      "Iteration: 12120. Loss: 0.010503380559384823. Accuracy: 81.4982506688619\n",
      "Epoch:  283\n",
      "Iteration: 12130. Loss: 0.055269934237003326. Accuracy: 80.61329491664952\n",
      "Iteration: 12140. Loss: 0.04251265153288841. Accuracy: 80.18110722370858\n",
      "Iteration: 12150. Loss: 0.020122293382883072. Accuracy: 80.88083967894629\n",
      "Iteration: 12160. Loss: 0.026142621412873268. Accuracy: 80.3045894216917\n",
      "Epoch:  284\n",
      "Iteration: 12170. Loss: 0.008749683387577534. Accuracy: 82.17740275776909\n",
      "Iteration: 12180. Loss: 0.02985844761133194. Accuracy: 80.22226795636962\n",
      "Iteration: 12190. Loss: 0.029668759554624557. Accuracy: 81.04548260959045\n",
      "Iteration: 12200. Loss: 0.03691098093986511. Accuracy: 81.27186663922618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 12210. Loss: 0.0221036896109581. Accuracy: 81.2924470055567\n",
      "Epoch:  285\n",
      "Iteration: 12220. Loss: 0.02587372064590454. Accuracy: 81.02490224325993\n",
      "Iteration: 12230. Loss: 0.010600627399981022. Accuracy: 80.92200041160733\n",
      "Iteration: 12240. Loss: 0.007050420623272657. Accuracy: 81.72463469849764\n",
      "Iteration: 12250. Loss: 0.021669035777449608. Accuracy: 81.41592920353982\n",
      "Epoch:  286\n",
      "Iteration: 12260. Loss: 0.016473349183797836. Accuracy: 80.5103930849969\n",
      "Iteration: 12270. Loss: 0.022215135395526886. Accuracy: 80.96316114426837\n",
      "Iteration: 12280. Loss: 0.02251226268708706. Accuracy: 81.2924470055567\n",
      "Iteration: 12290. Loss: 0.009274072013795376. Accuracy: 81.72463469849764\n",
      "Epoch:  287\n",
      "Iteration: 12300. Loss: 0.008855316787958145. Accuracy: 80.98374151059889\n",
      "Iteration: 12310. Loss: 0.06329125165939331. Accuracy: 80.4074912533443\n",
      "Iteration: 12320. Loss: 0.025738324970006943. Accuracy: 81.08664334225149\n",
      "Iteration: 12330. Loss: 0.009158936329185963. Accuracy: 81.04548260959045\n",
      "Iteration: 12340. Loss: 0.00758694251999259. Accuracy: 81.35418810454826\n",
      "Epoch:  288\n",
      "Iteration: 12350. Loss: 0.007016317918896675. Accuracy: 81.16896480757357\n",
      "Iteration: 12360. Loss: 0.013295479118824005. Accuracy: 81.64231323317556\n",
      "Iteration: 12370. Loss: 0.004437413066625595. Accuracy: 81.14838444124305\n",
      "Iteration: 12380. Loss: 0.016723113134503365. Accuracy: 81.37476847087878\n",
      "Epoch:  289\n",
      "Iteration: 12390. Loss: 0.04677421972155571. Accuracy: 80.77793784729369\n",
      "Iteration: 12400. Loss: 0.019347216933965683. Accuracy: 80.5103930849969\n",
      "Iteration: 12410. Loss: 0.007534681353718042. Accuracy: 80.88083967894629\n",
      "Iteration: 12420. Loss: 0.019666975364089012. Accuracy: 81.02490224325993\n",
      "Epoch:  290\n",
      "Iteration: 12430. Loss: 0.01894794963300228. Accuracy: 78.82280304589422\n",
      "Iteration: 12440. Loss: 0.08127638697624207. Accuracy: 80.0987857583865\n",
      "Iteration: 12450. Loss: 0.03467640280723572. Accuracy: 80.53097345132744\n",
      "Iteration: 12460. Loss: 0.03318410366773605. Accuracy: 80.88083967894629\n",
      "Iteration: 12470. Loss: 0.062308453023433685. Accuracy: 81.12780407491253\n",
      "Epoch:  291\n",
      "Iteration: 12480. Loss: 0.02692987397313118. Accuracy: 81.80695616381972\n",
      "Iteration: 12490. Loss: 0.030170388519763947. Accuracy: 81.3953488372093\n",
      "Iteration: 12500. Loss: 0.02726682461798191. Accuracy: 81.08664334225149\n",
      "Iteration: 12510. Loss: 0.006521143950521946. Accuracy: 81.12780407491253\n",
      "Epoch:  292\n",
      "Iteration: 12520. Loss: 0.03468914330005646. Accuracy: 81.35418810454826\n",
      "Iteration: 12530. Loss: 0.0079506766051054. Accuracy: 81.41592920353982\n",
      "Iteration: 12540. Loss: 0.0015027665067464113. Accuracy: 81.82753653015024\n",
      "Iteration: 12550. Loss: 0.0020193196833133698. Accuracy: 82.03334019345544\n",
      "Epoch:  293\n",
      "Iteration: 12560. Loss: 0.00853456649929285. Accuracy: 80.83967894628525\n",
      "Iteration: 12570. Loss: 0.018761202692985535. Accuracy: 80.71619674830212\n",
      "Iteration: 12580. Loss: 0.012260260991752148. Accuracy: 81.4982506688619\n",
      "Iteration: 12590. Loss: 0.003771410556510091. Accuracy: 81.37476847087878\n",
      "Epoch:  294\n",
      "Iteration: 12600. Loss: 0.019228141754865646. Accuracy: 81.41592920353982\n",
      "Iteration: 12610. Loss: 0.012625985778868198. Accuracy: 80.96316114426837\n",
      "Iteration: 12620. Loss: 0.009128991514444351. Accuracy: 81.97159909446388\n",
      "Iteration: 12630. Loss: 0.007148596458137035. Accuracy: 81.2924470055567\n",
      "Iteration: 12640. Loss: 0.004614654928445816. Accuracy: 81.47767030253138\n",
      "Epoch:  295\n",
      "Iteration: 12650. Loss: 0.07108722627162933. Accuracy: 81.06606297592097\n",
      "Iteration: 12660. Loss: 0.02320278063416481. Accuracy: 81.2924470055567\n",
      "Iteration: 12670. Loss: 0.005634735804051161. Accuracy: 81.02490224325993\n",
      "Iteration: 12680. Loss: 0.016927247866988182. Accuracy: 81.2924470055567\n",
      "Epoch:  296\n",
      "Iteration: 12690. Loss: 0.03360358625650406. Accuracy: 79.79008026342869\n",
      "Iteration: 12700. Loss: 0.03599116578698158. Accuracy: 79.64601769911505\n",
      "Iteration: 12710. Loss: 0.0320267416536808. Accuracy: 80.88083967894629\n",
      "Iteration: 12720. Loss: 0.007102362345904112. Accuracy: 81.4982506688619\n",
      "Epoch:  297\n",
      "Iteration: 12730. Loss: 0.02516203559935093. Accuracy: 81.02490224325993\n",
      "Iteration: 12740. Loss: 0.013602069579064846. Accuracy: 80.75735748096317\n",
      "Iteration: 12750. Loss: 0.032828595489263535. Accuracy: 81.25128627289565\n",
      "Iteration: 12760. Loss: 0.05546732246875763. Accuracy: 81.64231323317556\n",
      "Iteration: 12770. Loss: 0.03885526955127716. Accuracy: 80.73677711463264\n",
      "Epoch:  298\n",
      "Iteration: 12780. Loss: 0.013005116023123264. Accuracy: 81.06606297592097\n",
      "Iteration: 12790. Loss: 0.04185100644826889. Accuracy: 80.63387528298004\n",
      "Iteration: 12800. Loss: 0.026821527630090714. Accuracy: 81.14838444124305\n",
      "Iteration: 12810. Loss: 0.008996732532978058. Accuracy: 81.25128627289565\n",
      "Epoch:  299\n",
      "Iteration: 12820. Loss: 0.04074108973145485. Accuracy: 80.6956163819716\n",
      "Iteration: 12830. Loss: 0.019594984129071236. Accuracy: 80.88083967894629\n",
      "Iteration: 12840. Loss: 0.006083323620259762. Accuracy: 81.33360773821774\n",
      "Iteration: 12850. Loss: 0.011316073127090931. Accuracy: 82.15682239143857\n",
      "Epoch:  300\n",
      "Iteration: 12860. Loss: 0.006003832910209894. Accuracy: 80.67503601564108\n",
      "Iteration: 12870. Loss: 0.030476335436105728. Accuracy: 81.10722370858201\n",
      "Iteration: 12880. Loss: 0.06927748769521713. Accuracy: 81.16896480757357\n",
      "Iteration: 12890. Loss: 0.06314285099506378. Accuracy: 81.53941140152294\n",
      "Iteration: 12900. Loss: 0.1399027407169342. Accuracy: 80.77793784729369\n",
      "Epoch:  301\n",
      "Iteration: 12910. Loss: 0.013147598132491112. Accuracy: 81.55999176785346\n",
      "Iteration: 12920. Loss: 0.04763085022568703. Accuracy: 81.2924470055567\n",
      "Iteration: 12930. Loss: 0.01946699433028698. Accuracy: 80.94258077793785\n",
      "Iteration: 12940. Loss: 0.008673522621393204. Accuracy: 80.86025931261577\n",
      "Epoch:  302\n",
      "Iteration: 12950. Loss: 0.013124540448188782. Accuracy: 81.14838444124305\n",
      "Iteration: 12960. Loss: 0.0021969492081552744. Accuracy: 81.31302737188722\n",
      "Iteration: 12970. Loss: 0.021062830463051796. Accuracy: 81.35418810454826\n",
      "Iteration: 12980. Loss: 0.00465009780600667. Accuracy: 80.92200041160733\n",
      "Epoch:  303\n",
      "Iteration: 12990. Loss: 0.00716776167973876. Accuracy: 80.90142004527681\n",
      "Iteration: 13000. Loss: 0.04093426465988159. Accuracy: 80.42807161967482\n",
      "Iteration: 13010. Loss: 0.017501628026366234. Accuracy: 80.92200041160733\n",
      "Iteration: 13020. Loss: 0.02352919988334179. Accuracy: 80.3045894216917\n",
      "Epoch:  304\n",
      "Iteration: 13030. Loss: 0.027669306844472885. Accuracy: 81.70405433216712\n",
      "Iteration: 13040. Loss: 0.008402548730373383. Accuracy: 81.06606297592097\n",
      "Iteration: 13050. Loss: 0.024156389757990837. Accuracy: 81.53941140152294\n",
      "Iteration: 13060. Loss: 0.018664726987481117. Accuracy: 81.12780407491253\n",
      "Iteration: 13070. Loss: 0.0053450316190719604. Accuracy: 81.74521506482816\n",
      "Epoch:  305\n",
      "Iteration: 13080. Loss: 0.010931819677352905. Accuracy: 81.60115250051452\n",
      "Iteration: 13090. Loss: 0.0037948177196085453. Accuracy: 81.53941140152294\n",
      "Iteration: 13100. Loss: 0.006580541841685772. Accuracy: 80.86025931261577\n",
      "Iteration: 13110. Loss: 0.022255053743720055. Accuracy: 81.04548260959045\n",
      "Epoch:  306\n",
      "Iteration: 13120. Loss: 0.005552023183554411. Accuracy: 81.95101872813336\n",
      "Iteration: 13130. Loss: 0.0008110819035209715. Accuracy: 81.60115250051452\n",
      "Iteration: 13140. Loss: 0.002465355210006237. Accuracy: 81.580572134184\n",
      "Iteration: 13150. Loss: 0.023800021037459373. Accuracy: 81.43650956987034\n",
      "Epoch:  307\n",
      "Iteration: 13160. Loss: 0.011844615451991558. Accuracy: 80.46923235233587\n",
      "Iteration: 13170. Loss: 0.016173183917999268. Accuracy: 80.46923235233587\n",
      "Iteration: 13180. Loss: 0.0162554569542408. Accuracy: 81.3953488372093\n",
      "Iteration: 13190. Loss: 0.005619630683213472. Accuracy: 81.31302737188722\n",
      "Iteration: 13200. Loss: 0.0039007302839308977. Accuracy: 81.51883103519242\n",
      "Epoch:  308\n",
      "Iteration: 13210. Loss: 0.03970678895711899. Accuracy: 80.88083967894629\n",
      "Iteration: 13220. Loss: 0.0050835381262004375. Accuracy: 80.65445564931056\n",
      "Iteration: 13230. Loss: 0.01629248633980751. Accuracy: 81.64231323317556\n",
      "Iteration: 13240. Loss: 0.003116808831691742. Accuracy: 81.47767030253138\n",
      "Epoch:  309\n",
      "Iteration: 13250. Loss: 0.01147559192031622. Accuracy: 80.16052685737806\n",
      "Iteration: 13260. Loss: 0.004931092727929354. Accuracy: 80.77793784729369\n",
      "Iteration: 13270. Loss: 0.007688294164836407. Accuracy: 81.27186663922618\n",
      "Iteration: 13280. Loss: 0.007454823236912489. Accuracy: 81.06606297592097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  310\n",
      "Iteration: 13290. Loss: 0.004672978539019823. Accuracy: 81.86869726281128\n",
      "Iteration: 13300. Loss: 0.012569576501846313. Accuracy: 81.2924470055567\n",
      "Iteration: 13310. Loss: 0.003933393862098455. Accuracy: 81.3953488372093\n",
      "Iteration: 13320. Loss: 0.0016499963821843266. Accuracy: 81.82753653015024\n",
      "Iteration: 13330. Loss: 0.0031410581432282925. Accuracy: 81.16896480757357\n",
      "Epoch:  311\n",
      "Iteration: 13340. Loss: 0.01183423399925232. Accuracy: 81.35418810454826\n",
      "Iteration: 13350. Loss: 0.0076391249895095825. Accuracy: 81.10722370858201\n",
      "Iteration: 13360. Loss: 0.0020520701073110104. Accuracy: 80.98374151059889\n",
      "Iteration: 13370. Loss: 0.0022168599534779787. Accuracy: 81.93043836180284\n",
      "Epoch:  312\n",
      "Iteration: 13380. Loss: 0.020630531013011932. Accuracy: 80.592714550319\n",
      "Iteration: 13390. Loss: 0.02520417794585228. Accuracy: 80.73677711463264\n",
      "Iteration: 13400. Loss: 0.004375095013529062. Accuracy: 81.3953488372093\n",
      "Iteration: 13410. Loss: 0.005437429528683424. Accuracy: 80.98374151059889\n",
      "Epoch:  313\n",
      "Iteration: 13420. Loss: 0.02727115899324417. Accuracy: 80.90142004527681\n",
      "Iteration: 13430. Loss: 0.008299806155264378. Accuracy: 81.08664334225149\n",
      "Iteration: 13440. Loss: 0.008871464058756828. Accuracy: 81.10722370858201\n",
      "Iteration: 13450. Loss: 0.004594846162945032. Accuracy: 81.51883103519242\n",
      "Epoch:  314\n",
      "Iteration: 13460. Loss: 0.0013952795416116714. Accuracy: 81.25128627289565\n",
      "Iteration: 13470. Loss: 0.001610612845979631. Accuracy: 81.4982506688619\n",
      "Iteration: 13480. Loss: 0.0030498045962303877. Accuracy: 81.06606297592097\n",
      "Iteration: 13490. Loss: 0.024256346747279167. Accuracy: 81.27186663922618\n",
      "Iteration: 13500. Loss: 0.0023586645256727934. Accuracy: 81.23070590656513\n",
      "Epoch:  315\n",
      "Iteration: 13510. Loss: 0.018531261011958122. Accuracy: 80.65445564931056\n",
      "Iteration: 13520. Loss: 0.03556418791413307. Accuracy: 81.41592920353982\n",
      "Iteration: 13530. Loss: 0.03359982371330261. Accuracy: 81.00432187692941\n",
      "Iteration: 13540. Loss: 0.03379593789577484. Accuracy: 81.35418810454826\n",
      "Epoch:  316\n",
      "Iteration: 13550. Loss: 0.014504434540867805. Accuracy: 80.55155381765796\n",
      "Iteration: 13560. Loss: 0.015307631343603134. Accuracy: 81.04548260959045\n",
      "Iteration: 13570. Loss: 0.013149278238415718. Accuracy: 81.31302737188722\n",
      "Iteration: 13580. Loss: 0.028227534145116806. Accuracy: 82.23914385676065\n",
      "Epoch:  317\n",
      "Iteration: 13590. Loss: 0.007416213396936655. Accuracy: 80.77793784729369\n",
      "Iteration: 13600. Loss: 0.010501524433493614. Accuracy: 81.62173286684504\n",
      "Iteration: 13610. Loss: 0.03327161446213722. Accuracy: 81.43650956987034\n",
      "Iteration: 13620. Loss: 0.01585742086172104. Accuracy: 81.23070590656513\n",
      "Iteration: 13630. Loss: 0.04750925675034523. Accuracy: 81.21012554023461\n",
      "Epoch:  318\n",
      "Iteration: 13640. Loss: 0.034664664417505264. Accuracy: 80.94258077793785\n",
      "Iteration: 13650. Loss: 0.006224467419087887. Accuracy: 80.92200041160733\n",
      "Iteration: 13660. Loss: 0.0561702661216259. Accuracy: 81.80695616381972\n",
      "Iteration: 13670. Loss: 0.009766546078026295. Accuracy: 81.1895451739041\n",
      "Epoch:  319\n",
      "Iteration: 13680. Loss: 0.003459189785644412. Accuracy: 81.95101872813336\n",
      "Iteration: 13690. Loss: 0.04856482148170471. Accuracy: 81.51883103519242\n",
      "Iteration: 13700. Loss: 0.015639306977391243. Accuracy: 81.76579543115868\n",
      "Iteration: 13710. Loss: 0.01836702972650528. Accuracy: 81.47767030253138\n",
      "Epoch:  320\n",
      "Iteration: 13720. Loss: 0.009846135042607784. Accuracy: 80.90142004527681\n",
      "Iteration: 13730. Loss: 0.04560094326734543. Accuracy: 81.64231323317556\n",
      "Iteration: 13740. Loss: 0.017851507291197777. Accuracy: 81.16896480757357\n",
      "Iteration: 13750. Loss: 0.034052442759275436. Accuracy: 80.7985182136242\n",
      "Iteration: 13760. Loss: 0.15802858769893646. Accuracy: 81.06606297592097\n",
      "Epoch:  321\n",
      "Iteration: 13770. Loss: 0.004861955530941486. Accuracy: 80.83967894628525\n",
      "Iteration: 13780. Loss: 0.010729902423918247. Accuracy: 80.90142004527681\n",
      "Iteration: 13790. Loss: 0.023117415606975555. Accuracy: 81.80695616381972\n",
      "Iteration: 13800. Loss: 0.03794887661933899. Accuracy: 81.23070590656513\n",
      "Epoch:  322\n",
      "Iteration: 13810. Loss: 0.06878484040498734. Accuracy: 80.88083967894629\n",
      "Iteration: 13820. Loss: 0.030043572187423706. Accuracy: 81.21012554023461\n",
      "Iteration: 13830. Loss: 0.007494117598980665. Accuracy: 81.27186663922618\n",
      "Iteration: 13840. Loss: 0.038170307874679565. Accuracy: 81.37476847087878\n",
      "Epoch:  323\n",
      "Iteration: 13850. Loss: 0.011365532875061035. Accuracy: 81.10722370858201\n",
      "Iteration: 13860. Loss: 0.01317047793418169. Accuracy: 81.08664334225149\n",
      "Iteration: 13870. Loss: 0.007304140832275152. Accuracy: 81.41592920353982\n",
      "Iteration: 13880. Loss: 0.003973489161580801. Accuracy: 81.37476847087878\n",
      "Epoch:  324\n",
      "Iteration: 13890. Loss: 0.009289183653891087. Accuracy: 81.41592920353982\n",
      "Iteration: 13900. Loss: 0.04834882542490959. Accuracy: 81.51883103519242\n",
      "Iteration: 13910. Loss: 0.033910565078258514. Accuracy: 81.06606297592097\n",
      "Iteration: 13920. Loss: 0.004938699770718813. Accuracy: 81.4982506688619\n",
      "Iteration: 13930. Loss: 0.00274896202608943. Accuracy: 81.62173286684504\n",
      "Epoch:  325\n",
      "Iteration: 13940. Loss: 0.02274235151708126. Accuracy: 79.8929820950813\n",
      "Iteration: 13950. Loss: 0.039380114525556564. Accuracy: 79.76949989709817\n",
      "Iteration: 13960. Loss: 0.026913225650787354. Accuracy: 81.51883103519242\n",
      "Iteration: 13970. Loss: 0.02865205705165863. Accuracy: 80.90142004527681\n",
      "Epoch:  326\n",
      "Iteration: 13980. Loss: 0.02184450253844261. Accuracy: 80.6956163819716\n",
      "Iteration: 13990. Loss: 0.03346732258796692. Accuracy: 80.6956163819716\n",
      "Iteration: 14000. Loss: 0.028515158221125603. Accuracy: 80.5103930849969\n",
      "Iteration: 14010. Loss: 0.020025985315442085. Accuracy: 80.36633052068326\n",
      "Epoch:  327\n",
      "Iteration: 14020. Loss: 0.002967698732391. Accuracy: 81.08664334225149\n",
      "Iteration: 14030. Loss: 0.014833981171250343. Accuracy: 81.35418810454826\n",
      "Iteration: 14040. Loss: 0.0015116888098418713. Accuracy: 81.25128627289565\n",
      "Iteration: 14050. Loss: 0.006956503260880709. Accuracy: 81.21012554023461\n",
      "Iteration: 14060. Loss: 0.005490282084792852. Accuracy: 80.71619674830212\n",
      "Epoch:  328\n",
      "Iteration: 14070. Loss: 0.011972750537097454. Accuracy: 81.04548260959045\n",
      "Iteration: 14080. Loss: 0.0214349664747715. Accuracy: 81.74521506482816\n",
      "Iteration: 14090. Loss: 0.0026075292844325304. Accuracy: 81.1895451739041\n",
      "Iteration: 14100. Loss: 0.006237447261810303. Accuracy: 82.03334019345544\n",
      "Epoch:  329\n",
      "Iteration: 14110. Loss: 0.03451629355549812. Accuracy: 81.37476847087878\n",
      "Iteration: 14120. Loss: 0.012847580946981907. Accuracy: 80.77793784729369\n",
      "Iteration: 14130. Loss: 0.012933589518070221. Accuracy: 81.02490224325993\n",
      "Iteration: 14140. Loss: 0.005583025515079498. Accuracy: 81.3953488372093\n",
      "Epoch:  330\n",
      "Iteration: 14150. Loss: 0.007239810191094875. Accuracy: 80.77793784729369\n",
      "Iteration: 14160. Loss: 0.03621765971183777. Accuracy: 81.08664334225149\n",
      "Iteration: 14170. Loss: 0.02554290182888508. Accuracy: 81.25128627289565\n",
      "Iteration: 14180. Loss: 0.004341042600572109. Accuracy: 80.57213418398848\n",
      "Iteration: 14190. Loss: 0.058026086539030075. Accuracy: 80.71619674830212\n",
      "Epoch:  331\n",
      "Iteration: 14200. Loss: 0.011826325207948685. Accuracy: 81.35418810454826\n",
      "Iteration: 14210. Loss: 0.0007756009581498802. Accuracy: 80.67503601564108\n",
      "Iteration: 14220. Loss: 0.008168594911694527. Accuracy: 81.74521506482816\n",
      "Iteration: 14230. Loss: 0.02015751041471958. Accuracy: 81.580572134184\n",
      "Epoch:  332\n",
      "Iteration: 14240. Loss: 0.020609788596630096. Accuracy: 81.60115250051452\n",
      "Iteration: 14250. Loss: 0.003268324537202716. Accuracy: 81.6834739658366\n",
      "Iteration: 14260. Loss: 0.009981249459087849. Accuracy: 81.37476847087878\n",
      "Iteration: 14270. Loss: 0.003728472860530019. Accuracy: 80.92200041160733\n",
      "Epoch:  333\n",
      "Iteration: 14280. Loss: 0.008281090296804905. Accuracy: 81.31302737188722\n",
      "Iteration: 14290. Loss: 0.0035115263890475035. Accuracy: 81.27186663922618\n",
      "Iteration: 14300. Loss: 0.016035350039601326. Accuracy: 81.31302737188722\n",
      "Iteration: 14310. Loss: 0.02433294989168644. Accuracy: 82.34204568841325\n",
      "Epoch:  334\n",
      "Iteration: 14320. Loss: 0.009287329390645027. Accuracy: 80.61329491664952\n",
      "Iteration: 14330. Loss: 0.059160757809877396. Accuracy: 80.16052685737806\n",
      "Iteration: 14340. Loss: 0.07649321854114532. Accuracy: 79.0080263428689\n",
      "Iteration: 14350. Loss: 0.054044973105192184. Accuracy: 81.1895451739041\n",
      "Iteration: 14360. Loss: 0.019297363236546516. Accuracy: 80.94258077793785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  335\n",
      "Iteration: 14370. Loss: 0.02350241132080555. Accuracy: 80.7985182136242\n",
      "Iteration: 14380. Loss: 0.052769735455513. Accuracy: 81.8892776291418\n",
      "Iteration: 14390. Loss: 0.03385021537542343. Accuracy: 81.7863757974892\n",
      "Iteration: 14400. Loss: 0.02687130682170391. Accuracy: 81.00432187692941\n",
      "Epoch:  336\n",
      "Iteration: 14410. Loss: 0.01741744950413704. Accuracy: 80.53097345132744\n",
      "Iteration: 14420. Loss: 0.007173025980591774. Accuracy: 80.67503601564108\n",
      "Iteration: 14430. Loss: 0.022086437791585922. Accuracy: 80.90142004527681\n",
      "Iteration: 14440. Loss: 0.024644246324896812. Accuracy: 80.67503601564108\n",
      "Epoch:  337\n",
      "Iteration: 14450. Loss: 0.011491500772535801. Accuracy: 81.27186663922618\n",
      "Iteration: 14460. Loss: 0.0046195522882044315. Accuracy: 81.14838444124305\n",
      "Iteration: 14470. Loss: 0.020205823704600334. Accuracy: 82.52726898538793\n",
      "Iteration: 14480. Loss: 0.008583229035139084. Accuracy: 81.1895451739041\n",
      "Iteration: 14490. Loss: 0.0037800425197929144. Accuracy: 81.16896480757357\n",
      "Epoch:  338\n",
      "Iteration: 14500. Loss: 0.012268265709280968. Accuracy: 81.64231323317556\n",
      "Iteration: 14510. Loss: 0.0037316002417355776. Accuracy: 81.27186663922618\n",
      "Iteration: 14520. Loss: 0.0032857446931302547. Accuracy: 81.70405433216712\n",
      "Iteration: 14530. Loss: 0.013887451961636543. Accuracy: 82.01275982712492\n",
      "Epoch:  339\n",
      "Iteration: 14540. Loss: 0.03749917820096016. Accuracy: 79.76949989709817\n",
      "Iteration: 14550. Loss: 0.01542049553245306. Accuracy: 80.32516978802222\n",
      "Iteration: 14560. Loss: 0.04537757486104965. Accuracy: 81.23070590656513\n",
      "Iteration: 14570. Loss: 0.009511812590062618. Accuracy: 81.35418810454826\n",
      "Epoch:  340\n",
      "Iteration: 14580. Loss: 0.04865763336420059. Accuracy: 81.04548260959045\n",
      "Iteration: 14590. Loss: 0.002694620518013835. Accuracy: 81.27186663922618\n",
      "Iteration: 14600. Loss: 0.036014676094055176. Accuracy: 80.90142004527681\n",
      "Iteration: 14610. Loss: 0.012361761182546616. Accuracy: 81.64231323317556\n",
      "Iteration: 14620. Loss: 0.006340141873806715. Accuracy: 81.27186663922618\n",
      "Epoch:  341\n",
      "Iteration: 14630. Loss: 0.0198059119284153. Accuracy: 81.45708993620086\n",
      "Iteration: 14640. Loss: 0.02431037649512291. Accuracy: 81.72463469849764\n",
      "Iteration: 14650. Loss: 0.003093729028478265. Accuracy: 81.7863757974892\n",
      "Iteration: 14660. Loss: 0.003981274086982012. Accuracy: 81.8892776291418\n",
      "Epoch:  342\n",
      "Iteration: 14670. Loss: 0.05969671532511711. Accuracy: 81.25128627289565\n",
      "Iteration: 14680. Loss: 0.007683496456593275. Accuracy: 82.01275982712492\n",
      "Iteration: 14690. Loss: 0.012386550195515156. Accuracy: 81.47767030253138\n",
      "Iteration: 14700. Loss: 0.023468248546123505. Accuracy: 81.51883103519242\n",
      "Epoch:  343\n",
      "Iteration: 14710. Loss: 0.007571128197014332. Accuracy: 81.3953488372093\n",
      "Iteration: 14720. Loss: 0.017406776547431946. Accuracy: 80.83967894628525\n",
      "Iteration: 14730. Loss: 0.047327522188425064. Accuracy: 81.1895451739041\n",
      "Iteration: 14740. Loss: 0.020334171131253242. Accuracy: 81.3953488372093\n",
      "Epoch:  344\n",
      "Iteration: 14750. Loss: 0.004632510710507631. Accuracy: 80.28400905536118\n",
      "Iteration: 14760. Loss: 0.039483632892370224. Accuracy: 80.57213418398848\n",
      "Iteration: 14770. Loss: 0.060252703726291656. Accuracy: 81.31302737188722\n",
      "Iteration: 14780. Loss: 0.03221626579761505. Accuracy: 81.6834739658366\n",
      "Iteration: 14790. Loss: 0.021088240668177605. Accuracy: 81.10722370858201\n",
      "Epoch:  345\n",
      "Iteration: 14800. Loss: 0.022103535011410713. Accuracy: 81.10722370858201\n",
      "Iteration: 14810. Loss: 0.03284134343266487. Accuracy: 81.08664334225149\n",
      "Iteration: 14820. Loss: 0.016307301819324493. Accuracy: 81.82753653015024\n",
      "Iteration: 14830. Loss: 0.024695565924048424. Accuracy: 81.9921794607944\n",
      "Epoch:  346\n",
      "Iteration: 14840. Loss: 0.05265853554010391. Accuracy: 81.14838444124305\n",
      "Iteration: 14850. Loss: 0.014620664529502392. Accuracy: 81.06606297592097\n",
      "Iteration: 14860. Loss: 0.02140907384455204. Accuracy: 80.96316114426837\n",
      "Iteration: 14870. Loss: 0.0063982559368014336. Accuracy: 81.8892776291418\n",
      "Epoch:  347\n",
      "Iteration: 14880. Loss: 0.019435478374361992. Accuracy: 81.86869726281128\n",
      "Iteration: 14890. Loss: 0.0024526582565158606. Accuracy: 81.55999176785346\n",
      "Iteration: 14900. Loss: 0.003996668849140406. Accuracy: 81.4982506688619\n",
      "Iteration: 14910. Loss: 0.014426523819565773. Accuracy: 81.25128627289565\n",
      "Iteration: 14920. Loss: 0.003071598708629608. Accuracy: 81.74521506482816\n",
      "Epoch:  348\n",
      "Iteration: 14930. Loss: 0.00510164862498641. Accuracy: 81.45708993620086\n",
      "Iteration: 14940. Loss: 0.020342901349067688. Accuracy: 81.86869726281128\n",
      "Iteration: 14950. Loss: 0.016336942091584206. Accuracy: 81.23070590656513\n",
      "Iteration: 14960. Loss: 0.007838692516088486. Accuracy: 82.56842971804898\n",
      "Epoch:  349\n",
      "Iteration: 14970. Loss: 0.002606048481538892. Accuracy: 81.64231323317556\n",
      "Iteration: 14980. Loss: 0.014063467271625996. Accuracy: 81.4982506688619\n",
      "Iteration: 14990. Loss: 0.01169001404196024. Accuracy: 81.7863757974892\n",
      "Iteration: 15000. Loss: 0.0032792622223496437. Accuracy: 81.86869726281128\n",
      "Epoch:  350\n",
      "Iteration: 15010. Loss: 0.0200716033577919. Accuracy: 80.4074912533443\n",
      "Iteration: 15020. Loss: 0.011741367168724537. Accuracy: 81.35418810454826\n",
      "Iteration: 15030. Loss: 0.008953378535807133. Accuracy: 79.72833916443713\n",
      "Iteration: 15040. Loss: 0.029586270451545715. Accuracy: 81.4982506688619\n",
      "Iteration: 15050. Loss: 0.05435173213481903. Accuracy: 81.31302737188722\n",
      "Epoch:  351\n",
      "Iteration: 15060. Loss: 0.016520105302333832. Accuracy: 81.66289359950608\n",
      "Iteration: 15070. Loss: 0.0030176390428096056. Accuracy: 81.76579543115868\n",
      "Iteration: 15080. Loss: 0.008058796636760235. Accuracy: 81.43650956987034\n",
      "Iteration: 15090. Loss: 0.02780727483332157. Accuracy: 80.96316114426837\n",
      "Epoch:  352\n",
      "Iteration: 15100. Loss: 0.029906118288636208. Accuracy: 80.94258077793785\n",
      "Iteration: 15110. Loss: 0.008597997017204762. Accuracy: 81.60115250051452\n",
      "Iteration: 15120. Loss: 0.008761406876146793. Accuracy: 81.51883103519242\n",
      "Iteration: 15130. Loss: 0.0021407916210591793. Accuracy: 81.82753653015024\n",
      "Epoch:  353\n",
      "Iteration: 15140. Loss: 0.015340521931648254. Accuracy: 80.57213418398848\n",
      "Iteration: 15150. Loss: 0.06615685671567917. Accuracy: 80.34575015435274\n",
      "Iteration: 15160. Loss: 0.019654957577586174. Accuracy: 81.06606297592097\n",
      "Iteration: 15170. Loss: 0.017129121348261833. Accuracy: 81.14838444124305\n",
      "Epoch:  354\n",
      "Iteration: 15180. Loss: 0.00913446955382824. Accuracy: 81.37476847087878\n",
      "Iteration: 15190. Loss: 0.01524151861667633. Accuracy: 81.55999176785346\n",
      "Iteration: 15200. Loss: 0.022026879712939262. Accuracy: 81.06606297592097\n",
      "Iteration: 15210. Loss: 0.0011163136223331094. Accuracy: 81.4982506688619\n",
      "Iteration: 15220. Loss: 0.011540940962731838. Accuracy: 81.580572134184\n",
      "Epoch:  355\n",
      "Iteration: 15230. Loss: 0.029434453696012497. Accuracy: 79.9958839267339\n",
      "Iteration: 15240. Loss: 0.06242341548204422. Accuracy: 80.61329491664952\n",
      "Iteration: 15250. Loss: 0.03281756117939949. Accuracy: 81.04548260959045\n",
      "Iteration: 15260. Loss: 0.02001810446381569. Accuracy: 81.10722370858201\n",
      "Epoch:  356\n",
      "Iteration: 15270. Loss: 0.0099779162555933. Accuracy: 80.88083967894629\n",
      "Iteration: 15280. Loss: 0.03754705190658569. Accuracy: 81.47767030253138\n",
      "Iteration: 15290. Loss: 0.010295520536601543. Accuracy: 80.65445564931056\n",
      "Iteration: 15300. Loss: 0.013879328966140747. Accuracy: 81.2924470055567\n",
      "Epoch:  357\n",
      "Iteration: 15310. Loss: 0.02193593978881836. Accuracy: 80.92200041160733\n",
      "Iteration: 15320. Loss: 0.03956072777509689. Accuracy: 81.4982506688619\n",
      "Iteration: 15330. Loss: 0.007256488781422377. Accuracy: 81.95101872813336\n",
      "Iteration: 15340. Loss: 0.02529103308916092. Accuracy: 81.3953488372093\n",
      "Iteration: 15350. Loss: 0.003494302276521921. Accuracy: 80.34575015435274\n",
      "Epoch:  358\n",
      "Iteration: 15360. Loss: 0.020426297560334206. Accuracy: 81.43650956987034\n",
      "Iteration: 15370. Loss: 0.04021955281496048. Accuracy: 80.6956163819716\n",
      "Iteration: 15380. Loss: 0.035731423646211624. Accuracy: 80.34575015435274\n",
      "Iteration: 15390. Loss: 0.025132570415735245. Accuracy: 81.12780407491253\n",
      "Epoch:  359\n",
      "Iteration: 15400. Loss: 0.07562169432640076. Accuracy: 80.73677711463264\n",
      "Iteration: 15410. Loss: 0.02795819565653801. Accuracy: 80.61329491664952\n",
      "Iteration: 15420. Loss: 0.04483907297253609. Accuracy: 81.53941140152294\n",
      "Iteration: 15430. Loss: 0.014130288735032082. Accuracy: 80.94258077793785\n",
      "Epoch:  360\n",
      "Iteration: 15440. Loss: 0.01788369007408619. Accuracy: 80.63387528298004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 15450. Loss: 0.009962371550500393. Accuracy: 80.75735748096317\n",
      "Iteration: 15460. Loss: 0.035611703991889954. Accuracy: 81.2924470055567\n",
      "Iteration: 15470. Loss: 0.008707315661013126. Accuracy: 81.47767030253138\n",
      "Iteration: 15480. Loss: 0.03188258036971092. Accuracy: 81.45708993620086\n",
      "Epoch:  361\n",
      "Iteration: 15490. Loss: 0.0031279069371521473. Accuracy: 81.41592920353982\n",
      "Iteration: 15500. Loss: 0.0018799323588609695. Accuracy: 81.82753653015024\n",
      "Iteration: 15510. Loss: 0.00173149723559618. Accuracy: 81.64231323317556\n",
      "Iteration: 15520. Loss: 0.0110431257635355. Accuracy: 81.62173286684504\n",
      "Epoch:  362\n",
      "Iteration: 15530. Loss: 0.01573556661605835. Accuracy: 79.95472319407286\n",
      "Iteration: 15540. Loss: 0.011458724737167358. Accuracy: 81.16896480757357\n",
      "Iteration: 15550. Loss: 0.03696876019239426. Accuracy: 80.75735748096317\n",
      "Iteration: 15560. Loss: 0.01136005949229002. Accuracy: 81.02490224325993\n",
      "Epoch:  363\n",
      "Iteration: 15570. Loss: 0.027802767232060432. Accuracy: 80.55155381765796\n",
      "Iteration: 15580. Loss: 0.02510458417236805. Accuracy: 80.57213418398848\n",
      "Iteration: 15590. Loss: 0.010159608907997608. Accuracy: 80.42807161967482\n",
      "Iteration: 15600. Loss: 0.023163188248872757. Accuracy: 80.53097345132744\n",
      "Epoch:  364\n",
      "Iteration: 15610. Loss: 0.004644456319510937. Accuracy: 80.67503601564108\n",
      "Iteration: 15620. Loss: 0.013974855653941631. Accuracy: 80.75735748096317\n",
      "Iteration: 15630. Loss: 0.010745669715106487. Accuracy: 80.61329491664952\n",
      "Iteration: 15640. Loss: 0.02548849768936634. Accuracy: 80.88083967894629\n",
      "Iteration: 15650. Loss: 0.02277756854891777. Accuracy: 81.60115250051452\n",
      "Epoch:  365\n",
      "Iteration: 15660. Loss: 0.03390200063586235. Accuracy: 81.2924470055567\n",
      "Iteration: 15670. Loss: 0.03182264044880867. Accuracy: 81.6834739658366\n",
      "Iteration: 15680. Loss: 0.014391201548278332. Accuracy: 81.33360773821774\n",
      "Iteration: 15690. Loss: 0.008537309244275093. Accuracy: 80.75735748096317\n",
      "Epoch:  366\n",
      "Iteration: 15700. Loss: 0.00688897306099534. Accuracy: 81.02490224325993\n",
      "Iteration: 15710. Loss: 0.02152952179312706. Accuracy: 80.44865198600534\n",
      "Iteration: 15720. Loss: 0.005677320063114166. Accuracy: 81.1895451739041\n",
      "Iteration: 15730. Loss: 0.01400107890367508. Accuracy: 81.41592920353982\n",
      "Epoch:  367\n",
      "Iteration: 15740. Loss: 0.04807461053133011. Accuracy: 81.25128627289565\n",
      "Iteration: 15750. Loss: 0.007353884633630514. Accuracy: 81.02490224325993\n",
      "Iteration: 15760. Loss: 0.001440581283532083. Accuracy: 81.00432187692941\n",
      "Iteration: 15770. Loss: 0.010754005052149296. Accuracy: 81.8892776291418\n",
      "Iteration: 15780. Loss: 0.010668604634702206. Accuracy: 81.64231323317556\n",
      "Epoch:  368\n",
      "Iteration: 15790. Loss: 0.027134444564580917. Accuracy: 81.43650956987034\n",
      "Iteration: 15800. Loss: 0.012675235979259014. Accuracy: 81.66289359950608\n",
      "Iteration: 15810. Loss: 0.027641426771879196. Accuracy: 81.23070590656513\n",
      "Iteration: 15820. Loss: 0.005359760019928217. Accuracy: 81.45708993620086\n",
      "Epoch:  369\n",
      "Iteration: 15830. Loss: 0.0048233699053525925. Accuracy: 80.81909857995473\n",
      "Iteration: 15840. Loss: 0.020506327971816063. Accuracy: 80.92200041160733\n",
      "Iteration: 15850. Loss: 0.026527779176831245. Accuracy: 81.2924470055567\n",
      "Iteration: 15860. Loss: 0.020040474832057953. Accuracy: 81.06606297592097\n",
      "Epoch:  370\n",
      "Iteration: 15870. Loss: 0.01755657233297825. Accuracy: 80.4074912533443\n",
      "Iteration: 15880. Loss: 0.007683569099754095. Accuracy: 80.86025931261577\n",
      "Iteration: 15890. Loss: 0.005316553637385368. Accuracy: 80.77793784729369\n",
      "Iteration: 15900. Loss: 0.01764216274023056. Accuracy: 80.75735748096317\n",
      "Iteration: 15910. Loss: 0.167360320687294. Accuracy: 80.71619674830212\n",
      "Epoch:  371\n",
      "Iteration: 15920. Loss: 0.01928623951971531. Accuracy: 80.81909857995473\n",
      "Iteration: 15930. Loss: 0.021919986233115196. Accuracy: 81.84811689648076\n",
      "Iteration: 15940. Loss: 0.019488928839564323. Accuracy: 81.37476847087878\n",
      "Iteration: 15950. Loss: 0.02320513129234314. Accuracy: 81.16896480757357\n",
      "Epoch:  372\n",
      "Iteration: 15960. Loss: 0.010728606022894382. Accuracy: 81.04548260959045\n",
      "Iteration: 15970. Loss: 0.0019108575070276856. Accuracy: 80.81909857995473\n",
      "Iteration: 15980. Loss: 0.03913702815771103. Accuracy: 81.12780407491253\n",
      "Iteration: 15990. Loss: 0.03412223979830742. Accuracy: 81.21012554023461\n",
      "Epoch:  373\n",
      "Iteration: 16000. Loss: 0.012352668680250645. Accuracy: 81.1895451739041\n",
      "Iteration: 16010. Loss: 0.037094585597515106. Accuracy: 80.6956163819716\n",
      "Iteration: 16020. Loss: 0.006598706357181072. Accuracy: 81.10722370858201\n",
      "Iteration: 16030. Loss: 0.03372492268681526. Accuracy: 81.06606297592097\n",
      "Epoch:  374\n",
      "Iteration: 16040. Loss: 0.004179834853857756. Accuracy: 81.33360773821774\n",
      "Iteration: 16050. Loss: 0.01012240257114172. Accuracy: 80.57213418398848\n",
      "Iteration: 16060. Loss: 0.030034199357032776. Accuracy: 80.98374151059889\n",
      "Iteration: 16070. Loss: 0.011444796808063984. Accuracy: 81.14838444124305\n",
      "Iteration: 16080. Loss: 0.0030325863044708967. Accuracy: 81.23070590656513\n",
      "Epoch:  375\n",
      "Iteration: 16090. Loss: 0.005635636858642101. Accuracy: 80.7985182136242\n",
      "Iteration: 16100. Loss: 0.024822283536195755. Accuracy: 80.67503601564108\n",
      "Iteration: 16110. Loss: 0.022274883463978767. Accuracy: 80.65445564931056\n",
      "Iteration: 16120. Loss: 0.029254289343953133. Accuracy: 80.592714550319\n",
      "Epoch:  376\n",
      "Iteration: 16130. Loss: 0.041239604353904724. Accuracy: 80.67503601564108\n",
      "Iteration: 16140. Loss: 0.007787914946675301. Accuracy: 81.33360773821774\n",
      "Iteration: 16150. Loss: 0.024629900231957436. Accuracy: 81.25128627289565\n",
      "Iteration: 16160. Loss: 0.02265121042728424. Accuracy: 81.21012554023461\n",
      "Epoch:  377\n",
      "Iteration: 16170. Loss: 0.0056544141843914986. Accuracy: 81.580572134184\n",
      "Iteration: 16180. Loss: 0.014284113422036171. Accuracy: 81.51883103519242\n",
      "Iteration: 16190. Loss: 0.018034828826785088. Accuracy: 81.04548260959045\n",
      "Iteration: 16200. Loss: 0.008993064053356647. Accuracy: 81.64231323317556\n",
      "Iteration: 16210. Loss: 0.03328961133956909. Accuracy: 80.71619674830212\n",
      "Epoch:  378\n",
      "Iteration: 16220. Loss: 0.010468159802258015. Accuracy: 81.64231323317556\n",
      "Iteration: 16230. Loss: 0.01826571300625801. Accuracy: 80.34575015435274\n",
      "Iteration: 16240. Loss: 0.02031421847641468. Accuracy: 81.55999176785346\n",
      "Iteration: 16250. Loss: 0.020906444638967514. Accuracy: 81.7863757974892\n"
     ]
    }
   ],
   "source": [
    "iteration_loss = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: ', epoch + 1)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images) \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 10 == 0:        \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            iteration_loss.append(loss.item())\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "id": "IwU44FpRqO9t"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_base_80+.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "1AIS0RVwq8ul",
    "outputId": "91f24f38-911c-4bca-bde1-107f33dc4107"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.3031530380249023, 2.3043460845947266, 2.3038766384124756, 2.2653415203094482, 2.228445291519165, 2.123638868331909, 2.173280954360962, 2.112790822982788, 2.1765248775482178, 2.1119139194488525, 2.104520082473755, 2.0569252967834473, 2.1079978942871094, 2.02129864692688, 1.901497483253479, 1.932432770729065, 1.8025413751602173, 1.9576255083084106, 1.910561203956604, 1.820465326309204, 1.8324670791625977, 1.9106459617614746, 1.811011791229248, 1.834259271621704, 1.7167420387268066, 1.8241839408874512, 1.733518362045288, 1.8398329019546509, 1.734735369682312, 1.6966779232025146, 1.7333734035491943, 1.566197395324707, 1.5406967401504517, 1.510119915008545, 1.5708332061767578, 1.5260155200958252, 1.419560432434082, 1.438417911529541, 1.4699018001556396, 1.3723416328430176, 1.45710289478302, 1.4486781358718872, 2.316460609436035, 1.434361219406128, 1.4207475185394287, 1.3601036071777344, 1.243581771850586, 1.269171118736267, 1.3113294839859009, 1.2036372423171997, 1.1084238290786743, 1.2266336679458618, 1.2714663743972778, 1.1212464570999146, 1.2984851598739624, 1.0859047174453735, 1.1558146476745605, 1.1668391227722168, 1.152305006980896, 1.0928378105163574, 1.0397998094558716, 1.0647178888320923, 1.0422987937927246, 1.005084753036499, 1.0167028903961182, 0.9323525428771973, 0.9592559337615967, 0.939501166343689, 1.0153214931488037, 0.9821241497993469, 0.8932273387908936, 0.8769835829734802, 1.036132574081421, 0.8157591223716736, 0.9703607559204102, 0.8800994753837585, 0.8440461158752441, 0.9370862245559692, 0.8500074148178101, 0.8718163967132568, 0.7645472884178162, 1.0187819004058838, 0.9125189185142517, 0.9904233813285828, 0.8389627933502197, 1.3046365976333618, 0.7187325954437256, 0.8465017676353455, 0.8193798661231995, 0.7962177991867065, 0.8962096571922302, 0.7821381092071533, 0.636026918888092, 0.8230443596839905, 0.7726300358772278, 0.7986375093460083, 0.640605092048645, 0.738615095615387, 0.6726057529449463, 0.6992738842964172, 0.712192177772522, 0.6169694066047668, 0.7131761908531189, 0.6865469217300415, 0.7597590088844299, 0.6961367130279541, 0.6606661677360535, 0.7038230299949646, 0.7951817512512207, 0.7387277483940125, 0.7854244112968445, 0.5913735628128052, 0.5909423828125, 0.6734076738357544, 0.6562007665634155, 0.6141814589500427, 0.773618221282959, 0.6287664771080017, 0.5285555124282837, 0.64312744140625, 0.5432794690132141, 0.5284004807472229, 0.4896419942378998, 0.48154690861701965, 0.6465417742729187, 0.46484458446502686, 0.5173174142837524, 0.5416873097419739, 0.7341839671134949, 0.5410326719284058, 0.5235045552253723, 0.5215771794319153, 0.47479650378227234, 0.4833139479160309, 0.4597058892250061, 0.5475851893424988, 0.42967087030410767, 0.4156843423843384, 0.43970558047294617, 0.495061993598938, 0.42055562138557434, 0.4074088931083679, 0.4980162978172302, 0.476071834564209, 0.4667384624481201, 0.429205060005188, 0.4096432030200958, 0.42356038093566895, 0.3875509202480316, 0.4771789312362671, 0.3683488965034485, 0.42920559644699097, 0.3241051435470581, 0.4117262363433838, 0.38796672224998474, 0.3768640160560608, 0.35622236132621765, 0.3470757305622101, 0.3935009241104126, 0.39581093192100525, 0.3638567328453064, 0.37336617708206177, 0.37507104873657227, 0.2698887586593628, 0.41765096783638, 0.38523629307746887, 0.38838082551956177, 0.4165829122066498, 0.30824002623558044, 0.3134957253932953, 0.2945707142353058, 0.8601957559585571, 0.2874284088611603, 0.3506176471710205, 0.35748884081840515, 0.35372355580329895, 0.3109712302684784, 0.37343305349349976, 0.26715466380119324, 0.3113000988960266, 0.2881009876728058, 0.2971513867378235, 0.2709808349609375, 0.26109179854393005, 0.2680096924304962, 0.2722409665584564, 0.3332543671131134, 0.26593053340911865, 0.2791985273361206, 0.27464696764945984, 0.2639485001564026, 0.26177752017974854, 0.2857489585876465, 0.29943880438804626, 0.26426824927330017, 0.29742950201034546, 0.2856154441833496, 0.26901963353157043, 0.254823237657547, 0.3078150749206543, 0.2380947470664978, 0.3006457984447479, 0.17945373058319092, 0.26506805419921875, 0.22054226696491241, 0.2513965666294098, 0.24300141632556915, 0.19840359687805176, 0.19126255810260773, 0.168076291680336, 0.17324687540531158, 0.20082692801952362, 0.17485620081424713, 0.25355371832847595, 0.3482893109321594, 0.2166626751422882, 0.31900089979171753, 0.20667782425880432, 0.17804354429244995, 0.2591448724269867, 0.28025850653648376, 0.2261505424976349, 0.19511353969573975, 0.16041798889636993, 0.20384259521961212, 0.21443712711334229, 0.2229611873626709, 0.16594736278057098, 0.21415136754512787, 0.17093145847320557, 0.2426336407661438, 0.20441584289073944, 0.21555553376674652, 0.14210999011993408, 0.15308713912963867, 0.23297330737113953, 0.25076228380203247, 0.14125113189220428, 0.194580078125, 0.20696097612380981, 0.17731186747550964, 0.21694378554821014, 0.1410520374774933, 0.22763514518737793, 0.18659736216068268, 0.2196049690246582, 0.31314200162887573, 0.13567635416984558, 0.18663789331912994, 0.15670551359653473, 0.1762840449810028, 0.15301445126533508, 0.1577725112438202, 0.16568566858768463, 0.13807769119739532, 0.16488607227802277, 0.16366110742092133, 0.3318491578102112, 0.1984306126832962, 0.2140265554189682, 0.12798796594142914, 0.19454902410507202, 0.15319597721099854, 0.12867416441440582, 0.13744647800922394, 0.13813678920269012, 0.14808723330497742, 0.13327065110206604, 0.20674724876880646, 0.13629688322544098, 0.14856597781181335, 0.16247835755348206, 0.1191888228058815, 0.10047939419746399, 0.13149498403072357, 0.14550398290157318, 0.11390519142150879, 0.1619853526353836, 0.14511485397815704, 0.173702672123909, 0.1250087022781372, 0.15999828279018402, 0.1534670740365982, 0.15194320678710938, 0.17424538731575012, 0.11123546957969666, 0.16599325835704803, 0.10944143682718277, 0.13692855834960938, 0.13279883563518524, 0.1274634450674057, 0.08737008273601532, 0.12130013853311539, 0.15898790955543518, 0.0872003361582756, 0.18190398812294006, 0.1443721055984497, 0.17198941111564636, 0.15639902651309967, 0.14257578551769257, 0.3178168535232544, 0.1804935485124588, 0.10037651658058167, 0.16256915032863617, 0.1817912608385086, 0.1789967119693756, 0.15950074791908264, 0.08143645524978638, 0.08240810036659241, 0.12439456582069397, 0.13105222582817078, 0.08959139138460159, 0.09267893433570862, 0.04540408030152321, 0.13177956640720367, 0.09558036178350449, 0.16396614909172058, 0.09258487075567245, 0.11095510423183441, 0.08080807328224182, 0.13831159472465515, 0.10223662108182907, 0.11625451594591141, 0.11926208436489105, 0.12176503241062164, 0.14884673058986664, 0.13233639299869537, 0.09754520654678345, 0.05741773173213005, 0.0840839073061943, 0.09316404908895493, 0.1438060998916626, 0.12142159789800644, 0.08207292854785919, 0.08562785387039185, 0.11496564000844955, 0.17822518944740295, 0.08640705049037933, 0.08246386796236038, 0.134019136428833, 0.13029707968235016, 0.16437529027462006, 0.12462878227233887, 0.2984968423843384, 0.12124783545732498, 0.17518965899944305, 0.0703493058681488, 0.14141543209552765, 0.16564230620861053, 0.08166506886482239, 0.0664437860250473, 0.19341717660427094, 0.06092234328389168, 0.08138827979564667, 0.0977540835738182, 0.056659795343875885, 0.04483826085925102, 0.11965283006429672, 0.09873320907354355, 0.08389836549758911, 0.09232450276613235, 0.0725603848695755, 0.07877277582883835, 0.053236059844493866, 0.1488521248102188, 0.1960732340812683, 0.1338513195514679, 0.12505552172660828, 0.14028823375701904, 0.07189617305994034, 0.11823201179504395, 0.08375421911478043, 0.1511194258928299, 0.08919991552829742, 0.06685493886470795, 0.06384911388158798, 0.05596192553639412, 0.10230129957199097, 0.06743833422660828, 0.07254165410995483, 0.07059524208307266, 0.03741594776511192, 0.15214765071868896, 0.061247892677783966, 0.06466537714004517, 0.054986048489809036, 0.6099209785461426, 0.15809981524944305, 0.06755655258893967, 0.14017073810100555, 0.06960829347372055, 0.10392597317695618, 0.15484829246997833, 0.13675978779792786, 0.05974431335926056, 0.10129959136247635, 0.05884392932057381, 0.05033915489912033, 0.06142701581120491, 0.05954895168542862, 0.038981158286333084, 0.05731687694787979, 0.06086312606930733, 0.050680190324783325, 0.09032457321882248, 0.07578056305646896, 0.05245155841112137, 0.09954226762056351, 0.06664145737886429, 0.09332578629255295, 0.07366062700748444, 0.13836488127708435, 0.078484907746315, 0.1179206594824791, 0.0710664764046669, 0.0954187884926796, 0.07442795485258102, 0.05793953314423561, 0.06040739268064499, 0.06140198931097984, 0.09183746576309204, 0.10413933545351028, 0.08987154066562653, 0.11167025566101074, 0.07394269853830338, 0.0643899217247963, 0.038979921489953995, 0.044489581137895584, 0.057791341096162796, 0.32471394538879395, 0.05384831875562668, 0.0824994444847107, 0.05670909211039543, 0.05622732266783714, 0.06705518066883087, 0.028510682284832, 0.061941713094711304, 0.033474814146757126, 0.061252664774656296, 0.08119967579841614, 0.07438434660434723, 0.044764745980501175, 0.05297168716788292, 0.06761312484741211, 0.059918876737356186, 0.06074680760502815, 0.025060007348656654, 0.12795116007328033, 0.09505380690097809, 0.09222085028886795, 0.1252690553665161, 0.06350421160459518, 0.08434867858886719, 0.03695644065737724, 0.07472308725118637, 0.05310270935297012, 0.08849899470806122, 0.06273341178894043, 0.05072811245918274, 0.12162528187036514, 0.07441921532154083, 0.07330082356929779, 0.057243380695581436, 0.04069254919886589, 0.08844846487045288, 0.13955143094062805, 0.05640894174575806, 0.07122880220413208, 0.09973937273025513, 0.1374518871307373, 0.06859146058559418, 0.041574876755476, 0.3142363429069519, 0.10757718980312347, 0.09129485487937927, 0.041016604751348495, 0.07816935330629349, 0.045756060630083084, 0.06001908704638481, 0.021594252437353134, 0.017554068937897682, 0.05583609640598297, 0.035784170031547546, 0.049237556755542755, 0.04820720851421356, 0.024115215986967087, 0.11004220694303513, 0.07576341181993484, 0.07686054706573486, 0.05990450084209442, 0.0833660140633583, 0.03310425952076912, 0.0349106639623642, 0.05333463102579117, 0.037000760436058044, 0.03696485981345177, 0.07424286007881165, 0.034822914749383926, 0.05257931724190712, 0.03109130449593067, 0.059026412665843964, 0.03314271569252014, 0.04999179393053055, 0.0510118305683136, 0.01691785641014576, 0.07383470982313156, 0.060748517513275146, 0.07175954431295395, 0.0938098356127739, 0.09008560329675674, 0.07396314293146133, 0.054166585206985474, 0.10296602547168732, 0.041079554706811905, 0.05515787750482559, 0.1285114586353302, 0.06267660111188889, 0.049453288316726685, 0.051527492702007294, 0.03931638225913048, 0.030092915520071983, 0.021526789292693138, 0.02312282659113407, 0.04484539479017258, 0.026048213243484497, 0.06950423121452332, 0.06482689827680588, 0.09092961996793747, 0.06498127430677414, 0.06317566335201263, 0.07937517762184143, 0.04738249629735947, 0.0604451484978199, 0.07685345411300659, 0.027935488149523735, 0.042780522257089615, 0.03864355757832527, 0.021820202469825745, 0.017257850617170334, 0.05100522190332413, 0.027353590354323387, 0.01570657081902027, 0.03509720414876938, 0.017338206991553307, 0.024501889944076538, 0.036056339740753174, 0.07447311282157898, 0.019410090520977974, 0.02389821968972683, 0.05710837244987488, 0.04151608794927597, 0.05929609760642052, 0.018234875053167343, 0.014681677334010601, 0.036392129957675934, 0.059636469930410385, 0.044796209782361984, 0.027741072699427605, 0.26887941360473633, 0.07818256318569183, 0.031100884079933167, 0.061095837503671646, 0.020641261711716652, 0.11069947481155396, 0.048998184502124786, 0.07694312185049057, 0.05140196159482002, 0.11906826496124268, 0.06690113991498947, 0.0508376844227314, 0.037089332938194275, 0.019375991076231003, 0.06955717504024506, 0.028639018535614014, 0.021603718400001526, 0.035396866500377655, 0.030011147260665894, 0.025143973529338837, 0.01964988373219967, 0.025822628289461136, 0.05325804650783539, 0.08468042314052582, 0.04583388939499855, 0.018452180549502373, 0.007246006280183792, 0.02114824205636978, 0.014422675594687462, 0.024717969819903374, 0.009170680306851864, 0.0548015832901001, 0.027026580646634102, 0.02546994388103485, 0.021191805601119995, 0.057260289788246155, 0.02680203877389431, 0.04542781040072441, 0.0366339311003685, 0.029482509940862656, 0.04886604845523834, 0.041505809873342514, 0.039718981832265854, 0.16169878840446472, 0.06400591135025024, 0.04406590759754181, 0.03476589545607567, 0.04889241233468056, 0.02297919988632202, 0.04959549009799957, 0.010850967839360237, 0.010874591767787933, 0.02744225785136223, 0.04567256197333336, 0.07981404662132263, 0.03032011352479458, 0.026333283632993698, 0.055513303726911545, 0.033402521163225174, 0.036539748311042786, 0.029711643233895302, 0.06449246406555176, 0.09500869363546371, 0.01862993650138378, 0.05639929696917534, 0.02176721580326557, 0.024005219340324402, 0.03825938701629639, 0.029293902218341827, 0.017736496403813362, 0.03473629057407379, 0.03845076635479927, 0.03787022829055786, 0.049389053136110306, 0.04042121767997742, 0.04932960122823715, 0.04250650107860565, 0.021268948912620544, 0.025099987164139748, 0.01834753341972828, 0.0411098413169384, 0.03697699308395386, 0.04456270858645439, 0.007572014816105366, 0.023329351097345352, 0.014697756618261337, 0.03888622671365738, 0.021172886714339256, 0.014804063364863396, 0.02023807168006897, 0.02557452581822872, 0.040882375091314316, 0.02297336421906948, 0.019576694816350937, 0.056762855499982834, 0.11913745105266571, 0.15356962382793427, 0.028527718037366867, 0.05682026222348213, 0.025317523628473282, 0.03865741565823555, 0.06905414164066315, 0.030583754181861877, 0.021911561489105225, 0.1338839828968048, 0.047207679599523544, 0.030090857297182083, 0.039612192660570145, 0.09642710536718369, 0.07257480919361115, 0.033343177288770676, 0.0347408726811409, 0.04699544608592987, 0.01836239919066429, 0.019268963485956192, 0.05603741481900215, 0.039016544818878174, 0.05779591575264931, 0.02487354353070259, 0.036082830280065536, 0.01980743557214737, 0.017506349831819534, 0.022159148007631302, 0.0515725277364254, 0.03143877908587456, 0.028200190514326096, 0.04195889085531235, 0.016426296904683113, 0.020067239180207253, 0.3008769154548645, 0.05073004215955734, 0.03689225763082504, 0.012081285007297993, 0.02675243653357029, 0.02637760527431965, 0.073420450091362, 0.06012224778532982, 0.012565642595291138, 0.010930176824331284, 0.004393408540636301, 0.06228163093328476, 0.01953515224158764, 0.0054787686094641685, 0.033373963087797165, 0.009938523173332214, 0.024843454360961914, 0.01120286900550127, 0.05378195643424988, 0.037459682673215866, 0.041557006537914276, 0.043028295040130615, 0.09000304341316223, 0.023081809282302856, 0.09173517674207687, 0.05332763120532036, 0.033736418932676315, 0.04015154391527176, 0.03079625964164734, 0.011700655333697796, 0.04251012206077576, 0.02668207697570324, 0.006027093157172203, 0.014834457077085972, 0.0381028912961483, 0.048115964978933334, 0.04213687404990196, 0.05697247385978699, 0.04377763345837593, 0.06754797697067261, 0.05132368579506874, 0.09205025434494019, 0.03467119112610817, 0.19137133657932281, 0.09028731286525726, 0.014144373126327991, 0.03622055798768997, 0.0366465225815773, 0.06893376260995865, 0.020587705075740814, 0.020380135625600815, 0.027002645656466484, 0.036807429045438766, 0.03459664061665535, 0.027723047882318497, 0.026058917865157127, 0.013468951918184757, 0.029613427817821503, 0.031420592218637466, 0.017053809016942978, 0.03377138078212738, 0.04249133914709091, 0.015817753970623016, 0.024877261370420456, 0.04279192164540291, 0.023187650367617607, 0.025378938764333725, 0.03484160825610161, 0.023543449118733406, 0.015431561507284641, 0.04344973340630531, 0.014576750807464123, 0.006823839619755745, 0.029696952551603317, 0.022055182605981827, 0.04533643275499344, 0.03577890247106552, 0.005431863013654947, 0.007376282010227442, 0.036304835230112076, 0.02756175398826599, 0.023499812930822372, 0.01019530463963747, 0.01395522989332676, 0.021885547786951065, 0.027304982766509056, 0.4467688500881195, 0.07102914899587631, 0.03202008083462715, 0.05635134130716324, 0.02786322869360447, 0.08734503388404846, 0.024170640856027603, 0.04350831359624863, 0.025961291044950485, 0.029299600049853325, 0.038438037037849426, 0.093804270029068, 0.028300678357481956, 0.014192447066307068, 0.046362683176994324, 0.045600999146699905, 0.011471040546894073, 0.06257516145706177, 0.03131682053208351, 0.03263212367892265, 0.02064715512096882, 0.034522879868745804, 0.05511404573917389, 0.03211225941777229, 0.01671433262526989, 0.025743523612618446, 0.025534948334097862, 0.02647067792713642, 0.03923867642879486, 0.03376421704888344, 0.04515114799141884, 0.06467319279909134, 0.049357108771800995, 0.06812933832406998, 0.015947282314300537, 0.09468928724527359, 0.04720695689320564, 0.018617257475852966, 0.02983170934021473, 0.016504809260368347, 0.053531575947999954, 0.03995678201317787, 0.04306267201900482, 0.14611029624938965, 0.017394915223121643, 0.014985598623752594, 0.019207347184419632, 0.009770235978066921, 0.011115195229649544, 0.03439762443304062, 0.016570640727877617, 0.010910440236330032, 0.008073057048022747, 0.024677257984876633, 0.015904460102319717, 0.012651571072638035, 0.007501060608774424, 0.051507726311683655, 0.0112773347645998, 0.016348419710993767, 0.007855803705751896, 0.01839977689087391, 0.008193486370146275, 0.021341808140277863, 0.0082186758518219, 0.028367144986987114, 0.004540754947811365, 0.018025558441877365, 0.009044777601957321, 0.008358471095561981, 0.035577066242694855, 0.018155798316001892, 0.021883102133870125, 0.003546725260093808, 0.00657327426597476, 0.01637881249189377, 0.013997300527989864, 0.02173403836786747, 0.05790004879236221, 0.036409828811883926, 0.027569163590669632, 0.02862035110592842, 0.057803235948085785, 0.028950970619916916, 0.02459525316953659, 0.0027536186389625072, 0.12323346734046936, 0.040003687143325806, 0.038552094250917435, 0.024048779159784317, 0.022946208715438843, 0.03059210069477558, 0.028705425560474396, 0.04382224753499031, 0.05017288029193878, 0.03691839054226875, 0.07828011363744736, 0.0835176631808281, 0.04793839156627655, 0.028608333319425583, 0.02148810401558876, 0.07367655634880066, 0.018416617065668106, 0.04876793920993805, 0.01676856353878975, 0.03198316693305969, 0.017053840681910515, 0.02344023436307907, 0.022159792482852936, 0.027664875611662865, 0.016495121642947197, 0.02343170903623104, 0.02704193815588951, 0.017478059977293015, 0.02194427140057087, 0.023603588342666626, 0.014142422936856747, 0.01798703894019127, 0.031176438555121422, 0.015599063597619534, 0.019350625574588776, 0.0405288003385067, 0.05069632828235626, 0.012198084034025669, 0.015600097365677357, 0.010481791570782661, 0.024804847314953804, 0.014634172432124615, 0.01937040314078331, 0.08263186365365982, 0.011696475557982922, 0.030648190528154373, 0.02495841309428215, 0.01833888702094555, 0.07565813511610031, 0.08527792245149612, 0.11451765894889832, 0.057121649384498596, 0.030075697228312492, 0.05396987125277519, 0.08438989520072937, 0.0177727360278368, 0.00847588386386633, 0.024594273418188095, 0.03985985741019249, 0.028812916949391365, 0.035241853445768356, 0.016024716198444366, 0.02379339002072811, 0.024981806054711342, 0.027629103511571884, 0.022277863696217537, 0.018915068358182907, 0.041482698172330856, 0.04460526630282402, 0.04428955912590027, 0.06262218952178955, 0.059466373175382614, 0.04809599742293358, 0.04041127488017082, 0.03308339789509773, 0.014879616908729076, 0.02509501576423645, 0.02529694139957428, 0.00482956413179636, 0.026023894548416138, 0.002731229644268751, 0.0120492372661829, 0.022285738959908485, 0.007957343012094498, 0.019187359139323235, 0.01794864423573017, 0.07860628515481949, 0.052670493721961975, 0.05134354531764984, 0.02654438279569149, 0.025598060339689255, 0.03237446770071983, 0.009295294992625713, 0.04678526520729065, 0.020734131336212158, 0.011523710563778877, 0.0128407571464777, 0.02181308902800083, 0.0047789569944143295, 0.0025387934874743223, 0.05718603730201721, 0.03658216446638107, 0.0027270251885056496, 0.009729236364364624, 0.007626185193657875, 0.019631559029221535, 0.010725637897849083, 0.018320299685001373, 0.03347598388791084, 0.05244547128677368, 0.027221348136663437, 0.003413408063352108, 0.0553063340485096, 0.013172784820199013, 0.03146912530064583, 0.018847350031137466, 0.026884907856583595, 0.0433332622051239, 0.021512413397431374, 0.019398028030991554, 0.03148951753973961, 0.021897926926612854, 0.0446917749941349, 0.023391511291265488, 0.008885118179023266, 0.05058090016245842, 0.046596139669418335, 0.028068233281373978, 0.047745537012815475, 0.03798356652259827, 0.011561217717826366, 0.027958393096923828, 0.019296132028102875, 0.015446178615093231, 0.042369890958070755, 0.023356342688202858, 0.029140911996364594, 0.021586081013083458, 0.007437140680849552, 0.0069473907351493835, 0.013121183030307293, 0.010772863402962685, 0.015162531286478043, 0.0873408243060112, 0.023751934990286827, 0.00842352770268917, 0.011947720311582088, 0.01633962243795395, 0.009049850516021252, 0.03149827942252159, 0.03285852074623108, 0.05790668725967407, 0.048421796411275864, 0.030110225081443787, 0.11031288653612137, 0.028645731508731842, 0.05911105126142502, 0.015119070187211037, 0.02159418910741806, 0.025818677619099617, 0.024912437424063683, 0.03889048472046852, 0.01705235429108143, 0.03376239538192749, 0.014689136296510696, 0.021213626489043236, 0.031879644840955734, 0.014992967247962952, 0.004629030823707581, 0.03872368857264519, 0.01984560303390026, 0.03180098906159401, 0.246996209025383, 0.018013520166277885, 0.02773149125277996, 0.03778885677456856, 0.02174670621752739, 0.03578632324934006, 0.010255164466798306, 0.01216957438737154, 0.020239977166056633, 0.019148364663124084, 0.013708950951695442, 0.008612047880887985, 0.02212541736662388, 0.007962072268128395, 0.013750504702329636, 0.05204655975103378, 0.017281536012887955, 0.017253227531909943, 0.02592059224843979, 0.016415342688560486, 0.01219397597014904, 0.01651345193386078, 0.041892264038324356, 0.043968066573143005, 0.04677047207951546, 0.025019608438014984, 0.03541671857237816, 0.015032126568257809, 0.013863951899111271, 0.031093887984752655, 0.01229733508080244, 0.030861245468258858, 0.031157715246081352, 0.020296327769756317, 0.03569190576672554, 0.01911969855427742, 0.03678101673722267, 0.022155560553073883, 0.010771271772682667, 0.026192789897322655, 0.026376985013484955, 0.0174734964966774, 0.026975398883223534, 0.035778045654296875, 0.036010731011629105, 0.03322184085845947, 0.007729831151664257, 0.008889172226190567, 0.047400008887052536, 0.08169209212064743, 0.010809097439050674, 0.028183884918689728, 0.036547426134347916, 0.011379032395780087, 0.02496316097676754, 0.03790001943707466, 0.0052574798464775085, 0.028506936505436897, 0.02339114062488079, 0.04105221852660179, 0.03102097474038601, 0.011796247214078903, 0.010093715973198414, 0.017714790999889374, 0.005994231905788183, 0.011520752683281898, 0.025364257395267487, 0.028755519539117813, 0.00771603686735034, 0.002436082810163498, 0.021723637357354164, 0.018632672727108, 0.013137194328010082, 0.010520589537918568, 0.006441854871809483, 0.031977564096450806, 0.008312777616083622, 0.0029066409915685654, 0.07631077617406845, 0.05547843500971794, 0.041955314576625824, 0.026589766144752502, 0.04492296651005745, 0.05087239295244217, 0.02332797646522522, 0.042077112942934036, 0.12028271704912186, 0.009259544312953949, 0.0042384616099298, 0.009639431722462177, 0.009757774882018566, 0.021247057244181633, 0.009625044651329517, 0.0024635044392198324, 0.011435288935899734, 0.03772648796439171, 0.03153437003493309, 0.030104124918580055, 0.029184695333242416, 0.017896531149744987, 0.04163474962115288, 0.03827692195773125, 0.014657769352197647, 0.012280316092073917, 0.00974817480891943, 0.009036977775394917, 0.009437507949769497, 0.008001076057553291, 0.007492376025766134, 0.00791690219193697, 0.01720212772488594, 0.003639530623331666, 0.012179468758404255, 0.009818490594625473, 0.003883152501657605, 0.004732692148536444, 0.012456860393285751, 0.03742814436554909, 0.03984769061207771, 0.024024564772844315, 0.011176006868481636, 0.030188843607902527, 0.0352897010743618, 0.0270107202231884, 0.0066102417185902596, 0.029752610251307487, 0.029131004586815834, 0.010138891637325287, 0.034452833235263824, 0.20377153158187866, 0.03548101708292961, 0.049248628318309784, 0.03256473317742348, 0.0534406416118145, 0.014470874331891537, 0.0558759905397892, 0.05210241302847862, 0.020363686606287956, 0.042438142001628876, 0.022092141211032867, 0.0341896191239357, 0.0135194081813097, 0.013883577659726143, 0.021875547245144844, 0.06193939223885536, 0.011551621370017529, 0.004366474226117134, 0.0058982656337320805, 0.00872767623513937, 0.00375439808703959, 0.002428196370601654, 0.010956844314932823, 0.037415146827697754, 0.007117093540728092, 0.00897802785038948, 0.008813529275357723, 0.06886023283004761, 0.04503050446510315, 0.008618145249783993, 0.015633344650268555, 0.02764882706105709, 0.00525040365755558, 0.01786271296441555, 0.005435252096503973, 0.00567250233143568, 0.00648832181468606, 0.0071982042863965034, 0.005223305895924568, 0.028750456869602203, 0.025667745620012283, 0.0039493367075920105, 0.008971883915364742, 0.0509435199201107, 0.0013832247350364923, 0.05530978739261627, 0.013375034555792809, 0.04628274589776993, 0.0412481464445591, 0.008373305201530457, 0.049642205238342285, 0.010503380559384823, 0.055269934237003326, 0.04251265153288841, 0.020122293382883072, 0.026142621412873268, 0.008749683387577534, 0.02985844761133194, 0.029668759554624557, 0.03691098093986511, 0.0221036896109581, 0.02587372064590454, 0.010600627399981022, 0.007050420623272657, 0.021669035777449608, 0.016473349183797836, 0.022215135395526886, 0.02251226268708706, 0.009274072013795376, 0.008855316787958145, 0.06329125165939331, 0.025738324970006943, 0.009158936329185963, 0.00758694251999259, 0.007016317918896675, 0.013295479118824005, 0.004437413066625595, 0.016723113134503365, 0.04677421972155571, 0.019347216933965683, 0.007534681353718042, 0.019666975364089012, 0.01894794963300228, 0.08127638697624207, 0.03467640280723572, 0.03318410366773605, 0.062308453023433685, 0.02692987397313118, 0.030170388519763947, 0.02726682461798191, 0.006521143950521946, 0.03468914330005646, 0.0079506766051054, 0.0015027665067464113, 0.0020193196833133698, 0.00853456649929285, 0.018761202692985535, 0.012260260991752148, 0.003771410556510091, 0.019228141754865646, 0.012625985778868198, 0.009128991514444351, 0.007148596458137035, 0.004614654928445816, 0.07108722627162933, 0.02320278063416481, 0.005634735804051161, 0.016927247866988182, 0.03360358625650406, 0.03599116578698158, 0.0320267416536808, 0.007102362345904112, 0.02516203559935093, 0.013602069579064846, 0.032828595489263535, 0.05546732246875763, 0.03885526955127716, 0.013005116023123264, 0.04185100644826889, 0.026821527630090714, 0.008996732532978058, 0.04074108973145485, 0.019594984129071236, 0.006083323620259762, 0.011316073127090931, 0.006003832910209894, 0.030476335436105728, 0.06927748769521713, 0.06314285099506378, 0.1399027407169342, 0.013147598132491112, 0.04763085022568703, 0.01946699433028698, 0.008673522621393204, 0.013124540448188782, 0.0021969492081552744, 0.021062830463051796, 0.00465009780600667, 0.00716776167973876, 0.04093426465988159, 0.017501628026366234, 0.02352919988334179, 0.027669306844472885, 0.008402548730373383, 0.024156389757990837, 0.018664726987481117, 0.0053450316190719604, 0.010931819677352905, 0.0037948177196085453, 0.006580541841685772, 0.022255053743720055, 0.005552023183554411, 0.0008110819035209715, 0.002465355210006237, 0.023800021037459373, 0.011844615451991558, 0.016173183917999268, 0.0162554569542408, 0.005619630683213472, 0.0039007302839308977, 0.03970678895711899, 0.0050835381262004375, 0.01629248633980751, 0.003116808831691742, 0.01147559192031622, 0.004931092727929354, 0.007688294164836407, 0.007454823236912489, 0.004672978539019823, 0.012569576501846313, 0.003933393862098455, 0.0016499963821843266, 0.0031410581432282925, 0.01183423399925232, 0.0076391249895095825, 0.0020520701073110104, 0.0022168599534779787, 0.020630531013011932, 0.02520417794585228, 0.004375095013529062, 0.005437429528683424, 0.02727115899324417, 0.008299806155264378, 0.008871464058756828, 0.004594846162945032, 0.0013952795416116714, 0.001610612845979631, 0.0030498045962303877, 0.024256346747279167, 0.0023586645256727934, 0.018531261011958122, 0.03556418791413307, 0.03359982371330261, 0.03379593789577484, 0.014504434540867805, 0.015307631343603134, 0.013149278238415718, 0.028227534145116806, 0.007416213396936655, 0.010501524433493614, 0.03327161446213722, 0.01585742086172104, 0.04750925675034523, 0.034664664417505264, 0.006224467419087887, 0.0561702661216259, 0.009766546078026295, 0.003459189785644412, 0.04856482148170471, 0.015639306977391243, 0.01836702972650528, 0.009846135042607784, 0.04560094326734543, 0.017851507291197777, 0.034052442759275436, 0.15802858769893646, 0.004861955530941486, 0.010729902423918247, 0.023117415606975555, 0.03794887661933899, 0.06878484040498734, 0.030043572187423706, 0.007494117598980665, 0.038170307874679565, 0.011365532875061035, 0.01317047793418169, 0.007304140832275152, 0.003973489161580801, 0.009289183653891087, 0.04834882542490959, 0.033910565078258514, 0.004938699770718813, 0.00274896202608943, 0.02274235151708126, 0.039380114525556564, 0.026913225650787354, 0.02865205705165863, 0.02184450253844261, 0.03346732258796692, 0.028515158221125603, 0.020025985315442085, 0.002967698732391, 0.014833981171250343, 0.0015116888098418713, 0.006956503260880709, 0.005490282084792852, 0.011972750537097454, 0.0214349664747715, 0.0026075292844325304, 0.006237447261810303, 0.03451629355549812, 0.012847580946981907, 0.012933589518070221, 0.005583025515079498, 0.007239810191094875, 0.03621765971183777, 0.02554290182888508, 0.004341042600572109, 0.058026086539030075, 0.011826325207948685, 0.0007756009581498802, 0.008168594911694527, 0.02015751041471958, 0.020609788596630096, 0.003268324537202716, 0.009981249459087849, 0.003728472860530019, 0.008281090296804905, 0.0035115263890475035, 0.016035350039601326, 0.02433294989168644, 0.009287329390645027, 0.059160757809877396, 0.07649321854114532, 0.054044973105192184, 0.019297363236546516, 0.02350241132080555, 0.052769735455513, 0.03385021537542343, 0.02687130682170391, 0.01741744950413704, 0.007173025980591774, 0.022086437791585922, 0.024644246324896812, 0.011491500772535801, 0.0046195522882044315, 0.020205823704600334, 0.008583229035139084, 0.0037800425197929144, 0.012268265709280968, 0.0037316002417355776, 0.0032857446931302547, 0.013887451961636543, 0.03749917820096016, 0.01542049553245306, 0.04537757486104965, 0.009511812590062618, 0.04865763336420059, 0.002694620518013835, 0.036014676094055176, 0.012361761182546616, 0.006340141873806715, 0.0198059119284153, 0.02431037649512291, 0.003093729028478265, 0.003981274086982012, 0.05969671532511711, 0.007683496456593275, 0.012386550195515156, 0.023468248546123505, 0.007571128197014332, 0.017406776547431946, 0.047327522188425064, 0.020334171131253242, 0.004632510710507631, 0.039483632892370224, 0.060252703726291656, 0.03221626579761505, 0.021088240668177605, 0.022103535011410713, 0.03284134343266487, 0.016307301819324493, 0.024695565924048424, 0.05265853554010391, 0.014620664529502392, 0.02140907384455204, 0.0063982559368014336, 0.019435478374361992, 0.0024526582565158606, 0.003996668849140406, 0.014426523819565773, 0.003071598708629608, 0.00510164862498641, 0.020342901349067688, 0.016336942091584206, 0.007838692516088486, 0.002606048481538892, 0.014063467271625996, 0.01169001404196024, 0.0032792622223496437, 0.0200716033577919, 0.011741367168724537, 0.008953378535807133, 0.029586270451545715, 0.05435173213481903, 0.016520105302333832, 0.0030176390428096056, 0.008058796636760235, 0.02780727483332157, 0.029906118288636208, 0.008597997017204762, 0.008761406876146793, 0.0021407916210591793, 0.015340521931648254, 0.06615685671567917, 0.019654957577586174, 0.017129121348261833, 0.00913446955382824, 0.01524151861667633, 0.022026879712939262, 0.0011163136223331094, 0.011540940962731838, 0.029434453696012497, 0.06242341548204422, 0.03281756117939949, 0.02001810446381569, 0.0099779162555933, 0.03754705190658569, 0.010295520536601543, 0.013879328966140747, 0.02193593978881836, 0.03956072777509689, 0.007256488781422377, 0.02529103308916092, 0.003494302276521921, 0.020426297560334206, 0.04021955281496048, 0.035731423646211624, 0.025132570415735245, 0.07562169432640076, 0.02795819565653801, 0.04483907297253609, 0.014130288735032082, 0.01788369007408619, 0.009962371550500393, 0.035611703991889954, 0.008707315661013126, 0.03188258036971092, 0.0031279069371521473, 0.0018799323588609695, 0.00173149723559618, 0.0110431257635355, 0.01573556661605835, 0.011458724737167358, 0.03696876019239426, 0.01136005949229002, 0.027802767232060432, 0.02510458417236805, 0.010159608907997608, 0.023163188248872757, 0.004644456319510937, 0.013974855653941631, 0.010745669715106487, 0.02548849768936634, 0.02277756854891777, 0.03390200063586235, 0.03182264044880867, 0.014391201548278332, 0.008537309244275093, 0.00688897306099534, 0.02152952179312706, 0.005677320063114166, 0.01400107890367508, 0.04807461053133011, 0.007353884633630514, 0.001440581283532083, 0.010754005052149296, 0.010668604634702206, 0.027134444564580917, 0.012675235979259014, 0.027641426771879196, 0.005359760019928217, 0.0048233699053525925, 0.020506327971816063, 0.026527779176831245, 0.020040474832057953, 0.01755657233297825, 0.007683569099754095, 0.005316553637385368, 0.01764216274023056, 0.167360320687294, 0.01928623951971531, 0.021919986233115196, 0.019488928839564323, 0.02320513129234314, 0.010728606022894382, 0.0019108575070276856, 0.03913702815771103, 0.03412223979830742, 0.012352668680250645, 0.037094585597515106, 0.006598706357181072, 0.03372492268681526, 0.004179834853857756, 0.01012240257114172, 0.030034199357032776, 0.011444796808063984, 0.0030325863044708967, 0.005635636858642101, 0.024822283536195755, 0.022274883463978767, 0.029254289343953133, 0.041239604353904724, 0.007787914946675301, 0.024629900231957436, 0.02265121042728424, 0.0056544141843914986, 0.014284113422036171, 0.018034828826785088, 0.008993064053356647, 0.03328961133956909, 0.010468159802258015, 0.01826571300625801, 0.02031421847641468, 0.020906444638967514]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print (iteration_loss)\n",
    "plt.plot(iteration_loss)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.plot(iteration_loss[0:-1:10])\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.7863757974892\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250 # 300 te 83\n",
    "num_iters = 15000\n",
    "input_dim = 28*28\n",
    "num_hidden = 330\n",
    "output_dim = 10\n",
    "\n",
    "learning_rate = 0.28\n",
    "\n",
    "num_epochs = num_iters / (len(train_data) / batch_size)\n",
    "num_epochs = int(num_epochs)\n",
    "print(num_epochs)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataloader:78\n",
      "Test dataloader:20\n"
     ]
    }
   ],
   "source": [
    "test_size = 0.2\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(test_size * num_train))\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size,\n",
    "    sampler=train_sampler)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size,\n",
    "    sampler=test_sampler)\n",
    "\n",
    "print(\"Train dataloader:{}\".format(len(train_loader)))\n",
    "print(\"Test dataloader:{}\".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepNeuralNetworkModel(\n",
       "  (linear_1): Linear(in_features=784, out_features=330, bias=True)\n",
       "  (relu_1): ELU(alpha=1.0)\n",
       "  (linear_2): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_2): Softmax(dim=0)\n",
       "  (linear_3): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_3): ELU(alpha=1.0)\n",
       "  (linear_4): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_4): ELU(alpha=1.0)\n",
       "  (linear_5): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_5): ELU(alpha=1.0)\n",
       "  (linear_6): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_6): ELU(alpha=1.0)\n",
       "  (linear_7): Linear(in_features=330, out_features=330, bias=True)\n",
       "  (relu_7): ELU(alpha=1.0)\n",
       "  (linear_out): Linear(in_features=330, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "Iteration: 10. Loss: 2.312023639678955. Accuracy: 10.413665363243465\n",
      "Iteration: 20. Loss: 2.3047196865081787. Accuracy: 9.960897303972011\n",
      "Iteration: 30. Loss: 2.297774314880371. Accuracy: 11.874871372710434\n",
      "Iteration: 40. Loss: 2.2150990962982178. Accuracy: 15.414694381559991\n",
      "Iteration: 50. Loss: 2.1761434078216553. Accuracy: 16.27906976744186\n",
      "Iteration: 60. Loss: 2.1670968532562256. Accuracy: 17.719695410578307\n",
      "Iteration: 70. Loss: 2.2044131755828857. Accuracy: 18.97509775674007\n",
      "Epoch:  2\n",
      "Iteration: 80. Loss: 2.0955827236175537. Accuracy: 22.94710845853056\n",
      "Iteration: 90. Loss: 2.1141440868377686. Accuracy: 24.223091171022844\n",
      "Iteration: 100. Loss: 2.066253185272217. Accuracy: 26.137065239761267\n",
      "Iteration: 110. Loss: 2.034071445465088. Accuracy: 26.81621732866845\n",
      "Iteration: 120. Loss: 1.9356164932250977. Accuracy: 28.133360773821774\n",
      "Iteration: 130. Loss: 1.9332070350646973. Accuracy: 30.109075941551758\n",
      "Iteration: 140. Loss: 1.768379807472229. Accuracy: 31.446799753035602\n",
      "Iteration: 150. Loss: 1.9528977870941162. Accuracy: 27.227824655278862\n",
      "Epoch:  3\n",
      "Iteration: 160. Loss: 1.8649171590805054. Accuracy: 33.1343897921383\n",
      "Iteration: 170. Loss: 1.7641305923461914. Accuracy: 36.36550730603005\n",
      "Iteration: 180. Loss: 1.706095576286316. Accuracy: 36.83885573163202\n",
      "Iteration: 190. Loss: 1.654775619506836. Accuracy: 37.764972216505456\n",
      "Iteration: 200. Loss: 1.7720232009887695. Accuracy: 38.93805309734513\n",
      "Iteration: 210. Loss: 1.6089015007019043. Accuracy: 40.35809837415106\n",
      "Iteration: 220. Loss: 1.5800062417984009. Accuracy: 40.58448240378679\n",
      "Iteration: 230. Loss: 1.643058180809021. Accuracy: 43.07470672977979\n",
      "Epoch:  4\n",
      "Iteration: 240. Loss: 1.5002861022949219. Accuracy: 39.45256225560815\n",
      "Iteration: 250. Loss: 1.5447529554367065. Accuracy: 41.201893393702406\n",
      "Iteration: 260. Loss: 1.4039602279663086. Accuracy: 42.7865816011525\n",
      "Iteration: 270. Loss: 1.3864184617996216. Accuracy: 45.317966659806544\n",
      "Iteration: 280. Loss: 1.3618723154067993. Accuracy: 46.61452973862935\n",
      "Iteration: 290. Loss: 1.4396957159042358. Accuracy: 46.161761679357895\n",
      "Iteration: 300. Loss: 1.3723653554916382. Accuracy: 46.71743157028195\n",
      "Iteration: 310. Loss: 1.5043896436691284. Accuracy: 47.437744391850174\n",
      "Epoch:  5\n",
      "Iteration: 320. Loss: 1.3745267391204834. Accuracy: 46.38814570899362\n",
      "Iteration: 330. Loss: 1.3176883459091187. Accuracy: 48.69314673801194\n",
      "Iteration: 340. Loss: 1.2246367931365967. Accuracy: 50.01029018316526\n",
      "Iteration: 350. Loss: 1.281145453453064. Accuracy: 51.18337106400494\n",
      "Iteration: 360. Loss: 1.3050440549850464. Accuracy: 51.28627289565754\n",
      "Iteration: 370. Loss: 1.3279591798782349. Accuracy: 50.60712080675036\n",
      "Iteration: 380. Loss: 1.3305518627166748. Accuracy: 51.121629965013376\n",
      "Iteration: 390. Loss: 1.2595820426940918. Accuracy: 53.01502366742128\n",
      "Epoch:  6\n",
      "Iteration: 400. Loss: 1.2278919219970703. Accuracy: 51.98600535089525\n",
      "Iteration: 410. Loss: 1.1741080284118652. Accuracy: 53.838238320642105\n",
      "Iteration: 420. Loss: 1.1043013334274292. Accuracy: 54.80551553817658\n",
      "Iteration: 430. Loss: 1.2772800922393799. Accuracy: 53.797077587981065\n",
      "Iteration: 440. Loss: 1.1538273096084595. Accuracy: 56.28730191397407\n",
      "Iteration: 450. Loss: 1.1351292133331299. Accuracy: 54.49681004321877\n",
      "Iteration: 460. Loss: 1.1733424663543701. Accuracy: 56.24614118131303\n",
      "Epoch:  7\n",
      "Iteration: 470. Loss: 1.297203540802002. Accuracy: 52.89154146943815\n",
      "Iteration: 480. Loss: 1.1164454221725464. Accuracy: 55.85511422103313\n",
      "Iteration: 490. Loss: 1.143988013267517. Accuracy: 55.56698909240585\n",
      "Iteration: 500. Loss: 1.1989766359329224. Accuracy: 57.19283803251698\n",
      "Iteration: 510. Loss: 1.0764645338058472. Accuracy: 55.54640872607533\n",
      "Iteration: 520. Loss: 1.0222039222717285. Accuracy: 58.880428071619676\n",
      "Iteration: 530. Loss: 0.9653860330581665. Accuracy: 58.242436715373536\n",
      "Iteration: 540. Loss: 1.0796122550964355. Accuracy: 57.27515949783906\n",
      "Epoch:  8\n",
      "Iteration: 550. Loss: 1.0684982538223267. Accuracy: 59.33319613089113\n",
      "Iteration: 560. Loss: 1.1249935626983643. Accuracy: 59.62132125951842\n",
      "Iteration: 570. Loss: 1.0387771129608154. Accuracy: 56.36962337929615\n",
      "Iteration: 580. Loss: 0.9848451614379883. Accuracy: 61.74109899156205\n",
      "Iteration: 590. Loss: 0.8504851460456848. Accuracy: 61.16484873430747\n",
      "Iteration: 600. Loss: 0.9111066460609436. Accuracy: 60.38279481374769\n",
      "Iteration: 610. Loss: 0.9455463886260986. Accuracy: 61.4941345955958\n",
      "Iteration: 620. Loss: 0.9587122201919556. Accuracy: 61.86458118954518\n",
      "Epoch:  9\n",
      "Iteration: 630. Loss: 1.0890727043151855. Accuracy: 61.47355422926528\n",
      "Iteration: 640. Loss: 1.0613508224487305. Accuracy: 62.97592097139329\n",
      "Iteration: 650. Loss: 0.9386826157569885. Accuracy: 60.156410784111955\n",
      "Iteration: 660. Loss: 0.9669148921966553. Accuracy: 59.66248199217946\n",
      "Iteration: 670. Loss: 0.981536328792572. Accuracy: 61.576456060917884\n",
      "Iteration: 680. Loss: 0.9522764682769775. Accuracy: 62.70837620909652\n",
      "Iteration: 690. Loss: 1.0018900632858276. Accuracy: 63.14056390203746\n",
      "Iteration: 700. Loss: 0.8918524980545044. Accuracy: 64.00493928791933\n",
      "Epoch:  10\n",
      "Iteration: 710. Loss: 0.7776798605918884. Accuracy: 64.33422514920765\n",
      "Iteration: 720. Loss: 0.8260402679443359. Accuracy: 64.6840913768265\n",
      "Iteration: 730. Loss: 0.8963145613670349. Accuracy: 65.73369005968306\n",
      "Iteration: 740. Loss: 0.747285008430481. Accuracy: 66.3716814159292\n",
      "Iteration: 750. Loss: 0.8658396005630493. Accuracy: 65.79543115867463\n",
      "Iteration: 760. Loss: 0.8788273334503174. Accuracy: 65.178020168759\n",
      "Iteration: 770. Loss: 0.9112675189971924. Accuracy: 66.04239555464088\n",
      "Iteration: 780. Loss: 1.1434712409973145. Accuracy: 66.3716814159292\n",
      "Epoch:  11\n",
      "Iteration: 790. Loss: 0.9067857265472412. Accuracy: 65.13685943609796\n",
      "Iteration: 800. Loss: 0.8111087083816528. Accuracy: 66.65980654455649\n",
      "Iteration: 810. Loss: 0.7945818901062012. Accuracy: 66.20703848528504\n",
      "Iteration: 820. Loss: 0.7976146340370178. Accuracy: 67.40069973245524\n",
      "Iteration: 830. Loss: 0.7369769215583801. Accuracy: 68.1621732866845\n",
      "Iteration: 840. Loss: 0.8447705507278442. Accuracy: 67.89462852438773\n",
      "Iteration: 850. Loss: 0.7762812376022339. Accuracy: 66.24819921794608\n",
      "Epoch:  12\n",
      "Iteration: 860. Loss: 0.7594589591026306. Accuracy: 67.9563696233793\n",
      "Iteration: 870. Loss: 0.6684272289276123. Accuracy: 66.14529738629348\n",
      "Iteration: 880. Loss: 0.8947857618331909. Accuracy: 68.656102078617\n",
      "Iteration: 890. Loss: 0.9302622079849243. Accuracy: 65.19860053508953\n",
      "Iteration: 900. Loss: 0.7626451849937439. Accuracy: 69.21177196954106\n",
      "Iteration: 910. Loss: 0.7434272170066833. Accuracy: 68.34739658365919\n",
      "Iteration: 920. Loss: 0.8012635707855225. Accuracy: 69.12945050421898\n",
      "Iteration: 930. Loss: 0.8804606795310974. Accuracy: 70.09672772175345\n",
      "Epoch:  13\n",
      "Iteration: 940. Loss: 0.6490767598152161. Accuracy: 69.72628112780407\n",
      "Iteration: 950. Loss: 0.6987957954406738. Accuracy: 70.77587981066063\n",
      "Iteration: 960. Loss: 0.6700429320335388. Accuracy: 71.18748713727105\n",
      "Iteration: 970. Loss: 0.7248603701591492. Accuracy: 70.28195101872814\n",
      "Iteration: 980. Loss: 0.8071635961532593. Accuracy: 70.40543321671126\n",
      "Iteration: 990. Loss: 0.661085307598114. Accuracy: 71.10516567194897\n",
      "Iteration: 1000. Loss: 0.7175834774971008. Accuracy: 72.15476435480552\n",
      "Iteration: 1010. Loss: 0.6942732930183411. Accuracy: 72.09302325581395\n",
      "Epoch:  14\n",
      "Iteration: 1020. Loss: 0.7147907018661499. Accuracy: 70.38485285038074\n",
      "Iteration: 1030. Loss: 0.7656784653663635. Accuracy: 72.17534472113604\n",
      "Iteration: 1040. Loss: 0.5966864824295044. Accuracy: 71.9489606915003\n",
      "Iteration: 1050. Loss: 0.6478719711303711. Accuracy: 69.54105783082939\n",
      "Iteration: 1060. Loss: 0.6632673740386963. Accuracy: 68.28565548466763\n",
      "Iteration: 1070. Loss: 0.6875508427619934. Accuracy: 71.9489606915003\n",
      "Iteration: 1080. Loss: 0.705971360206604. Accuracy: 72.09302325581395\n",
      "Iteration: 1090. Loss: 0.7500264048576355. Accuracy: 72.75159497839061\n",
      "Epoch:  15\n",
      "Iteration: 1100. Loss: 0.6306061148643494. Accuracy: 71.47561226589833\n",
      "Iteration: 1110. Loss: 0.6967757344245911. Accuracy: 73.98641695822185\n",
      "Iteration: 1120. Loss: 0.6372684836387634. Accuracy: 74.60382794813748\n",
      "Iteration: 1130. Loss: 0.6742116808891296. Accuracy: 72.95739864169582\n",
      "Iteration: 1140. Loss: 0.6064385771751404. Accuracy: 73.84235439390821\n",
      "Iteration: 1150. Loss: 0.5126871466636658. Accuracy: 74.08931878987445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1160. Loss: 0.6340683698654175. Accuracy: 75.48878370034987\n",
      "Iteration: 1170. Loss: 0.597608745098114. Accuracy: 73.41016670096728\n",
      "Epoch:  16\n",
      "Iteration: 1180. Loss: 0.5560312271118164. Accuracy: 74.54208684914592\n",
      "Iteration: 1190. Loss: 0.5934350490570068. Accuracy: 74.37744391850175\n",
      "Iteration: 1200. Loss: 0.4773763418197632. Accuracy: 74.68614941345956\n",
      "Iteration: 1210. Loss: 0.6555861234664917. Accuracy: 75.01543527474789\n",
      "Iteration: 1220. Loss: 0.51692134141922. Accuracy: 75.7151677299856\n",
      "Iteration: 1230. Loss: 0.5113083720207214. Accuracy: 75.09775674006997\n",
      "Iteration: 1240. Loss: 0.5914056301116943. Accuracy: 73.71887219592509\n",
      "Epoch:  17\n",
      "Iteration: 1250. Loss: 0.4391714334487915. Accuracy: 75.94155175962132\n",
      "Iteration: 1260. Loss: 0.6076355576515198. Accuracy: 75.48878370034987\n",
      "Iteration: 1270. Loss: 0.5527290105819702. Accuracy: 75.63284626466351\n",
      "Iteration: 1280. Loss: 0.532680094242096. Accuracy: 74.56266721547644\n",
      "Iteration: 1290. Loss: 0.4323222041130066. Accuracy: 74.19222062152706\n",
      "Iteration: 1300. Loss: 0.5286645889282227. Accuracy: 75.3241407697057\n",
      "Iteration: 1310. Loss: 0.7104276418685913. Accuracy: 75.65342663099403\n",
      "Iteration: 1320. Loss: 0.45466315746307373. Accuracy: 76.0238732249434\n",
      "Epoch:  18\n",
      "Iteration: 1330. Loss: 0.6140844821929932. Accuracy: 75.75632846264664\n",
      "Iteration: 1340. Loss: 0.5922932624816895. Accuracy: 75.11833710640049\n",
      "Iteration: 1350. Loss: 0.5823835730552673. Accuracy: 75.03601564107841\n",
      "Iteration: 1360. Loss: 0.4733878970146179. Accuracy: 76.43548055155382\n",
      "Iteration: 1370. Loss: 0.550580620765686. Accuracy: 75.98271249228236\n",
      "Iteration: 1380. Loss: 0.40781068801879883. Accuracy: 76.99115044247787\n",
      "Iteration: 1390. Loss: 0.5501306653022766. Accuracy: 76.47664128421486\n",
      "Iteration: 1400. Loss: 0.45796704292297363. Accuracy: 75.63284626466351\n",
      "Epoch:  19\n",
      "Iteration: 1410. Loss: 0.47022154927253723. Accuracy: 77.19695410578308\n",
      "Iteration: 1420. Loss: 0.5304713845252991. Accuracy: 77.42333813541882\n",
      "Iteration: 1430. Loss: 0.36002317070961. Accuracy: 76.86766824449475\n",
      "Iteration: 1440. Loss: 0.4614322781562805. Accuracy: 77.15579337312204\n",
      "Iteration: 1450. Loss: 0.33928021788597107. Accuracy: 77.77320436303766\n",
      "Iteration: 1460. Loss: 0.48708805441856384. Accuracy: 76.94998970981683\n",
      "Iteration: 1470. Loss: 0.4840371608734131. Accuracy: 76.74418604651163\n",
      "Iteration: 1480. Loss: 0.5282121300697327. Accuracy: 76.70302531385059\n",
      "Epoch:  20\n",
      "Iteration: 1490. Loss: 0.3456931710243225. Accuracy: 76.04445359127392\n",
      "Iteration: 1500. Loss: 0.46128666400909424. Accuracy: 76.126775056596\n",
      "Iteration: 1510. Loss: 0.5436171889305115. Accuracy: 77.23811483844412\n",
      "Iteration: 1520. Loss: 0.5383365154266357. Accuracy: 77.13521300679152\n",
      "Iteration: 1530. Loss: 0.46645715832710266. Accuracy: 78.22597242230911\n",
      "Iteration: 1540. Loss: 0.43136608600616455. Accuracy: 77.9172669273513\n",
      "Iteration: 1550. Loss: 0.40454891324043274. Accuracy: 76.53838238320643\n",
      "Iteration: 1560. Loss: 0.6134588718414307. Accuracy: 77.69088289771558\n",
      "Epoch:  21\n",
      "Iteration: 1570. Loss: 0.4237425923347473. Accuracy: 77.73204363037662\n",
      "Iteration: 1580. Loss: 0.3675873577594757. Accuracy: 76.84708787816423\n",
      "Iteration: 1590. Loss: 0.4354160726070404. Accuracy: 76.82650751183371\n",
      "Iteration: 1600. Loss: 0.4441975951194763. Accuracy: 77.52623996707142\n",
      "Iteration: 1610. Loss: 0.45168226957321167. Accuracy: 78.02016875900391\n",
      "Iteration: 1620. Loss: 0.46713006496429443. Accuracy: 76.97057007614735\n",
      "Iteration: 1630. Loss: 0.5270847082138062. Accuracy: 77.87610619469027\n",
      "Epoch:  22\n",
      "Iteration: 1640. Loss: 0.40524813532829285. Accuracy: 77.5056596007409\n",
      "Iteration: 1650. Loss: 0.43790727853775024. Accuracy: 78.6993208479111\n",
      "Iteration: 1660. Loss: 0.35765281319618225. Accuracy: 78.51409755093641\n",
      "Iteration: 1670. Loss: 0.5832330584526062. Accuracy: 78.37003498662276\n",
      "Iteration: 1680. Loss: 0.3927149772644043. Accuracy: 77.3204363037662\n",
      "Iteration: 1690. Loss: 0.3898867070674896. Accuracy: 79.31673183782671\n",
      "Iteration: 1700. Loss: 0.3280008137226105. Accuracy: 78.74048158057214\n",
      "Iteration: 1710. Loss: 0.4273308515548706. Accuracy: 79.41963366947931\n",
      "Epoch:  23\n",
      "Iteration: 1720. Loss: 0.3955565094947815. Accuracy: 78.26713315497015\n",
      "Iteration: 1730. Loss: 0.32273340225219727. Accuracy: 78.65816011525006\n",
      "Iteration: 1740. Loss: 0.44999152421951294. Accuracy: 78.88454414488578\n",
      "Iteration: 1750. Loss: 0.3138526976108551. Accuracy: 78.57583864992797\n",
      "Iteration: 1760. Loss: 0.5789594054222107. Accuracy: 78.43177608561433\n",
      "Iteration: 1770. Loss: 0.46355724334716797. Accuracy: 76.27083762090965\n",
      "Iteration: 1780. Loss: 0.4637807607650757. Accuracy: 79.0080263428689\n",
      "Iteration: 1790. Loss: 0.29835864901542664. Accuracy: 78.71990121424162\n",
      "Epoch:  24\n",
      "Iteration: 1800. Loss: 0.38307157158851624. Accuracy: 77.97900802634287\n",
      "Iteration: 1810. Loss: 0.3631981313228607. Accuracy: 78.88454414488578\n",
      "Iteration: 1820. Loss: 0.500474214553833. Accuracy: 77.79378472936818\n",
      "Iteration: 1830. Loss: 0.4196065664291382. Accuracy: 79.13150854085202\n",
      "Iteration: 1840. Loss: 0.266575425863266. Accuracy: 77.75262399670714\n",
      "Iteration: 1850. Loss: 0.33523938059806824. Accuracy: 77.58798106606298\n",
      "Iteration: 1860. Loss: 0.4304487109184265. Accuracy: 78.9051245112163\n",
      "Iteration: 1870. Loss: 0.5147307515144348. Accuracy: 79.74891953076765\n",
      "Epoch:  25\n",
      "Iteration: 1880. Loss: 0.39126402139663696. Accuracy: 79.74891953076765\n",
      "Iteration: 1890. Loss: 0.3767946660518646. Accuracy: 78.6993208479111\n",
      "Iteration: 1900. Loss: 0.33939844369888306. Accuracy: 78.82280304589422\n",
      "Iteration: 1910. Loss: 0.35902640223503113. Accuracy: 78.86396377855526\n",
      "Iteration: 1920. Loss: 0.3167511224746704. Accuracy: 77.42333813541882\n",
      "Iteration: 1930. Loss: 0.35285893082618713. Accuracy: 78.92570487754682\n",
      "Iteration: 1940. Loss: 0.3328048288822174. Accuracy: 79.58427660012349\n",
      "Iteration: 1950. Loss: 0.395769864320755. Accuracy: 79.13150854085202\n",
      "Epoch:  26\n",
      "Iteration: 1960. Loss: 0.30693212151527405. Accuracy: 78.96686561020786\n",
      "Iteration: 1970. Loss: 0.40121859312057495. Accuracy: 79.37847293681827\n",
      "Iteration: 1980. Loss: 0.3463606834411621. Accuracy: 79.56369623379297\n",
      "Iteration: 1990. Loss: 0.23356319963932037. Accuracy: 80.01646429306442\n",
      "Iteration: 2000. Loss: 0.29006344079971313. Accuracy: 78.34945462029224\n",
      "Iteration: 2010. Loss: 0.2910420000553131. Accuracy: 78.76106194690266\n",
      "Iteration: 2020. Loss: 0.35182639956474304. Accuracy: 78.20539205597859\n",
      "Epoch:  27\n",
      "Iteration: 2030. Loss: 0.40095409750938416. Accuracy: 79.25499073883515\n",
      "Iteration: 2040. Loss: 0.2944038510322571. Accuracy: 80.03704465939494\n",
      "Iteration: 2050. Loss: 0.3133126497268677. Accuracy: 79.72833916443713\n",
      "Iteration: 2060. Loss: 0.3963930308818817. Accuracy: 80.18110722370858\n",
      "Iteration: 2070. Loss: 0.3146336078643799. Accuracy: 79.81066062975921\n",
      "Iteration: 2080. Loss: 0.33634063601493835. Accuracy: 79.27557110516567\n",
      "Iteration: 2090. Loss: 0.376587837934494. Accuracy: 79.15208890718255\n",
      "Iteration: 2100. Loss: 0.42981603741645813. Accuracy: 79.60485696645401\n",
      "Epoch:  28\n",
      "Iteration: 2110. Loss: 0.3651411533355713. Accuracy: 79.44021403580983\n",
      "Iteration: 2120. Loss: 0.38946622610092163. Accuracy: 79.85182136242025\n",
      "Iteration: 2130. Loss: 0.3491666913032532. Accuracy: 79.0080263428689\n",
      "Iteration: 2140. Loss: 0.2253032922744751. Accuracy: 80.61329491664952\n",
      "Iteration: 2150. Loss: 0.238033264875412. Accuracy: 78.78164231323318\n",
      "Iteration: 2160. Loss: 0.34786108136177063. Accuracy: 78.98744597653838\n",
      "Iteration: 2170. Loss: 0.3081533908843994. Accuracy: 79.31673183782671\n",
      "Iteration: 2180. Loss: 0.33333688974380493. Accuracy: 79.19324963984359\n",
      "Epoch:  29\n",
      "Iteration: 2190. Loss: 0.3279162049293518. Accuracy: 79.33731220415723\n",
      "Iteration: 2200. Loss: 0.1816500574350357. Accuracy: 79.9958839267339\n",
      "Iteration: 2210. Loss: 0.2696303129196167. Accuracy: 79.23441037250463\n",
      "Iteration: 2220. Loss: 0.3105871379375458. Accuracy: 79.97530356040338\n",
      "Iteration: 2230. Loss: 0.2908099889755249. Accuracy: 79.39905330314879\n",
      "Iteration: 2240. Loss: 0.30062007904052734. Accuracy: 80.592714550319\n",
      "Iteration: 2250. Loss: 0.213058739900589. Accuracy: 79.29615147149619\n",
      "Iteration: 2260. Loss: 0.34411028027534485. Accuracy: 79.54311586746245\n",
      "Epoch:  30\n",
      "Iteration: 2270. Loss: 0.2919226586818695. Accuracy: 79.0080263428689\n",
      "Iteration: 2280. Loss: 0.22214315831661224. Accuracy: 79.60485696645401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2290. Loss: 0.3798162639141083. Accuracy: 79.83124099608973\n",
      "Iteration: 2300. Loss: 0.30071789026260376. Accuracy: 80.2016875900391\n",
      "Iteration: 2310. Loss: 0.2197769731283188. Accuracy: 79.56369623379297\n",
      "Iteration: 2320. Loss: 0.3644135594367981. Accuracy: 79.70775879810661\n",
      "Iteration: 2330. Loss: 0.24366606771945953. Accuracy: 79.48137476847089\n",
      "Iteration: 2340. Loss: 0.3114723563194275. Accuracy: 79.23441037250463\n",
      "Epoch:  31\n",
      "Iteration: 2350. Loss: 0.16131819784641266. Accuracy: 79.70775879810661\n",
      "Iteration: 2360. Loss: 0.34733477234840393. Accuracy: 79.56369623379297\n",
      "Iteration: 2370. Loss: 0.2804253101348877. Accuracy: 80.6956163819716\n",
      "Iteration: 2380. Loss: 0.2357075959444046. Accuracy: 80.55155381765796\n",
      "Iteration: 2390. Loss: 0.3153219521045685. Accuracy: 80.03704465939494\n",
      "Iteration: 2400. Loss: 0.3698221445083618. Accuracy: 79.19324963984359\n",
      "Iteration: 2410. Loss: 0.315632700920105. Accuracy: 80.07820539205598\n",
      "Epoch:  32\n",
      "Iteration: 2420. Loss: 0.30775147676467896. Accuracy: 79.60485696645401\n",
      "Iteration: 2430. Loss: 0.21607035398483276. Accuracy: 80.46923235233587\n",
      "Iteration: 2440. Loss: 0.2362348884344101. Accuracy: 79.85182136242025\n",
      "Iteration: 2450. Loss: 0.2557360529899597. Accuracy: 80.55155381765796\n",
      "Iteration: 2460. Loss: 0.17516370117664337. Accuracy: 81.8892776291418\n",
      "Iteration: 2470. Loss: 0.2452557384967804. Accuracy: 80.96316114426837\n",
      "Iteration: 2480. Loss: 0.21508097648620605. Accuracy: 80.11936612471702\n",
      "Iteration: 2490. Loss: 0.26798322796821594. Accuracy: 80.73677711463264\n",
      "Epoch:  33\n",
      "Iteration: 2500. Loss: 0.3475639224052429. Accuracy: 80.55155381765796\n",
      "Iteration: 2510. Loss: 0.19063925743103027. Accuracy: 79.97530356040338\n",
      "Iteration: 2520. Loss: 0.2470475733280182. Accuracy: 79.33731220415723\n",
      "Iteration: 2530. Loss: 0.2184019237756729. Accuracy: 79.13150854085202\n",
      "Iteration: 2540. Loss: 0.2700636386871338. Accuracy: 79.62543733278453\n",
      "Iteration: 2550. Loss: 0.24884182214736938. Accuracy: 80.03704465939494\n",
      "Iteration: 2560. Loss: 0.2173055112361908. Accuracy: 80.90142004527681\n",
      "Iteration: 2570. Loss: 0.26694294810295105. Accuracy: 79.93414282774233\n",
      "Epoch:  34\n",
      "Iteration: 2580. Loss: 0.16042372584342957. Accuracy: 80.5103930849969\n",
      "Iteration: 2590. Loss: 0.28774553537368774. Accuracy: 80.5103930849969\n",
      "Iteration: 2600. Loss: 0.18336623907089233. Accuracy: 79.81066062975921\n",
      "Iteration: 2610. Loss: 0.2069472074508667. Accuracy: 79.76949989709817\n",
      "Iteration: 2620. Loss: 0.20428629219532013. Accuracy: 79.64601769911505\n",
      "Iteration: 2630. Loss: 0.23048672080039978. Accuracy: 80.65445564931056\n",
      "Iteration: 2640. Loss: 0.2808552384376526. Accuracy: 80.03704465939494\n",
      "Iteration: 2650. Loss: 0.2842256426811218. Accuracy: 79.97530356040338\n",
      "Epoch:  35\n",
      "Iteration: 2660. Loss: 0.27256327867507935. Accuracy: 80.01646429306442\n",
      "Iteration: 2670. Loss: 0.22656989097595215. Accuracy: 80.53097345132744\n",
      "Iteration: 2680. Loss: 0.17214295268058777. Accuracy: 80.7985182136242\n",
      "Iteration: 2690. Loss: 0.20021481812000275. Accuracy: 80.11936612471702\n",
      "Iteration: 2700. Loss: 0.3120724856853485. Accuracy: 80.94258077793785\n",
      "Iteration: 2710. Loss: 0.2085454910993576. Accuracy: 80.0987857583865\n",
      "Iteration: 2720. Loss: 0.24081973731517792. Accuracy: 80.01646429306442\n",
      "Iteration: 2730. Loss: 0.18610846996307373. Accuracy: 80.2016875900391\n",
      "Epoch:  36\n",
      "Iteration: 2740. Loss: 0.20516237616539001. Accuracy: 80.592714550319\n",
      "Iteration: 2750. Loss: 0.2408749908208847. Accuracy: 81.16896480757357\n",
      "Iteration: 2760. Loss: 0.12036427110433578. Accuracy: 81.31302737188722\n",
      "Iteration: 2770. Loss: 0.27347156405448914. Accuracy: 79.37847293681827\n",
      "Iteration: 2780. Loss: 0.31803613901138306. Accuracy: 79.52253550113193\n",
      "Iteration: 2790. Loss: 0.2906302213668823. Accuracy: 80.34575015435274\n",
      "Iteration: 2800. Loss: 0.15072865784168243. Accuracy: 80.26342868903066\n",
      "Epoch:  37\n",
      "Iteration: 2810. Loss: 0.21890054643154144. Accuracy: 79.23441037250463\n",
      "Iteration: 2820. Loss: 0.28930702805519104. Accuracy: 80.16052685737806\n",
      "Iteration: 2830. Loss: 0.15754558145999908. Accuracy: 80.11936612471702\n",
      "Iteration: 2840. Loss: 0.2588638365268707. Accuracy: 80.61329491664952\n",
      "Iteration: 2850. Loss: 0.17992958426475525. Accuracy: 80.77793784729369\n",
      "Iteration: 2860. Loss: 0.2177722454071045. Accuracy: 80.26342868903066\n",
      "Iteration: 2870. Loss: 0.2706494629383087. Accuracy: 79.58427660012349\n",
      "Iteration: 2880. Loss: 0.2516925036907196. Accuracy: 80.65445564931056\n",
      "Epoch:  38\n",
      "Iteration: 2890. Loss: 0.16386187076568604. Accuracy: 81.06606297592097\n",
      "Iteration: 2900. Loss: 0.23185430467128754. Accuracy: 80.73677711463264\n",
      "Iteration: 2910. Loss: 0.11725810915231705. Accuracy: 80.75735748096317\n",
      "Iteration: 2920. Loss: 0.17435848712921143. Accuracy: 81.10722370858201\n",
      "Iteration: 2930. Loss: 0.24512812495231628. Accuracy: 80.6956163819716\n",
      "Iteration: 2940. Loss: 0.18722683191299438. Accuracy: 80.96316114426837\n",
      "Iteration: 2950. Loss: 0.2549685537815094. Accuracy: 80.55155381765796\n",
      "Iteration: 2960. Loss: 0.23634538054466248. Accuracy: 80.36633052068326\n",
      "Epoch:  39\n",
      "Iteration: 2970. Loss: 0.21220993995666504. Accuracy: 79.66659806544557\n",
      "Iteration: 2980. Loss: 0.1793270707130432. Accuracy: 80.24284832270014\n",
      "Iteration: 2990. Loss: 0.18839454650878906. Accuracy: 80.5103930849969\n",
      "Iteration: 3000. Loss: 0.14518319070339203. Accuracy: 80.83967894628525\n",
      "Iteration: 3010. Loss: 0.19558373093605042. Accuracy: 81.02490224325993\n",
      "Iteration: 3020. Loss: 0.22418352961540222. Accuracy: 81.47767030253138\n",
      "Iteration: 3030. Loss: 0.2755303680896759. Accuracy: 81.7863757974892\n",
      "Iteration: 3040. Loss: 0.23627451062202454. Accuracy: 82.03334019345544\n",
      "Epoch:  40\n",
      "Iteration: 3050. Loss: 0.1327621042728424. Accuracy: 80.2016875900391\n",
      "Iteration: 3060. Loss: 0.20470209419727325. Accuracy: 81.10722370858201\n",
      "Iteration: 3070. Loss: 0.21606309711933136. Accuracy: 80.81909857995473\n",
      "Iteration: 3080. Loss: 0.16252818703651428. Accuracy: 80.6956163819716\n",
      "Iteration: 3090. Loss: 0.15360626578330994. Accuracy: 81.43650956987034\n",
      "Iteration: 3100. Loss: 0.16780537366867065. Accuracy: 81.00432187692941\n",
      "Iteration: 3110. Loss: 0.21644175052642822. Accuracy: 81.70405433216712\n",
      "Iteration: 3120. Loss: 0.16070204973220825. Accuracy: 81.45708993620086\n",
      "Epoch:  41\n",
      "Iteration: 3130. Loss: 0.19788220524787903. Accuracy: 81.33360773821774\n",
      "Iteration: 3140. Loss: 0.26500800251960754. Accuracy: 81.10722370858201\n",
      "Iteration: 3150. Loss: 0.19202855229377747. Accuracy: 81.00432187692941\n",
      "Iteration: 3160. Loss: 0.20673494040966034. Accuracy: 79.41963366947931\n",
      "Iteration: 3170. Loss: 0.27880528569221497. Accuracy: 80.48981271866639\n",
      "Iteration: 3180. Loss: 0.18825319409370422. Accuracy: 81.33360773821774\n",
      "Iteration: 3190. Loss: 0.24225156009197235. Accuracy: 80.53097345132744\n",
      "Epoch:  42\n",
      "Iteration: 3200. Loss: 0.1645900160074234. Accuracy: 81.31302737188722\n",
      "Iteration: 3210. Loss: 0.16473031044006348. Accuracy: 81.80695616381972\n",
      "Iteration: 3220. Loss: 0.2180250883102417. Accuracy: 81.23070590656513\n",
      "Iteration: 3230. Loss: 0.23176971077919006. Accuracy: 81.72463469849764\n",
      "Iteration: 3240. Loss: 0.1291390359401703. Accuracy: 81.70405433216712\n",
      "Iteration: 3250. Loss: 0.19243252277374268. Accuracy: 81.04548260959045\n",
      "Iteration: 3260. Loss: 0.25637388229370117. Accuracy: 81.6834739658366\n",
      "Iteration: 3270. Loss: 0.21459844708442688. Accuracy: 80.94258077793785\n",
      "Epoch:  43\n",
      "Iteration: 3280. Loss: 0.17825168371200562. Accuracy: 80.44865198600534\n",
      "Iteration: 3290. Loss: 0.15908603370189667. Accuracy: 80.73677711463264\n",
      "Iteration: 3300. Loss: 0.19768661260604858. Accuracy: 80.592714550319\n",
      "Iteration: 3310. Loss: 0.1818762868642807. Accuracy: 80.57213418398848\n",
      "Iteration: 3320. Loss: 0.1502142995595932. Accuracy: 81.35418810454826\n",
      "Iteration: 3330. Loss: 0.1406242996454239. Accuracy: 81.55999176785346\n",
      "Iteration: 3340. Loss: 0.18621905148029327. Accuracy: 79.79008026342869\n",
      "Iteration: 3350. Loss: 0.16625748574733734. Accuracy: 79.8929820950813\n",
      "Epoch:  44\n",
      "Iteration: 3360. Loss: 0.15076853334903717. Accuracy: 81.64231323317556\n",
      "Iteration: 3370. Loss: 0.17025317251682281. Accuracy: 81.27186663922618\n",
      "Iteration: 3380. Loss: 0.15440461039543152. Accuracy: 80.07820539205598\n",
      "Iteration: 3390. Loss: 0.17709752917289734. Accuracy: 80.34575015435274\n",
      "Iteration: 3400. Loss: 0.17648889124393463. Accuracy: 80.73677711463264\n",
      "Iteration: 3410. Loss: 0.2035236805677414. Accuracy: 79.9958839267339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3420. Loss: 0.17623703181743622. Accuracy: 80.48981271866639\n",
      "Iteration: 3430. Loss: 0.1687319278717041. Accuracy: 80.98374151059889\n",
      "Epoch:  45\n",
      "Iteration: 3440. Loss: 0.10873907059431076. Accuracy: 81.4982506688619\n",
      "Iteration: 3450. Loss: 0.09320056438446045. Accuracy: 81.6834739658366\n",
      "Iteration: 3460. Loss: 0.1470012366771698. Accuracy: 81.55999176785346\n",
      "Iteration: 3470. Loss: 0.3120656907558441. Accuracy: 81.12780407491253\n",
      "Iteration: 3480. Loss: 0.15091350674629211. Accuracy: 80.88083967894629\n",
      "Iteration: 3490. Loss: 0.12298097461462021. Accuracy: 81.580572134184\n",
      "Iteration: 3500. Loss: 0.15412724018096924. Accuracy: 81.84811689648076\n",
      "Iteration: 3510. Loss: 0.23917746543884277. Accuracy: 81.76579543115868\n",
      "Epoch:  46\n",
      "Iteration: 3520. Loss: 0.1965971738100052. Accuracy: 82.32146532208273\n",
      "Iteration: 3530. Loss: 0.1666354537010193. Accuracy: 80.96316114426837\n",
      "Iteration: 3540. Loss: 0.13744297623634338. Accuracy: 81.3953488372093\n",
      "Iteration: 3550. Loss: 0.13663579523563385. Accuracy: 80.94258077793785\n",
      "Iteration: 3560. Loss: 0.21143130958080292. Accuracy: 81.45708993620086\n",
      "Iteration: 3570. Loss: 0.1536039561033249. Accuracy: 80.01646429306442\n",
      "Iteration: 3580. Loss: 0.12284770607948303. Accuracy: 82.17740275776909\n",
      "Epoch:  47\n",
      "Iteration: 3590. Loss: 0.1715995967388153. Accuracy: 81.580572134184\n",
      "Iteration: 3600. Loss: 0.08617192506790161. Accuracy: 82.36262605474377\n",
      "Iteration: 3610. Loss: 0.2089596837759018. Accuracy: 82.44494752006585\n",
      "Iteration: 3620. Loss: 0.06999780237674713. Accuracy: 81.3953488372093\n",
      "Iteration: 3630. Loss: 0.23299303650856018. Accuracy: 81.60115250051452\n",
      "Iteration: 3640. Loss: 0.18221589922904968. Accuracy: 81.7863757974892\n",
      "Iteration: 3650. Loss: 0.16326478123664856. Accuracy: 81.8892776291418\n",
      "Iteration: 3660. Loss: 0.18951189517974854. Accuracy: 82.23914385676065\n",
      "Epoch:  48\n",
      "Iteration: 3670. Loss: 0.07609175145626068. Accuracy: 81.82753653015024\n",
      "Iteration: 3680. Loss: 0.10621599107980728. Accuracy: 82.44494752006585\n",
      "Iteration: 3690. Loss: 0.11632153391838074. Accuracy: 80.90142004527681\n",
      "Iteration: 3700. Loss: 0.14812146127223969. Accuracy: 79.8929820950813\n",
      "Iteration: 3710. Loss: 0.17876863479614258. Accuracy: 80.92200041160733\n",
      "Iteration: 3720. Loss: 0.14890669286251068. Accuracy: 80.63387528298004\n",
      "Iteration: 3730. Loss: 0.18001094460487366. Accuracy: 81.33360773821774\n",
      "Iteration: 3740. Loss: 0.22950980067253113. Accuracy: 81.4982506688619\n",
      "Epoch:  49\n",
      "Iteration: 3750. Loss: 0.1654190868139267. Accuracy: 81.45708993620086\n",
      "Iteration: 3760. Loss: 0.15530118346214294. Accuracy: 81.27186663922618\n",
      "Iteration: 3770. Loss: 0.09377148747444153. Accuracy: 80.90142004527681\n",
      "Iteration: 3780. Loss: 0.2000948041677475. Accuracy: 81.06606297592097\n",
      "Iteration: 3790. Loss: 0.1654258817434311. Accuracy: 81.60115250051452\n",
      "Iteration: 3800. Loss: 0.1622188240289688. Accuracy: 80.24284832270014\n",
      "Iteration: 3810. Loss: 0.12989163398742676. Accuracy: 79.95472319407286\n",
      "Iteration: 3820. Loss: 0.10515693575143814. Accuracy: 79.70775879810661\n",
      "Epoch:  50\n",
      "Iteration: 3830. Loss: 0.1199469044804573. Accuracy: 81.31302737188722\n",
      "Iteration: 3840. Loss: 0.11261529475450516. Accuracy: 81.70405433216712\n",
      "Iteration: 3850. Loss: 0.11983044445514679. Accuracy: 81.84811689648076\n",
      "Iteration: 3860. Loss: 0.11913183331489563. Accuracy: 81.93043836180284\n",
      "Iteration: 3870. Loss: 0.10671945661306381. Accuracy: 81.84811689648076\n",
      "Iteration: 3880. Loss: 0.13159675896167755. Accuracy: 81.16896480757357\n",
      "Iteration: 3890. Loss: 0.16596218943595886. Accuracy: 81.6834739658366\n",
      "Iteration: 3900. Loss: 0.4292563498020172. Accuracy: 81.84811689648076\n",
      "Epoch:  51\n",
      "Iteration: 3910. Loss: 0.2626686990261078. Accuracy: 80.34575015435274\n",
      "Iteration: 3920. Loss: 0.173068568110466. Accuracy: 80.61329491664952\n",
      "Iteration: 3930. Loss: 0.10286755114793777. Accuracy: 80.63387528298004\n",
      "Iteration: 3940. Loss: 0.15717019140720367. Accuracy: 81.64231323317556\n",
      "Iteration: 3950. Loss: 0.10488881170749664. Accuracy: 81.62173286684504\n",
      "Iteration: 3960. Loss: 0.127994567155838. Accuracy: 81.72463469849764\n",
      "Iteration: 3970. Loss: 0.17461396753787994. Accuracy: 81.70405433216712\n",
      "Epoch:  52\n",
      "Iteration: 3980. Loss: 0.0876879021525383. Accuracy: 81.80695616381972\n",
      "Iteration: 3990. Loss: 0.11287770420312881. Accuracy: 81.97159909446388\n",
      "Iteration: 4000. Loss: 0.12725356221199036. Accuracy: 82.65075118337107\n",
      "Iteration: 4010. Loss: 0.14295047521591187. Accuracy: 81.95101872813336\n",
      "Iteration: 4020. Loss: 0.12539705634117126. Accuracy: 81.23070590656513\n",
      "Iteration: 4030. Loss: 0.15681862831115723. Accuracy: 81.93043836180284\n",
      "Iteration: 4040. Loss: 0.10993345826864243. Accuracy: 81.86869726281128\n",
      "Iteration: 4050. Loss: 0.1650969237089157. Accuracy: 81.31302737188722\n",
      "Epoch:  53\n",
      "Iteration: 4060. Loss: 0.13191674649715424. Accuracy: 81.45708993620086\n",
      "Iteration: 4070. Loss: 0.15031418204307556. Accuracy: 81.08664334225149\n",
      "Iteration: 4080. Loss: 0.1872445046901703. Accuracy: 81.90985799547232\n",
      "Iteration: 4090. Loss: 0.15140840411186218. Accuracy: 81.72463469849764\n",
      "Iteration: 4100. Loss: 0.14426346123218536. Accuracy: 81.51883103519242\n",
      "Iteration: 4110. Loss: 0.1730637401342392. Accuracy: 81.90985799547232\n",
      "Iteration: 4120. Loss: 0.10346829146146774. Accuracy: 81.97159909446388\n",
      "Iteration: 4130. Loss: 0.1815551519393921. Accuracy: 82.19798312409961\n",
      "Epoch:  54\n",
      "Iteration: 4140. Loss: 0.11911515891551971. Accuracy: 82.28030458942169\n",
      "Iteration: 4150. Loss: 0.06689903885126114. Accuracy: 81.93043836180284\n",
      "Iteration: 4160. Loss: 0.04303491860628128. Accuracy: 82.23914385676065\n",
      "Iteration: 4170. Loss: 0.08818406611680984. Accuracy: 81.82753653015024\n",
      "Iteration: 4180. Loss: 0.055716197937726974. Accuracy: 81.14838444124305\n",
      "Iteration: 4190. Loss: 0.11658371984958649. Accuracy: 81.47767030253138\n",
      "Iteration: 4200. Loss: 0.10637857019901276. Accuracy: 82.17740275776909\n",
      "Iteration: 4210. Loss: 0.14455646276474. Accuracy: 80.98374151059889\n",
      "Epoch:  55\n",
      "Iteration: 4220. Loss: 0.07681713998317719. Accuracy: 82.01275982712492\n",
      "Iteration: 4230. Loss: 0.05719413608312607. Accuracy: 81.74521506482816\n",
      "Iteration: 4240. Loss: 0.1140807569026947. Accuracy: 82.07450092611649\n",
      "Iteration: 4250. Loss: 0.09328044205904007. Accuracy: 81.8892776291418\n",
      "Iteration: 4260. Loss: 0.11594033241271973. Accuracy: 81.74521506482816\n",
      "Iteration: 4270. Loss: 0.175541952252388. Accuracy: 81.35418810454826\n",
      "Iteration: 4280. Loss: 0.1859738975763321. Accuracy: 82.03334019345544\n",
      "Iteration: 4290. Loss: 0.28823739290237427. Accuracy: 81.580572134184\n",
      "Epoch:  56\n",
      "Iteration: 4300. Loss: 0.07105857133865356. Accuracy: 80.61329491664952\n",
      "Iteration: 4310. Loss: 0.16751278936862946. Accuracy: 81.51883103519242\n",
      "Iteration: 4320. Loss: 0.1893828958272934. Accuracy: 81.64231323317556\n",
      "Iteration: 4330. Loss: 0.10766805708408356. Accuracy: 81.27186663922618\n",
      "Iteration: 4340. Loss: 0.12423599511384964. Accuracy: 81.66289359950608\n",
      "Iteration: 4350. Loss: 0.07357286661863327. Accuracy: 81.53941140152294\n",
      "Iteration: 4360. Loss: 0.1354377269744873. Accuracy: 81.8892776291418\n",
      "Epoch:  57\n",
      "Iteration: 4370. Loss: 0.1366584151983261. Accuracy: 81.4982506688619\n",
      "Iteration: 4380. Loss: 0.1483420580625534. Accuracy: 81.31302737188722\n",
      "Iteration: 4390. Loss: 0.07613222301006317. Accuracy: 80.71619674830212\n",
      "Iteration: 4400. Loss: 0.1512017399072647. Accuracy: 81.76579543115868\n",
      "Iteration: 4410. Loss: 0.12645921111106873. Accuracy: 81.10722370858201\n",
      "Iteration: 4420. Loss: 0.17454257607460022. Accuracy: 81.33360773821774\n",
      "Iteration: 4430. Loss: 0.17139765620231628. Accuracy: 81.3953488372093\n",
      "Iteration: 4440. Loss: 0.07601518929004669. Accuracy: 81.82753653015024\n",
      "Epoch:  58\n",
      "Iteration: 4450. Loss: 0.05471358448266983. Accuracy: 81.97159909446388\n",
      "Iteration: 4460. Loss: 0.055444344878196716. Accuracy: 82.01275982712492\n",
      "Iteration: 4470. Loss: 0.08891986310482025. Accuracy: 81.1895451739041\n",
      "Iteration: 4480. Loss: 0.10926754772663116. Accuracy: 81.47767030253138\n",
      "Iteration: 4490. Loss: 0.1491987407207489. Accuracy: 81.74521506482816\n",
      "Iteration: 4500. Loss: 0.14536245167255402. Accuracy: 82.32146532208273\n",
      "Iteration: 4510. Loss: 0.10300411283969879. Accuracy: 81.90985799547232\n",
      "Iteration: 4520. Loss: 0.09535200148820877. Accuracy: 81.3953488372093\n",
      "Epoch:  59\n",
      "Iteration: 4530. Loss: 0.0558350533246994. Accuracy: 81.80695616381972\n",
      "Iteration: 4540. Loss: 0.10382896661758423. Accuracy: 80.92200041160733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 4550. Loss: 0.09830954670906067. Accuracy: 81.6834739658366\n",
      "Iteration: 4560. Loss: 0.09207633882761002. Accuracy: 81.580572134184\n",
      "Iteration: 4570. Loss: 0.1187758818268776. Accuracy: 81.8892776291418\n",
      "Iteration: 4580. Loss: 0.1305117905139923. Accuracy: 81.4982506688619\n",
      "Iteration: 4590. Loss: 0.11663392186164856. Accuracy: 81.70405433216712\n",
      "Iteration: 4600. Loss: 0.12178017944097519. Accuracy: 81.47767030253138\n",
      "Epoch:  60\n",
      "Iteration: 4610. Loss: 0.1473046988248825. Accuracy: 80.77793784729369\n",
      "Iteration: 4620. Loss: 0.1666761189699173. Accuracy: 81.53941140152294\n",
      "Iteration: 4630. Loss: 0.0709725171327591. Accuracy: 81.35418810454826\n",
      "Iteration: 4640. Loss: 0.18563969433307648. Accuracy: 81.90985799547232\n",
      "Iteration: 4650. Loss: 0.18310393393039703. Accuracy: 82.13624202510805\n",
      "Iteration: 4660. Loss: 0.1138935536146164. Accuracy: 82.19798312409961\n",
      "Iteration: 4670. Loss: 0.14927661418914795. Accuracy: 81.23070590656513\n",
      "Iteration: 4680. Loss: 0.18198873102664948. Accuracy: 81.00432187692941\n",
      "Epoch:  61\n",
      "Iteration: 4690. Loss: 0.1594880372285843. Accuracy: 81.1895451739041\n",
      "Iteration: 4700. Loss: 0.07213594764471054. Accuracy: 81.80695616381972\n",
      "Iteration: 4710. Loss: 0.11011794954538345. Accuracy: 81.55999176785346\n",
      "Iteration: 4720. Loss: 0.07188107818365097. Accuracy: 82.01275982712492\n",
      "Iteration: 4730. Loss: 0.10451344400644302. Accuracy: 82.21856349043013\n",
      "Iteration: 4740. Loss: 0.11006557196378708. Accuracy: 82.36262605474377\n",
      "Iteration: 4750. Loss: 0.06942753493785858. Accuracy: 80.92200041160733\n",
      "Epoch:  62\n",
      "Iteration: 4760. Loss: 0.09185393154621124. Accuracy: 81.580572134184\n",
      "Iteration: 4770. Loss: 0.10309059172868729. Accuracy: 81.64231323317556\n",
      "Iteration: 4780. Loss: 0.07196372002363205. Accuracy: 81.74521506482816\n",
      "Iteration: 4790. Loss: 0.0645185336470604. Accuracy: 80.88083967894629\n",
      "Iteration: 4800. Loss: 0.09132079035043716. Accuracy: 82.28030458942169\n",
      "Iteration: 4810. Loss: 0.09692273288965225. Accuracy: 81.4982506688619\n",
      "Iteration: 4820. Loss: 0.09470807760953903. Accuracy: 82.40378678740481\n",
      "Iteration: 4830. Loss: 0.1432470828294754. Accuracy: 81.7863757974892\n",
      "Epoch:  63\n",
      "Iteration: 4840. Loss: 0.09661237895488739. Accuracy: 80.6956163819716\n",
      "Iteration: 4850. Loss: 0.091011181473732. Accuracy: 81.62173286684504\n",
      "Iteration: 4860. Loss: 0.05848173052072525. Accuracy: 82.52726898538793\n",
      "Iteration: 4870. Loss: 0.14983955025672913. Accuracy: 82.23914385676065\n",
      "Iteration: 4880. Loss: 0.08935824036598206. Accuracy: 81.37476847087878\n",
      "Iteration: 4890. Loss: 0.05941169708967209. Accuracy: 81.93043836180284\n",
      "Iteration: 4900. Loss: 0.1338377594947815. Accuracy: 81.33360773821774\n",
      "Iteration: 4910. Loss: 0.09073658287525177. Accuracy: 81.2924470055567\n",
      "Epoch:  64\n",
      "Iteration: 4920. Loss: 0.11825882643461227. Accuracy: 81.35418810454826\n",
      "Iteration: 4930. Loss: 0.10204225033521652. Accuracy: 80.88083967894629\n",
      "Iteration: 4940. Loss: 0.07874659448862076. Accuracy: 81.6834739658366\n",
      "Iteration: 4950. Loss: 0.11034131050109863. Accuracy: 81.6834739658366\n",
      "Iteration: 4960. Loss: 0.1268099993467331. Accuracy: 81.95101872813336\n",
      "Iteration: 4970. Loss: 0.061503734439611435. Accuracy: 80.75735748096317\n",
      "Iteration: 4980. Loss: 0.11074308305978775. Accuracy: 80.38691088701378\n",
      "Iteration: 4990. Loss: 0.11202623695135117. Accuracy: 81.35418810454826\n",
      "Epoch:  65\n",
      "Iteration: 5000. Loss: 0.0855448916554451. Accuracy: 81.37476847087878\n",
      "Iteration: 5010. Loss: 0.09234224259853363. Accuracy: 81.64231323317556\n",
      "Iteration: 5020. Loss: 0.17348694801330566. Accuracy: 80.92200041160733\n",
      "Iteration: 5030. Loss: 0.10273216664791107. Accuracy: 81.86869726281128\n",
      "Iteration: 5040. Loss: 0.10792781412601471. Accuracy: 81.95101872813336\n",
      "Iteration: 5050. Loss: 0.07014960795640945. Accuracy: 82.44494752006585\n",
      "Iteration: 5060. Loss: 0.06450898200273514. Accuracy: 81.8892776291418\n",
      "Iteration: 5070. Loss: 0.15017180144786835. Accuracy: 81.70405433216712\n",
      "Epoch:  66\n",
      "Iteration: 5080. Loss: 0.06546933948993683. Accuracy: 81.27186663922618\n",
      "Iteration: 5090. Loss: 0.11431204527616501. Accuracy: 81.41592920353982\n",
      "Iteration: 5100. Loss: 0.21751245856285095. Accuracy: 81.51883103519242\n",
      "Iteration: 5110. Loss: 0.04530281201004982. Accuracy: 82.32146532208273\n",
      "Iteration: 5120. Loss: 0.1951148808002472. Accuracy: 81.95101872813336\n",
      "Iteration: 5130. Loss: 0.05049002170562744. Accuracy: 82.15682239143857\n",
      "Iteration: 5140. Loss: 0.05334332212805748. Accuracy: 81.33360773821774\n",
      "Epoch:  67\n",
      "Iteration: 5150. Loss: 0.08656174689531326. Accuracy: 81.31302737188722\n",
      "Iteration: 5160. Loss: 0.15216746926307678. Accuracy: 81.74521506482816\n",
      "Iteration: 5170. Loss: 0.049987148493528366. Accuracy: 81.41592920353982\n",
      "Iteration: 5180. Loss: 0.021275809034705162. Accuracy: 81.76579543115868\n",
      "Iteration: 5190. Loss: 0.10259560495615005. Accuracy: 82.25972422309117\n",
      "Iteration: 5200. Loss: 0.09512247145175934. Accuracy: 81.4982506688619\n",
      "Iteration: 5210. Loss: 0.13559503853321075. Accuracy: 81.8892776291418\n",
      "Iteration: 5220. Loss: 0.1519254446029663. Accuracy: 81.53941140152294\n",
      "Epoch:  68\n",
      "Iteration: 5230. Loss: 0.05370146036148071. Accuracy: 81.4982506688619\n",
      "Iteration: 5240. Loss: 0.09245746582746506. Accuracy: 81.90985799547232\n",
      "Iteration: 5250. Loss: 0.05245199054479599. Accuracy: 81.33360773821774\n",
      "Iteration: 5260. Loss: 0.09566211700439453. Accuracy: 81.70405433216712\n",
      "Iteration: 5270. Loss: 0.1417437195777893. Accuracy: 82.13624202510805\n",
      "Iteration: 5280. Loss: 0.08484785258769989. Accuracy: 81.80695616381972\n",
      "Iteration: 5290. Loss: 0.09868856519460678. Accuracy: 82.05392055978596\n",
      "Iteration: 5300. Loss: 0.09559950977563858. Accuracy: 81.55999176785346\n",
      "Epoch:  69\n",
      "Iteration: 5310. Loss: 0.10949059575796127. Accuracy: 81.86869726281128\n",
      "Iteration: 5320. Loss: 0.050268229097127914. Accuracy: 81.82753653015024\n",
      "Iteration: 5330. Loss: 0.05529371276497841. Accuracy: 81.74521506482816\n",
      "Iteration: 5340. Loss: 0.07589172571897507. Accuracy: 81.70405433216712\n",
      "Iteration: 5350. Loss: 0.07455597072839737. Accuracy: 82.25972422309117\n",
      "Iteration: 5360. Loss: 0.07499874383211136. Accuracy: 82.17740275776909\n",
      "Iteration: 5370. Loss: 0.057644836604595184. Accuracy: 82.34204568841325\n",
      "Iteration: 5380. Loss: 0.07551287114620209. Accuracy: 81.95101872813336\n",
      "Epoch:  70\n",
      "Iteration: 5390. Loss: 0.12664645910263062. Accuracy: 81.27186663922618\n",
      "Iteration: 5400. Loss: 0.07218462228775024. Accuracy: 81.60115250051452\n",
      "Iteration: 5410. Loss: 0.06233453005552292. Accuracy: 81.84811689648076\n",
      "Iteration: 5420. Loss: 0.06591256707906723. Accuracy: 81.27186663922618\n",
      "Iteration: 5430. Loss: 0.18997131288051605. Accuracy: 81.33360773821774\n",
      "Iteration: 5440. Loss: 0.06132297217845917. Accuracy: 80.67503601564108\n",
      "Iteration: 5450. Loss: 0.1953798532485962. Accuracy: 81.60115250051452\n",
      "Iteration: 5460. Loss: 0.14941398799419403. Accuracy: 81.66289359950608\n",
      "Epoch:  71\n",
      "Iteration: 5470. Loss: 0.05115717649459839. Accuracy: 81.14838444124305\n",
      "Iteration: 5480. Loss: 0.07377861440181732. Accuracy: 81.16896480757357\n",
      "Iteration: 5490. Loss: 0.08810083568096161. Accuracy: 81.41592920353982\n",
      "Iteration: 5500. Loss: 0.07460229843854904. Accuracy: 81.60115250051452\n",
      "Iteration: 5510. Loss: 0.08057171106338501. Accuracy: 82.19798312409961\n",
      "Iteration: 5520. Loss: 0.11808934062719345. Accuracy: 81.76579543115868\n",
      "Iteration: 5530. Loss: 0.03797144815325737. Accuracy: 82.32146532208273\n",
      "Epoch:  72\n",
      "Iteration: 5540. Loss: 0.06118990480899811. Accuracy: 81.93043836180284\n",
      "Iteration: 5550. Loss: 0.10529428720474243. Accuracy: 82.81539411401523\n",
      "Iteration: 5560. Loss: 0.07495485991239548. Accuracy: 81.8892776291418\n",
      "Iteration: 5570. Loss: 0.07410931587219238. Accuracy: 82.34204568841325\n",
      "Iteration: 5580. Loss: 0.05913007631897926. Accuracy: 82.56842971804898\n",
      "Iteration: 5590. Loss: 0.1116715520620346. Accuracy: 81.90985799547232\n",
      "Iteration: 5600. Loss: 0.11250458657741547. Accuracy: 81.74521506482816\n",
      "Iteration: 5610. Loss: 0.08436787873506546. Accuracy: 81.70405433216712\n",
      "Epoch:  73\n",
      "Iteration: 5620. Loss: 0.06090375781059265. Accuracy: 80.98374151059889\n",
      "Iteration: 5630. Loss: 0.11848314851522446. Accuracy: 81.80695616381972\n",
      "Iteration: 5640. Loss: 0.07427526265382767. Accuracy: 82.56842971804898\n",
      "Iteration: 5650. Loss: 0.05897744745016098. Accuracy: 81.23070590656513\n",
      "Iteration: 5660. Loss: 0.13651998341083527. Accuracy: 81.04548260959045\n",
      "Iteration: 5670. Loss: 0.1304100751876831. Accuracy: 81.55999176785346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5680. Loss: 0.09963918477296829. Accuracy: 79.70775879810661\n",
      "Iteration: 5690. Loss: 0.21551816165447235. Accuracy: 81.55999176785346\n",
      "Epoch:  74\n",
      "Iteration: 5700. Loss: 0.1117946058511734. Accuracy: 82.21856349043013\n",
      "Iteration: 5710. Loss: 0.06062343344092369. Accuracy: 82.38320642107429\n",
      "Iteration: 5720. Loss: 0.08818842470645905. Accuracy: 82.15682239143857\n",
      "Iteration: 5730. Loss: 0.09911132603883743. Accuracy: 81.70405433216712\n",
      "Iteration: 5740. Loss: 0.09732465445995331. Accuracy: 81.53941140152294\n",
      "Iteration: 5750. Loss: 0.034239303320646286. Accuracy: 82.11566165877753\n",
      "Iteration: 5760. Loss: 0.11800706386566162. Accuracy: 82.07450092611649\n",
      "Iteration: 5770. Loss: 0.06380236148834229. Accuracy: 82.67133154970159\n",
      "Epoch:  75\n",
      "Iteration: 5780. Loss: 0.08493704348802567. Accuracy: 81.86869726281128\n",
      "Iteration: 5790. Loss: 0.07742509245872498. Accuracy: 81.47767030253138\n",
      "Iteration: 5800. Loss: 0.10795392096042633. Accuracy: 82.44494752006585\n",
      "Iteration: 5810. Loss: 0.15320703387260437. Accuracy: 81.86869726281128\n",
      "Iteration: 5820. Loss: 0.16715054214000702. Accuracy: 82.42436715373533\n",
      "Iteration: 5830. Loss: 0.07628647983074188. Accuracy: 82.13624202510805\n",
      "Iteration: 5840. Loss: 0.05280859023332596. Accuracy: 81.43650956987034\n",
      "Iteration: 5850. Loss: 0.07432333379983902. Accuracy: 81.70405433216712\n",
      "Epoch:  76\n",
      "Iteration: 5860. Loss: 0.09542422741651535. Accuracy: 81.8892776291418\n",
      "Iteration: 5870. Loss: 0.0844474509358406. Accuracy: 81.06606297592097\n",
      "Iteration: 5880. Loss: 0.11288846284151077. Accuracy: 82.71249228236263\n",
      "Iteration: 5890. Loss: 0.1323017179965973. Accuracy: 82.54784935171845\n",
      "Iteration: 5900. Loss: 0.0677516907453537. Accuracy: 82.19798312409961\n",
      "Iteration: 5910. Loss: 0.05808872729539871. Accuracy: 81.97159909446388\n",
      "Iteration: 5920. Loss: 0.0968671590089798. Accuracy: 81.66289359950608\n",
      "Epoch:  77\n",
      "Iteration: 5930. Loss: 0.034599728882312775. Accuracy: 81.95101872813336\n",
      "Iteration: 5940. Loss: 0.03660706803202629. Accuracy: 82.15682239143857\n",
      "Iteration: 5950. Loss: 0.11575130373239517. Accuracy: 82.69191191603211\n",
      "Iteration: 5960. Loss: 0.06097964942455292. Accuracy: 81.3953488372093\n",
      "Iteration: 5970. Loss: 0.1474626362323761. Accuracy: 82.23914385676065\n",
      "Iteration: 5980. Loss: 0.06972966343164444. Accuracy: 81.72463469849764\n",
      "Iteration: 5990. Loss: 0.0515250526368618. Accuracy: 81.64231323317556\n",
      "Iteration: 6000. Loss: 0.04591979458928108. Accuracy: 81.70405433216712\n",
      "Epoch:  78\n",
      "Iteration: 6010. Loss: 0.1346185952425003. Accuracy: 82.17740275776909\n",
      "Iteration: 6020. Loss: 0.09663654863834381. Accuracy: 82.67133154970159\n",
      "Iteration: 6030. Loss: 0.16169685125350952. Accuracy: 81.43650956987034\n",
      "Iteration: 6040. Loss: 0.06797141581773758. Accuracy: 81.53941140152294\n",
      "Iteration: 6050. Loss: 0.07558887451887131. Accuracy: 82.07450092611649\n",
      "Iteration: 6060. Loss: 0.0987672209739685. Accuracy: 81.27186663922618\n",
      "Iteration: 6070. Loss: 0.10731393843889236. Accuracy: 81.8892776291418\n",
      "Iteration: 6080. Loss: 0.17629998922348022. Accuracy: 82.07450092611649\n",
      "Epoch:  79\n",
      "Iteration: 6090. Loss: 0.05848192796111107. Accuracy: 82.095081292447\n",
      "Iteration: 6100. Loss: 0.1170952320098877. Accuracy: 81.3953488372093\n",
      "Iteration: 6110. Loss: 0.07304256409406662. Accuracy: 82.23914385676065\n",
      "Iteration: 6120. Loss: 0.10587827116250992. Accuracy: 81.97159909446388\n",
      "Iteration: 6130. Loss: 0.09958131611347198. Accuracy: 82.21856349043013\n",
      "Iteration: 6140. Loss: 0.15355445444583893. Accuracy: 82.4861082527269\n",
      "Iteration: 6150. Loss: 0.12092192471027374. Accuracy: 82.34204568841325\n",
      "Iteration: 6160. Loss: 0.10191170871257782. Accuracy: 81.9921794607944\n",
      "Epoch:  80\n",
      "Iteration: 6170. Loss: 0.04752909392118454. Accuracy: 82.5890100843795\n",
      "Iteration: 6180. Loss: 0.06892412155866623. Accuracy: 82.89771557933732\n",
      "Iteration: 6190. Loss: 0.04265245050191879. Accuracy: 81.80695616381972\n",
      "Iteration: 6200. Loss: 0.05791332200169563. Accuracy: 82.13624202510805\n",
      "Iteration: 6210. Loss: 0.06742309778928757. Accuracy: 82.11566165877753\n",
      "Iteration: 6220. Loss: 0.05265084654092789. Accuracy: 81.70405433216712\n",
      "Iteration: 6230. Loss: 0.08969442546367645. Accuracy: 81.95101872813336\n",
      "Iteration: 6240. Loss: 0.1274874210357666. Accuracy: 82.15682239143857\n",
      "Epoch:  81\n",
      "Iteration: 6250. Loss: 0.05829411745071411. Accuracy: 82.07450092611649\n",
      "Iteration: 6260. Loss: 0.14934474229812622. Accuracy: 82.25972422309117\n",
      "Iteration: 6270. Loss: 0.047067295759916306. Accuracy: 81.76579543115868\n",
      "Iteration: 6280. Loss: 0.07754012197256088. Accuracy: 81.16896480757357\n",
      "Iteration: 6290. Loss: 0.06588094681501389. Accuracy: 81.74521506482816\n",
      "Iteration: 6300. Loss: 0.07858378440141678. Accuracy: 81.60115250051452\n",
      "Iteration: 6310. Loss: 0.05416422709822655. Accuracy: 82.07450092611649\n",
      "Epoch:  82\n",
      "Iteration: 6320. Loss: 0.09993941336870193. Accuracy: 80.83967894628525\n",
      "Iteration: 6330. Loss: 0.08016978204250336. Accuracy: 82.01275982712492\n",
      "Iteration: 6340. Loss: 0.09514430910348892. Accuracy: 82.23914385676065\n",
      "Iteration: 6350. Loss: 0.07053014636039734. Accuracy: 81.90985799547232\n",
      "Iteration: 6360. Loss: 0.1007828339934349. Accuracy: 81.21012554023461\n",
      "Iteration: 6370. Loss: 0.06507331132888794. Accuracy: 81.93043836180284\n",
      "Iteration: 6380. Loss: 0.060573577880859375. Accuracy: 81.80695616381972\n",
      "Iteration: 6390. Loss: 0.04159386083483696. Accuracy: 81.14838444124305\n",
      "Epoch:  83\n",
      "Iteration: 6400. Loss: 0.12024986743927002. Accuracy: 81.37476847087878\n",
      "Iteration: 6410. Loss: 0.04050276055932045. Accuracy: 82.21856349043013\n",
      "Iteration: 6420. Loss: 0.12674802541732788. Accuracy: 81.90985799547232\n",
      "Iteration: 6430. Loss: 0.09652402251958847. Accuracy: 81.31302737188722\n",
      "Iteration: 6440. Loss: 0.113398976624012. Accuracy: 80.98374151059889\n",
      "Iteration: 6450. Loss: 0.057627104222774506. Accuracy: 81.9921794607944\n",
      "Iteration: 6460. Loss: 0.04099550470709801. Accuracy: 82.07450092611649\n",
      "Iteration: 6470. Loss: 0.05935234948992729. Accuracy: 81.62173286684504\n",
      "Epoch:  84\n",
      "Iteration: 6480. Loss: 0.04788767918944359. Accuracy: 81.95101872813336\n",
      "Iteration: 6490. Loss: 0.03910508751869202. Accuracy: 80.73677711463264\n",
      "Iteration: 6500. Loss: 0.09407467395067215. Accuracy: 81.95101872813336\n",
      "Iteration: 6510. Loss: 0.08896131813526154. Accuracy: 81.47767030253138\n",
      "Iteration: 6520. Loss: 0.06330692023038864. Accuracy: 81.53941140152294\n",
      "Iteration: 6530. Loss: 0.09149309992790222. Accuracy: 80.83967894628525\n",
      "Iteration: 6540. Loss: 0.04555573686957359. Accuracy: 81.27186663922618\n",
      "Iteration: 6550. Loss: 0.03851213678717613. Accuracy: 82.17740275776909\n",
      "Epoch:  85\n",
      "Iteration: 6560. Loss: 0.015794338658452034. Accuracy: 81.70405433216712\n",
      "Iteration: 6570. Loss: 0.07537910342216492. Accuracy: 81.9921794607944\n",
      "Iteration: 6580. Loss: 0.08770909160375595. Accuracy: 81.86869726281128\n",
      "Iteration: 6590. Loss: 0.05113953724503517. Accuracy: 82.19798312409961\n",
      "Iteration: 6600. Loss: 0.03495140001177788. Accuracy: 81.8892776291418\n",
      "Iteration: 6610. Loss: 0.07952696830034256. Accuracy: 82.11566165877753\n",
      "Iteration: 6620. Loss: 0.0452241450548172. Accuracy: 81.70405433216712\n",
      "Iteration: 6630. Loss: 0.07345772534608841. Accuracy: 81.86869726281128\n",
      "Epoch:  86\n",
      "Iteration: 6640. Loss: 0.057792581617832184. Accuracy: 81.90985799547232\n",
      "Iteration: 6650. Loss: 0.08406342566013336. Accuracy: 81.6834739658366\n",
      "Iteration: 6660. Loss: 0.12469752132892609. Accuracy: 81.580572134184\n",
      "Iteration: 6670. Loss: 0.04259445145726204. Accuracy: 82.05392055978596\n",
      "Iteration: 6680. Loss: 0.12746992707252502. Accuracy: 82.17740275776909\n",
      "Iteration: 6690. Loss: 0.040307119488716125. Accuracy: 81.76579543115868\n",
      "Iteration: 6700. Loss: 0.038214851170778275. Accuracy: 82.01275982712492\n",
      "Epoch:  87\n",
      "Iteration: 6710. Loss: 0.03113264963030815. Accuracy: 80.6956163819716\n",
      "Iteration: 6720. Loss: 0.08393198251724243. Accuracy: 80.88083967894629\n",
      "Iteration: 6730. Loss: 0.18339452147483826. Accuracy: 81.64231323317556\n",
      "Iteration: 6740. Loss: 0.06304707378149033. Accuracy: 81.8892776291418\n",
      "Iteration: 6750. Loss: 0.06439012289047241. Accuracy: 82.30088495575221\n",
      "Iteration: 6760. Loss: 0.06629300862550735. Accuracy: 81.21012554023461\n",
      "Iteration: 6770. Loss: 0.06924483180046082. Accuracy: 80.73677711463264\n",
      "Iteration: 6780. Loss: 0.045351043343544006. Accuracy: 81.82753653015024\n",
      "Epoch:  88\n",
      "Iteration: 6790. Loss: 0.09491362422704697. Accuracy: 81.10722370858201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 6800. Loss: 0.06233074888586998. Accuracy: 81.21012554023461\n",
      "Iteration: 6810. Loss: 0.03669911250472069. Accuracy: 82.03334019345544\n",
      "Iteration: 6820. Loss: 0.023032907396554947. Accuracy: 82.05392055978596\n",
      "Iteration: 6830. Loss: 0.030227061361074448. Accuracy: 82.44494752006585\n",
      "Iteration: 6840. Loss: 0.07108064740896225. Accuracy: 81.70405433216712\n",
      "Iteration: 6850. Loss: 0.07179660350084305. Accuracy: 82.11566165877753\n",
      "Iteration: 6860. Loss: 0.04299427568912506. Accuracy: 81.04548260959045\n",
      "Epoch:  89\n",
      "Iteration: 6870. Loss: 0.07485952228307724. Accuracy: 81.80695616381972\n",
      "Iteration: 6880. Loss: 0.022594915702939034. Accuracy: 81.25128627289565\n",
      "Iteration: 6890. Loss: 0.06397286802530289. Accuracy: 81.74521506482816\n",
      "Iteration: 6900. Loss: 0.0735735297203064. Accuracy: 82.52726898538793\n",
      "Iteration: 6910. Loss: 0.10138502717018127. Accuracy: 81.72463469849764\n",
      "Iteration: 6920. Loss: 0.09633594751358032. Accuracy: 81.60115250051452\n",
      "Iteration: 6930. Loss: 0.04391784965991974. Accuracy: 81.86869726281128\n",
      "Iteration: 6940. Loss: 0.05955718085169792. Accuracy: 81.6834739658366\n",
      "Epoch:  90\n",
      "Iteration: 6950. Loss: 0.11790022253990173. Accuracy: 81.66289359950608\n",
      "Iteration: 6960. Loss: 0.05001719668507576. Accuracy: 81.25128627289565\n",
      "Iteration: 6970. Loss: 0.07869502156972885. Accuracy: 82.21856349043013\n",
      "Iteration: 6980. Loss: 0.07212826609611511. Accuracy: 82.01275982712492\n",
      "Iteration: 6990. Loss: 0.07840146124362946. Accuracy: 81.3953488372093\n",
      "Iteration: 7000. Loss: 0.06903041154146194. Accuracy: 80.53097345132744\n",
      "Iteration: 7010. Loss: 0.07917563617229462. Accuracy: 81.43650956987034\n",
      "Iteration: 7020. Loss: 0.16939836740493774. Accuracy: 81.60115250051452\n",
      "Epoch:  91\n",
      "Iteration: 7030. Loss: 0.10295160859823227. Accuracy: 80.42807161967482\n",
      "Iteration: 7040. Loss: 0.029565652832388878. Accuracy: 81.41592920353982\n",
      "Iteration: 7050. Loss: 0.08749795705080032. Accuracy: 81.72463469849764\n",
      "Iteration: 7060. Loss: 0.04082440584897995. Accuracy: 81.62173286684504\n",
      "Iteration: 7070. Loss: 0.1214083731174469. Accuracy: 81.64231323317556\n",
      "Iteration: 7080. Loss: 0.0727945864200592. Accuracy: 81.51883103519242\n",
      "Iteration: 7090. Loss: 0.10876637697219849. Accuracy: 81.23070590656513\n",
      "Epoch:  92\n",
      "Iteration: 7100. Loss: 0.08166364580392838. Accuracy: 81.41592920353982\n",
      "Iteration: 7110. Loss: 0.07524320483207703. Accuracy: 82.17740275776909\n",
      "Iteration: 7120. Loss: 0.06966733187437057. Accuracy: 81.64231323317556\n",
      "Iteration: 7130. Loss: 0.0950111374258995. Accuracy: 82.01275982712492\n",
      "Iteration: 7140. Loss: 0.10566949099302292. Accuracy: 81.580572134184\n",
      "Iteration: 7150. Loss: 0.08637932687997818. Accuracy: 80.73677711463264\n",
      "Iteration: 7160. Loss: 0.023449504747986794. Accuracy: 81.66289359950608\n",
      "Iteration: 7170. Loss: 0.08448132127523422. Accuracy: 82.56842971804898\n",
      "Epoch:  93\n",
      "Iteration: 7180. Loss: 0.03498014807701111. Accuracy: 82.17740275776909\n",
      "Iteration: 7190. Loss: 0.04923897236585617. Accuracy: 81.60115250051452\n",
      "Iteration: 7200. Loss: 0.05849252641201019. Accuracy: 81.93043836180284\n",
      "Iteration: 7210. Loss: 0.06450530886650085. Accuracy: 82.07450092611649\n",
      "Iteration: 7220. Loss: 0.06182824447751045. Accuracy: 82.38320642107429\n",
      "Iteration: 7230. Loss: 0.11461140960454941. Accuracy: 82.65075118337107\n",
      "Iteration: 7240. Loss: 0.05247531458735466. Accuracy: 82.11566165877753\n",
      "Iteration: 7250. Loss: 0.04342098906636238. Accuracy: 81.76579543115868\n",
      "Epoch:  94\n",
      "Iteration: 7260. Loss: 0.12330511957406998. Accuracy: 82.13624202510805\n",
      "Iteration: 7270. Loss: 0.053185638040304184. Accuracy: 82.34204568841325\n",
      "Iteration: 7280. Loss: 0.017726846039295197. Accuracy: 81.23070590656513\n",
      "Iteration: 7290. Loss: 0.01255320105701685. Accuracy: 81.86869726281128\n",
      "Iteration: 7300. Loss: 0.0766717866063118. Accuracy: 82.67133154970159\n",
      "Iteration: 7310. Loss: 0.10989470779895782. Accuracy: 82.05392055978596\n",
      "Iteration: 7320. Loss: 0.026093658059835434. Accuracy: 81.8892776291418\n",
      "Iteration: 7330. Loss: 0.0468696653842926. Accuracy: 82.30088495575221\n",
      "Epoch:  95\n",
      "Iteration: 7340. Loss: 0.05715269595384598. Accuracy: 82.46552788639637\n",
      "Iteration: 7350. Loss: 0.04655520245432854. Accuracy: 81.60115250051452\n",
      "Iteration: 7360. Loss: 0.05060424283146858. Accuracy: 82.40378678740481\n",
      "Iteration: 7370. Loss: 0.05189552158117294. Accuracy: 82.34204568841325\n",
      "Iteration: 7380. Loss: 0.04294748604297638. Accuracy: 82.38320642107429\n",
      "Iteration: 7390. Loss: 0.14246784150600433. Accuracy: 81.86869726281128\n",
      "Iteration: 7400. Loss: 0.03311420977115631. Accuracy: 81.60115250051452\n",
      "Iteration: 7410. Loss: 0.04442405700683594. Accuracy: 82.25972422309117\n",
      "Epoch:  96\n",
      "Iteration: 7420. Loss: 0.0750909075140953. Accuracy: 82.75365301502367\n",
      "Iteration: 7430. Loss: 0.027712922543287277. Accuracy: 82.13624202510805\n",
      "Iteration: 7440. Loss: 0.04195799678564072. Accuracy: 82.75365301502367\n",
      "Iteration: 7450. Loss: 0.01681026630103588. Accuracy: 81.82753653015024\n",
      "Iteration: 7460. Loss: 0.14280153810977936. Accuracy: 82.4861082527269\n",
      "Iteration: 7470. Loss: 0.05077759549021721. Accuracy: 82.7742333813542\n",
      "Iteration: 7480. Loss: 0.06388501077890396. Accuracy: 82.85655484667627\n",
      "Epoch:  97\n",
      "Iteration: 7490. Loss: 0.02553543820977211. Accuracy: 82.07450092611649\n",
      "Iteration: 7500. Loss: 0.028264371678233147. Accuracy: 82.30088495575221\n",
      "Iteration: 7510. Loss: 0.027183540165424347. Accuracy: 82.4861082527269\n",
      "Iteration: 7520. Loss: 0.04415968433022499. Accuracy: 82.42436715373533\n",
      "Iteration: 7530. Loss: 0.031315259635448456. Accuracy: 81.72463469849764\n",
      "Iteration: 7540. Loss: 0.17244963347911835. Accuracy: 82.07450092611649\n",
      "Iteration: 7550. Loss: 0.06083028018474579. Accuracy: 82.36262605474377\n",
      "Iteration: 7560. Loss: 0.07319944351911545. Accuracy: 82.11566165877753\n",
      "Epoch:  98\n",
      "Iteration: 7570. Loss: 0.09800143539905548. Accuracy: 82.95945667832888\n",
      "Iteration: 7580. Loss: 0.06042042002081871. Accuracy: 82.50668861905741\n",
      "Iteration: 7590. Loss: 0.04879511892795563. Accuracy: 83.00061741098992\n",
      "Iteration: 7600. Loss: 0.10105068236589432. Accuracy: 82.095081292447\n",
      "Iteration: 7610. Loss: 0.07366817444562912. Accuracy: 81.1895451739041\n",
      "Iteration: 7620. Loss: 0.049817223101854324. Accuracy: 82.50668861905741\n",
      "Iteration: 7630. Loss: 0.06356373429298401. Accuracy: 82.25972422309117\n",
      "Iteration: 7640. Loss: 0.0790456235408783. Accuracy: 81.6834739658366\n",
      "Epoch:  99\n",
      "Iteration: 7650. Loss: 0.06367887556552887. Accuracy: 81.86869726281128\n",
      "Iteration: 7660. Loss: 0.030847182497382164. Accuracy: 82.11566165877753\n",
      "Iteration: 7670. Loss: 0.038439132273197174. Accuracy: 82.11566165877753\n",
      "Iteration: 7680. Loss: 0.08780890703201294. Accuracy: 82.93887631199836\n",
      "Iteration: 7690. Loss: 0.10011833161115646. Accuracy: 81.66289359950608\n",
      "Iteration: 7700. Loss: 0.09154953807592392. Accuracy: 81.51883103519242\n",
      "Iteration: 7710. Loss: 0.09293283522129059. Accuracy: 82.44494752006585\n",
      "Iteration: 7720. Loss: 0.02587730810046196. Accuracy: 82.13624202510805\n",
      "Epoch:  100\n",
      "Iteration: 7730. Loss: 0.055225636810064316. Accuracy: 81.35418810454826\n",
      "Iteration: 7740. Loss: 0.05146803706884384. Accuracy: 82.095081292447\n",
      "Iteration: 7750. Loss: 0.04196852818131447. Accuracy: 82.40378678740481\n",
      "Iteration: 7760. Loss: 0.06785495579242706. Accuracy: 82.01275982712492\n",
      "Iteration: 7770. Loss: 0.037042807787656784. Accuracy: 82.13624202510805\n",
      "Iteration: 7780. Loss: 0.052369505167007446. Accuracy: 82.42436715373533\n",
      "Iteration: 7790. Loss: 0.14893551170825958. Accuracy: 82.93887631199836\n",
      "Iteration: 7800. Loss: 0.09415367990732193. Accuracy: 81.70405433216712\n",
      "Epoch:  101\n",
      "Iteration: 7810. Loss: 0.041898470371961594. Accuracy: 82.05392055978596\n",
      "Iteration: 7820. Loss: 0.04523293673992157. Accuracy: 82.11566165877753\n",
      "Iteration: 7830. Loss: 0.05164097994565964. Accuracy: 81.84811689648076\n",
      "Iteration: 7840. Loss: 0.0349702388048172. Accuracy: 82.11566165877753\n",
      "Iteration: 7850. Loss: 0.044950857758522034. Accuracy: 81.74521506482816\n",
      "Iteration: 7860. Loss: 0.04263301193714142. Accuracy: 82.67133154970159\n",
      "Iteration: 7870. Loss: 0.04705679789185524. Accuracy: 81.7863757974892\n",
      "Epoch:  102\n",
      "Iteration: 7880. Loss: 0.019077269360423088. Accuracy: 82.34204568841325\n",
      "Iteration: 7890. Loss: 0.07866591960191727. Accuracy: 82.01275982712492\n",
      "Iteration: 7900. Loss: 0.026609446853399277. Accuracy: 82.52726898538793\n",
      "Iteration: 7910. Loss: 0.08982954919338226. Accuracy: 82.38320642107429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 7920. Loss: 0.01945946179330349. Accuracy: 82.67133154970159\n",
      "Iteration: 7930. Loss: 0.04585489258170128. Accuracy: 81.45708993620086\n",
      "Iteration: 7940. Loss: 0.09703444689512253. Accuracy: 82.19798312409961\n",
      "Iteration: 7950. Loss: 0.0436520092189312. Accuracy: 81.82753653015024\n",
      "Epoch:  103\n",
      "Iteration: 7960. Loss: 0.012264850549399853. Accuracy: 81.8892776291418\n",
      "Iteration: 7970. Loss: 0.034127190709114075. Accuracy: 82.40378678740481\n",
      "Iteration: 7980. Loss: 0.0965576246380806. Accuracy: 81.06606297592097\n",
      "Iteration: 7990. Loss: 0.04624423757195473. Accuracy: 82.19798312409961\n",
      "Iteration: 8000. Loss: 0.05838678404688835. Accuracy: 82.13624202510805\n",
      "Iteration: 8010. Loss: 0.05670524388551712. Accuracy: 81.1895451739041\n",
      "Iteration: 8020. Loss: 0.08986880630254745. Accuracy: 81.04548260959045\n",
      "Iteration: 8030. Loss: 0.05908413976430893. Accuracy: 81.21012554023461\n",
      "Epoch:  104\n",
      "Iteration: 8040. Loss: 0.025897163897752762. Accuracy: 81.8892776291418\n",
      "Iteration: 8050. Loss: 0.0181294996291399. Accuracy: 81.1895451739041\n",
      "Iteration: 8060. Loss: 0.05375264212489128. Accuracy: 82.28030458942169\n",
      "Iteration: 8070. Loss: 0.10113295912742615. Accuracy: 82.15682239143857\n",
      "Iteration: 8080. Loss: 0.05196665599942207. Accuracy: 82.52726898538793\n",
      "Iteration: 8090. Loss: 0.10498884320259094. Accuracy: 82.23914385676065\n",
      "Iteration: 8100. Loss: 0.021805286407470703. Accuracy: 82.32146532208273\n",
      "Iteration: 8110. Loss: 0.026982922106981277. Accuracy: 82.23914385676065\n",
      "Epoch:  105\n",
      "Iteration: 8120. Loss: 0.05617533251643181. Accuracy: 82.52726898538793\n",
      "Iteration: 8130. Loss: 0.017910506576299667. Accuracy: 82.25972422309117\n",
      "Iteration: 8140. Loss: 0.08790712058544159. Accuracy: 82.95945667832888\n",
      "Iteration: 8150. Loss: 0.058140914887189865. Accuracy: 82.95945667832888\n",
      "Iteration: 8160. Loss: 0.012688362039625645. Accuracy: 82.73307264869315\n",
      "Iteration: 8170. Loss: 0.051823776215314865. Accuracy: 82.65075118337107\n",
      "Iteration: 8180. Loss: 0.04335680231451988. Accuracy: 82.34204568841325\n",
      "Iteration: 8190. Loss: 0.07141578197479248. Accuracy: 82.11566165877753\n",
      "Epoch:  106\n",
      "Iteration: 8200. Loss: 0.04572223499417305. Accuracy: 81.27186663922618\n",
      "Iteration: 8210. Loss: 0.040635108947753906. Accuracy: 82.40378678740481\n",
      "Iteration: 8220. Loss: 0.07518317550420761. Accuracy: 81.2924470055567\n",
      "Iteration: 8230. Loss: 0.08550692349672318. Accuracy: 82.17740275776909\n",
      "Iteration: 8240. Loss: 0.02479666657745838. Accuracy: 82.34204568841325\n",
      "Iteration: 8250. Loss: 0.08346483111381531. Accuracy: 83.32990327227824\n",
      "Iteration: 8260. Loss: 0.04934170842170715. Accuracy: 82.19798312409961\n",
      "Epoch:  107\n",
      "Iteration: 8270. Loss: 0.04016288369894028. Accuracy: 82.095081292447\n",
      "Iteration: 8280. Loss: 0.08001355081796646. Accuracy: 82.21856349043013\n",
      "Iteration: 8290. Loss: 0.07682129740715027. Accuracy: 81.8892776291418\n",
      "Iteration: 8300. Loss: 0.04642214626073837. Accuracy: 82.79481374768471\n",
      "Iteration: 8310. Loss: 0.06521251797676086. Accuracy: 82.56842971804898\n",
      "Iteration: 8320. Loss: 0.028711959719657898. Accuracy: 82.56842971804898\n",
      "Iteration: 8330. Loss: 0.07068687677383423. Accuracy: 82.28030458942169\n",
      "Iteration: 8340. Loss: 0.08446987718343735. Accuracy: 81.51883103519242\n",
      "Epoch:  108\n",
      "Iteration: 8350. Loss: 0.042538613080978394. Accuracy: 81.95101872813336\n",
      "Iteration: 8360. Loss: 0.06425976753234863. Accuracy: 82.28030458942169\n",
      "Iteration: 8370. Loss: 0.0251917764544487. Accuracy: 81.45708993620086\n",
      "Iteration: 8380. Loss: 0.027928892523050308. Accuracy: 82.5890100843795\n",
      "Iteration: 8390. Loss: 0.049088962376117706. Accuracy: 82.25972422309117\n",
      "Iteration: 8400. Loss: 0.09842459112405777. Accuracy: 81.51883103519242\n",
      "Iteration: 8410. Loss: 0.052982576191425323. Accuracy: 82.01275982712492\n",
      "Iteration: 8420. Loss: 0.08224918693304062. Accuracy: 82.50668861905741\n",
      "Epoch:  109\n",
      "Iteration: 8430. Loss: 0.054256755858659744. Accuracy: 82.25972422309117\n",
      "Iteration: 8440. Loss: 0.06979595869779587. Accuracy: 82.42436715373533\n",
      "Iteration: 8450. Loss: 0.044915493577718735. Accuracy: 81.82753653015024\n",
      "Iteration: 8460. Loss: 0.01725042797625065. Accuracy: 82.52726898538793\n",
      "Iteration: 8470. Loss: 0.08897683024406433. Accuracy: 80.57213418398848\n",
      "Iteration: 8480. Loss: 0.06439663469791412. Accuracy: 82.05392055978596\n",
      "Iteration: 8490. Loss: 0.03222744166851044. Accuracy: 81.33360773821774\n",
      "Iteration: 8500. Loss: 0.06793436408042908. Accuracy: 82.07450092611649\n",
      "Epoch:  110\n",
      "Iteration: 8510. Loss: 0.07166163623332977. Accuracy: 82.17740275776909\n",
      "Iteration: 8520. Loss: 0.03634363040328026. Accuracy: 81.6834739658366\n",
      "Iteration: 8530. Loss: 0.028059424832463264. Accuracy: 82.23914385676065\n",
      "Iteration: 8540. Loss: 0.0905398428440094. Accuracy: 82.81539411401523\n",
      "Iteration: 8550. Loss: 0.05946861952543259. Accuracy: 81.43650956987034\n",
      "Iteration: 8560. Loss: 0.0413581021130085. Accuracy: 82.4861082527269\n",
      "Iteration: 8570. Loss: 0.041012588888406754. Accuracy: 82.40378678740481\n",
      "Iteration: 8580. Loss: 0.1069735586643219. Accuracy: 82.01275982712492\n",
      "Epoch:  111\n",
      "Iteration: 8590. Loss: 0.05024366453289986. Accuracy: 81.95101872813336\n",
      "Iteration: 8600. Loss: 0.032172493636608124. Accuracy: 81.97159909446388\n",
      "Iteration: 8610. Loss: 0.07983431965112686. Accuracy: 82.19798312409961\n",
      "Iteration: 8620. Loss: 0.05623258277773857. Accuracy: 82.07450092611649\n",
      "Iteration: 8630. Loss: 0.05110495537519455. Accuracy: 81.95101872813336\n",
      "Iteration: 8640. Loss: 0.06792640686035156. Accuracy: 82.01275982712492\n",
      "Iteration: 8650. Loss: 0.08545272052288055. Accuracy: 81.3953488372093\n",
      "Epoch:  112\n",
      "Iteration: 8660. Loss: 0.05967889353632927. Accuracy: 82.095081292447\n",
      "Iteration: 8670. Loss: 0.08214361220598221. Accuracy: 82.30088495575221\n",
      "Iteration: 8680. Loss: 0.05668584257364273. Accuracy: 82.42436715373533\n",
      "Iteration: 8690. Loss: 0.0392211489379406. Accuracy: 81.60115250051452\n",
      "Iteration: 8700. Loss: 0.03431279957294464. Accuracy: 82.56842971804898\n",
      "Iteration: 8710. Loss: 0.07712694257497787. Accuracy: 80.94258077793785\n",
      "Iteration: 8720. Loss: 0.12283451110124588. Accuracy: 82.30088495575221\n",
      "Iteration: 8730. Loss: 0.03464917466044426. Accuracy: 82.91829594566784\n",
      "Epoch:  113\n",
      "Iteration: 8740. Loss: 0.07021477073431015. Accuracy: 82.19798312409961\n",
      "Iteration: 8750. Loss: 0.02918051928281784. Accuracy: 82.05392055978596\n",
      "Iteration: 8760. Loss: 0.07085543870925903. Accuracy: 82.73307264869315\n",
      "Iteration: 8770. Loss: 0.019196517765522003. Accuracy: 82.17740275776909\n",
      "Iteration: 8780. Loss: 0.05253581330180168. Accuracy: 82.32146532208273\n",
      "Iteration: 8790. Loss: 0.07946392893791199. Accuracy: 82.60959045071002\n",
      "Iteration: 8800. Loss: 0.0845881849527359. Accuracy: 82.01275982712492\n",
      "Iteration: 8810. Loss: 0.0752243921160698. Accuracy: 82.50668861905741\n",
      "Epoch:  114\n",
      "Iteration: 8820. Loss: 0.033265121281147. Accuracy: 81.66289359950608\n",
      "Iteration: 8830. Loss: 0.04211775213479996. Accuracy: 82.40378678740481\n",
      "Iteration: 8840. Loss: 0.033656876534223557. Accuracy: 82.46552788639637\n",
      "Iteration: 8850. Loss: 0.09133315086364746. Accuracy: 82.17740275776909\n",
      "Iteration: 8860. Loss: 0.06720355898141861. Accuracy: 83.12409960897304\n",
      "Iteration: 8870. Loss: 0.0705878734588623. Accuracy: 81.8892776291418\n",
      "Iteration: 8880. Loss: 0.044422585517168045. Accuracy: 81.93043836180284\n",
      "Iteration: 8890. Loss: 0.05517204850912094. Accuracy: 82.01275982712492\n",
      "Epoch:  115\n",
      "Iteration: 8900. Loss: 0.01990262046456337. Accuracy: 82.73307264869315\n",
      "Iteration: 8910. Loss: 0.04245594143867493. Accuracy: 81.1895451739041\n",
      "Iteration: 8920. Loss: 0.0584086999297142. Accuracy: 81.9921794607944\n",
      "Iteration: 8930. Loss: 0.014122226275503635. Accuracy: 82.25972422309117\n",
      "Iteration: 8940. Loss: 0.03393645957112312. Accuracy: 81.4982506688619\n",
      "Iteration: 8950. Loss: 0.08217284828424454. Accuracy: 82.85655484667627\n",
      "Iteration: 8960. Loss: 0.020862706005573273. Accuracy: 81.8892776291418\n",
      "Iteration: 8970. Loss: 0.10905788838863373. Accuracy: 82.4861082527269\n",
      "Epoch:  116\n",
      "Iteration: 8980. Loss: 0.05931813642382622. Accuracy: 81.93043836180284\n",
      "Iteration: 8990. Loss: 0.10934343934059143. Accuracy: 81.62173286684504\n",
      "Iteration: 9000. Loss: 0.04858472943305969. Accuracy: 82.40378678740481\n",
      "Iteration: 9010. Loss: 0.10205861181020737. Accuracy: 82.67133154970159\n",
      "Iteration: 9020. Loss: 0.030157772824168205. Accuracy: 81.55999176785346\n",
      "Iteration: 9030. Loss: 0.03372393921017647. Accuracy: 81.12780407491253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 9040. Loss: 0.028379356488585472. Accuracy: 82.85655484667627\n",
      "Epoch:  117\n",
      "Iteration: 9050. Loss: 0.05918616056442261. Accuracy: 81.86869726281128\n",
      "Iteration: 9060. Loss: 0.06356982886791229. Accuracy: 81.95101872813336\n",
      "Iteration: 9070. Loss: 0.03244940564036369. Accuracy: 82.56842971804898\n",
      "Iteration: 9080. Loss: 0.03814668953418732. Accuracy: 81.76579543115868\n",
      "Iteration: 9090. Loss: 0.045539870858192444. Accuracy: 82.46552788639637\n",
      "Iteration: 9100. Loss: 0.011534620076417923. Accuracy: 82.30088495575221\n",
      "Iteration: 9110. Loss: 0.03141239657998085. Accuracy: 82.52726898538793\n",
      "Iteration: 9120. Loss: 0.014706567861139774. Accuracy: 83.06235850998148\n",
      "Epoch:  118\n",
      "Iteration: 9130. Loss: 0.050760891288518906. Accuracy: 81.90985799547232\n",
      "Iteration: 9140. Loss: 0.023972952738404274. Accuracy: 81.80695616381972\n",
      "Iteration: 9150. Loss: 0.02713587135076523. Accuracy: 82.11566165877753\n",
      "Iteration: 9160. Loss: 0.03103215992450714. Accuracy: 82.56842971804898\n",
      "Iteration: 9170. Loss: 0.014318183995783329. Accuracy: 81.6834739658366\n",
      "Iteration: 9180. Loss: 0.061542365700006485. Accuracy: 81.6834739658366\n",
      "Iteration: 9190. Loss: 0.04505853354930878. Accuracy: 81.23070590656513\n",
      "Iteration: 9200. Loss: 0.04815012589097023. Accuracy: 82.03334019345544\n",
      "Epoch:  119\n",
      "Iteration: 9210. Loss: 0.04861321672797203. Accuracy: 82.01275982712492\n",
      "Iteration: 9220. Loss: 0.08318176865577698. Accuracy: 81.35418810454826\n",
      "Iteration: 9230. Loss: 0.025259897112846375. Accuracy: 82.21856349043013\n",
      "Iteration: 9240. Loss: 0.03420700132846832. Accuracy: 82.34204568841325\n",
      "Iteration: 9250. Loss: 0.05131356418132782. Accuracy: 82.13624202510805\n",
      "Iteration: 9260. Loss: 0.08333034813404083. Accuracy: 82.40378678740481\n",
      "Iteration: 9270. Loss: 0.06611639261245728. Accuracy: 81.55999176785346\n",
      "Iteration: 9280. Loss: 0.028552135452628136. Accuracy: 81.90985799547232\n",
      "Epoch:  120\n",
      "Iteration: 9290. Loss: 0.09536509960889816. Accuracy: 82.095081292447\n",
      "Iteration: 9300. Loss: 0.05458989366889. Accuracy: 81.4982506688619\n",
      "Iteration: 9310. Loss: 0.03051874227821827. Accuracy: 81.86869726281128\n",
      "Iteration: 9320. Loss: 0.1003827452659607. Accuracy: 82.8771352130068\n",
      "Iteration: 9330. Loss: 0.028559895232319832. Accuracy: 82.15682239143857\n",
      "Iteration: 9340. Loss: 0.09466525912284851. Accuracy: 82.15682239143857\n",
      "Iteration: 9350. Loss: 0.0712016373872757. Accuracy: 82.60959045071002\n",
      "Iteration: 9360. Loss: 0.06435319781303406. Accuracy: 81.33360773821774\n",
      "Epoch:  121\n",
      "Iteration: 9370. Loss: 0.05238265544176102. Accuracy: 82.38320642107429\n",
      "Iteration: 9380. Loss: 0.028935132548213005. Accuracy: 82.25972422309117\n",
      "Iteration: 9390. Loss: 0.026751555502414703. Accuracy: 82.52726898538793\n",
      "Iteration: 9400. Loss: 0.08026932179927826. Accuracy: 83.10351924264252\n",
      "Iteration: 9410. Loss: 0.022664548829197884. Accuracy: 82.13624202510805\n",
      "Iteration: 9420. Loss: 0.023053457960486412. Accuracy: 82.63017081704054\n",
      "Iteration: 9430. Loss: 0.036764245480298996. Accuracy: 81.53941140152294\n",
      "Epoch:  122\n",
      "Iteration: 9440. Loss: 0.02828284353017807. Accuracy: 82.73307264869315\n",
      "Iteration: 9450. Loss: 0.05851045250892639. Accuracy: 82.54784935171845\n",
      "Iteration: 9460. Loss: 0.03557461127638817. Accuracy: 82.17740275776909\n",
      "Iteration: 9470. Loss: 0.024045085534453392. Accuracy: 82.9800370446594\n",
      "Iteration: 9480. Loss: 0.08751048147678375. Accuracy: 82.095081292447\n",
      "Iteration: 9490. Loss: 0.024170273914933205. Accuracy: 82.54784935171845\n",
      "Iteration: 9500. Loss: 0.07249048352241516. Accuracy: 81.580572134184\n",
      "Iteration: 9510. Loss: 0.05022932589054108. Accuracy: 81.76579543115868\n",
      "Epoch:  123\n",
      "Iteration: 9520. Loss: 0.03062671609222889. Accuracy: 82.21856349043013\n",
      "Iteration: 9530. Loss: 0.030291404575109482. Accuracy: 82.63017081704054\n",
      "Iteration: 9540. Loss: 0.02008013427257538. Accuracy: 82.44494752006585\n",
      "Iteration: 9550. Loss: 0.03480006381869316. Accuracy: 81.8892776291418\n",
      "Iteration: 9560. Loss: 0.029000265523791313. Accuracy: 81.53941140152294\n",
      "Iteration: 9570. Loss: 0.0567181222140789. Accuracy: 82.28030458942169\n",
      "Iteration: 9580. Loss: 0.04739696532487869. Accuracy: 81.82753653015024\n",
      "Iteration: 9590. Loss: 0.025887006893754005. Accuracy: 81.08664334225149\n",
      "Epoch:  124\n",
      "Iteration: 9600. Loss: 0.1560027152299881. Accuracy: 81.66289359950608\n",
      "Iteration: 9610. Loss: 0.03148721531033516. Accuracy: 81.8892776291418\n",
      "Iteration: 9620. Loss: 0.10981947928667068. Accuracy: 82.71249228236263\n",
      "Iteration: 9630. Loss: 0.07257085293531418. Accuracy: 82.095081292447\n",
      "Iteration: 9640. Loss: 0.023369846865534782. Accuracy: 82.32146532208273\n",
      "Iteration: 9650. Loss: 0.057045914232730865. Accuracy: 82.05392055978596\n",
      "Iteration: 9660. Loss: 0.05861624702811241. Accuracy: 82.42436715373533\n",
      "Iteration: 9670. Loss: 0.08372247964143753. Accuracy: 82.50668861905741\n",
      "Epoch:  125\n",
      "Iteration: 9680. Loss: 0.0678882822394371. Accuracy: 82.34204568841325\n",
      "Iteration: 9690. Loss: 0.027360593900084496. Accuracy: 82.05392055978596\n",
      "Iteration: 9700. Loss: 0.03171461820602417. Accuracy: 81.6834739658366\n",
      "Iteration: 9710. Loss: 0.06575611978769302. Accuracy: 83.06235850998148\n",
      "Iteration: 9720. Loss: 0.08580741286277771. Accuracy: 82.15682239143857\n",
      "Iteration: 9730. Loss: 0.11330725252628326. Accuracy: 82.63017081704054\n",
      "Iteration: 9740. Loss: 0.02138635702431202. Accuracy: 82.23914385676065\n",
      "Iteration: 9750. Loss: 0.0104142464697361. Accuracy: 81.2924470055567\n",
      "Epoch:  126\n",
      "Iteration: 9760. Loss: 0.018282966688275337. Accuracy: 82.28030458942169\n",
      "Iteration: 9770. Loss: 0.012386741116642952. Accuracy: 82.42436715373533\n",
      "Iteration: 9780. Loss: 0.023860212415456772. Accuracy: 82.9800370446594\n",
      "Iteration: 9790. Loss: 0.0052743880078196526. Accuracy: 82.03334019345544\n",
      "Iteration: 9800. Loss: 0.06619064509868622. Accuracy: 82.17740275776909\n",
      "Iteration: 9810. Loss: 0.06698159128427505. Accuracy: 82.81539411401523\n",
      "Iteration: 9820. Loss: 0.02923966757953167. Accuracy: 82.30088495575221\n",
      "Epoch:  127\n",
      "Iteration: 9830. Loss: 0.019003886729478836. Accuracy: 82.91829594566784\n",
      "Iteration: 9840. Loss: 0.042863599956035614. Accuracy: 82.32146532208273\n",
      "Iteration: 9850. Loss: 0.03574573993682861. Accuracy: 82.67133154970159\n",
      "Iteration: 9860. Loss: 0.026261266320943832. Accuracy: 82.81539411401523\n",
      "Iteration: 9870. Loss: 0.11902306973934174. Accuracy: 83.26816217328668\n",
      "Iteration: 9880. Loss: 0.006164380349218845. Accuracy: 82.73307264869315\n",
      "Iteration: 9890. Loss: 0.027653228491544724. Accuracy: 82.46552788639637\n",
      "Iteration: 9900. Loss: 0.039641134440898895. Accuracy: 83.04177814365096\n",
      "Epoch:  128\n",
      "Iteration: 9910. Loss: 0.014449999667704105. Accuracy: 81.97159909446388\n",
      "Iteration: 9920. Loss: 0.00979730673134327. Accuracy: 82.21856349043013\n",
      "Iteration: 9930. Loss: 0.037649206817150116. Accuracy: 82.19798312409961\n",
      "Iteration: 9940. Loss: 0.01879040338099003. Accuracy: 83.00061741098992\n",
      "Iteration: 9950. Loss: 0.09274030476808548. Accuracy: 82.50668861905741\n",
      "Iteration: 9960. Loss: 0.08680890500545502. Accuracy: 82.42436715373533\n",
      "Iteration: 9970. Loss: 0.03349979966878891. Accuracy: 82.54784935171845\n",
      "Iteration: 9980. Loss: 0.01365840807557106. Accuracy: 82.01275982712492\n",
      "Epoch:  129\n",
      "Iteration: 9990. Loss: 0.03158341348171234. Accuracy: 82.63017081704054\n",
      "Iteration: 10000. Loss: 0.017650455236434937. Accuracy: 82.4861082527269\n",
      "Iteration: 10010. Loss: 0.050302352756261826. Accuracy: 82.71249228236263\n",
      "Iteration: 10020. Loss: 0.057957857847213745. Accuracy: 81.60115250051452\n",
      "Iteration: 10030. Loss: 0.023788196966052055. Accuracy: 82.30088495575221\n",
      "Iteration: 10040. Loss: 0.07918061316013336. Accuracy: 82.93887631199836\n",
      "Iteration: 10050. Loss: 0.0284349974244833. Accuracy: 82.63017081704054\n",
      "Iteration: 10060. Loss: 0.04345150664448738. Accuracy: 82.30088495575221\n",
      "Epoch:  130\n",
      "Iteration: 10070. Loss: 0.06898345053195953. Accuracy: 82.095081292447\n",
      "Iteration: 10080. Loss: 0.021997947245836258. Accuracy: 82.17740275776909\n",
      "Iteration: 10090. Loss: 0.031278274953365326. Accuracy: 83.06235850998148\n",
      "Iteration: 10100. Loss: 0.03736226633191109. Accuracy: 82.42436715373533\n",
      "Iteration: 10110. Loss: 0.033369604498147964. Accuracy: 81.6834739658366\n",
      "Iteration: 10120. Loss: 0.03924962878227234. Accuracy: 82.67133154970159\n",
      "Iteration: 10130. Loss: 0.053042612969875336. Accuracy: 81.2924470055567\n",
      "Iteration: 10140. Loss: 0.035115502774715424. Accuracy: 82.07450092611649\n",
      "Epoch:  131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10150. Loss: 0.023905033245682716. Accuracy: 82.21856349043013\n",
      "Iteration: 10160. Loss: 0.03005843423306942. Accuracy: 81.21012554023461\n",
      "Iteration: 10170. Loss: 0.034264396876096725. Accuracy: 81.86869726281128\n",
      "Iteration: 10180. Loss: 0.0213664211332798. Accuracy: 81.43650956987034\n",
      "Iteration: 10190. Loss: 0.026065275073051453. Accuracy: 81.95101872813336\n",
      "Iteration: 10200. Loss: 0.015868473798036575. Accuracy: 81.37476847087878\n",
      "Iteration: 10210. Loss: 0.0796908363699913. Accuracy: 81.6834739658366\n",
      "Epoch:  132\n",
      "Iteration: 10220. Loss: 0.0174263846129179. Accuracy: 81.51883103519242\n",
      "Iteration: 10230. Loss: 0.04044690728187561. Accuracy: 81.76579543115868\n",
      "Iteration: 10240. Loss: 0.026162223890423775. Accuracy: 82.05392055978596\n",
      "Iteration: 10250. Loss: 0.018025632947683334. Accuracy: 81.90985799547232\n",
      "Iteration: 10260. Loss: 0.07658334076404572. Accuracy: 82.42436715373533\n",
      "Iteration: 10270. Loss: 0.1144297644495964. Accuracy: 81.64231323317556\n",
      "Iteration: 10280. Loss: 0.05830210819840431. Accuracy: 81.82753653015024\n",
      "Iteration: 10290. Loss: 0.06880910694599152. Accuracy: 82.11566165877753\n",
      "Epoch:  133\n",
      "Iteration: 10300. Loss: 0.069717176258564. Accuracy: 81.27186663922618\n",
      "Iteration: 10310. Loss: 0.03701937571167946. Accuracy: 81.97159909446388\n",
      "Iteration: 10320. Loss: 0.07743404060602188. Accuracy: 82.23914385676065\n",
      "Iteration: 10330. Loss: 0.012318352237343788. Accuracy: 81.02490224325993\n",
      "Iteration: 10340. Loss: 0.06296629458665848. Accuracy: 82.25972422309117\n",
      "Iteration: 10350. Loss: 0.06693136692047119. Accuracy: 81.60115250051452\n",
      "Iteration: 10360. Loss: 0.054925501346588135. Accuracy: 81.14838444124305\n",
      "Iteration: 10370. Loss: 0.031104642897844315. Accuracy: 80.98374151059889\n",
      "Epoch:  134\n",
      "Iteration: 10380. Loss: 0.12895990908145905. Accuracy: 82.44494752006585\n",
      "Iteration: 10390. Loss: 0.02208762988448143. Accuracy: 81.51883103519242\n",
      "Iteration: 10400. Loss: 0.027602050453424454. Accuracy: 81.80695616381972\n",
      "Iteration: 10410. Loss: 0.01728871278464794. Accuracy: 82.46552788639637\n",
      "Iteration: 10420. Loss: 0.061717689037323. Accuracy: 82.4861082527269\n",
      "Iteration: 10430. Loss: 0.01635337434709072. Accuracy: 82.38320642107429\n",
      "Iteration: 10440. Loss: 0.0398542545735836. Accuracy: 82.4861082527269\n",
      "Iteration: 10450. Loss: 0.05692020058631897. Accuracy: 82.83597448034575\n",
      "Epoch:  135\n",
      "Iteration: 10460. Loss: 0.042445410043001175. Accuracy: 82.17740275776909\n",
      "Iteration: 10470. Loss: 0.015392502769827843. Accuracy: 82.4861082527269\n",
      "Iteration: 10480. Loss: 0.019502675160765648. Accuracy: 82.36262605474377\n",
      "Iteration: 10490. Loss: 0.025296650826931. Accuracy: 82.50668861905741\n",
      "Iteration: 10500. Loss: 0.02956663817167282. Accuracy: 81.90985799547232\n",
      "Iteration: 10510. Loss: 0.04959019646048546. Accuracy: 82.17740275776909\n",
      "Iteration: 10520. Loss: 0.02248919941484928. Accuracy: 82.73307264869315\n",
      "Iteration: 10530. Loss: 0.035242170095443726. Accuracy: 81.80695616381972\n",
      "Epoch:  136\n",
      "Iteration: 10540. Loss: 0.01710868999361992. Accuracy: 81.80695616381972\n",
      "Iteration: 10550. Loss: 0.01187477819621563. Accuracy: 81.27186663922618\n",
      "Iteration: 10560. Loss: 0.043671853840351105. Accuracy: 81.84811689648076\n",
      "Iteration: 10570. Loss: 0.0638488233089447. Accuracy: 81.9921794607944\n",
      "Iteration: 10580. Loss: 0.010838968679308891. Accuracy: 82.34204568841325\n",
      "Iteration: 10590. Loss: 0.04198600724339485. Accuracy: 82.36262605474377\n",
      "Iteration: 10600. Loss: 0.08620347827672958. Accuracy: 82.4861082527269\n",
      "Epoch:  137\n",
      "Iteration: 10610. Loss: 0.0849706158041954. Accuracy: 82.17740275776909\n",
      "Iteration: 10620. Loss: 0.004961851518601179. Accuracy: 82.38320642107429\n",
      "Iteration: 10630. Loss: 0.013714081607758999. Accuracy: 82.60959045071002\n",
      "Iteration: 10640. Loss: 0.03635304793715477. Accuracy: 81.80695616381972\n",
      "Iteration: 10650. Loss: 0.05118868872523308. Accuracy: 82.23914385676065\n",
      "Iteration: 10660. Loss: 0.01968027465045452. Accuracy: 82.79481374768471\n",
      "Iteration: 10670. Loss: 0.048639606684446335. Accuracy: 82.5890100843795\n",
      "Iteration: 10680. Loss: 0.031011905521154404. Accuracy: 82.03334019345544\n",
      "Epoch:  138\n",
      "Iteration: 10690. Loss: 0.05357745662331581. Accuracy: 81.72463469849764\n",
      "Iteration: 10700. Loss: 0.04594070464372635. Accuracy: 82.36262605474377\n",
      "Iteration: 10710. Loss: 0.04026931896805763. Accuracy: 83.06235850998148\n",
      "Iteration: 10720. Loss: 0.038371309638023376. Accuracy: 82.13624202510805\n",
      "Iteration: 10730. Loss: 0.01833992637693882. Accuracy: 82.38320642107429\n",
      "Iteration: 10740. Loss: 0.10147680342197418. Accuracy: 81.80695616381972\n",
      "Iteration: 10750. Loss: 0.04260599985718727. Accuracy: 82.38320642107429\n",
      "Iteration: 10760. Loss: 0.05551302805542946. Accuracy: 81.41592920353982\n",
      "Epoch:  139\n",
      "Iteration: 10770. Loss: 0.03742391616106033. Accuracy: 82.13624202510805\n",
      "Iteration: 10780. Loss: 0.04211544618010521. Accuracy: 82.19798312409961\n",
      "Iteration: 10790. Loss: 0.027500035241246223. Accuracy: 81.82753653015024\n",
      "Iteration: 10800. Loss: 0.017138762399554253. Accuracy: 81.97159909446388\n",
      "Iteration: 10810. Loss: 0.020980900153517723. Accuracy: 81.580572134184\n",
      "Iteration: 10820. Loss: 0.03529709577560425. Accuracy: 82.32146532208273\n",
      "Iteration: 10830. Loss: 0.08122681826353073. Accuracy: 81.70405433216712\n",
      "Iteration: 10840. Loss: 0.07557659596204758. Accuracy: 82.25972422309117\n",
      "Epoch:  140\n",
      "Iteration: 10850. Loss: 0.016642021015286446. Accuracy: 81.8892776291418\n",
      "Iteration: 10860. Loss: 0.03799121454358101. Accuracy: 81.6834739658366\n",
      "Iteration: 10870. Loss: 0.04131142050027847. Accuracy: 82.01275982712492\n",
      "Iteration: 10880. Loss: 0.06549002975225449. Accuracy: 82.07450092611649\n",
      "Iteration: 10890. Loss: 0.0850544348359108. Accuracy: 82.44494752006585\n",
      "Iteration: 10900. Loss: 0.026757465675473213. Accuracy: 82.73307264869315\n",
      "Iteration: 10910. Loss: 0.039713405072689056. Accuracy: 82.65075118337107\n",
      "Iteration: 10920. Loss: 0.02167930267751217. Accuracy: 82.095081292447\n",
      "Epoch:  141\n",
      "Iteration: 10930. Loss: 0.03523650020360947. Accuracy: 82.4861082527269\n",
      "Iteration: 10940. Loss: 0.039345428347587585. Accuracy: 81.7863757974892\n",
      "Iteration: 10950. Loss: 0.06944537162780762. Accuracy: 82.34204568841325\n",
      "Iteration: 10960. Loss: 0.02355257049202919. Accuracy: 82.81539411401523\n",
      "Iteration: 10970. Loss: 0.06325046718120575. Accuracy: 82.93887631199836\n",
      "Iteration: 10980. Loss: 0.011245856061577797. Accuracy: 83.51512656925293\n",
      "Iteration: 10990. Loss: 0.05196244642138481. Accuracy: 83.26816217328668\n",
      "Epoch:  142\n",
      "Iteration: 11000. Loss: 0.03383577615022659. Accuracy: 82.30088495575221\n",
      "Iteration: 11010. Loss: 0.04183466359972954. Accuracy: 82.38320642107429\n",
      "Iteration: 11020. Loss: 0.05823291093111038. Accuracy: 81.60115250051452\n",
      "Iteration: 11030. Loss: 0.02188715524971485. Accuracy: 82.23914385676065\n",
      "Iteration: 11040. Loss: 0.011309485882520676. Accuracy: 82.71249228236263\n",
      "Iteration: 11050. Loss: 0.05694296583533287. Accuracy: 82.5890100843795\n",
      "Iteration: 11060. Loss: 0.05972227454185486. Accuracy: 82.05392055978596\n",
      "Iteration: 11070. Loss: 0.027917472645640373. Accuracy: 82.5890100843795\n",
      "Epoch:  143\n",
      "Iteration: 11080. Loss: 0.008639377541840076. Accuracy: 82.79481374768471\n",
      "Iteration: 11090. Loss: 0.03748041018843651. Accuracy: 82.25972422309117\n",
      "Iteration: 11100. Loss: 0.016210585832595825. Accuracy: 82.23914385676065\n",
      "Iteration: 11110. Loss: 0.02972358465194702. Accuracy: 83.082938876312\n",
      "Iteration: 11120. Loss: 0.04323467239737511. Accuracy: 82.65075118337107\n",
      "Iteration: 11130. Loss: 0.01098998636007309. Accuracy: 83.02119777732044\n",
      "Iteration: 11140. Loss: 0.013913800939917564. Accuracy: 82.4861082527269\n",
      "Iteration: 11150. Loss: 0.021319875493645668. Accuracy: 82.67133154970159\n",
      "Epoch:  144\n",
      "Iteration: 11160. Loss: 0.016079485416412354. Accuracy: 81.72463469849764\n",
      "Iteration: 11170. Loss: 0.03361417353153229. Accuracy: 81.27186663922618\n",
      "Iteration: 11180. Loss: 0.050399769097566605. Accuracy: 83.10351924264252\n",
      "Iteration: 11190. Loss: 0.041688382625579834. Accuracy: 82.81539411401523\n",
      "Iteration: 11200. Loss: 0.03636014088988304. Accuracy: 81.84811689648076\n",
      "Iteration: 11210. Loss: 0.09334361553192139. Accuracy: 82.21856349043013\n",
      "Iteration: 11220. Loss: 0.01543912198394537. Accuracy: 81.64231323317556\n",
      "Iteration: 11230. Loss: 0.014672229997813702. Accuracy: 81.6834739658366\n",
      "Epoch:  145\n",
      "Iteration: 11240. Loss: 0.04978952556848526. Accuracy: 82.03334019345544\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 11250. Loss: 0.02031809464097023. Accuracy: 81.21012554023461\n",
      "Iteration: 11260. Loss: 0.029463455080986023. Accuracy: 82.52726898538793\n",
      "Iteration: 11270. Loss: 0.02098795399069786. Accuracy: 82.69191191603211\n",
      "Iteration: 11280. Loss: 0.058832790702581406. Accuracy: 82.21856349043013\n",
      "Iteration: 11290. Loss: 0.018030356615781784. Accuracy: 81.66289359950608\n",
      "Iteration: 11300. Loss: 0.03474225848913193. Accuracy: 82.32146532208273\n",
      "Iteration: 11310. Loss: 0.03875729814171791. Accuracy: 82.30088495575221\n",
      "Epoch:  146\n",
      "Iteration: 11320. Loss: 0.024989036843180656. Accuracy: 81.8892776291418\n",
      "Iteration: 11330. Loss: 0.051666855812072754. Accuracy: 81.97159909446388\n",
      "Iteration: 11340. Loss: 0.017991142347455025. Accuracy: 82.81539411401523\n",
      "Iteration: 11350. Loss: 0.0112101249396801. Accuracy: 82.40378678740481\n",
      "Iteration: 11360. Loss: 0.10402750968933105. Accuracy: 82.05392055978596\n",
      "Iteration: 11370. Loss: 0.024574901908636093. Accuracy: 82.93887631199836\n",
      "Iteration: 11380. Loss: 0.014976668171584606. Accuracy: 82.65075118337107\n",
      "Epoch:  147\n",
      "Iteration: 11390. Loss: 0.010050199925899506. Accuracy: 82.30088495575221\n",
      "Iteration: 11400. Loss: 0.015070242807269096. Accuracy: 82.5890100843795\n",
      "Iteration: 11410. Loss: 0.023141028359532356. Accuracy: 82.83597448034575\n",
      "Iteration: 11420. Loss: 0.014194498769938946. Accuracy: 82.21856349043013\n",
      "Iteration: 11430. Loss: 0.00847206637263298. Accuracy: 82.28030458942169\n",
      "Iteration: 11440. Loss: 0.012243036180734634. Accuracy: 82.75365301502367\n",
      "Iteration: 11450. Loss: 0.04245009645819664. Accuracy: 82.46552788639637\n",
      "Iteration: 11460. Loss: 0.034107621759176254. Accuracy: 82.52726898538793\n",
      "Epoch:  148\n",
      "Iteration: 11470. Loss: 0.006790967658162117. Accuracy: 81.25128627289565\n",
      "Iteration: 11480. Loss: 0.008493740111589432. Accuracy: 82.07450092611649\n",
      "Iteration: 11490. Loss: 0.05328287184238434. Accuracy: 82.32146532208273\n",
      "Iteration: 11500. Loss: 0.030341047793626785. Accuracy: 81.47767030253138\n",
      "Iteration: 11510. Loss: 0.0707176998257637. Accuracy: 82.25972422309117\n",
      "Iteration: 11520. Loss: 0.06409095227718353. Accuracy: 81.84811689648076\n",
      "Iteration: 11530. Loss: 0.02514583431184292. Accuracy: 82.50668861905741\n",
      "Iteration: 11540. Loss: 0.01828247867524624. Accuracy: 82.60959045071002\n",
      "Epoch:  149\n",
      "Iteration: 11550. Loss: 0.06592708081007004. Accuracy: 81.62173286684504\n",
      "Iteration: 11560. Loss: 0.054715365171432495. Accuracy: 81.33360773821774\n",
      "Iteration: 11570. Loss: 0.010531886480748653. Accuracy: 81.62173286684504\n",
      "Iteration: 11580. Loss: 0.1028190329670906. Accuracy: 81.66289359950608\n",
      "Iteration: 11590. Loss: 0.0174569059163332. Accuracy: 81.74521506482816\n",
      "Iteration: 11600. Loss: 0.06176286190748215. Accuracy: 81.80695616381972\n",
      "Iteration: 11610. Loss: 0.028755752369761467. Accuracy: 82.25972422309117\n",
      "Iteration: 11620. Loss: 0.08300070464611053. Accuracy: 81.37476847087878\n",
      "Epoch:  150\n",
      "Iteration: 11630. Loss: 0.01574731059372425. Accuracy: 82.50668861905741\n",
      "Iteration: 11640. Loss: 0.08733358979225159. Accuracy: 82.75365301502367\n",
      "Iteration: 11650. Loss: 0.0657481849193573. Accuracy: 82.44494752006585\n",
      "Iteration: 11660. Loss: 0.015405572019517422. Accuracy: 82.01275982712492\n",
      "Iteration: 11670. Loss: 0.026698056608438492. Accuracy: 82.60959045071002\n",
      "Iteration: 11680. Loss: 0.01925606280565262. Accuracy: 81.95101872813336\n",
      "Iteration: 11690. Loss: 0.06958302110433578. Accuracy: 82.28030458942169\n",
      "Iteration: 11700. Loss: 0.05508188158273697. Accuracy: 81.90985799547232\n",
      "Epoch:  151\n",
      "Iteration: 11710. Loss: 0.041663024574518204. Accuracy: 81.7863757974892\n",
      "Iteration: 11720. Loss: 0.13414332270622253. Accuracy: 80.94258077793785\n",
      "Iteration: 11730. Loss: 0.06627900153398514. Accuracy: 82.13624202510805\n",
      "Iteration: 11740. Loss: 0.040096379816532135. Accuracy: 81.08664334225149\n",
      "Iteration: 11750. Loss: 0.011854846030473709. Accuracy: 81.23070590656513\n",
      "Iteration: 11760. Loss: 0.04093519225716591. Accuracy: 81.25128627289565\n",
      "Iteration: 11770. Loss: 0.02921760454773903. Accuracy: 82.44494752006585\n",
      "Epoch:  152\n",
      "Iteration: 11780. Loss: 0.009102154523134232. Accuracy: 82.19798312409961\n",
      "Iteration: 11790. Loss: 0.045000966638326645. Accuracy: 82.36262605474377\n",
      "Iteration: 11800. Loss: 0.022860689088702202. Accuracy: 82.67133154970159\n",
      "Iteration: 11810. Loss: 0.0443236269056797. Accuracy: 82.095081292447\n",
      "Iteration: 11820. Loss: 0.030763356015086174. Accuracy: 82.23914385676065\n",
      "Iteration: 11830. Loss: 0.044930100440979004. Accuracy: 81.82753653015024\n",
      "Iteration: 11840. Loss: 0.011414174921810627. Accuracy: 81.9921794607944\n",
      "Iteration: 11850. Loss: 0.03374820947647095. Accuracy: 82.23914385676065\n",
      "Epoch:  153\n",
      "Iteration: 11860. Loss: 0.01754869520664215. Accuracy: 82.38320642107429\n",
      "Iteration: 11870. Loss: 0.03220541030168533. Accuracy: 82.40378678740481\n",
      "Iteration: 11880. Loss: 0.021395158022642136. Accuracy: 82.63017081704054\n",
      "Iteration: 11890. Loss: 0.03292635455727577. Accuracy: 82.19798312409961\n",
      "Iteration: 11900. Loss: 0.03468356281518936. Accuracy: 82.17740275776909\n",
      "Iteration: 11910. Loss: 0.02660541422665119. Accuracy: 82.01275982712492\n",
      "Iteration: 11920. Loss: 0.010282021015882492. Accuracy: 82.03334019345544\n",
      "Iteration: 11930. Loss: 0.06459648907184601. Accuracy: 82.89771557933732\n",
      "Epoch:  154\n",
      "Iteration: 11940. Loss: 0.04413645714521408. Accuracy: 81.74521506482816\n",
      "Iteration: 11950. Loss: 0.009462092071771622. Accuracy: 82.25972422309117\n",
      "Iteration: 11960. Loss: 0.01896001026034355. Accuracy: 82.01275982712492\n",
      "Iteration: 11970. Loss: 0.028679830953478813. Accuracy: 82.07450092611649\n",
      "Iteration: 11980. Loss: 0.02441478706896305. Accuracy: 81.76579543115868\n",
      "Iteration: 11990. Loss: 0.05338073521852493. Accuracy: 82.36262605474377\n",
      "Iteration: 12000. Loss: 0.015407267026603222. Accuracy: 82.21856349043013\n",
      "Iteration: 12010. Loss: 0.040481917560100555. Accuracy: 82.11566165877753\n"
     ]
    }
   ],
   "source": [
    "iteration_loss = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch: ', epoch + 1)\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "\n",
    "        images = images.view(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images) \n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 10 == 0:        \n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in test_loader:\n",
    "               \n",
    "                images = images.view(-1, 28*28).to(device)\n",
    "\n",
    "                outputs = model(images)\n",
    "\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum() \n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct.item() / total\n",
    "\n",
    "            iteration_loss.append(loss.item())\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'elu_7_soft_at_2_acc_82.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepNeuralNetworkModel(input_size = input_dim, num_classes = output_dim, num_hidden = num_hidden)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('elu_7_soft_at_2_acc_82.pkl'))\n",
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
